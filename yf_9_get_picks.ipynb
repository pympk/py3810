{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose : True\n",
      "store_results: False\n",
      "n_samples: 1\n",
      "days_lookbacks: [30, 60, 120]\n",
      "days_eval: 0\n",
      "n_top_syms: 20\n",
      "syms_start: 0\n",
      "syms_end: 10\n",
      "fp_df_picks: df_picks\n",
      "max_days_lookbacks: 120\n",
      "run_type: current\n",
      "dropped last 0 row(s) from df\n",
      "df.tail():\n",
      "                     A         AA    AAL         AAP        AAPL         AB        ABB        ABBV         ABC        ABM    ABR        ABT       ACGL       ACHC       ACIW  ...       XRAY    XRX        XYL       YELP       YUMC         YY         ZBH        ZBRA         ZD         ZG       ZION        ZTO         ZTS       ZUMZ        ZWS\n",
      "Date                                                                                                                                                                          ...                                                                                                                                                                    \n",
      "2023-03-20  134.539993  40.279999  13.96  118.680000  157.399994  35.130001  32.560001  156.119995  153.860001  44.119999  11.82  97.870003  65.610001  70.449997  26.150000  ...  36.990002  14.85  97.650002  29.690001  60.950001  29.150000  126.330002  290.839996  74.650002  39.830002  30.180000  28.020000  165.820007  18.110001  20.830000\n",
      "2023-03-21  137.009995  41.910000  14.37  119.790001  159.279999  35.459999  33.270000  156.770004  156.039993  44.220001  11.91  98.330002  67.209999  70.959999  26.200001  ...  37.709999  15.30  98.519997  30.059999  61.169998  28.590000  127.790001  294.429993  75.570000  41.939999  32.290001  28.230000  166.240005  18.549999  21.180000\n",
      "2023-03-22  133.729996  40.060001  13.82  113.599998  157.830002  33.930000  33.119999  153.669998  153.440002  43.020000  11.14  96.860001  65.870003  69.800003  25.570000  ...  36.380001  14.85  97.570000  29.860001  62.520000  29.540001  125.389999  288.109985  73.790001  41.270000  30.120001  28.270000  161.380005  17.920000  20.270000\n",
      "2023-03-23  131.130005  40.230000  13.63  111.139999  158.929993  33.669998  33.380001  155.300003  150.929993  42.430000  10.84  97.040001  65.599998  69.440002  24.959999  ...  36.759998  14.56  97.230003  29.940001  63.830002  30.129999  124.959999  288.750000  74.410004  42.470001  27.450001  28.540001  161.240005  17.490000  19.790001\n",
      "2023-03-24  131.960007  40.080002  13.72  110.830002  160.250000  33.490002  32.750000  158.020004  156.410004  43.430000  11.11  98.050003  66.050003  70.160004  25.270000  ...  37.250000  14.63  98.589996  30.040001  61.680000  29.959999  126.040001  288.730011  75.209999  42.560001  28.250000  28.510000  164.179993  17.620001  19.850000\n",
      "\n",
      "[5 rows x 1322 columns]\n",
      "\n",
      "df.tail(3):\n",
      "                     A         AA    AAL         AAP        AAPL         AB        ABB        ABBV         ABC    ABM    ABR        ABT       ACGL       ACHC       ACIW  ...       XRAY    XRX        XYL       YELP       YUMC         YY         ZBH        ZBRA         ZD         ZG       ZION        ZTO         ZTS       ZUMZ        ZWS\n",
      "Date                                                                                                                                                                      ...                                                                                                                                                                    \n",
      "2023-03-22  133.729996  40.060001  13.82  113.599998  157.830002  33.930000  33.119999  153.669998  153.440002  43.02  11.14  96.860001  65.870003  69.800003  25.570000  ...  36.380001  14.85  97.570000  29.860001  62.520000  29.540001  125.389999  288.109985  73.790001  41.270000  30.120001  28.270000  161.380005  17.920000  20.270000\n",
      "2023-03-23  131.130005  40.230000  13.63  111.139999  158.929993  33.669998  33.380001  155.300003  150.929993  42.43  10.84  97.040001  65.599998  69.440002  24.959999  ...  36.759998  14.56  97.230003  29.940001  63.830002  30.129999  124.959999  288.750000  74.410004  42.470001  27.450001  28.540001  161.240005  17.490000  19.790001\n",
      "2023-03-24  131.960007  40.080002  13.72  110.830002  160.250000  33.490002  32.750000  158.020004  156.410004  43.43  11.11  98.050003  66.050003  70.160004  25.270000  ...  37.250000  14.63  98.589996  30.040001  61.680000  29.959999  126.040001  288.730011  75.209999  42.560001  28.250000  28.510000  164.179993  17.620001  19.850000\n",
      "\n",
      "[3 rows x 1322 columns]\n",
      "\n",
      "len(df): 120\n",
      "number of max_lookback_slices is equal to n_samples = 1\n",
      "max_lookback_slices:\n",
      "[(0, 120, 120)]\n",
      "\n",
      "days_lookbacks: [30, 60, 120]\n",
      "sets_lookback_slices:\n",
      "[[(90, 120, 120), (60, 120, 120), (0, 120, 120)]]\n",
      "\n",
      "number of sets in sets_lookback_slices is equal to n_samples = 1\n",
      "number of tuples in each \"set of lookback slices\" is equal to len(days_lookbacks): 3\n",
      "\n",
      "########## 1 of 1 lb_slices in sets_lookcak_slices ##########\n",
      "days lookback:       30,  1 of 3 days_lookbacks: [30, 60, 120]\n",
      "lb_slices:           [(90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "lb_slice:            (90, 120, 120)\n",
      "days eval:           0\n",
      "iloc_start_train:    90\n",
      "iloc_end_train:      120\n",
      "date_start_df_train: 2023-02-10\n",
      "date_end_df_train:   2023-03-24\n",
      "perf_ranks: {'period-30': {'r_CAGR/UI': array(['TA', 'SGEN', 'LNTH', 'GBTC', 'HY', 'SHV', 'PDFS', 'ANET', 'NTRA',\n",
      "       'FCN', 'WST', 'FSLR', 'FTSM', 'NVDA', 'MYGN', 'RELX', 'FIZZ',\n",
      "       'PERI', 'AMPH', 'MLR'], dtype=object), 'r_CAGR/retnStd': array(['TA', 'SGEN', 'GBTC', 'HY', 'LNTH', 'ANET', 'PDFS', 'NTRA', 'FSLR',\n",
      "       'PERI', 'MYGN', 'NVDA', 'WST', 'SHV', 'FCN', 'OR', 'BTC-USD',\n",
      "       'FIZZ', 'AMD', 'WING'], dtype=object), 'r_retnStd/UI': array(['TA', 'SHV', 'SGEN', 'LNTH', 'FCN', 'FTSM', 'PDFS', 'WST', 'AMPH',\n",
      "       'RELX', 'NTRA', 'ATCO', 'GE', 'CHT', 'HY', 'GBTC', 'FIZZ', 'LAUR',\n",
      "       'FSLR', 'NVDA'], dtype=object)}}\n",
      "most_freq_syms: [('TA', 3), ('SGEN', 3), ('LNTH', 3), ('GBTC', 3), ('HY', 3), ('SHV', 3), ('PDFS', 3), ('NTRA', 3), ('FCN', 3), ('WST', 3), ('FSLR', 3), ('NVDA', 3), ('FIZZ', 3), ('ANET', 2), ('FTSM', 2), ('MYGN', 2), ('RELX', 2), ('PERI', 2), ('AMPH', 2), ('MLR', 1), ('OR', 1), ('BTC-USD', 1), ('AMD', 1), ('WING', 1), ('ATCO', 1), ('GE', 1), ('CHT', 1), ('LAUR', 1)]\n",
      "+++ finish lookback slice 30 +++\n",
      "\n",
      "days lookback:       60,  2 of 3 days_lookbacks: [30, 60, 120]\n",
      "lb_slices:           [(90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "lb_slice:            (60, 120, 120)\n",
      "days eval:           0\n",
      "iloc_start_train:    60\n",
      "iloc_end_train:      120\n",
      "date_start_df_train: 2022-12-28\n",
      "date_end_df_train:   2023-03-24\n",
      "perf_ranks: {'period-60': {'r_CAGR/UI': array(['TA', 'NVDA', 'SHV', 'LNTH', 'ACLS', 'PDFS', 'SGEN', 'GBTC',\n",
      "       'FTSM', 'MARA', 'HY', 'GE', 'META', 'PERI', 'DCP', 'WST', 'CRUS',\n",
      "       'BTC-USD', 'OLED', 'CRM'], dtype=object), 'r_CAGR/retnStd': array(['MARA', 'NVDA', 'GBTC', 'HY', 'ACLS', 'META', 'LNTH', 'PERI',\n",
      "       'CRUS', 'PDFS', 'TA', 'MYGN', 'GE', 'CNK', 'BTC-USD', 'TSLA',\n",
      "       'SGEN', 'CRM', 'AMD', 'WBD'], dtype=object), 'r_retnStd/UI': array(['TA', 'DCP', 'SHV', 'FTSM', 'SGEN', 'PDFS', 'LNTH', 'AMPH', 'NVDA',\n",
      "       'FCN', 'GE', 'WST', 'ACLS', 'RVNC', 'OLED', 'RELX', 'NTRA', 'CPRT',\n",
      "       'MTSI', 'GDEN'], dtype=object)}}\n",
      "most_freq_syms: [('TA', 3), ('NVDA', 3), ('LNTH', 3), ('ACLS', 3), ('PDFS', 3), ('SGEN', 3), ('GE', 3), ('SHV', 2), ('GBTC', 2), ('FTSM', 2), ('MARA', 2), ('HY', 2), ('META', 2), ('PERI', 2), ('DCP', 2), ('WST', 2), ('CRUS', 2), ('BTC-USD', 2), ('OLED', 2), ('CRM', 2), ('MYGN', 1), ('CNK', 1), ('TSLA', 1), ('AMD', 1), ('WBD', 1), ('AMPH', 1), ('FCN', 1), ('RVNC', 1), ('RELX', 1), ('NTRA', 1), ('CPRT', 1), ('MTSI', 1), ('GDEN', 1)]\n",
      "+++ finish lookback slice 60 +++\n",
      "\n",
      "days lookback:       120,  3 of 3 days_lookbacks: [30, 60, 120]\n",
      "lb_slices:           [(90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "lb_slice:            (0, 120, 120)\n",
      "days eval:           0\n",
      "iloc_start_train:    0\n",
      "iloc_end_train:      120\n",
      "date_start_df_train: 2022-10-03\n",
      "date_end_df_train:   2023-03-24\n",
      "perf_ranks: {'period-120': {'r_CAGR/UI': array(['SHV', 'FTSM', 'ELF', 'AJRD', 'NVO', 'GE', 'COTY', 'PERI', 'MLR',\n",
      "       'HZNP', 'NVDA', 'OEC', 'RMBS', 'HY', 'AXON', 'PKX', 'MCFT', 'ACLS',\n",
      "       'EXAS', 'STRL'], dtype=object), 'r_CAGR/retnStd': array(['SHV', 'GE', 'FTSM', 'ELF', 'ACLS', 'PERI', 'NVDA', 'AXON', 'HY',\n",
      "       'OEC', 'COTY', 'NVO', 'PKX', 'RMBS', 'MLR', 'STRL', 'AJRD', 'THR',\n",
      "       'LSCC', 'EXAS'], dtype=object), 'r_retnStd/UI': array(['SHV', 'FTSM', 'AJRD', 'ATCO', 'NVO', 'HZNP', 'ELF', 'TMHC',\n",
      "       'COTY', 'LW', 'MCFT', 'MLR', 'OI', 'CCEP', 'ACGL', 'PGR', 'GVA',\n",
      "       'FDX', 'FIVE', 'EXAS'], dtype=object)}}\n",
      "most_freq_syms: [('SHV', 3), ('FTSM', 3), ('ELF', 3), ('AJRD', 3), ('NVO', 3), ('COTY', 3), ('MLR', 3), ('EXAS', 3), ('GE', 2), ('PERI', 2), ('HZNP', 2), ('NVDA', 2), ('OEC', 2), ('RMBS', 2), ('HY', 2), ('AXON', 2), ('PKX', 2), ('MCFT', 2), ('ACLS', 2), ('STRL', 2), ('THR', 1), ('LSCC', 1), ('ATCO', 1), ('TMHC', 1), ('LW', 1), ('OI', 1), ('CCEP', 1), ('ACGL', 1), ('PGR', 1), ('GVA', 1), ('FDX', 1), ('FIVE', 1)]\n",
      "+++ finish lookback slice 120 +++\n",
      "\n",
      "grp_most_freq_syms: [[('TA', 3), ('SGEN', 3), ('LNTH', 3), ('GBTC', 3), ('HY', 3), ('SHV', 3), ('PDFS', 3), ('NTRA', 3), ('FCN', 3), ('WST', 3), ('FSLR', 3), ('NVDA', 3), ('FIZZ', 3), ('ANET', 2), ('FTSM', 2), ('MYGN', 2), ('RELX', 2), ('PERI', 2), ('AMPH', 2), ('MLR', 1), ('OR', 1), ('BTC-USD', 1), ('AMD', 1), ('WING', 1), ('ATCO', 1), ('GE', 1), ('CHT', 1), ('LAUR', 1)], [('TA', 3), ('NVDA', 3), ('LNTH', 3), ('ACLS', 3), ('PDFS', 3), ('SGEN', 3), ('GE', 3), ('SHV', 2), ('GBTC', 2), ('FTSM', 2), ('MARA', 2), ('HY', 2), ('META', 2), ('PERI', 2), ('DCP', 2), ('WST', 2), ('CRUS', 2), ('BTC-USD', 2), ('OLED', 2), ('CRM', 2), ('MYGN', 1), ('CNK', 1), ('TSLA', 1), ('AMD', 1), ('WBD', 1), ('AMPH', 1), ('FCN', 1), ('RVNC', 1), ('RELX', 1), ('NTRA', 1), ('CPRT', 1), ('MTSI', 1), ('GDEN', 1)], [('SHV', 3), ('FTSM', 3), ('ELF', 3), ('AJRD', 3), ('NVO', 3), ('COTY', 3), ('MLR', 3), ('EXAS', 3), ('GE', 2), ('PERI', 2), ('HZNP', 2), ('NVDA', 2), ('OEC', 2), ('RMBS', 2), ('HY', 2), ('AXON', 2), ('PKX', 2), ('MCFT', 2), ('ACLS', 2), ('STRL', 2), ('THR', 1), ('LSCC', 1), ('ATCO', 1), ('TMHC', 1), ('LW', 1), ('OI', 1), ('CCEP', 1), ('ACGL', 1), ('PGR', 1), ('GVA', 1), ('FDX', 1), ('FIVE', 1)]]\n",
      "**** finish lookback slices [(90, 120, 120), (60, 120, 120), (0, 120, 120)] ****\n",
      "\n",
      "top 20 ranked symbols and frequency from set [(90, 120, 120), (60, 120, 120), (0, 120, 120)]:\n",
      "[('NVDA', 8), ('SHV', 8), ('FTSM', 7), ('HY', 7), ('GE', 6), ('LNTH', 6), ('PDFS', 6), ('PERI', 6), ('SGEN', 6), ('TA', 6), ('ACLS', 5), ('GBTC', 5), ('WST', 5), ('FCN', 4), ('MLR', 4), ('NTRA', 4), ('AJRD', 3), ('AMPH', 3), ('BTC-USD', 3), ('COTY', 3)]\n",
      "top 20 ranked symbols from set [(90, 120, 120), (60, 120, 120), (0, 120, 120)]:\n",
      "['NVDA', 'SHV', 'FTSM', 'HY', 'GE', 'LNTH', 'PDFS', 'PERI', 'SGEN', 'TA']\n",
      "===== finish top 20 ranked symbols from days_lookback set [(90, 120, 120), (60, 120, 120), (0, 120, 120)] =====\n",
      "\n",
      "\n",
      "set_lookback_slices: [(90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "max_lookback_slices: [(0, 120, 120)]\n",
      "\n",
      "data below will be added to df_picks\n",
      "date_end_df_train:   2023-03-24\n",
      "max_days_lookbacks:  120\n",
      "days_lookbacks:      [30, 60, 120]\n",
      "sym_freq_15:         []\n",
      "sym_freq_14:         []\n",
      "sym_freq_13:         []\n",
      "sym_freq_12:         []\n",
      "sym_freq_11:         []\n",
      "sym_freq_10:         []\n",
      "sym_freq_9:          []\n",
      "sym_freq_8:          ['NVDA', 'SHV']\n",
      "sym_freq_7:          ['FTSM', 'HY']\n",
      "sym_freq_6:          ['GE', 'LNTH', 'PDFS', 'PERI', 'SGEN', 'TA']\n",
      "sym_freq_5:          ['ACLS', 'GBTC', 'WST']\n",
      "sym_freq_4:          ['FCN', 'MLR', 'NTRA']\n",
      "sym_freq_3:          ['AJRD', 'AMPH', 'BTC-USD', 'COTY']\n",
      "sym_freq_2:          []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def best_perf_syms_sets_lookback_slices(sets_lookback_slices, verbose=False):\n",
    "\n",
    "  # grp_top_set_syms_n_freq is a list of lists of top_set_syms_n_freq, e.g.\n",
    "  #   [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)],\n",
    "  #    [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "  #   where each list is the best performing symbols from a lb_slices, e.g.\n",
    "  #     [(483, 513, 523), (453, 513, 523), (393, 513, 523)]  \n",
    "  grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "  grp_top_set_syms = []  # grp_top_set_syms_n_freq without the frequency count\n",
    "\n",
    "  # lb_slices, e.g  [(483, 513, 523), (453, 513, 523), (393, 513, 523)],\n",
    "  #  is one max_lookback_slice, e.g. (393, 513, 523), along with\n",
    "  #  the remaining slices of the days_lookbacks, e.g. (483, 513, 523), (453, 513, 523)  \n",
    "  for i, lb_slices in enumerate(sets_lookback_slices):\n",
    "    print(f'\\n########## {i + 1} of {len(sets_lookback_slices)} lb_slices in sets_lookcak_slices ##########')\n",
    "    # unsorted list of the most frequent symbols in performance metrics of the lb_slices  \n",
    "    grp_most_freq_syms = []\n",
    "    for j, lb_slice in enumerate(lb_slices):  # lb_slice, e.g. (246, 276, 286)\n",
    "      iloc_start_train = lb_slice[0]     # iloc of start of training period\n",
    "      iloc_end_train   = lb_slice[1]     # iloc of end of training period\n",
    "      iloc_start_eval  = iloc_end_train  # iloc of start of evaluation period\n",
    "      iloc_end_eval    = lb_slice[2]     # iloc of end of evaluation period\n",
    "      lookback         = iloc_end_train - iloc_start_train\n",
    "      d_eval           = iloc_end_eval - iloc_start_eval\n",
    "\n",
    "      _df = df.iloc[iloc_start_train:iloc_end_train]\n",
    "      date_start_df_train = _df.index[0].strftime('%Y-%m-%d')\n",
    "      date_end_df_train = _df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "      if verbose:\n",
    "        print(f'days lookback:       {lookback},  {j + 1} of {len(days_lookbacks)} days_lookbacks: {days_lookbacks}')\n",
    "        print(f'lb_slices:           {lb_slices}')\n",
    "        print(f'lb_slice:            {lb_slice}')\n",
    "        print(f'days eval:           {d_eval}')    \n",
    "        print(f'iloc_start_train:    {iloc_start_train}')\n",
    "        print(f'iloc_end_train:      {iloc_end_train}')\n",
    "        print(f'date_start_df_train: {date_start_df_train}')\n",
    "        print(f'date_end_df_train:   {date_end_df_train}')\n",
    "\n",
    "\n",
    "      perf_ranks, most_freq_syms = _5_perf_ranks(_df, n_top_syms=n_top_syms)\n",
    "      # unsorted list of the most frequent symbols in performance metrics of the lb_slices  \n",
    "      grp_most_freq_syms.append(most_freq_syms)  \n",
    "      if verbose:    \n",
    "        # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "        print(f'perf_ranks: {perf_ranks}')  \n",
    "        # most common symbols of perf_ranks \n",
    "        print(f'most_freq_syms: {most_freq_syms}')     \n",
    "        # grp_perf_ranks[lookback] = perf_ranks\n",
    "        print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "    if verbose:\n",
    "      print(f'grp_most_freq_syms: {grp_most_freq_syms}')\n",
    "      # grp_most_freq_syms a is list of lists of tuples of \n",
    "      #  the most-common-symbols symbol:frequency cumulated from\n",
    "      #  each days_lookback  \n",
    "      print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "    # flatten list of lists of (symbol:frequency)\n",
    "    flat_grp_most_freq_syms = [val for sublist in grp_most_freq_syms for val in sublist]\n",
    "    # return \"symbol, frequency\" pairs of the most frequent symbols, i.e. best performing symbols,\n",
    "    #  in flat_grp_most_freq_syms. The paris are sorted in descending frequency.   \n",
    "    set_most_freq_syms = _6_grp_tuples_sort_sum(flat_grp_most_freq_syms, reverse=True)\n",
    "    # get the top n_top_syms of the most frequent \"symbol, frequency\" pairs\n",
    "    top_set_syms_n_freq = set_most_freq_syms[0:n_top_syms]\n",
    "    # get symbols from top_set_syms_n_freq, i[0] = symbol, i[1]=symbol's frequency count\n",
    "    top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]  \n",
    "\n",
    "    # grp_top_set_syms_n_freq is a list of lists of top_set_syms_n_freq, e.g.\n",
    "    #   [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)],\n",
    "    #    [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "    #   where each list is the best performing symbols from a lb_slices, e.g.\n",
    "    #     [(483, 513, 523), (453, 513, 523), (393, 513, 523)]    \n",
    "    grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "    grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "    if verbose:  \n",
    "      print(f'top {n_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "      print(f'top {n_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "      print(f'===== finish top {n_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')\n",
    "\n",
    "  return   grp_top_set_syms_n_freq, grp_top_set_syms, date_end_df_train     \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import datetime\n",
    "# from IPython.display import display, HTML\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum, top_set_sym_freq_cnt\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 16)\n",
    "pd.set_option('display.width', 790)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "fp_df_close_clean = 'df_close_clean'\n",
    "\n",
    "# verbose = False  # True prints more output\n",
    "verbose = True  # True prints more output\n",
    "\n",
    "# store_results = True\n",
    "store_results = False\n",
    "\n",
    "n_samples = 20\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback iloc_end_train\n",
    "days_lookbacks = [30, 60, 120]\n",
    "# days_lookbacks = [15, 30, 60, 120]\n",
    "days_lookbacks.sort()\n",
    "\n",
    "# number of days from iloc_end_train are used to evaluate effectiveness of the training\n",
    "days_eval = 4\n",
    "# days_eval = 5\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "\n",
    "# slice starts and ends for selecting the best performing symbols\n",
    "syms_start = 0\n",
    "syms_end = 10\n",
    "\n",
    "# get picks of previous days by dropping the last n rows from df_current\n",
    "#  drop_last_n_rows = 1 drops the last row from df_current\n",
    "drop_last_n_rows = 0\n",
    "\n",
    "# over-ride parameters for run_type 'current'\n",
    "# if run_type == 'current':\n",
    "days_eval = 0  # no need to eval, df_eval will be empty\n",
    "n_samples = 1  # no need to repeat sample the current result, repeat sample will yield the same tuple\n",
    "\n",
    "\n",
    "# fp_df_eval_results = f'df_eval_results_{run_type}'\n",
    "fp_df_picks = f'df_picks'\n",
    "\n",
    "print(f'verbose : {verbose }')\n",
    "print(f'store_results: {store_results}')\n",
    "print(f'n_samples: {n_samples}')\n",
    "print(f'days_lookbacks: {days_lookbacks}')\n",
    "print(f'days_eval: {days_eval}')\n",
    "print(f'n_top_syms: {n_top_syms}')\n",
    "print(f'syms_start: {syms_start}')\n",
    "print(f'syms_end: {syms_end}')\n",
    "print(f'fp_df_picks: {fp_df_picks}')\n",
    "\n",
    "df_picks = pickle_load(path_data_dump, fp_df_picks)\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)\n",
    "\n",
    "max_days_lookbacks = max(days_lookbacks)\n",
    "print(f'max_days_lookbacks: {max_days_lookbacks}')\n",
    "\n",
    "df_current = df_close_clean.copy()\n",
    "\n",
    "print(f'run_type: current')\n",
    "slice_start = -(max_days_lookbacks + drop_last_n_rows)  \n",
    "slice_end = -drop_last_n_rows\n",
    "if drop_last_n_rows == 0:  # return df with all rows\n",
    "  df = df_current[slice_start:].copy()\n",
    "else:  # return df with dropped drop_last_n_rows rows  \n",
    "  df = df_current[slice_start:slice_end].copy()            \n",
    "print(f'dropped last {drop_last_n_rows} row(s) from df')          \n",
    "print(f'df.tail():\\n{df.tail()}\\n')\n",
    "print(f'df.tail(3):\\n{df.tail(3)}\\n')\n",
    "len_df = len(df)\n",
    "len_df_current = len(df_current)\n",
    "print(f'len(df): {len(df)}')\n",
    "\n",
    "\n",
    "# return n_samples slices\n",
    "max_lookback_slices = _3_random_slices(len_df, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval, verbose=False)\n",
    "# return n_samples * len(days_lookbacks) slices\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'number of max_lookback_slices is equal to n_samples = {n_samples}')\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}\\n')\n",
    "  print(f'days_lookbacks: {days_lookbacks}')  \n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}\\n')\n",
    "  print(f'number of sets in sets_lookback_slices is equal to n_samples = {n_samples}')\n",
    "  print(f'number of tuples in each \"set of lookback slices\" is equal to len(days_lookbacks): {len(days_lookbacks)}')    \n",
    "\n",
    "grp_top_set_syms_n_freq, grp_top_set_syms, date_end_df_train = best_perf_syms_sets_lookback_slices(sets_lookback_slices, verbose=verbose)\n",
    "\n",
    "for i, top_set_syms_n_freq in enumerate(grp_top_set_syms_n_freq):\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(top_set_syms_n_freq)\n",
    "  if verbose:\n",
    "    print(f'set_lookback_slices: {sets_lookback_slices[i]}')\n",
    "    print(f'max_lookback_slices: {max_lookback_slices}\\n')\n",
    "    print(f'data below will be added to {fp_df_picks}')\n",
    "    print(f'date_end_df_train:   {date_end_df_train}')    \n",
    "    print(f'max_days_lookbacks:  {max_days_lookbacks}')   \n",
    "    print(f'days_lookbacks:      {days_lookbacks}')\n",
    "    print(f'sym_freq_15:         {l_sym_freq_cnt[0]}')\n",
    "    print(f'sym_freq_14:         {l_sym_freq_cnt[1]}')\n",
    "    print(f'sym_freq_13:         {l_sym_freq_cnt[2]}')\n",
    "    print(f'sym_freq_12:         {l_sym_freq_cnt[3]}')\n",
    "    print(f'sym_freq_11:         {l_sym_freq_cnt[4]}')\n",
    "    print(f'sym_freq_10:         {l_sym_freq_cnt[5]}')\n",
    "    print(f'sym_freq_9:          {l_sym_freq_cnt[6]}')\n",
    "    print(f'sym_freq_8:          {l_sym_freq_cnt[7]}')\n",
    "    print(f'sym_freq_7:          {l_sym_freq_cnt[8]}')\n",
    "    print(f'sym_freq_6:          {l_sym_freq_cnt[9]}')\n",
    "    print(f'sym_freq_5:          {l_sym_freq_cnt[10]}')\n",
    "    print(f'sym_freq_4:          {l_sym_freq_cnt[11]}')\n",
    "    print(f'sym_freq_3:          {l_sym_freq_cnt[12]}')\n",
    "    print(f'sym_freq_2:          {l_sym_freq_cnt[13]}\\n')\n",
    "\n",
    "if store_results:\n",
    "  row_picks0      = [date_end_df_train, max_days_lookbacks, str(days_lookbacks)]\n",
    "  row_picks1      = [str(l_sym_freq_cnt[0]),  str(l_sym_freq_cnt[1]), str(l_sym_freq_cnt[2]),  str(l_sym_freq_cnt[3])]\n",
    "  row_picks2      = [str(l_sym_freq_cnt[4]),  str(l_sym_freq_cnt[5]), str(l_sym_freq_cnt[6]),  str(l_sym_freq_cnt[7])]\n",
    "  row_picks3      = [str(l_sym_freq_cnt[8]),  str(l_sym_freq_cnt[9]), str(l_sym_freq_cnt[10]), str(l_sym_freq_cnt[11])]\n",
    "  row_picks4      = [str(l_sym_freq_cnt[12]), str(l_sym_freq_cnt[13])]\n",
    "  row_picks_total = row_picks0 + row_picks1 + row_picks2 + row_picks3 + row_picks4\n",
    "  print(f'row_picks_total: {row_picks_total}')\n",
    "\n",
    "  df_picks.loc[len(df_picks)] = row_picks_total\n",
    "  pickle_dump(df_picks, path_data_dump, fp_df_picks)\n",
    "  print(f'appended row_picks_total to df_picks:\\n{row_picks_total}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
