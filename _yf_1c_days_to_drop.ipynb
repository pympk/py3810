{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of days_to_drop from df_close_clean such that the last date in the df is a date in dates_missing_in_df_picks<br>Pickle the list of days_to_drop to \"l_days_to_drop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", 11)\n",
    "pd.set_option(\"display.max_colwidth\", 16)\n",
    "pd.set_option(\"display.width\", 145)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "fp_df_close_clean = \"df_close_clean\"\n",
    "fp_dates_missing_in_df_picks = \"dates_missing_in_df_picks\"\n",
    "# list of integers that are days_to_drop from df_close_clean\n",
    "#  s.t. the last date in the df is a date in dates_missing_in_df_picks\n",
    "fp_l_days_to_drop = \"l_days_to_drop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_close_clean:\n",
      "                     A         AA        AAL        AAP        AAPL  ...       ZION        ZTO         ZTS       ZUMZ        ZWS\n",
      "Date                                                                 ...                                                        \n",
      "2017-12-26   64.257431  49.313107  51.511108  93.872307   40.323353  ...  42.246853  14.869720   69.510918  21.850000  25.017214\n",
      "2017-12-27   64.305222  50.742184  51.072506  91.855995   40.330452  ...  42.122246  14.860385   69.616608  21.150000  25.220133\n",
      "2017-12-28   64.448540  52.993481  51.130985  91.800774   40.443916  ...  42.645565  14.851050   69.558929  21.200001  25.326426\n",
      "2017-12-29   64.131569  52.729195  50.711876  91.782364   40.006565  ...  42.221931  14.795043   69.222618  20.830000  25.142830\n",
      "2018-01-02   64.734879  54.001663  51.647560  97.674683   40.722878  ...  42.113949  15.327105   68.963203  20.000000  25.104181\n",
      "...                ...        ...        ...        ...         ...  ...        ...        ...         ...        ...        ...\n",
      "2023-12-05  127.879997  25.240000  13.130000  53.160000  193.419998  ...  37.389999  21.389999  179.649994  19.600000  29.299999\n",
      "2023-12-06  128.910004  25.120001  13.480000  55.160000  192.320007  ...  37.150002  21.420000  182.000000  19.430000  29.209999\n",
      "2023-12-07  128.679993  24.940001  13.910000  56.250000  194.270004  ...  38.380001  21.260000  181.830002  19.469999  29.480000\n",
      "2023-12-08  127.199997  25.020000  13.760000  56.270000  195.710007  ...  38.930000  21.309999  184.600006  19.350000  29.389999\n",
      "2023-12-11  128.970001  24.930000  13.720000  57.080002  193.179993  ...  38.630001  21.020000  189.460007  18.969999  29.610001\n",
      "\n",
      "[1500 rows x 1270 columns]\n",
      "\n",
      "df_close_clean_index:\n",
      "DatetimeIndex(['2017-12-26', '2017-12-27', '2017-12-28', '2017-12-29', '2018-01-02', '2018-01-03', '2018-01-04', '2018-01-05', '2018-01-08',\n",
      "               '2018-01-09',\n",
      "               ...\n",
      "               '2023-11-28', '2023-11-29', '2023-11-30', '2023-12-01', '2023-12-04', '2023-12-05', '2023-12-06', '2023-12-07', '2023-12-08',\n",
      "               '2023-12-11'],\n",
      "              dtype='datetime64[ns]', name='Date', length=1500, freq=None)\n"
     ]
    }
   ],
   "source": [
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)\n",
    "# Sort the DataFrame by the date index in place\n",
    "df_close_clean.sort_index(inplace=True)\n",
    "print(f'df_close_clean:\\n{df_close_clean}\\n')\n",
    "df_close_clean_index = df_close_clean.index\n",
    "print(f'df_close_clean_index:\\n{df_close_clean_index}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates_missing_in_df_picks, len(29):\n",
      "['2023-07-17', '2023-07-19', '2023-07-24', '2023-07-28', '2023-07-31', '2023-08-16', '2023-08-21', '2023-08-22', '2023-08-23', '2023-08-24', '2023-08-28', '2023-08-29', '2023-08-30', '2023-08-31', '2023-09-06', '2023-09-07', '2023-09-19', '2023-09-26', '2023-09-27', '2023-10-03', '2023-10-09', '2023-10-10', '2023-10-11', '2023-10-13', '2023-10-16', '2023-10-18', '2023-11-14', '2023-11-27', '2023-11-29']\n"
     ]
    }
   ],
   "source": [
    "dates_missing_in_df_picks = pickle_load(path_data_dump, fp_dates_missing_in_df_picks)\n",
    "print(f'dates_missing_in_df_picks, len({len(dates_missing_in_df_picks)}):\\n{dates_missing_in_df_picks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================================\n",
      "+ def pickle_dump(file_to_pickle, path_pickle_dump, filename_pickle)\n",
      "\n",
      "Wrote pickled file to C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/l_days_to_drop\n",
      "- def pickle_dump(file_to_pickle, path_pickle_dump, filename_pickle)\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "dates_missing_in_df_picks, len=29: ['2023-07-17', '2023-07-19', '2023-07-24', '2023-07-28', '2023-07-31', '2023-08-16', '2023-08-21', '2023-08-22', '2023-08-23', '2023-08-24', '2023-08-28', '2023-08-29', '2023-08-30', '2023-08-31', '2023-09-06', '2023-09-07', '2023-09-19', '2023-09-26', '2023-09-27', '2023-10-03', '2023-10-09', '2023-10-10', '2023-10-11', '2023-10-13', '2023-10-16', '2023-10-18', '2023-11-14', '2023-11-27', '2023-11-29']\n",
      "l_days_to_drop, len=29: [103, 101, 98, 94, 93, 81, 78, 77, 76, 75, 73, 72, 71, 70, 67, 66, 58, 53, 52, 48, 44, 43, 42, 40, 39, 37, 18, 10, 8]\n"
     ]
    }
   ],
   "source": [
    "# list to store days_to_drop from df_close_clean\n",
    "l_days_to_drop = []\n",
    "\n",
    "# Calculate the number of days to drop from the date index.\n",
    "for i in range(len(dates_missing_in_df_picks)):\n",
    "  date = dates_missing_in_df_picks[i]\n",
    "  last_date_index = df_close_clean_index.get_loc(date)\n",
    "  # number of days to drop from df such that the last date is a missing date    \n",
    "  days_to_drop = len(df_close_clean_index) - last_date_index - 1\n",
    "  # print(f'i: {i}, date: {date}, days_to_drop: {days_to_drop}')\n",
    "  l_days_to_drop.append(days_to_drop)  \n",
    "\n",
    "pickle_dump(l_days_to_drop, path_data_dump, fp_l_days_to_drop, verbose=True)    \n",
    "print(f'\\ndates_missing_in_df_picks, len={len(dates_missing_in_df_picks)}: {dates_missing_in_df_picks}')\n",
    "print(f'l_days_to_drop, len={len(l_days_to_drop)}: {l_days_to_drop}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to df's last dates are same as dates_missing_in_df_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates_missing_in_df_picks: ['2023-07-17', '2023-07-19', '2023-07-24', '2023-07-28', '2023-07-31', '2023-08-16', '2023-08-21', '2023-08-22', '2023-08-23', '2023-08-24', '2023-08-28', '2023-08-29', '2023-08-30', '2023-08-31', '2023-09-06', '2023-09-07', '2023-09-19', '2023-09-26', '2023-09-27', '2023-10-03', '2023-10-09', '2023-10-10', '2023-10-11', '2023-10-13', '2023-10-16', '2023-10-18', '2023-11-14', '2023-11-27', '2023-11-29']\n",
      "check_l_days_to_drop:      ['2023-07-17', '2023-07-19', '2023-07-24', '2023-07-28', '2023-07-31', '2023-08-16', '2023-08-21', '2023-08-22', '2023-08-23', '2023-08-24', '2023-08-28', '2023-08-29', '2023-08-30', '2023-08-31', '2023-09-06', '2023-09-07', '2023-09-19', '2023-09-26', '2023-09-27', '2023-10-03', '2023-10-09', '2023-10-10', '2023-10-11', '2023-10-13', '2023-10-16', '2023-10-18', '2023-11-14', '2023-11-27', '2023-11-29']\n",
      "The lists are equal.\n"
     ]
    }
   ],
   "source": [
    "check_l_days_to_drop = []\n",
    "for n in l_days_to_drop:\n",
    "  df_current = df_close_clean.copy()\n",
    "\n",
    "  # only drop last n rows from df if n != 0; if n=0, no need to drop any rows\n",
    "  if n != 0:\n",
    "    # Drop the last n rows\n",
    "    df_current = df_current.drop(df_current.index[-n:])\n",
    "\n",
    "  check_l_days_to_drop.append(df_current.index[-1].strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "print(f'dates_missing_in_df_picks: {dates_missing_in_df_picks}')\n",
    "print(f'check_l_days_to_drop:      {check_l_days_to_drop}')\n",
    "\n",
    "def compare_lists(list1, list2):\n",
    "    if list1 != list2:\n",
    "        raise ValueError(\"The lists are not equal!\")\n",
    "    else:\n",
    "        print(\"The lists are equal.\")\n",
    "\n",
    "try:\n",
    "    compare_lists(dates_missing_in_df_picks, check_l_days_to_drop)\n",
    "except ValueError as error:\n",
    "    print(error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
