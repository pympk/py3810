{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum\n",
    "from myUtils import pickle_load\n",
    "\n",
    "# verbose = False  # True prints more output\n",
    "verbose = True  # True prints more output\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "fp_df_close_clean = 'df_close_clean'\n",
    "fp_rtn_results = 'rtn_results'\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of days to lookback from last df date for performance evaluation\n",
    "# days_lookbacks = [60, 120]\n",
    "days_lookbacks = [15, 30, 60]\n",
    "days_lookbacks.sort()  # sort list of integers in ascending order\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "\n",
    "syms_start = 0  # slice start of set_most_common_syms\n",
    "syms_end = 10  #  slice end of set_most_common_syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load past mean daily return of top_set_syms verus SPY return \n",
    "# rtn_results = pickle_load(path_data_dump, fp_rtn_results)\n",
    "# rtn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "# grp_top_set_syms = []  # list of lists of top_set_symbols, there are n_samples lists in list\n",
    "grp_most_common_syms = []  # accumulates the best performing symbols from each days_lookback\n",
    "grp_perf_ranks = []  # accumulates the best performance ranking symbols from each days_lookback \n",
    "grp_dates = []  # dates of days_lookbacks \n",
    "\n",
    "for d_lookback in days_lookbacks:\n",
    "  df = df_close_clean.iloc[-d_lookback:]\n",
    "  perf_ranks, most_common_syms = _5_perf_ranks(df, n_top_syms=n_top_syms)  # get the best performance symbols and rankings\n",
    "  grp_most_common_syms.append(most_common_syms)\n",
    "  grp_perf_ranks.append(perf_ranks)  \n",
    "  grp_dates.append(df.index[0].strftime(\"%Y-%m-%d\")) \n",
    "\n",
    "grp_dates.append(df.index[-1].strftime(\"%Y-%m-%d\"))  # get df's last date\n",
    "grp_dates.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten list of lists of (symbol:frequency)\n",
    "flat_grp_most_common_syms = [val for sublist in grp_most_common_syms for val in sublist]\n",
    "# group symbols from set of days_lookbacks (i.e. lb_slices) and sum frequency of the symbols\n",
    "set_most_common_syms = _6_grp_tuples_sort_sum(flat_grp_most_common_syms, reverse=True)\n",
    "# get the top few most-frequent symbol:frequency pairs\n",
    "top_set_syms_n_freq = set_most_common_syms[0:n_top_syms]\n",
    "# get symbols from top_set_syms_n_freq\n",
    "top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('TA', 3),\n",
       "  ('TNK', 3),\n",
       "  ('ACGL', 3),\n",
       "  ('CNA', 3),\n",
       "  ('SGEN', 3),\n",
       "  ('OEC', 3),\n",
       "  ('PDFS', 3),\n",
       "  ('HZO', 3),\n",
       "  ('TNP', 2),\n",
       "  ('STNG', 2),\n",
       "  ('ASC', 2),\n",
       "  ('CTLT', 2),\n",
       "  ('LNTH', 2),\n",
       "  ('AMCX', 2),\n",
       "  ('FTI', 2),\n",
       "  ('MMS', 2),\n",
       "  ('KBR', 2),\n",
       "  ('BP', 2),\n",
       "  ('EURN', 2),\n",
       "  ('MSGS', 2),\n",
       "  ('RRC', 1),\n",
       "  ('XPRO', 1),\n",
       "  ('CLMT', 1),\n",
       "  ('ATCO', 1),\n",
       "  ('FTSM', 1),\n",
       "  ('TWNK', 1),\n",
       "  ('EME', 1),\n",
       "  ('NVGS', 1),\n",
       "  ('FDP', 1),\n",
       "  ('PGR', 1),\n",
       "  ('FCN', 1),\n",
       "  ('HUM', 1)],\n",
       " [('TA', 3),\n",
       "  ('ELF', 3),\n",
       "  ('TNK', 3),\n",
       "  ('TSLA', 3),\n",
       "  ('OEC', 3),\n",
       "  ('LNTH', 3),\n",
       "  ('CTLT', 3),\n",
       "  ('EURN', 3),\n",
       "  ('WIRE', 3),\n",
       "  ('NVDA', 2),\n",
       "  ('SMG', 2),\n",
       "  ('LRN', 2),\n",
       "  ('NVGS', 2),\n",
       "  ('PDFS', 2),\n",
       "  ('ASC', 2),\n",
       "  ('TEX', 2),\n",
       "  ('SGEN', 2),\n",
       "  ('ACLS', 2),\n",
       "  ('THR', 2),\n",
       "  ('XPRO', 2),\n",
       "  ('RVNC', 1),\n",
       "  ('TNP', 1),\n",
       "  ('CNK', 1),\n",
       "  ('CRUS', 1),\n",
       "  ('COUP', 1),\n",
       "  ('MMS', 1),\n",
       "  ('FISV', 1),\n",
       "  ('NATI', 1),\n",
       "  ('AQN', 1),\n",
       "  ('CME', 1),\n",
       "  ('CIGI', 1)],\n",
       " [('BVH', 3),\n",
       "  ('MCFT', 3),\n",
       "  ('PEN', 3),\n",
       "  ('HEES', 3),\n",
       "  ('ATI', 3),\n",
       "  ('COUP', 2),\n",
       "  ('ACLS', 2),\n",
       "  ('CRUS', 2),\n",
       "  ('META', 2),\n",
       "  ('HZNP', 2),\n",
       "  ('ALGN', 2),\n",
       "  ('IPGP', 2),\n",
       "  ('SGEN', 2),\n",
       "  ('HSBC', 2),\n",
       "  ('AJRD', 2),\n",
       "  ('CCU', 2),\n",
       "  ('TPX', 2),\n",
       "  ('PAR', 2),\n",
       "  ('URI', 2),\n",
       "  ('WYNN', 2),\n",
       "  ('SMG', 1),\n",
       "  ('BMA', 1),\n",
       "  ('OEC', 1),\n",
       "  ('THR', 1),\n",
       "  ('TX', 1),\n",
       "  ('NVDA', 1),\n",
       "  ('LW', 1),\n",
       "  ('TA', 1),\n",
       "  ('RVNC', 1),\n",
       "  ('MMS', 1),\n",
       "  ('VRNS', 1),\n",
       "  ('OTTR', 1),\n",
       "  ('PNM', 1),\n",
       "  ('ACGL', 1),\n",
       "  ('EXAS', 1)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_most_common_syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grp_dates: ['2022-11-29', '2023-01-12', '2023-02-03', '2023-02-24']\n",
      "top_set_syms_n_freq: [('OEC', 7), ('SGEN', 7), ('TA', 7), ('TNK', 6), ('CTLT', 5), ('EURN', 5), ('LNTH', 5), ('PDFS', 5), ('ACGL', 4), ('ACLS', 4), ('ASC', 4), ('MMS', 4), ('ATI', 3), ('BVH', 3), ('CNA', 3), ('COUP', 3), ('CRUS', 3), ('ELF', 3), ('HEES', 3), ('HZO', 3)]\n",
      "top_set_syms: ['OEC', 'SGEN', 'TA', 'TNK', 'CTLT', 'EURN', 'LNTH', 'PDFS', 'ACGL', 'ACLS']\n"
     ]
    }
   ],
   "source": [
    "print(f'grp_dates: {grp_dates}')\n",
    "print(f'top_set_syms_n_freq: {top_set_syms_n_freq}')\n",
    "print(f'top_set_syms: {top_set_syms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import webbrowser\n",
    "\n",
    "# y_quote = 'https://finance.yahoo.com/quote/'\n",
    "# for sym in top_set_syms:\n",
    "#   url = y_quote + sym\n",
    "#   print(url)\n",
    "#   webbrowser.open(url)  # open symbols in yahoo finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing Pandas to create DataFrame\n",
    "# import pandas as pd\n",
    "\n",
    "# my_cols = ['date', 'days_lookbacks', 'n_top_syms', 'syms_start', 'syms_end', 'grp_dates', 'top_set_syms_n_freq', 'top_set_syms']\n",
    "# # Creating Empty DataFrame and Storing it in variable df\n",
    "# df = pd.DataFrame(columns=my_cols)\n",
    "# pickle_dump(df, path_data_dump, fp_top_set_syms)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "fp_top_set_syms = 'df_top_set_syms'  # df to store top set symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle_load(path_data_dump, fp_top_set_syms)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_add = [grp_dates[-1], days_lookbacks, n_top_syms, syms_start, syms_end, grp_dates, top_set_syms_n_freq, top_set_syms]\n",
    "df.loc[len(df)] = row_add\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df\n",
    "_df = df.astype(str)\n",
    "# df.loc[df.astype(str).drop_duplicates(subset=['date', 'days_lookbacks'])]\n",
    "_df = _df.drop_duplicates(subset=['date', 'days_lookbacks'])\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump(_df, path_data_dump, fp_top_set_syms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pickle_load(path_data_dump, fp_top_set_syms)\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[\"top_set_syms_n_freq\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_top_set_syms = df[\"top_set_syms\"].iloc[-2]\n",
    "prev_top_set_syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.options.display.width = 120\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "print(f'_df[\"top_set_syms_n_freq\"]:\\n{_df[\"top_set_syms_n_freq\"]}\\n')\n",
    "l_last_top_set_syms_n_freq = _df['top_set_syms_n_freq'].iloc[-1]\n",
    "\n",
    "print(f'_df[\"top_set_syms\"]:\\n{_df[\"top_set_syms\"]}')\n",
    "l_last_top_set_syms = _df['top_set_syms'].iloc[-1]\n",
    "print(f'last row of top_set_syms:\\n{l_last_top_set_syms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_top_set_syms = []\n",
    "for symbols in _df[\"top_set_syms\"]:\n",
    "  recent_top_set_syms.append(symbols)\n",
    "recent_top_set_syms\n",
    "\n",
    "# flatten symbols_download_err which is a list-of-lists\n",
    "recent_top_set_syms = [val for sublist in recent_top_set_syms for val in sublist]\n",
    "recent_top_set_syms\n",
    "# get list of unique symbols in df_OHLCV, list(df) is a list of tuples\n",
    "# e.g.: [('AAPL', 'Open')..('AAPL', 'Volume'),...\n",
    "#        ('ZZZZ', 'Open')..('ZZZZ', 'Volume')]\n",
    "recent_top_set_syms = list(set(recent_top_set_syms))\n",
    "recent_top_set_syms.append(\"SPY\")\n",
    "recent_top_set_syms.sort()\n",
    "print(recent_top_set_syms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_cols.sort() will not change order of l_last_top_set_syms \n",
    "my_cols = recent_top_set_syms.copy()  \n",
    "my_cols.sort()\n",
    "# my_cols.append('SPY')\n",
    "_df = df_close_clean[my_cols].tail(10)\n",
    "# print(_df)\n",
    "print(_df.pct_change())\n",
    "_df.pct_change().tail(1)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# today's return from previous top_set_syms\n",
    "prev_top_set_syms_n_SPY = prev_top_set_syms + ['SPY']\n",
    "rtn_prev_top_set_syms = _df.pct_change().tail(1)[prev_top_set_syms_n_SPY]\n",
    "rtn_prev_top_set_syms_mean = rtn_prev_top_set_syms.mean(axis=1)[0]\n",
    "rtn_prev_top_set_syms_std = rtn_prev_top_set_syms.std(axis=1)[0]\n",
    "# print(f'rtn_prev_top_set_syms:\\n{rtn_prev_top_set_syms}')\n",
    "print(f'rtn_prev_top_set_syms_mean:                                                {rtn_prev_top_set_syms_mean:>10.6f}')\n",
    "print(f'rtn_prev_top_set_syms_std:                                                 {rtn_prev_top_set_syms_std:>10.6f}\\n')\n",
    "\n",
    "rtn_SPY = _df.pct_change().tail(1)['SPY'][0]  # [0] changes pd.Series to a value\n",
    "rtn_dif = rtn_prev_top_set_syms_mean - rtn_SPY\n",
    "print(f'rtn_SPY:                                                                   {rtn_SPY:>10.6f}\\n')                  \n",
    "print(f\"Difference in daily return between yesterday's top_set_syms_mean and SPY:  {rtn_dif:>10.6f}\")\n",
    "\n",
    "print(\"\\nToday's return of previous top_set_syms and SPY\")\n",
    "rtn_prev_top_set_syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_date = rtn_prev_top_set_syms.tail(1).index.strftime('%Y-%m-%d')[0]\n",
    "_rtn_tss_mean = rtn_prev_top_set_syms_mean\n",
    "_rtn_tss_std = rtn_prev_top_set_syms_std\n",
    "_rtn_SPY = rtn_SPY\n",
    "_rtn_dif = rtn_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_add = [_date, _rtn_tss_mean, _rtn_tss_std, _rtn_SPY, _rtn_dif]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_cols\n",
    "row_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Creating Empty DataFrame and Storing it in variable df\n",
    "# my_cols = ['date', 'rtn_tss_mean', 'rtn_tss_std', 'rtn_SPY', 'rtn_dif']\n",
    "# rtn_results = pd.DataFrame(columns=my_cols)\n",
    "\n",
    "rtn_results.loc[len(rtn_results)] = row_add\n",
    "rtn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtn_results = rtn_results.drop_duplicates(subset=['date'])\n",
    "rtn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump(rtn_results, path_data_dump, fp_rtn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pickle_load(path_data_dump, fp_rtn_results)\n",
    "_df.sort_values(by='date', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
