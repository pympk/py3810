{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picks the best performing symbols based on parameter settings<br> - Get dates in df_close_clean that are missing in df_picks<br> - Calculate days_to_drop from df_close_clean s.t. the last date in df_close_clean is the missing date in df_picks<br> - Get picks for the missing dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lists(list_a, list_b):\n",
    "  \"\"\"Compares two lists and returns a list of values that are in list A but not in list B.\n",
    "\n",
    "  Args:\n",
    "    list_a: A list of objects.\n",
    "    list_b: A list of objects.\n",
    "\n",
    "  Returns:\n",
    "    A list of values that are in list_a but not in list_b.\n",
    "  \"\"\"\n",
    "\n",
    "  list_difference = []\n",
    "\n",
    "  for item in list_a:\n",
    "    if item not in list_b:\n",
    "      list_difference.append(item)\n",
    "\n",
    "  return list_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from yf_utils import random_slices, lookback_slices\n",
    "from yf_utils import rank_perf, grp_tuples_sort_sum, top_set_sym_freq_cnt\n",
    "from yf_utils import best_perf_syms_sets_lookback_slices\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "# pd.set_option(\"display.max_columns\", 11)\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.max_colwidth\", 26)\n",
    "# pd.set_option(\"display.width\", 280)\n",
    "pd.set_option(\"display.width\", 500)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "fp_df_close_clean = \"df_close_clean\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose : False\n",
      "store_results: True\n",
      "n_samples: 1\n",
      "l_sorted_days_lookbacks: [[30, 60, 120], [15, 30, 60, 120]]\n",
      "days_eval: 0\n",
      "n_top_syms: 20\n",
      "syms_start: 0\n",
      "syms_end: 10\n",
      "fp_df_picks: df_picks\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Set parameters ######################################################################\n",
    "# fp_df_eval_results = f'df_eval_results_{run_type}'\n",
    "fp_df_picks = f\"df_picks\"\n",
    "\n",
    "verbose = False  # True prints more output\n",
    "# verbose = True  # True prints more output\n",
    "\n",
    "store_results = True\n",
    "\n",
    "# n_samples is the number of random samples of df chunks s.t.\n",
    "#   len(df) = max_days_lookbacks. For getting the current picks\n",
    "#   n_samples is always 1 since more samples will always yield\n",
    "#   the same df chunk\n",
    "n_samples = 1  # only need 1 sample to get the current picks\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback iloc_end_train\n",
    "l_days_lookbacks = [[30, 60, 120], [15, 30, 60, 120]]\n",
    "\n",
    "# e.g sort from [[60, 30, 120], [15, 60, 30, 120]] to [[30, 60, 120], [15, 30, 60, 120]] \n",
    "l_sorted_days_lookbacks = []\n",
    "for days_lookbacks in l_days_lookbacks:\n",
    "    l_sorted_days_lookbacks.append(sorted(days_lookbacks))\n",
    "\n",
    "# number of days from iloc_end_train are used to evaluate effectiveness of the training\n",
    "days_eval = 0\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20\n",
    "\n",
    "# slice starts and ends for selecting the best performing symbols\n",
    "syms_start = 0\n",
    "syms_end = 10\n",
    "#########################################################################\n",
    "\n",
    "print(f\"verbose : {verbose }\")\n",
    "print(f\"store_results: {store_results}\")\n",
    "print(f\"n_samples: {n_samples}\")\n",
    "print(f\"l_sorted_days_lookbacks: {l_sorted_days_lookbacks}\")\n",
    "print(f\"days_eval: {days_eval}\")\n",
    "print(f\"n_top_syms: {n_top_syms}\")\n",
    "print(f\"syms_start: {syms_start}\")\n",
    "print(f\"syms_end: {syms_end}\")\n",
    "print(f\"fp_df_picks: {fp_df_picks}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load past picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_picks, len(388):\n",
      "    date_end_df_train  max_days_lookbacks     days_lookbacks sym_freq_15 sym_freq_14 sym_freq_13 sym_freq_12      sym_freq_11      sym_freq_10       sym_freq_9       sym_freq_8              sym_freq_7                 sym_freq_6                 sym_freq_5                 sym_freq_4                 sym_freq_3 sym_freq_2\n",
      "0          2023-12-19                 120      [30, 60, 120]          []          []          []          []               []               []               []   ['GPS', 'SHV']                ['FTSM']                         []  ['ANF', 'HIBB', 'SQ', ...  ['AMKR', 'LRN', 'MARA'...  ['BA', 'BPMC', 'BTC-US...         []\n",
      "1          2023-12-19                 120  [15, 30, 60, 120]          []          []          []          []               []          ['SHV']               []          ['GPS']         ['FTSM', 'MBI']  ['HA', 'MARA', 'WOR', ...  ['ANF', 'FFWM', 'HIBB'...  ['AMKR', 'LOB', 'LRN',...                     ['BA']         []\n",
      "2          2023-12-18                 120      [30, 60, 120]          []          []          []          []               []               []               []          ['SHV']         ['FTSM', 'GPS']                      ['X']     ['ANF', 'HIBB', 'LRN']  ['AMKR', 'KKR', 'MARA'...  ['BPMC', 'BTC-USD', 'C...         []\n",
      "3          2023-12-18                 120  [15, 30, 60, 120]          []          []          []          []               []          ['SHV']            ['X']               []  ['FTSM', 'GPS', 'MBI']             ['HA', 'MARA']  ['ANF', 'HIBB', 'LRN',...  ['AMKR', 'CG', 'KKR', ...        ['BPMC', 'BTC-USD']         []\n",
      "4          2023-12-15                 120      [30, 60, 120]          []          []          []          []               []               []               []          ['SHV']         ['FTSM', 'GPS']                         []     ['ANF', 'HIBB', 'LRN']      ['MARA', 'MBI', 'SQ']  ['AMKR', 'AXGN', 'BPMC...         []\n",
      "..                ...                 ...                ...         ...         ...         ...         ...              ...              ...              ...              ...                     ...                        ...                        ...                        ...                        ...        ...\n",
      "383        2023-03-17                 120  [15, 30, 60, 120]          []          []          []          []          ['SHV']               []   ['FTSM', 'GE']               []        ['NVDA', 'SGEN']  ['ANET', 'FCN', 'GBTC'...  ['ACLS', 'FSLR', 'HY',...     ['AMD', 'ATCO', 'MLR']                   ['AJRD']         []\n",
      "384        2023-03-16                 120      [30, 60, 120]          []          []          []          []               []               []  ['FTSM', 'SHV']               []                      []    ['LNTH', 'SGEN', 'WST']  ['ACLS', 'AMPH', 'CTLT...       ['HY', 'MLR', 'OEC']  ['ANET', 'ATCO', 'ATKR...         []\n",
      "385        2023-03-16                 120  [15, 30, 60, 120]          []          []          []          []               []  ['FTSM', 'SHV']         ['SGEN']               []                 ['MLR']  ['ANET', 'FCN', 'FSLR'...  ['ACLS', 'AMPH', 'CTLT...                         []                         []         []\n",
      "386        2023-03-15                 120      [30, 60, 120]          []          []          []          []               []               []  ['FTSM', 'SHV']               []                      []  ['CTLT', 'ELF', 'SGEN'...  ['ACLS', 'AMPH', 'FCN'...  ['ATCO', 'HY', 'LNTH',...  ['ATKR', 'BURL', 'FIZZ...         []\n",
      "387        2023-03-15                 120  [15, 30, 60, 120]          []          []          []          []  ['FTSM', 'SHV']               []         ['SGEN']  ['AMPH', 'FCN']    ['GE', 'HY', 'META']  ['CTLT', 'ELF', 'FIZZ'...   ['ACLS', 'ANET', 'SRPT']           ['ATCO', 'LNTH']                         []         []\n",
      "\n",
      "[388 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "df_picks = pickle_load(path_data_dump, fp_df_picks)\n",
    "# drop duplicates\n",
    "df_picks = df_picks.drop_duplicates(subset=['date_end_df_train', 'max_days_lookbacks', 'days_lookbacks'], keep='last')\n",
    "# sort, most recent date is first\n",
    "df_picks = df_picks.sort_values(by=['date_end_df_train', 'max_days_lookbacks', 'days_lookbacks'], ascending=False)\n",
    "# re-index\n",
    "df_picks = df_picks.reset_index(drop=True)\n",
    "# save results\n",
    "pickle_dump(df_picks, path_data_dump, fp_df_picks)\n",
    "print(f'df_picks, len({len(df_picks)}):\\n{df_picks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_end_df_train</th>\n",
       "      <th>max_days_lookbacks</th>\n",
       "      <th>days_lookbacks</th>\n",
       "      <th>sym_freq_15</th>\n",
       "      <th>sym_freq_14</th>\n",
       "      <th>sym_freq_13</th>\n",
       "      <th>sym_freq_12</th>\n",
       "      <th>sym_freq_11</th>\n",
       "      <th>sym_freq_10</th>\n",
       "      <th>sym_freq_9</th>\n",
       "      <th>sym_freq_8</th>\n",
       "      <th>sym_freq_7</th>\n",
       "      <th>sym_freq_6</th>\n",
       "      <th>sym_freq_5</th>\n",
       "      <th>sym_freq_4</th>\n",
       "      <th>sym_freq_3</th>\n",
       "      <th>sym_freq_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>120</td>\n",
       "      <td>[30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['GPS', 'SHV']</td>\n",
       "      <td>['FTSM']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ANF', 'HIBB', 'SQ', ...</td>\n",
       "      <td>['AMKR', 'LRN', 'MARA'...</td>\n",
       "      <td>['BA', 'BPMC', 'BTC-US...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>120</td>\n",
       "      <td>[15, 30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['SHV']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['GPS']</td>\n",
       "      <td>['FTSM', 'MBI']</td>\n",
       "      <td>['HA', 'MARA', 'WOR', ...</td>\n",
       "      <td>['ANF', 'FFWM', 'HIBB'...</td>\n",
       "      <td>['AMKR', 'LOB', 'LRN',...</td>\n",
       "      <td>['BA']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>120</td>\n",
       "      <td>[30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['SHV']</td>\n",
       "      <td>['FTSM', 'GPS']</td>\n",
       "      <td>['X']</td>\n",
       "      <td>['ANF', 'HIBB', 'LRN']</td>\n",
       "      <td>['AMKR', 'KKR', 'MARA'...</td>\n",
       "      <td>['BPMC', 'BTC-USD', 'C...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>120</td>\n",
       "      <td>[15, 30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['SHV']</td>\n",
       "      <td>['X']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['FTSM', 'GPS', 'MBI']</td>\n",
       "      <td>['HA', 'MARA']</td>\n",
       "      <td>['ANF', 'HIBB', 'LRN',...</td>\n",
       "      <td>['AMKR', 'CG', 'KKR', ...</td>\n",
       "      <td>['BPMC', 'BTC-USD']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>120</td>\n",
       "      <td>[30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['SHV']</td>\n",
       "      <td>['FTSM', 'GPS']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ANF', 'HIBB', 'LRN']</td>\n",
       "      <td>['MARA', 'MBI', 'SQ']</td>\n",
       "      <td>['AMKR', 'AXGN', 'BPMC...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>120</td>\n",
       "      <td>[15, 30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['SHV']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['FTSM', 'GE']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['NVDA', 'SGEN']</td>\n",
       "      <td>['ANET', 'FCN', 'GBTC'...</td>\n",
       "      <td>['ACLS', 'FSLR', 'HY',...</td>\n",
       "      <td>['AMD', 'ATCO', 'MLR']</td>\n",
       "      <td>['AJRD']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>120</td>\n",
       "      <td>[30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['FTSM', 'SHV']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['LNTH', 'SGEN', 'WST']</td>\n",
       "      <td>['ACLS', 'AMPH', 'CTLT...</td>\n",
       "      <td>['HY', 'MLR', 'OEC']</td>\n",
       "      <td>['ANET', 'ATCO', 'ATKR...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>120</td>\n",
       "      <td>[15, 30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['FTSM', 'SHV']</td>\n",
       "      <td>['SGEN']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['MLR']</td>\n",
       "      <td>['ANET', 'FCN', 'FSLR'...</td>\n",
       "      <td>['ACLS', 'AMPH', 'CTLT...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>120</td>\n",
       "      <td>[30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['FTSM', 'SHV']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['CTLT', 'ELF', 'SGEN'...</td>\n",
       "      <td>['ACLS', 'AMPH', 'FCN'...</td>\n",
       "      <td>['ATCO', 'HY', 'LNTH',...</td>\n",
       "      <td>['ATKR', 'BURL', 'FIZZ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>120</td>\n",
       "      <td>[15, 30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['FTSM', 'SHV']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['SGEN']</td>\n",
       "      <td>['AMPH', 'FCN']</td>\n",
       "      <td>['GE', 'HY', 'META']</td>\n",
       "      <td>['CTLT', 'ELF', 'FIZZ'...</td>\n",
       "      <td>['ACLS', 'ANET', 'SRPT']</td>\n",
       "      <td>['ATCO', 'LNTH']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    date_end_df_train  max_days_lookbacks     days_lookbacks sym_freq_15 sym_freq_14 sym_freq_13 sym_freq_12      sym_freq_11      sym_freq_10       sym_freq_9       sym_freq_8              sym_freq_7                 sym_freq_6                 sym_freq_5                 sym_freq_4                 sym_freq_3 sym_freq_2\n",
       "0          2023-12-19                 120      [30, 60, 120]          []          []          []          []               []               []               []   ['GPS', 'SHV']                ['FTSM']                         []  ['ANF', 'HIBB', 'SQ', ...  ['AMKR', 'LRN', 'MARA'...  ['BA', 'BPMC', 'BTC-US...         []\n",
       "1          2023-12-19                 120  [15, 30, 60, 120]          []          []          []          []               []          ['SHV']               []          ['GPS']         ['FTSM', 'MBI']  ['HA', 'MARA', 'WOR', ...  ['ANF', 'FFWM', 'HIBB'...  ['AMKR', 'LOB', 'LRN',...                     ['BA']         []\n",
       "2          2023-12-18                 120      [30, 60, 120]          []          []          []          []               []               []               []          ['SHV']         ['FTSM', 'GPS']                      ['X']     ['ANF', 'HIBB', 'LRN']  ['AMKR', 'KKR', 'MARA'...  ['BPMC', 'BTC-USD', 'C...         []\n",
       "3          2023-12-18                 120  [15, 30, 60, 120]          []          []          []          []               []          ['SHV']            ['X']               []  ['FTSM', 'GPS', 'MBI']             ['HA', 'MARA']  ['ANF', 'HIBB', 'LRN',...  ['AMKR', 'CG', 'KKR', ...        ['BPMC', 'BTC-USD']         []\n",
       "4          2023-12-15                 120      [30, 60, 120]          []          []          []          []               []               []               []          ['SHV']         ['FTSM', 'GPS']                         []     ['ANF', 'HIBB', 'LRN']      ['MARA', 'MBI', 'SQ']  ['AMKR', 'AXGN', 'BPMC...         []\n",
       "..                ...                 ...                ...         ...         ...         ...         ...              ...              ...              ...              ...                     ...                        ...                        ...                        ...                        ...        ...\n",
       "383        2023-03-17                 120  [15, 30, 60, 120]          []          []          []          []          ['SHV']               []   ['FTSM', 'GE']               []        ['NVDA', 'SGEN']  ['ANET', 'FCN', 'GBTC'...  ['ACLS', 'FSLR', 'HY',...     ['AMD', 'ATCO', 'MLR']                   ['AJRD']         []\n",
       "384        2023-03-16                 120      [30, 60, 120]          []          []          []          []               []               []  ['FTSM', 'SHV']               []                      []    ['LNTH', 'SGEN', 'WST']  ['ACLS', 'AMPH', 'CTLT...       ['HY', 'MLR', 'OEC']  ['ANET', 'ATCO', 'ATKR...         []\n",
       "385        2023-03-16                 120  [15, 30, 60, 120]          []          []          []          []               []  ['FTSM', 'SHV']         ['SGEN']               []                 ['MLR']  ['ANET', 'FCN', 'FSLR'...  ['ACLS', 'AMPH', 'CTLT...                         []                         []         []\n",
       "386        2023-03-15                 120      [30, 60, 120]          []          []          []          []               []               []  ['FTSM', 'SHV']               []                      []  ['CTLT', 'ELF', 'SGEN'...  ['ACLS', 'AMPH', 'FCN'...  ['ATCO', 'HY', 'LNTH',...  ['ATKR', 'BURL', 'FIZZ...         []\n",
       "387        2023-03-15                 120  [15, 30, 60, 120]          []          []          []          []  ['FTSM', 'SHV']               []         ['SGEN']  ['AMPH', 'FCN']    ['GE', 'HY', 'META']  ['CTLT', 'ELF', 'FIZZ'...   ['ACLS', 'ANET', 'SRPT']           ['ATCO', 'LNTH']                         []         []\n",
       "\n",
       "[388 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_picks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dates in df_close_clean that are missing in df_picks<br>=============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date, earliest date in df_picks:   2023-03-15\n",
      "end_date, latest date in df_close_clean: 2023-12-20\n",
      "date range to find dates in df_close_clean that are missing in df_picks: 2023-03-15 - 2023-12-20\n"
     ]
    }
   ],
   "source": [
    "# earliest date in df_picks\n",
    "start_date = df_picks.date_end_df_train.min()\n",
    "# load df with symbols' close\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)\n",
    "# latest date in df_close_clean\n",
    "end_date = df_close_clean.index[-1].strftime('%Y-%m-%d')\n",
    "print(f'start_date, earliest date in df_picks:   {start_date}')\n",
    "print(f'end_date, latest date in df_close_clean: {end_date}')\n",
    "print(f'date range to find dates in df_close_clean that are missing in df_picks: {start_date} - {end_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_dates_df_picks, len(194):\n",
      "['2023-12-19', '2023-12-18', '2023-12-15', '2023-12-14', '2023-12-13', '2023-12-12', '2023-12-11', '2023-12-08', '2023-12-07', '2023-12-06', '2023-12-05', '2023-12-04', '2023-12-01', '2023-11-30', '2023-11-29', '2023-11-28', '2023-11-27', '2023-11-24', '2023-11-22', '2023-11-21', '2023-11-20', '2023-11-17', '2023-11-16', '2023-11-15', '2023-11-14', '2023-11-13', '2023-11-10', '2023-11-09', '2023-11-08', '2023-11-07', '2023-11-06', '2023-11-03', '2023-11-02', '2023-11-01', '2023-10-31', '2023-10-30', '2023-10-27', '2023-10-26', '2023-10-25', '2023-10-24', '2023-10-23', '2023-10-20', '2023-10-19', '2023-10-18', '2023-10-17', '2023-10-16', '2023-10-13', '2023-10-12', '2023-10-11', '2023-10-10', '2023-10-09', '2023-10-06', '2023-10-05', '2023-10-04', '2023-10-03', '2023-10-02', '2023-09-29', '2023-09-28', '2023-09-27', '2023-09-26', '2023-09-25', '2023-09-22', '2023-09-21', '2023-09-20', '2023-09-19', '2023-09-18', '2023-09-15', '2023-09-14', '2023-09-13', '2023-09-12', '2023-09-11', '2023-09-08', '2023-09-07', '2023-09-06', '2023-09-05', '2023-09-01', '2023-08-31', '2023-08-30', '2023-08-29', '2023-08-28', '2023-08-25', '2023-08-24', '2023-08-23', '2023-08-22', '2023-08-21', '2023-08-18', '2023-08-17', '2023-08-16', '2023-08-15', '2023-08-14', '2023-08-11', '2023-08-10', '2023-08-09', '2023-08-08', '2023-08-07', '2023-08-04', '2023-08-03', '2023-08-02', '2023-08-01', '2023-07-31', '2023-07-28', '2023-07-27', '2023-07-26', '2023-07-25', '2023-07-24', '2023-07-21', '2023-07-20', '2023-07-19', '2023-07-18', '2023-07-17', '2023-07-14', '2023-07-13', '2023-07-12', '2023-07-11', '2023-07-10', '2023-07-07', '2023-07-06', '2023-07-05', '2023-07-03', '2023-06-30', '2023-06-29', '2023-06-28', '2023-06-27', '2023-06-26', '2023-06-23', '2023-06-22', '2023-06-21', '2023-06-20', '2023-06-16', '2023-06-15', '2023-06-14', '2023-06-13', '2023-06-12', '2023-06-09', '2023-06-08', '2023-06-07', '2023-06-06', '2023-06-05', '2023-06-02', '2023-06-01', '2023-05-31', '2023-05-30', '2023-05-26', '2023-05-25', '2023-05-24', '2023-05-23', '2023-05-22', '2023-05-19', '2023-05-18', '2023-05-17', '2023-05-16', '2023-05-15', '2023-05-12', '2023-05-11', '2023-05-10', '2023-05-09', '2023-05-08', '2023-05-05', '2023-05-04', '2023-05-03', '2023-05-02', '2023-05-01', '2023-04-28', '2023-04-27', '2023-04-26', '2023-04-25', '2023-04-24', '2023-04-21', '2023-04-20', '2023-04-19', '2023-04-18', '2023-04-17', '2023-04-14', '2023-04-13', '2023-04-12', '2023-04-11', '2023-04-10', '2023-04-06', '2023-04-05', '2023-04-04', '2023-04-03', '2023-03-31', '2023-03-30', '2023-03-29', '2023-03-28', '2023-03-27', '2023-03-24', '2023-03-23', '2023-03-22', '2023-03-21', '2023-03-20', '2023-03-17', '2023-03-16', '2023-03-15']\n"
     ]
    }
   ],
   "source": [
    "l_dates_df_picks = df_picks.date_end_df_train.unique().tolist()  # unique dates in df_picks\n",
    "print(f'l_dates_df_picks, len({len(l_dates_df_picks)}):\\n{l_dates_df_picks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_dates_df_close, (len=195):\n",
      "Index(['2023-03-15', '2023-03-16', '2023-03-17', '2023-03-20', '2023-03-21', '2023-03-22', '2023-03-23', '2023-03-24', '2023-03-27', '2023-03-28',\n",
      "       ...\n",
      "       '2023-12-07', '2023-12-08', '2023-12-11', '2023-12-12', '2023-12-13', '2023-12-14', '2023-12-15', '2023-12-18', '2023-12-19', '2023-12-20'], dtype='object', name='Date', length=195)\n"
     ]
    }
   ],
   "source": [
    "# Select rows in df_close_clean between the start_date and end_date in df_picks\n",
    "mask = (df_close_clean.index >= start_date) & (df_close_clean.index <= end_date)\n",
    "l_dates_df_close = df_close_clean[mask].index\n",
    "# list of date index in 'yyyy-mm-dd' format\n",
    "l_dates_df_close = l_dates_df_close.strftime('%Y-%m-%d')\n",
    "print(f'l_dates_df_close, (len={len(l_dates_df_close )}):\\n{l_dates_df_close }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates_missing_in_df_picks, (len=1):\n",
      "['2023-12-20']\n"
     ]
    }
   ],
   "source": [
    "dates_missing_in_df_picks  = compare_lists(l_dates_df_close, l_dates_df_picks)\n",
    "# pickle_dump(dates_missing_in_df_picks, path_data_dump, fp_dates_missing_in_df_picks, verbose=verbose)\n",
    "print(f'dates_missing_in_df_picks, (len={len(dates_missing_in_df_picks )}):\\n{dates_missing_in_df_picks }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =============================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dates in df_close_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_close_clean:\n",
      "                     A         AA        AAL         AAP        AAPL         AB        ABBV        ABR         ABT       ACGL       ACHC       ACIW        ACLS       ACRS        ADBE  ...        XRX         XYL       YELP         YUM       YUMC          YY         ZBH        ZBRA         ZD         ZG       ZION        ZTO         ZTS       ZUMZ        ZWS\n",
      "Date                                                                                                                                                                                    ...                                                                                                                                                                           \n",
      "2018-01-05   66.937393  52.944538  51.316174  103.281639   41.370628  15.561795   77.047852   4.778927   53.267544  29.453333  33.110001  22.799999   31.000000  24.629999  185.339996  ...  22.849245   64.364021  43.169998   74.412132  40.453087  111.087791  117.000504  109.540001  63.475464  42.340000  42.255157  14.981730   70.491020  22.549999  25.442385\n",
      "2018-01-08   67.081032  53.835262  50.809349  102.554283   41.216965  15.858775   75.813362   4.834756   53.114040  29.456667  32.389999  23.040001   31.299999  25.379999  185.039993  ...  23.116623   64.596443  43.669998   74.537888  40.386848  112.102417  117.223366  110.629997  64.410538  42.619999  42.047497  14.655027   71.336601  23.000000  26.766201\n",
      "2018-01-09   68.728127  53.052208  50.760609  101.725693   41.212223  16.333944   76.384895   4.778927   53.204353  29.076668  33.070000  22.920000   31.049999  25.639999  186.699997  ...  23.063150   64.615044  43.290001   74.340256  40.964077  111.651451  115.338058  114.019997  63.652363  41.959999  43.035976  14.692364   72.172569  22.049999  26.746874\n",
      "2018-01-10   67.789665  54.980492  52.417545  101.817734   41.202763  16.096359   75.965767   4.745429   53.123066  28.916668  33.000000  22.879999   30.250000  25.420000  187.110001  ...  23.185373   64.150185  43.290001   74.151634  40.386848  110.550133  113.796394  114.779999  63.660793  42.189999  43.484520  14.337657   71.019501  22.200001  26.370020\n",
      "2018-01-11   67.799232  55.704819  54.990658  103.990540   41.436817  16.126060   76.188347   4.790093   53.485992  29.623333  34.380001  23.500000   29.400000  25.510000  188.919998  ...  24.338917   65.052002  44.000000   74.097740  41.446671  110.688881  113.573494  121.169998  65.320343  44.230000  44.115810  14.823048   71.672897  22.400000  27.162380\n",
      "...                ...        ...        ...         ...         ...        ...         ...        ...         ...        ...        ...        ...         ...        ...         ...  ...        ...         ...        ...         ...        ...         ...         ...         ...        ...        ...        ...        ...         ...        ...        ...\n",
      "2023-12-14  137.960007  29.900000  14.590000   63.970001  198.110001  31.870001  154.880005  15.700000  108.599998  74.669998  77.580002  29.639999  140.429993   1.060000  584.640015  ...  17.580000  110.930000  45.360001  131.110001  40.160000   38.799999  118.529999  272.160004  66.320000  54.500000  45.669998  20.309999  200.089996  19.930000  29.610001\n",
      "2023-12-15  136.779999  31.100000  14.490000   62.720001  197.570007  32.020000  154.039993  15.380000  107.290001  73.419998  75.430000  29.719999  136.089996   1.010000  584.679993  ...  18.290001  110.720001  44.790001  128.639999  40.029999   38.540001  118.690002  270.179993  66.550003  54.779999  43.840000  19.830000  196.289993  19.389999  29.350000\n",
      "2023-12-18  137.529999  30.520000  14.240000   60.660000  195.889999  32.209999  153.419998  15.360000  108.059998  74.650002  75.730003  29.730000  134.860001   0.938000  599.130005  ...  18.040001  110.709999  46.459999  130.470001  40.080002   38.799999  118.800003  266.679993  66.260002  55.330002  43.040001  20.200001  196.720001  19.059999  29.629999\n",
      "2023-12-19  139.789993  32.419998  14.300000   60.860001  196.940002  32.750000  153.600006  16.100000  108.419998  74.830002  76.519997  30.360001  136.179993   1.020000  604.640015  ...  18.469999  111.580002  46.820000  130.240005  41.330002   39.880001  119.970001  269.420013  67.510002  56.930000  43.930000  19.940001  198.080002  19.459999  29.770000\n",
      "2023-12-20  138.179993  30.650000  13.980000   59.450001  194.830002  31.620001  151.690002  15.490000  107.400002  73.610001  75.660004  29.690001  128.740005   0.935000  596.059998  ...  18.290001  109.669998  47.599998  129.039993  40.430000   39.840000  120.000000  261.609985  66.190002  55.480000  42.540001  19.920000  194.630005  18.850000  29.629999\n",
      "\n",
      "[1500 rows x 1270 columns]\n",
      "\n",
      "df_close_clean_index:\n",
      "DatetimeIndex(['2018-01-05', '2018-01-08', '2018-01-09', '2018-01-10', '2018-01-11', '2018-01-12', '2018-01-16', '2018-01-17', '2018-01-18', '2018-01-19',\n",
      "               ...\n",
      "               '2023-12-07', '2023-12-08', '2023-12-11', '2023-12-12', '2023-12-13', '2023-12-14', '2023-12-15', '2023-12-18', '2023-12-19', '2023-12-20'], dtype='datetime64[ns]', name='Date', length=1500, freq=None)\n"
     ]
    }
   ],
   "source": [
    "# df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)\n",
    "# Sort the DataFrame by the date index in place\n",
    "df_close_clean.sort_index(inplace=True)\n",
    "print(f'df_close_clean:\\n{df_close_clean}\\n')\n",
    "df_close_clean_index = df_close_clean.index\n",
    "print(f'df_close_clean_index:\\n{df_close_clean_index}')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a missing date in df_picks, calculate the number of days_to_drop from df_close_clean s.t. the last date in df_close_clean is the missing date in df_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates_missing_in_df_picks, len=1: ['2023-12-20']\n",
      "l_days_to_drop, len=1: [0]\n"
     ]
    }
   ],
   "source": [
    "# list to store days_to_drop from df_close_clean\n",
    "l_days_to_drop = []\n",
    "\n",
    "# Calculate the number of days to drop from the date index.\n",
    "for i in range(len(dates_missing_in_df_picks)):\n",
    "  date = dates_missing_in_df_picks[i]\n",
    "  last_date_index = df_close_clean_index.get_loc(date)\n",
    "  # number of days to drop from df such that the last date is a missing date    \n",
    "  days_to_drop = len(df_close_clean_index) - last_date_index - 1\n",
    "  l_days_to_drop.append(days_to_drop)  \n",
    "\n",
    "print(f'dates_missing_in_df_picks, len={len(dates_missing_in_df_picks)}: {dates_missing_in_df_picks}')\n",
    "print(f'l_days_to_drop, len={len(l_days_to_drop)}: {l_days_to_drop}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get picks for the missing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of For_Loop  1 of 2 loops  ========================================\n",
      "i: 1\n",
      "drop_last_n_rows: 0\n",
      "date_missing_in_df_picks: 2023-12-20\n",
      "days_lookbacks: [30, 60, 120]\n",
      "\n",
      "1 of 2 days_lookbacks: [30, 60, 120] in l_sorted_days_lookbacks: [[30, 60, 120], [15, 30, 60, 120]]\n",
      "max_days_lookbacks: 120\n",
      "\n",
      "dropped last 0 row(s) from df since drop_last_n_rows = 0\n",
      "df.head(1):\n",
      "                    A        AA   AAL        AAP        AAPL         AB        ABBV        ABR         ABT       ACGL       ACHC       ACIW        ACLS   ACRS        ADBE  ...        XRX         XYL       YELP         YUM       YUMC         YY         ZBH        ZBRA         ZD         ZG       ZION    ZTO         ZTS   ZUMZ        ZWS\n",
      "Date                                                                                                                                                                        ...                                                                                                                                                                  \n",
      "2023-07-03  119.07991  34.02372  18.1  70.354485  191.947586  31.305861  132.206345  14.204214  106.120781  73.989998  79.190002  23.299999  181.740005  10.47  485.209991  ...  14.802627  111.105598  36.529999  135.986664  57.163639  31.601398  142.201187  296.269989  70.099998  50.290001  27.482635  25.15  169.450729  17.24  26.653244\n",
      "\n",
      "[1 rows x 1270 columns]\n",
      "\n",
      "df.tail(1):\n",
      "                     A     AA    AAL        AAP        AAPL         AB        ABBV    ABR         ABT       ACGL       ACHC       ACIW        ACLS   ACRS        ADBE  ...        XRX         XYL       YELP         YUM   YUMC     YY    ZBH        ZBRA         ZD     ZG       ZION    ZTO         ZTS   ZUMZ        ZWS\n",
      "Date                                                                                                                                                                   ...                                                                                                                                                 \n",
      "2023-12-20  138.179993  30.65  13.98  59.450001  194.830002  31.620001  151.690002  15.49  107.400002  73.610001  75.660004  29.690001  128.740005  0.935  596.059998  ...  18.290001  109.669998  47.599998  129.039993  40.43  39.84  120.0  261.609985  66.190002  55.48  42.540001  19.92  194.630005  18.85  29.629999\n",
      "\n",
      "[1 rows x 1270 columns]\n",
      "\n",
      "date_last_index: 2023-12-20\n",
      "Passed Error Check: date_missing_in_df_picks 2023-12-20 == date_last_index 2023-12-20\n",
      "len_df: 120, len_slice: 120\n",
      "\n",
      "\n",
      "########## 1 of 1 lb_slices in sets_lookback_slices ##########\n",
      "\n",
      "Output from function best_perf_syms_sets_lookback_slices\n",
      "````````````````````````````````````````````````````````````\n",
      "sets_lookback_slices: [[(90, 120, 120), (60, 120, 120), (0, 120, 120)]]\n",
      "\n",
      "grp_top_set_syms_n_freq:\n",
      "[[('GPS', 8), ('SHV', 8), ('FTSM', 7), ('ANF', 5), ('HIBB', 5), ('SQ', 5), ('X', 5), ('LRN', 4), ('M', 4), ('MARA', 4), ('MBI', 4), ('VRNS', 4), ('BA', 3), ('BPMC', 3), ('FFWM', 3), ('GBTC', 3), ('GDDY', 3), ('HA', 3), ('HRB', 3), ('IBP', 3)]]\n",
      "\n",
      "grp_top_set_syms:\n",
      "[['GPS', 'SHV', 'FTSM', 'ANF', 'HIBB', 'SQ', 'X', 'LRN', 'M', 'MARA']]\n",
      "\n",
      "date_end_df_train:\n",
      "2023-12-20\n",
      "````````````````````````````````````````````````````````````\n",
      "\n",
      "\n",
      "0, grp_top_set_syms_n_freq:\n",
      "[[('GPS', 8), ('SHV', 8), ('FTSM', 7), ('ANF', 5), ('HIBB', 5), ('SQ', 5), ('X', 5), ('LRN', 4), ('M', 4), ('MARA', 4), ('MBI', 4), ('VRNS', 4), ('BA', 3), ('BPMC', 3), ('FFWM', 3), ('GBTC', 3), ('GDDY', 3), ('HA', 3), ('HRB', 3), ('IBP', 3)]]\n",
      "0, top_set_syms_n_freq:\n",
      "[('GPS', 8), ('SHV', 8), ('FTSM', 7), ('ANF', 5), ('HIBB', 5), ('SQ', 5), ('X', 5), ('LRN', 4), ('M', 4), ('MARA', 4), ('MBI', 4), ('VRNS', 4), ('BA', 3), ('BPMC', 3), ('FFWM', 3), ('GBTC', 3), ('GDDY', 3), ('HA', 3), ('HRB', 3), ('IBP', 3)]\n",
      "0, l_sym_freq_cnt:\n",
      "[[], [], [], [], [], [], [], ['GPS', 'SHV'], ['FTSM'], [], ['ANF', 'HIBB', 'SQ', 'X'], ['LRN', 'M', 'MARA', 'MBI', 'VRNS'], ['BA', 'BPMC', 'FFWM', 'GBTC', 'GDDY', 'HA', 'HRB', 'IBP'], []]\n",
      "\n",
      "row_picks_total: ['2023-12-20', 120, '[30, 60, 120]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', \"['GPS', 'SHV']\", \"['FTSM']\", '[]', \"['ANF', 'HIBB', 'SQ', 'X']\", \"['LRN', 'M', 'MARA', 'MBI', 'VRNS']\", \"['BA', 'BPMC', 'FFWM', 'GBTC', 'GDDY', 'HA', 'HRB', 'IBP']\", '[]']\n",
      "appended row_picks_total to df_picks:\n",
      "['2023-12-20', 120, '[30, 60, 120]', '[]', '[]', '[]', '[]', '[]', '[]', '[]', \"['GPS', 'SHV']\", \"['FTSM']\", '[]', \"['ANF', 'HIBB', 'SQ', 'X']\", \"['LRN', 'M', 'MARA', 'MBI', 'VRNS']\", \"['BA', 'BPMC', 'FFWM', 'GBTC', 'GDDY', 'HA', 'HRB', 'IBP']\", '[]']\n",
      "\n",
      "End of For_Loop  1 of 2 loops    ========================================\n",
      "\n",
      "\n",
      "Start of For_Loop  2 of 2 loops  ========================================\n",
      "i: 2\n",
      "drop_last_n_rows: 0\n",
      "date_missing_in_df_picks: 2023-12-20\n",
      "days_lookbacks: [15, 30, 60, 120]\n",
      "\n",
      "2 of 2 days_lookbacks: [15, 30, 60, 120] in l_sorted_days_lookbacks: [[30, 60, 120], [15, 30, 60, 120]]\n",
      "max_days_lookbacks: 120\n",
      "\n",
      "dropped last 0 row(s) from df since drop_last_n_rows = 0\n",
      "df.head(1):\n",
      "                    A        AA   AAL        AAP        AAPL         AB        ABBV        ABR         ABT       ACGL       ACHC       ACIW        ACLS   ACRS        ADBE  ...        XRX         XYL       YELP         YUM       YUMC         YY         ZBH        ZBRA         ZD         ZG       ZION    ZTO         ZTS   ZUMZ        ZWS\n",
      "Date                                                                                                                                                                        ...                                                                                                                                                                  \n",
      "2023-07-03  119.07991  34.02372  18.1  70.354485  191.947586  31.305861  132.206345  14.204214  106.120781  73.989998  79.190002  23.299999  181.740005  10.47  485.209991  ...  14.802627  111.105598  36.529999  135.986664  57.163639  31.601398  142.201187  296.269989  70.099998  50.290001  27.482635  25.15  169.450729  17.24  26.653244\n",
      "\n",
      "[1 rows x 1270 columns]\n",
      "\n",
      "df.tail(1):\n",
      "                     A     AA    AAL        AAP        AAPL         AB        ABBV    ABR         ABT       ACGL       ACHC       ACIW        ACLS   ACRS        ADBE  ...        XRX         XYL       YELP         YUM   YUMC     YY    ZBH        ZBRA         ZD     ZG       ZION    ZTO         ZTS   ZUMZ        ZWS\n",
      "Date                                                                                                                                                                   ...                                                                                                                                                 \n",
      "2023-12-20  138.179993  30.65  13.98  59.450001  194.830002  31.620001  151.690002  15.49  107.400002  73.610001  75.660004  29.690001  128.740005  0.935  596.059998  ...  18.290001  109.669998  47.599998  129.039993  40.43  39.84  120.0  261.609985  66.190002  55.48  42.540001  19.92  194.630005  18.85  29.629999\n",
      "\n",
      "[1 rows x 1270 columns]\n",
      "\n",
      "date_last_index: 2023-12-20\n",
      "Passed Error Check: date_missing_in_df_picks 2023-12-20 == date_last_index 2023-12-20\n",
      "len_df: 120, len_slice: 120\n",
      "\n",
      "\n",
      "########## 1 of 1 lb_slices in sets_lookback_slices ##########\n",
      "\n",
      "Output from function best_perf_syms_sets_lookback_slices\n",
      "````````````````````````````````````````````````````````````\n",
      "sets_lookback_slices: [[(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)]]\n",
      "\n",
      "grp_top_set_syms_n_freq:\n",
      "[[('SHV', 10), ('GPS', 8), ('FTSM', 7), ('MBI', 7), ('FFWM', 6), ('HA', 6), ('MARA', 6), ('X', 6), ('ANF', 5), ('HIBB', 5), ('SQ', 5), ('HPP', 4), ('LC', 4), ('LRN', 4), ('M', 4), ('PRAA', 4), ('TNDM', 4), ('VRNS', 4), ('WOR', 4), ('XRX', 4)]]\n",
      "\n",
      "grp_top_set_syms:\n",
      "[['SHV', 'GPS', 'FTSM', 'MBI', 'FFWM', 'HA', 'MARA', 'X', 'ANF', 'HIBB']]\n",
      "\n",
      "date_end_df_train:\n",
      "2023-12-20\n",
      "````````````````````````````````````````````````````````````\n",
      "\n",
      "\n",
      "0, grp_top_set_syms_n_freq:\n",
      "[[('SHV', 10), ('GPS', 8), ('FTSM', 7), ('MBI', 7), ('FFWM', 6), ('HA', 6), ('MARA', 6), ('X', 6), ('ANF', 5), ('HIBB', 5), ('SQ', 5), ('HPP', 4), ('LC', 4), ('LRN', 4), ('M', 4), ('PRAA', 4), ('TNDM', 4), ('VRNS', 4), ('WOR', 4), ('XRX', 4)]]\n",
      "0, top_set_syms_n_freq:\n",
      "[('SHV', 10), ('GPS', 8), ('FTSM', 7), ('MBI', 7), ('FFWM', 6), ('HA', 6), ('MARA', 6), ('X', 6), ('ANF', 5), ('HIBB', 5), ('SQ', 5), ('HPP', 4), ('LC', 4), ('LRN', 4), ('M', 4), ('PRAA', 4), ('TNDM', 4), ('VRNS', 4), ('WOR', 4), ('XRX', 4)]\n",
      "0, l_sym_freq_cnt:\n",
      "[[], [], [], [], [], ['SHV'], [], ['GPS'], ['FTSM', 'MBI'], ['FFWM', 'HA', 'MARA', 'X'], ['ANF', 'HIBB', 'SQ'], ['HPP', 'LC', 'LRN', 'M', 'PRAA', 'TNDM', 'VRNS', 'WOR', 'XRX'], [], []]\n",
      "\n",
      "row_picks_total: ['2023-12-20', 120, '[15, 30, 60, 120]', '[]', '[]', '[]', '[]', '[]', \"['SHV']\", '[]', \"['GPS']\", \"['FTSM', 'MBI']\", \"['FFWM', 'HA', 'MARA', 'X']\", \"['ANF', 'HIBB', 'SQ']\", \"['HPP', 'LC', 'LRN', 'M', 'PRAA', 'TNDM', 'VRNS', 'WOR', 'XRX']\", '[]', '[]']\n",
      "appended row_picks_total to df_picks:\n",
      "['2023-12-20', 120, '[15, 30, 60, 120]', '[]', '[]', '[]', '[]', '[]', \"['SHV']\", '[]', \"['GPS']\", \"['FTSM', 'MBI']\", \"['FFWM', 'HA', 'MARA', 'X']\", \"['ANF', 'HIBB', 'SQ']\", \"['HPP', 'LC', 'LRN', 'M', 'PRAA', 'TNDM', 'VRNS', 'WOR', 'XRX']\", '[]', '[]']\n",
      "\n",
      "End of For_Loop  2 of 2 loops    ========================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_current = df_close_clean.copy()\n",
    "\n",
    "# list to store the last df date\n",
    "l_date_last_index = []\n",
    "\n",
    "# list to sore date in zipped dates_missing_in_df_picks\n",
    "l_date_missing_in_df_picks = []\n",
    "\n",
    "# total number of iteration\n",
    "i_total = len(l_days_to_drop) * len(l_sorted_days_lookbacks)\n",
    "\n",
    "for i, values in enumerate(itertools.product(zip(l_days_to_drop, dates_missing_in_df_picks), l_sorted_days_lookbacks)):\n",
    "    print(f'Start of For_Loop  {i+1} of {i_total} loops{\"=\"*40:>42}')\n",
    "    drop_last_n_rows = values[0][0]\n",
    "    date_missing_in_df_picks = values[0][1] \n",
    "    days_lookbacks = values[1]\n",
    "    l_date_missing_in_df_picks.append(date)\n",
    " \n",
    "    print(f'i: {i+1}')    \n",
    "    print(f'drop_last_n_rows: {drop_last_n_rows}') \n",
    "    print(f'date_missing_in_df_picks: {date_missing_in_df_picks}')\n",
    "    print(f'days_lookbacks: {days_lookbacks}\\n')\n",
    "    print(f'{i+1} of {len(l_sorted_days_lookbacks)} days_lookbacks: {days_lookbacks} in l_sorted_days_lookbacks: {l_sorted_days_lookbacks}')    \n",
    "\n",
    "    # drops df rows by drop_last_n_rows, limits df length to max_days_lookbacks \n",
    "    # e.g. days_lookbacks: [15, 30, 60, 120] => max_days_lookbacks: 120\n",
    "    max_days_lookbacks = max(days_lookbacks)\n",
    "    print(f\"max_days_lookbacks: {max_days_lookbacks}\\n\")\n",
    "    slice_start = -(max_days_lookbacks + drop_last_n_rows)\n",
    "    slice_end = -drop_last_n_rows\n",
    "    if drop_last_n_rows == 0:  # return df with all rows\n",
    "        df = df_current[slice_start:].copy()\n",
    "    else:  # return df with dropped drop_last_n_rows rows\n",
    "        df = df_current[slice_start:slice_end].copy()\n",
    "    print(f\"dropped last {drop_last_n_rows} row(s) from df since drop_last_n_rows = {drop_last_n_rows}\")\n",
    "    print(f\"df.head(1):\\n{df.head(1)}\\n\")\n",
    "    print(f\"df.tail(1):\\n{df.tail(1)}\\n\")\n",
    "\n",
    "    date_last_index = df.index[-1].strftime('%Y-%m-%d')\n",
    "    print(f'date_last_index: {date_last_index}')\n",
    "\n",
    "    # Error check\n",
    "    if date_missing_in_df_picks == date_last_index:\n",
    "        print(f\"Passed Error Check: date_missing_in_df_picks {date_missing_in_df_picks} == date_last_index {date_last_index}\")  \n",
    "    else:\n",
    "        print(\"ERROR: date_missing_in_df_picks != date_last_index\")\n",
    "        print(f'date_missing_in_df_picks: {date_missing_in_df_picks}')\n",
    "        print(f'date_last_index: {date_last_index}')\n",
    "        sys.exit(1)  \n",
    "\n",
    "    l_date_last_index.append(date_last_index)\n",
    "    len_df = len(df)\n",
    "    len_slice = slice_end - slice_start\n",
    "    # print(f\"len(df): {len(df)}\\n\")\n",
    "    print(f\"len_df: {len_df}, len_slice: {len_slice}\\n\")    \n",
    "\n",
    "    # Since df rows has been sliced to max_days_lookbacks,\n",
    "    #   n_samples > 1, will always return more copies of the same slice. \n",
    "    # Returns a list of random tuples of start_train, end_train, end_eval,\n",
    "    # where iloc[start_train:end_train] is used for training,\n",
    "    # and iloc[end_train:end_eval] is used for evaluation.  The length of the\n",
    "    # list is equal to n_samples.\n",
    "    max_lookback_slices = random_slices(\n",
    "        len_df = len_df,\n",
    "        n_samples=n_samples,\n",
    "        days_lookback=max(days_lookbacks),\n",
    "        days_eval=days_eval,\n",
    "        verbose=False,\n",
    "    )    \n",
    "\n",
    "    # Create sets of sub-slices from max_slices and days_lookbacks. A slice is\n",
    "    # a tuple of iloc values for start_train:end_train=start_eval:end_eval.\n",
    "    # Given 2 max_slices of [(104, 224, 234), (626, 746, 756)], it returns 2 sets\n",
    "    # [[(194, 224, 234), (164, 224, 234), (104, 224, 234)],\n",
    "    # [(716, 746, 756), (686, 746, 756), (626, 746, 756)]]. End_train is constant\n",
    "    # for each set. End_train - start_train is the value of the maximum slice.     \n",
    "    sets_lookback_slices = lookback_slices(\n",
    "        max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"number of random samples of max_lookback_slices taken is n_samples = {n_samples}\")\n",
    "        print(f\"max_lookback_slices: {max_lookback_slices}\\n\")\n",
    "        print(f\"days_lookbacks: {days_lookbacks}\")\n",
    "        print(f\"sets_lookback_slices, e.g. (start_train:end_train:end_eval): {sets_lookback_slices}\\n\")\n",
    "\n",
    "        print(f\"number of sets in sets_lookback_slices is equal to n_samples = {n_samples}\")\n",
    "        print(\n",
    "            f'number of tuples in each \"set of lookback slices\" is equal to len(days_lookbacks): {len(days_lookbacks)}'\n",
    "        )\n",
    "\n",
    "    # If given:\n",
    "    #  performance metric: r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "    #  l_sorted_days_lookbacks: [[30, 60, 120], [15, 30, 60, 120]]\n",
    "    #   => days_lookbacks: [30, 60, 120]\n",
    "    #    => sets_lookback_slices: [[(90, 120, 120), (60, 120, 120), (0, 120, 120)]]\n",
    "    # Then, grp_top_set_syms_n_freq is a list of lists of the top n_top_syms of the\n",
    "    # best performing symbols and their number of occurrence for sets_lookback_slices.\n",
    "    # The list of lists corresponds to days_lookbacks in l_sorted_days_lookbacks.  \n",
    "    #  e.g. grp_top_set_syms_n_freq:\n",
    "    #   [[('GPS', 8), ('SHV', 8), ('FTSM', 7), ('GBTC', 7), ('BTC-USD', 6), ('CBOE', 6), ('ANF', 5), ('NRG', 5), ('WING', 5), ('DELL', 4), ('EDU', 4), ('HIBB', 4), ('LRN', 4), ('ALL', 3), ('CAH', 3), ('CMG', 3), ('GDDY', 3), ('HRB', 3), ('MDLZ', 3), ('PGR', 3)]]\n",
    "    # grp_top_set_syms is grp_top_set_syms_n_freq with number of occurrence dropped\n",
    "    #   e.g. [['GPS', 'SHV', 'FTSM', 'GBTC', 'BTC-USD', 'CBOE', 'ANF', 'NRG', 'WING', 'DELL']]\n",
    "    # date_end_df_train, e.g. 2023-11-22\n",
    "    (\n",
    "        grp_top_set_syms_n_freq,\n",
    "        grp_top_set_syms,\n",
    "        date_end_df_train,\n",
    "    ) = best_perf_syms_sets_lookback_slices(\n",
    "        df_close=df,\n",
    "        sets_lookback_slices=sets_lookback_slices,\n",
    "        n_top_syms=20,\n",
    "        syms_start=0,\n",
    "        syms_end=10,\n",
    "        verbose=verbose\n",
    "        )\n",
    "\n",
    "    print(f'\\nOutput from function best_perf_syms_sets_lookback_slices')\n",
    "    print(f'{\"`\"*60}')\n",
    "    print(f'sets_lookback_slices: {sets_lookback_slices}\\n')\n",
    "    print(f'grp_top_set_syms_n_freq:\\n{grp_top_set_syms_n_freq}\\n')\n",
    "    print(f'grp_top_set_syms:\\n{grp_top_set_syms}\\n')\n",
    "    print(f'date_end_df_train:\\n{date_end_df_train}')    \n",
    "    print(f'{\"`\"*60}\\n\\n')\n",
    "\n",
    "    for j, top_set_syms_n_freq in enumerate(grp_top_set_syms_n_freq):\n",
    "        # If given top_set_syms_n_freq:\n",
    "        #  [('GPS', 10), ('SHV', 9), ('FTSM', 7), ('GBTC', 7), ('WING', 7), ('CBOE', 6),\n",
    "        #  ('ANF', 5), ('BTC-USD', 5), ('NRG', 5), ('TSEM', 5), ('BURL', 4), ('CRSP', 4),\n",
    "        #  ('EDU', 4), ('GDDY', 4), ('LRN', 4), ('NFLX', 4), ('PI', 4), ('WRB', 4),\n",
    "        #  ('AXGN', 3), ('CAH', 3)]\n",
    "        # Then, l_sym_freq_cnt, where symbol frequency count is from 15, 14, ..., 2:\n",
    "        #  [[], [], [], [], [], ['GPS'], ['SHV'], [], ['FTSM', 'GBTC', 'WING'], ['CBOE'],\n",
    "        #  ['ANF', 'BTC-USD', 'NRG', 'TSEM'],\n",
    "        #  ['BURL', 'CRSP', 'EDU', 'GDDY', 'LRN', 'NFLX', 'PI', 'WRB'],\n",
    "        #  ['AXGN', 'CAH'], []]\n",
    "        l_sym_freq_cnt = top_set_sym_freq_cnt(top_set_syms_n_freq)\n",
    "        print(f'{j}, grp_top_set_syms_n_freq:\\n{grp_top_set_syms_n_freq}')\n",
    "        print(f'{j}, top_set_syms_n_freq:\\n{top_set_syms_n_freq}')\n",
    "        print(f'{j}, l_sym_freq_cnt:\\n{l_sym_freq_cnt}\\n')                \n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"set_lookback_slices: {sets_lookback_slices[j]}\")\n",
    "            print(f\"max_lookback_slices: {max_lookback_slices}\\n\")\n",
    "            print(f\"data below will be added to {fp_df_picks}\")\n",
    "            print(f\"date_end_df_train:   {date_end_df_train}\")\n",
    "            print(f\"max_days_lookbacks:  {max_days_lookbacks}\")\n",
    "            print(f\"days_lookbacks:      {days_lookbacks}\")\n",
    "            print(f\"sym_freq_15:         {l_sym_freq_cnt[0]}\")\n",
    "            print(f\"sym_freq_14:         {l_sym_freq_cnt[1]}\")\n",
    "            print(f\"sym_freq_13:         {l_sym_freq_cnt[2]}\")\n",
    "            print(f\"sym_freq_12:         {l_sym_freq_cnt[3]}\")\n",
    "            print(f\"sym_freq_11:         {l_sym_freq_cnt[4]}\")\n",
    "            print(f\"sym_freq_10:         {l_sym_freq_cnt[5]}\")\n",
    "            print(f\"sym_freq_9:          {l_sym_freq_cnt[6]}\")\n",
    "            print(f\"sym_freq_8:          {l_sym_freq_cnt[7]}\")\n",
    "            print(f\"sym_freq_7:          {l_sym_freq_cnt[8]}\")\n",
    "            print(f\"sym_freq_6:          {l_sym_freq_cnt[9]}\")\n",
    "            print(f\"sym_freq_5:          {l_sym_freq_cnt[10]}\")\n",
    "            print(f\"sym_freq_4:          {l_sym_freq_cnt[11]}\")\n",
    "            print(f\"sym_freq_3:          {l_sym_freq_cnt[12]}\")\n",
    "            print(f\"sym_freq_2:          {l_sym_freq_cnt[13]}\\n\")\n",
    "\n",
    "    if store_results:\n",
    "        row_picks0 = [date_end_df_train, max_days_lookbacks, str(days_lookbacks)]\n",
    "        row_picks1 = [\n",
    "            str(l_sym_freq_cnt[0]),\n",
    "            str(l_sym_freq_cnt[1]),\n",
    "            str(l_sym_freq_cnt[2]),\n",
    "            str(l_sym_freq_cnt[3]),\n",
    "        ]\n",
    "        row_picks2 = [\n",
    "            str(l_sym_freq_cnt[4]),\n",
    "            str(l_sym_freq_cnt[5]),\n",
    "            str(l_sym_freq_cnt[6]),\n",
    "            str(l_sym_freq_cnt[7]),\n",
    "        ]\n",
    "        row_picks3 = [\n",
    "            str(l_sym_freq_cnt[8]),\n",
    "            str(l_sym_freq_cnt[9]),\n",
    "            str(l_sym_freq_cnt[10]),\n",
    "            str(l_sym_freq_cnt[11]),\n",
    "        ]\n",
    "        row_picks4 = [str(l_sym_freq_cnt[12]), str(l_sym_freq_cnt[13])]\n",
    "        row_picks_total = row_picks0 + row_picks1 + row_picks2 + row_picks3 + row_picks4\n",
    "        print(f\"row_picks_total: {row_picks_total}\")\n",
    "\n",
    "        df_picks.loc[len(df_picks)] = row_picks_total\n",
    "        pickle_dump(df_picks, path_data_dump, fp_df_picks)\n",
    "        print(f\"appended row_picks_total to df_picks:\\n{row_picks_total}\\n\")\n",
    "\n",
    "    print(f'End of For_Loop  {i+1} of {i_total} loops{\"=\"*40:>44}\\n\\n')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
