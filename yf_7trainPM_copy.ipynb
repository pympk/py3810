{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.wrighters.io/parameters-jupyter-notebooks-with-papermill/\n",
    "import papermill as pm\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose = True  # True prints more output\n",
    "verbose = False  # True prints more output\n",
    "\n",
    "# write run results to df_eval_results\n",
    "# store_results = False\n",
    "store_results = True\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "\n",
    "syms_start = 0  #  start index of n_top_syms for evaluation\n",
    "syms_end = 10  #  end index of n_top_syms for evaluation\n",
    "\n",
    "# number of max lookback tuples to create\n",
    "n_samples_train = 400  # default samples for train\n",
    "# n_samples_train = 12  # debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_types = ['train', 'validate', 'test']\n",
    "\n",
    "# l_days_eval = [4, 5, 6] \n",
    "l_days_eval = [4, 5] \n",
    "# l_days_eval = [4] \n",
    "\n",
    "l_days_lookbacks = [\n",
    "    [15],\n",
    "    # [30],\n",
    "    # [60],\n",
    "    # [120],\n",
    "    [15, 30],\n",
    "    # [30, 60],\n",
    "    # [60, 120],\n",
    "    # [15, 30, 60],\n",
    "    # [30, 60, 120],\n",
    "    # [15, 30, 60, 120],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': False,\n",
       " 'store_results': True,\n",
       " 'n_top_syms': 20,\n",
       " 'syms_start': 0,\n",
       " 'syms_end': 10}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_params = dict(\n",
    "                  verbose=verbose,\n",
    "                  store_results=store_results,\n",
    "                  n_top_syms=n_top_syms,\n",
    "                  syms_start=syms_start,\n",
    "                  syms_end=syms_end,\n",
    "                  )\n",
    "\n",
    "run_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = len(list(product(run_types, l_days_eval, l_days_lookbacks)))\n",
    "len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train', 4, [15]),\n",
       " ('train', 4, [15, 30]),\n",
       " ('train', 5, [15]),\n",
       " ('train', 5, [15, 30]),\n",
       " ('validate', 4, [15]),\n",
       " ('validate', 4, [15, 30]),\n",
       " ('validate', 5, [15]),\n",
       " ('validate', 5, [15, 30]),\n",
       " ('test', 4, [15]),\n",
       " ('test', 4, [15, 30]),\n",
       " ('test', 5, [15]),\n",
       " ('test', 5, [15, 30])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(product(run_types, l_days_eval, l_days_lookbacks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the run parameters before running. It will take about 1 hour and 20 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 1.5 hrs to run 90 iteration\n",
    "len_list = len(list(product(run_types, l_days_eval, l_days_lookbacks)))\n",
    "\n",
    "i = 1\n",
    "for run_type, days_eval, days_lookbacks in list(product(run_types, l_days_eval, l_days_lookbacks)):\n",
    "  # use n_samples_train to scale n_samples of other run_types \n",
    "  if run_type == 'train':\n",
    "    n_samples = n_samples_train  # train\n",
    "    fp_df_eval_results = f'df_eval_results_train'    \n",
    "  elif run_type == 'validate':\n",
    "    n_samples = round(n_samples_train * 0.2/0.7)  # validate, proportion to .7,.2,.1 split of train, validate, test\n",
    "    fp_df_eval_results = f'df_eval_results_validate'    \n",
    "  elif run_type == 'test':\n",
    "    n_samples = round(n_samples_train * 0.1/0.7)  # test, proportion to .7,.2,.1 split of train, validate, test  \n",
    "    fp_df_eval_results = f'df_eval_results_test'\n",
    "  elif run_type == 'current':\n",
    "    fp_df_eval_results = 'Not_Applicable'\n",
    "    days_eval = 0  # no need to eval when getting the current picks    \n",
    "    n_samples = 1\n",
    "    # fp_df_eval_results = f'df_eval_results_test'              \n",
    "  else:\n",
    "    n_samples = 2  # debug\n",
    "    fp_df_eval_results = f'df_eval_results' \n",
    "\n",
    "  run_params['run_type'] = run_type\n",
    "  run_params['fp_df_eval_results'] = fp_df_eval_results  \n",
    "  run_params['n_samples'] = n_samples\n",
    "  run_params['days_eval'] = days_eval\n",
    "  run_params['days_lookbacks'] = days_lookbacks\n",
    "\n",
    "  # print(f'run_type: {run_type:<10}    fp_df_eval_results: {fp_df_eval_results:<26}    n_samples: {n_samples:<5.0f}    days_eval: {days_eval:<5.0f}    days_lookbacks: {days_lookbacks}')\n",
    "  print(f'{i:<4} of {len_list}    run_type: {run_type:<10}    fp_df_eval_results: {fp_df_eval_results:<26}    n_samples: {n_samples:<5.0f}    days_eval: {days_eval:<5.0f}    days_lookbacks: {days_lookbacks}')\n",
    "\n",
    "  res = pm.execute_notebook(\n",
    "    'yf_7train.ipynb',\n",
    "    'yf_7trainPM_out.ipynb',    \n",
    "    parameters = run_params \n",
    "  )\n",
    "\n",
    "  i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from myUtils import pickle_load\n",
    "# path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "# path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "# # df = pickle_load(path_data_dump, 'df_eval_results_train')\n",
    "# # df = pickle_load(path_data_dump, 'df_eval_results_validate')\n",
    "# # df = pickle_load(path_data_dump, 'df_eval_results_test')\n",
    "# df = pickle_load(path_data_dump, 'df_picks')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tbl_concat.loc[tbl_concat['run_type'] == 'train']\n",
    "# df.loc[df['date_end_df_train'] == '2023-03-17', 'sym_freq_9']\n",
    "# # df.loc[df['date_end_df_train'] == '2023-03-17', 'sym_freq_8']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
