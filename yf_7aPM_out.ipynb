{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf23dcb",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [15]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b9acf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:04.601061Z",
     "iopub.status.busy": "2023-03-23T04:04:04.601061Z",
     "iopub.status.idle": "2023-03-23T04:04:04.625062Z",
     "shell.execute_reply": "2023-03-23T04:04:04.624062Z"
    },
    "papermill": {
     "duration": 0.035002,
     "end_time": "2023-03-23T04:04:04.627062",
     "exception": false,
     "start_time": "2023-03-23T04:04:04.592060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_set_sym_freq_cnt(top_set_syms_n_freq):\n",
    "    # accommodate upto 5 periods of days_lookbacks(i.e. days_lookbacks = [5, 10, 15, 20, 25])\n",
    "    sym_freq_cnt_15 = []\n",
    "    sym_freq_cnt_14 = []\n",
    "    sym_freq_cnt_13 = []\n",
    "    sym_freq_cnt_12 = []\n",
    "    sym_freq_cnt_11 = []\n",
    "    sym_freq_cnt_10 = []\n",
    "    sym_freq_cnt_9 = []\n",
    "    sym_freq_cnt_8 = []\n",
    "    sym_freq_cnt_7 = []\n",
    "    sym_freq_cnt_6 = []\n",
    "    sym_freq_cnt_5 = []\n",
    "    sym_freq_cnt_4 = []\n",
    "    sym_freq_cnt_3 = []\n",
    "    sym_freq_cnt_2 = []\n",
    "\n",
    "    for sym_n_freq in top_set_syms_n_freq:\n",
    "        _sym = sym_n_freq[0]\n",
    "        _freq = sym_n_freq[1]\n",
    "        if _freq == 15:\n",
    "            sym_freq_cnt_15.append(_sym)\n",
    "        elif _freq == 14:\n",
    "            sym_freq_cnt_14.append(_sym)\n",
    "        elif _freq == 13:\n",
    "            sym_freq_cnt_13.append(_sym)\n",
    "        elif _freq == 12:\n",
    "            sym_freq_cnt_12.append(_sym)                        \n",
    "        elif _freq == 11:\n",
    "            sym_freq_cnt_11.append(_sym)\n",
    "        elif _freq == 10:\n",
    "            sym_freq_cnt_10.append(_sym)            \n",
    "        elif _freq == 9:\n",
    "            sym_freq_cnt_9.append(_sym)\n",
    "        elif _freq == 8:\n",
    "            sym_freq_cnt_8.append(_sym)\n",
    "        elif _freq == 7:\n",
    "            sym_freq_cnt_7.append(_sym)  \n",
    "        elif _freq == 6:\n",
    "            sym_freq_cnt_6.append(_sym)\n",
    "        elif _freq == 5:\n",
    "            sym_freq_cnt_5.append(_sym)\n",
    "        elif _freq == 4:\n",
    "            sym_freq_cnt_4.append(_sym)\n",
    "        elif _freq == 3:\n",
    "            sym_freq_cnt_3.append(_sym)          \n",
    "        else:\n",
    "            sym_freq_cnt_2.append(_sym)\n",
    "\n",
    "    l_sym_freq_cnt = []\n",
    "\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_15)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_14)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_13)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_12)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_11)   \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_10)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_9)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_8)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_7)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_6)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_5)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_4)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_3)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_2)    \n",
    "\n",
    "    return l_sym_freq_cnt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9d6fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:04.648060Z",
     "iopub.status.busy": "2023-03-23T04:04:04.647064Z",
     "iopub.status.idle": "2023-03-23T04:04:05.481062Z",
     "shell.execute_reply": "2023-03-23T04:04:05.480061Z"
    },
    "papermill": {
     "duration": 0.847003,
     "end_time": "2023-03-23T04:04:05.484064",
     "exception": false,
     "start_time": "2023-03-23T04:04:04.637061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import datetime\n",
    "# from IPython.display import display, HTML\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 16)\n",
    "pd.set_option('display.width', 790)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "fp_df_close_clean = 'df_close_clean'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5807251f",
   "metadata": {
    "papermill": {
     "duration": 0.008001,
     "end_time": "2023-03-23T04:04:05.505065",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.497064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Check run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21f00d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:05.524063Z",
     "iopub.status.busy": "2023-03-23T04:04:05.523061Z",
     "iopub.status.idle": "2023-03-23T04:04:05.529060Z",
     "shell.execute_reply": "2023-03-23T04:04:05.528064Z"
    },
    "papermill": {
     "duration": 0.017001,
     "end_time": "2023-03-23T04:04:05.531061",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.514060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_train)\n",
    "# df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_validate)\n",
    "# df = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "# df = pickle_load(path_data_dump, fp_df_picks)\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ce40223",
   "metadata": {
    "papermill": {
     "duration": 0.008998,
     "end_time": "2023-03-23T04:04:05.549061",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.540063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Select run parameters. Parameters can also be passed using papermill by running yf_7_freq_cnt_pm_.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c826a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:05.568061Z",
     "iopub.status.busy": "2023-03-23T04:04:05.568061Z",
     "iopub.status.idle": "2023-03-23T04:04:05.593062Z",
     "shell.execute_reply": "2023-03-23T04:04:05.592063Z"
    },
    "papermill": {
     "duration": 0.039001,
     "end_time": "2023-03-23T04:04:05.597067",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.558066",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose : True\n",
      "store_results: False\n",
      "run_type: current\n",
      "n_samples: 1\n",
      "days_lookbacks: [30, 60, 120]\n",
      "days_eval: 0\n",
      "n_top_syms: 20\n",
      "syms_start: 0\n",
      "syms_end: 10\n",
      "fp_df_eval_results: df_eval_results_current\n",
      "fp_df_picks: df_picks\n"
     ]
    }
   ],
   "source": [
    "# SELECT RUN PARAMETERS.async Parameters can also be passed using papermill by running yf_7_freq_cnt_pm_.ipynb\n",
    "verbose = True  # True prints more output\n",
    "# verbose = False  # True prints more output\n",
    "\n",
    "# write run results to df_eval_results\n",
    "store_results = False\n",
    "# store_results = True\n",
    "\n",
    "# select run type\n",
    "# run_type = 'train'\n",
    "# run_type = 'validate'\n",
    "# run_type = 'test'\n",
    "run_type = 'current'\n",
    "\n",
    "# number of max lookback tuples to create for iloc iloc_start_train:iloc_end_train:iloc_end_eval\n",
    "# i.e. number of grp_top_set_syms_n_freq and grp_top_set_syms \n",
    "# n_samples = 400  \n",
    "n_samples = 20\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback iloc_end_train\n",
    "days_lookbacks = [30, 60, 120]\n",
    "# days_lookbacks = [15, 30, 60, 120]\n",
    "days_lookbacks.sort()\n",
    "\n",
    "# number of days from iloc_end_train are used to evaluate effectiveness of the training\n",
    "days_eval = 4\n",
    "# days_eval = 5\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "\n",
    "# slice starts and ends for selecting the best performing symbols\n",
    "syms_start = 0\n",
    "syms_end = 10\n",
    "\n",
    "# get picks of previous days by dropping the last n rows from df_current\n",
    "#  drop_last_n_rows = 1 drops the last row from df_current\n",
    "drop_last_n_rows = 0\n",
    "\n",
    "# over-ride parameters for run_type 'current'\n",
    "if run_type == 'current':\n",
    "  days_eval = 0  # no need to eval, df_eval will be empty\n",
    "  n_samples = 1  # no need to repeat sample the current result, repeat sample will yield the same tuple\n",
    "\n",
    "\n",
    "fp_df_eval_results = f'df_eval_results_{run_type}'\n",
    "fp_df_picks = f'df_picks'\n",
    "\n",
    "print(f'verbose : {verbose }')\n",
    "print(f'store_results: {store_results}')\n",
    "print(f'run_type: {run_type}')\n",
    "print(f'n_samples: {n_samples}')\n",
    "print(f'days_lookbacks: {days_lookbacks}')\n",
    "print(f'days_eval: {days_eval}')\n",
    "print(f'n_top_syms: {n_top_syms}')\n",
    "print(f'syms_start: {syms_start}')\n",
    "print(f'syms_end: {syms_end}')\n",
    "print(f'fp_df_eval_results: {fp_df_eval_results}')\n",
    "print(f'fp_df_picks: {fp_df_picks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523c63ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:05.623062Z",
     "iopub.status.busy": "2023-03-23T04:04:05.623062Z",
     "iopub.status.idle": "2023-03-23T04:04:05.641062Z",
     "shell.execute_reply": "2023-03-23T04:04:05.640063Z"
    },
    "papermill": {
     "duration": 0.036998,
     "end_time": "2023-03-23T04:04:05.649060",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.612062",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "verbose = True\n",
    "store_results = True\n",
    "n_top_syms = 20\n",
    "syms_start = 0\n",
    "syms_end = 10\n",
    "run_type = \"current\"\n",
    "fp_df_eval_results = \"Not_Applicable\"\n",
    "n_samples = 1\n",
    "days_eval = 0\n",
    "days_lookbacks = [30, 60, 120]\n",
    "drop_last_n_rows = 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75c82ec0",
   "metadata": {
    "papermill": {
     "duration": 0.053002,
     "end_time": "2023-03-23T04:04:05.801061",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.748059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Load previous run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b8b3be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:05.820062Z",
     "iopub.status.busy": "2023-03-23T04:04:05.819060Z",
     "iopub.status.idle": "2023-03-23T04:04:05.849062Z",
     "shell.execute_reply": "2023-03-23T04:04:05.848060Z"
    },
    "papermill": {
     "duration": 0.041999,
     "end_time": "2023-03-23T04:04:05.852061",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.810062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if run_type != 'current':\n",
    "  df_eval_results = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "\n",
    "df_picks = pickle_load(path_data_dump, fp_df_picks)\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae5fbd",
   "metadata": {
    "papermill": {
     "duration": 0.007,
     "end_time": "2023-03-23T04:04:05.868062",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.861062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Drop the last n row in df_close_clean to get previous picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aaa5a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:05.886061Z",
     "iopub.status.busy": "2023-03-23T04:04:05.886061Z",
     "iopub.status.idle": "2023-03-23T04:04:05.896060Z",
     "shell.execute_reply": "2023-03-23T04:04:05.895060Z"
    },
    "papermill": {
     "duration": 0.021998,
     "end_time": "2023-03-23T04:04:05.898062",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.876064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # drop the last n row(s)\n",
    "# n = 1\n",
    "# df_close_clean = df_close_clean[:-n]\n",
    "# df_close_clean.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22e28845",
   "metadata": {
    "papermill": {
     "duration": 0.009002,
     "end_time": "2023-03-23T04:04:05.943063",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.934061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Split dataframe into Train, Validate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38db433f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:05.961062Z",
     "iopub.status.busy": "2023-03-23T04:04:05.961062Z",
     "iopub.status.idle": "2023-03-23T04:04:05.975065Z",
     "shell.execute_reply": "2023-03-23T04:04:05.974064Z"
    },
    "papermill": {
     "duration": 0.027007,
     "end_time": "2023-03-23T04:04:05.978068",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.951061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split df_close_clean into training (df_train), validation (df_val) and test (df_test) set.\n",
    "# The default split is 0.7, 0.2, 0.1 respectively.\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_close_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62f9aecc",
   "metadata": {
    "papermill": {
     "duration": 0.010999,
     "end_time": "2023-03-23T04:04:05.997061",
     "exception": false,
     "start_time": "2023-03-23T04:04:05.986062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Create df_current, a df with the latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "328a5ba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:06.016062Z",
     "iopub.status.busy": "2023-03-23T04:04:06.016062Z",
     "iopub.status.idle": "2023-03-23T04:04:06.023060Z",
     "shell.execute_reply": "2023-03-23T04:04:06.022061Z"
    },
    "papermill": {
     "duration": 0.021001,
     "end_time": "2023-03-23T04:04:06.026062",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.005061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_days_lookbacks: 120\n"
     ]
    }
   ],
   "source": [
    "max_days_lookbacks = max(days_lookbacks)\n",
    "print(f'max_days_lookbacks: {max_days_lookbacks}')\n",
    "\n",
    "\n",
    "# df_current = df_test.tail(max_days_lookbacks)  \n",
    "df_current = df_test.copy()\n",
    "\n",
    "# df_current.tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24914fee",
   "metadata": {
    "papermill": {
     "duration": 0.009,
     "end_time": "2023-03-23T04:04:06.045061",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.036061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Load df according to run_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c42559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:06.063060Z",
     "iopub.status.busy": "2023-03-23T04:04:06.062061Z",
     "iopub.status.idle": "2023-03-23T04:04:06.102064Z",
     "shell.execute_reply": "2023-03-23T04:04:06.101064Z"
    },
    "papermill": {
     "duration": 0.052999,
     "end_time": "2023-03-23T04:04:06.106062",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.053063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_type: current\n",
      "dropped last 0 row(s) from df\n",
      "df.tail():\n",
      "                     A         AA    AAL         AAP        AAPL         AB        ABB        ABBV         ABC        ABM    ABR        ABT       ACGL       ACHC       ACIW  ...       XRAY    XRX        XYL       YELP       YUMC         YY         ZBH        ZBRA         ZD         ZG       ZION        ZTO         ZTS       ZUMZ        ZWS\n",
      "Date                                                                                                                                                                          ...                                                                                                                                                                    \n",
      "2023-03-16  136.820007  40.750000  14.12  122.029999  155.850006  35.310001  32.549999  155.300003  152.050003  44.790001  11.50  99.029999  66.070000  70.230003  25.780001  ...  37.439999  15.20  97.160004  29.780001  60.980000  28.000000  125.430000  294.929993  74.510002  40.849998  32.110001  28.000000  166.309998  19.250000  20.969999\n",
      "2023-03-17  133.179993  39.150002  13.98  119.400002  155.000000  34.980000  31.990000  154.220001  152.020004  43.730000  11.19  97.010002  63.150002  69.459999  26.940001  ...  36.880001  14.62  94.730003  29.330000  60.720001  28.830000  124.309998  288.709991  74.129997  39.810001  29.940001  28.450001  164.470001  18.540001  20.530001\n",
      "2023-03-20  134.539993  40.279999  13.96  118.680000  157.399994  35.130001  32.560001  156.119995  153.860001  44.119999  11.82  97.870003  65.610001  70.449997  26.150000  ...  36.990002  14.85  97.650002  29.690001  60.950001  29.150000  126.330002  290.839996  74.650002  39.830002  30.180000  28.020000  165.820007  18.110001  20.830000\n",
      "2023-03-21  137.009995  41.910000  14.37  119.790001  159.279999  35.459999  33.270000  156.770004  156.039993  44.220001  11.91  98.330002  67.209999  70.959999  26.200001  ...  37.709999  15.30  98.519997  30.059999  61.169998  28.590000  127.790001  294.429993  75.570000  41.939999  32.290001  28.230000  166.240005  18.549999  21.180000\n",
      "2023-03-22  133.729996  40.060001  13.82  113.599998  157.830002  33.930000  33.119999  153.669998  153.440002  43.020000  11.14  96.860001  65.870003  69.800003  25.570000  ...  36.380001  14.85  97.570000  29.860001  62.520000  29.540001  125.389999  288.109985  73.790001  41.270000  30.120001  28.270000  161.380005  17.920000  20.270000\n",
      "\n",
      "[5 rows x 1322 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if run_type == 'train':\n",
    "  df = df_train.copy()    \n",
    "elif run_type == 'validate':\n",
    "  df = df_val.copy()\n",
    "elif run_type == 'test':\n",
    "  df = df_test.copy()\n",
    "elif run_type == 'current':  # get the current picks\n",
    "  print(f'run_type: current')\n",
    "  slice_start = -(max_days_lookbacks + drop_last_n_rows)  \n",
    "  slice_end = -drop_last_n_rows\n",
    "  if drop_last_n_rows == 0:  # return df with all rows\n",
    "    df = df_current[slice_start:].copy()\n",
    "\n",
    "\n",
    "  else:  # return df with dropped drop_last_n_rows rows  \n",
    "    df = df_current[slice_start:slice_end].copy()            \n",
    "\n",
    "\n",
    "  print(f'dropped last {drop_last_n_rows} row(s) from df')          \n",
    "  print(f'df.tail():\\n{df.tail()}\\n')\n",
    "else:\n",
    "  msg_stop = f\"ERROR run_type must be 'train', 'validate', 'test' or 'current', run_type is: {run_type}\"\n",
    "  raise SystemExit(msg_stop )  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbfb1460",
   "metadata": {
    "papermill": {
     "duration": 0.010001,
     "end_time": "2023-03-23T04:04:06.139062",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.129061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Print dataframe for the run, and lengths of other dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c17dff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:06.159060Z",
     "iopub.status.busy": "2023-03-23T04:04:06.158065Z",
     "iopub.status.idle": "2023-03-23T04:04:06.181063Z",
     "shell.execute_reply": "2023-03-23T04:04:06.180063Z"
    },
    "papermill": {
     "duration": 0.035998,
     "end_time": "2023-03-23T04:04:06.184061",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.148063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_type: current, df.tail(3):\n",
      "                     A         AA    AAL         AAP        AAPL         AB        ABB        ABBV         ABC        ABM    ABR        ABT       ACGL       ACHC       ACIW  ...       XRAY    XRX        XYL       YELP       YUMC         YY         ZBH        ZBRA         ZD         ZG       ZION    ZTO         ZTS       ZUMZ    ZWS\n",
      "Date                                                                                                                                                                          ...                                                                                                                                                            \n",
      "2023-03-20  134.539993  40.279999  13.96  118.680000  157.399994  35.130001  32.560001  156.119995  153.860001  44.119999  11.82  97.870003  65.610001  70.449997  26.150000  ...  36.990002  14.85  97.650002  29.690001  60.950001  29.150000  126.330002  290.839996  74.650002  39.830002  30.180000  28.02  165.820007  18.110001  20.83\n",
      "2023-03-21  137.009995  41.910000  14.37  119.790001  159.279999  35.459999  33.270000  156.770004  156.039993  44.220001  11.91  98.330002  67.209999  70.959999  26.200001  ...  37.709999  15.30  98.519997  30.059999  61.169998  28.590000  127.790001  294.429993  75.570000  41.939999  32.290001  28.23  166.240005  18.549999  21.18\n",
      "2023-03-22  133.729996  40.060001  13.82  113.599998  157.830002  33.930000  33.119999  153.669998  153.440002  43.020000  11.14  96.860001  65.870003  69.800003  25.570000  ...  36.380001  14.85  97.570000  29.860001  62.520000  29.540001  125.389999  288.109985  73.790001  41.270000  30.120001  28.27  161.380005  17.920000  20.27\n",
      "\n",
      "[3 rows x 1322 columns]\n",
      "\n",
      "run_type: current, len(df): 120\n",
      "len_df_train: 1050, len_df_val: 300, len_df_test: 150, len_df_current: 150 \n"
     ]
    }
   ],
   "source": [
    "print(f'run_type: {run_type}, df.tail(3):\\n{df.tail(3)}\\n')\n",
    "len_df = len(df)\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)\n",
    "len_df_current = len(df_current)\n",
    "print(f'run_type: {run_type}, len(df): {len(df)}')\n",
    "print(f'len_df_train: {len_df_train}, len_df_val: {len_df_val}, len_df_test: {len_df_test}, len_df_current: {len_df_current} ')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6f20c65",
   "metadata": {
    "papermill": {
     "duration": 0.006998,
     "end_time": "2023-03-23T04:04:06.200060",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.193062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Create a sets of iloc lookback slices (iloc_start_train:iloc_end_train:iloc_end_eval), where:  \n",
    "* iloc_end_train - iloc_start_train = days_lookback\n",
    "* iloc_end_eval - iloc_end_train = days_eval  \n",
    "#### for example, if given:  \n",
    "* n_samples = 2  \n",
    "* days_lookbacks = [10, 20, 30]  \n",
    "* days_eval = 5  \n",
    "#### a possible result is:  \n",
    "  - max_lookback_slices: [(417, 447, 452), (265, 295, 300)], where:\n",
    "    - len(max_lookback_slices) = n_samples = 2\n",
    "    - middle number in the tuples, 447 and 295, is the iloc of the \"pivot day\" for the days in \"days_lookbacks\" to lookback\n",
    "    - 447 - 417 = middle number - first number = max(days_lookbacks) = 30\n",
    "    - 295 - 265 = middle number - first number = max(days_lookbacks) = 30      \n",
    "    - 452 - 447 = last number - middle number = days_eval = 5\n",
    "    - 300 - 295 = last number - middle number = days_eval = 5    \n",
    "  - sets_lookback_slices: [[(437, 447, 452), (427, 447, 452), (417, 447, 452)], [(285, 295, 300), (275, 295, 300), (265, 295, 300)]], where:\n",
    "    - len(sets_lookback_slices) = n_samples = 2\n",
    "    - last tuple in each list, i.e. (417, 447, 452) and (265, 295, 300), is a tuple from max_lookback_slices\n",
    "    - where a set, e.g. [(437, 447, 452), (427, 447, 452), (417, 447, 452)]:\n",
    "      - middle number, 447, iloc of the \"pivot day\" is constant for that set\n",
    "      - middle number - first number, is the training period specified in days_lookbacks\n",
    "        - 447 - 437 = middle number - first number = days_lookbacks[0] = 10\n",
    "        - 447 - 427 = middle number - first number = days_lookbacks[1] = 20\n",
    "        - 447 - 417 = middle number - first number = days_lookbacks[2] = 30\n",
    "      - last number, 452, iloc of the end of the evaluation period is constant\n",
    "        - 452 - 447 = last number - middle number = days_eval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b507e0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:06.221063Z",
     "iopub.status.busy": "2023-03-23T04:04:06.221063Z",
     "iopub.status.idle": "2023-03-23T04:04:06.229062Z",
     "shell.execute_reply": "2023-03-23T04:04:06.228062Z"
    },
    "papermill": {
     "duration": 0.023003,
     "end_time": "2023-03-23T04:04:06.233064",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.210061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of max_lookback_slices is equal to n_samples = 1\n",
      "max_lookback_slices:\n",
      "[(0, 120, 120)]\n",
      "\n",
      "days_lookbacks: [30, 60, 120]\n",
      "sets_lookback_slices:\n",
      "[[(90, 120, 120), (60, 120, 120), (0, 120, 120)]]\n",
      "\n",
      "number of sets in sets_lookback_slices is equal to n_samples = 1\n",
      "number of tuples in each \"set of lookback slices\" is equal to len(days_lookbacks): 3\n"
     ]
    }
   ],
   "source": [
    "# return n_samples slices\n",
    "max_lookback_slices = _3_random_slices(len_df, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval, verbose=False)\n",
    "# return n_samples * len(days_lookbacks) slices\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'number of max_lookback_slices is equal to n_samples = {n_samples}')\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}\\n')\n",
    "  print(f'days_lookbacks: {days_lookbacks}')  \n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}\\n')\n",
    "  print(f'number of sets in sets_lookback_slices is equal to n_samples = {n_samples}')\n",
    "  print(f'number of tuples in each \"set of lookback slices\" is equal to len(days_lookbacks): {len(days_lookbacks)}')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0bea8aa",
   "metadata": {
    "papermill": {
     "duration": 0.008001,
     "end_time": "2023-03-23T04:04:06.251062",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.243061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Generate grp_top_set_syms_n_freq. It is a list of sub-lists, e.g.:\n",
    " - [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)], ..., [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "#### grp_top_set_syms_n_freq has n_samples sub-lists. Each sub-list corresponds to a tuple in the max_lookback_slices. Each sub-list has n_top_syms tuples of (symbol, frequency) pairs, and is sorted in descending order of frequency. The frequency is the number of times the symbol appears in the top n_top_syms performance rankings of CAGR/UI, CAGR/retnStd and retnStd/UI.\n",
    "#### Therefore, symbols in the sub-list are the best performing symbols for the periods in days_lookbacks. Each sub-list corresponds to a tuple in max_lookback_slices. There are as many sub-lists as there are tuples in max_lookback_slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "583de435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:06.281063Z",
     "iopub.status.busy": "2023-03-23T04:04:06.280061Z",
     "iopub.status.idle": "2023-03-23T04:04:06.745061Z",
     "shell.execute_reply": "2023-03-23T04:04:06.744060Z"
    },
    "papermill": {
     "duration": 0.487,
     "end_time": "2023-03-23T04:04:06.748062",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.261062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## 1 of 1 lb_slices in sets_lookcak_slices ##########\n",
      "days lookback:       30,  1 of 3 days_lookbacks: [30, 60, 120]\n",
      "lb_slices:           [(90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "lb_slice:            (90, 120, 120)\n",
      "days eval:           0\n",
      "iloc_start_train:    90\n",
      "iloc_end_train:      120\n",
      "date_start_df_train: 2023-02-08\n",
      "date_end_df_train:   2023-03-22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perf_ranks: {'period-30': {'r_CAGR/UI': array(['TA', 'SGEN', 'LNTH', 'HY', 'SHV', 'WST', 'FCN', 'ANET', 'NTRA',\n",
      "       'AMPH', 'FTSM', 'TNK', 'PDFS', 'PERI', 'FSLR', 'GBTC', 'RELX',\n",
      "       'MYGN', 'FIZZ', 'NVDA'], dtype=object), 'r_CAGR/retnStd': array(['TA', 'SGEN', 'HY', 'LNTH', 'TNK', 'ANET', 'PERI', 'WST', 'NTRA',\n",
      "       'SHV', 'FSLR', 'GBTC', 'FCN', 'AMPH', 'MYGN', 'PDFS', 'OR', 'TIMB',\n",
      "       'NVDA', 'FTSM'], dtype=object), 'r_retnStd/UI': array(['TA', 'SGEN', 'SHV', 'LNTH', 'FCN', 'FTSM', 'WST', 'AMPH', 'RELX',\n",
      "       'PDFS', 'NTRA', 'ATCO', 'GE', 'CHT', 'LAUR', 'HY', 'FIZZ', 'IRBT',\n",
      "       'TWNK', 'FSLR'], dtype=object)}}\n",
      "most_freq_syms: [('TA', 3), ('SGEN', 3), ('LNTH', 3), ('HY', 3), ('SHV', 3), ('WST', 3), ('FCN', 3), ('NTRA', 3), ('AMPH', 3), ('FTSM', 3), ('PDFS', 3), ('FSLR', 3), ('ANET', 2), ('TNK', 2), ('PERI', 2), ('GBTC', 2), ('RELX', 2), ('MYGN', 2), ('FIZZ', 2), ('NVDA', 2), ('OR', 1), ('TIMB', 1), ('ATCO', 1), ('GE', 1), ('CHT', 1), ('LAUR', 1), ('IRBT', 1), ('TWNK', 1)]\n",
      "+++ finish lookback slice 30 +++\n",
      "\n",
      "days lookback:       60,  2 of 3 days_lookbacks: [30, 60, 120]\n",
      "lb_slices:           [(90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "lb_slice:            (60, 120, 120)\n",
      "days eval:           0\n",
      "iloc_start_train:    60\n",
      "iloc_end_train:      120\n",
      "date_start_df_train: 2022-12-23\n",
      "date_end_df_train:   2023-03-22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perf_ranks: {'period-60': {'r_CAGR/UI': array(['TA', 'SHV', 'NVDA', 'ACLS', 'SGEN', 'LNTH', 'FTSM', 'HY', 'GE',\n",
      "       'PDFS', 'META', 'PERI', 'DCP', 'GBTC', 'BTC-USD', 'WST', 'MARA',\n",
      "       'CRM', 'OLED', 'CRUS'], dtype=object), 'r_CAGR/retnStd': array(['HY', 'ACLS', 'NVDA', 'MARA', 'GBTC', 'META', 'PERI', 'LNTH',\n",
      "       'BTC-USD', 'GE', 'SGEN', 'WBD', 'SHV', 'CRUS', 'CRM', 'COTY',\n",
      "       'AMD', 'PDFS', 'TA', 'ANET'], dtype=object), 'r_retnStd/UI': array(['TA', 'DCP', 'SHV', 'FTSM', 'SGEN', 'LNTH', 'PDFS', 'AMPH', 'FCN',\n",
      "       'GE', 'WST', 'NVDA', 'RVNC', 'ACLS', 'OLED', 'RELX', 'GDEN',\n",
      "       'CPRT', 'MTSI', 'NTRA'], dtype=object)}}\n",
      "most_freq_syms: [('TA', 3), ('SHV', 3), ('NVDA', 3), ('ACLS', 3), ('SGEN', 3), ('LNTH', 3), ('GE', 3), ('PDFS', 3), ('FTSM', 2), ('HY', 2), ('META', 2), ('PERI', 2), ('DCP', 2), ('GBTC', 2), ('BTC-USD', 2), ('WST', 2), ('MARA', 2), ('CRM', 2), ('OLED', 2), ('CRUS', 2), ('WBD', 1), ('COTY', 1), ('AMD', 1), ('ANET', 1), ('AMPH', 1), ('FCN', 1), ('RVNC', 1), ('RELX', 1), ('GDEN', 1), ('CPRT', 1), ('MTSI', 1), ('NTRA', 1)]\n",
      "+++ finish lookback slice 60 +++\n",
      "\n",
      "days lookback:       120,  3 of 3 days_lookbacks: [30, 60, 120]\n",
      "lb_slices:           [(90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "lb_slice:            (0, 120, 120)\n",
      "days eval:           0\n",
      "iloc_start_train:    0\n",
      "iloc_end_train:      120\n",
      "date_start_df_train: 2022-09-29\n",
      "date_end_df_train:   2023-03-22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perf_ranks: {'period-120': {'r_CAGR/UI': array(['SHV', 'FTSM', 'AJRD', 'ELF', 'GE', 'NVO', 'COTY', 'PERI', 'HZNP',\n",
      "       'BURL', 'MCFT', 'OEC', 'STRL', 'RMBS', 'NVDA', 'MLR', 'PKX', 'GVA',\n",
      "       'ACLS', 'OI'], dtype=object), 'r_CAGR/retnStd': array(['SHV', 'FTSM', 'GE', 'ACLS', 'NVDA', 'AXON', 'PERI', 'ELF', 'RMBS',\n",
      "       'HY', 'STRL', 'OEC', 'PKX', 'BURL', 'AJRD', 'COTY', 'THR', 'NVO',\n",
      "       'AIR', 'LSCC'], dtype=object), 'r_retnStd/UI': array(['SHV', 'FTSM', 'AJRD', 'ATCO', 'HZNP', 'NVO', 'ELF', 'MCFT',\n",
      "       'TMHC', 'LW', 'COTY', 'GVA', 'MLR', 'ACGL', 'OI', 'PGR', 'CCEP',\n",
      "       'DCI', 'BA', 'BURL'], dtype=object)}}\n",
      "most_freq_syms: [('SHV', 3), ('FTSM', 3), ('AJRD', 3), ('ELF', 3), ('NVO', 3), ('COTY', 3), ('BURL', 3), ('GE', 2), ('PERI', 2), ('HZNP', 2), ('MCFT', 2), ('OEC', 2), ('STRL', 2), ('RMBS', 2), ('NVDA', 2), ('MLR', 2), ('PKX', 2), ('GVA', 2), ('ACLS', 2), ('OI', 2), ('AXON', 1), ('HY', 1), ('THR', 1), ('AIR', 1), ('LSCC', 1), ('ATCO', 1), ('TMHC', 1), ('LW', 1), ('ACGL', 1), ('PGR', 1), ('CCEP', 1), ('DCI', 1), ('BA', 1)]\n",
      "+++ finish lookback slice 120 +++\n",
      "\n",
      "grp_most_freq_syms: [[('TA', 3), ('SGEN', 3), ('LNTH', 3), ('HY', 3), ('SHV', 3), ('WST', 3), ('FCN', 3), ('NTRA', 3), ('AMPH', 3), ('FTSM', 3), ('PDFS', 3), ('FSLR', 3), ('ANET', 2), ('TNK', 2), ('PERI', 2), ('GBTC', 2), ('RELX', 2), ('MYGN', 2), ('FIZZ', 2), ('NVDA', 2), ('OR', 1), ('TIMB', 1), ('ATCO', 1), ('GE', 1), ('CHT', 1), ('LAUR', 1), ('IRBT', 1), ('TWNK', 1)], [('TA', 3), ('SHV', 3), ('NVDA', 3), ('ACLS', 3), ('SGEN', 3), ('LNTH', 3), ('GE', 3), ('PDFS', 3), ('FTSM', 2), ('HY', 2), ('META', 2), ('PERI', 2), ('DCP', 2), ('GBTC', 2), ('BTC-USD', 2), ('WST', 2), ('MARA', 2), ('CRM', 2), ('OLED', 2), ('CRUS', 2), ('WBD', 1), ('COTY', 1), ('AMD', 1), ('ANET', 1), ('AMPH', 1), ('FCN', 1), ('RVNC', 1), ('RELX', 1), ('GDEN', 1), ('CPRT', 1), ('MTSI', 1), ('NTRA', 1)], [('SHV', 3), ('FTSM', 3), ('AJRD', 3), ('ELF', 3), ('NVO', 3), ('COTY', 3), ('BURL', 3), ('GE', 2), ('PERI', 2), ('HZNP', 2), ('MCFT', 2), ('OEC', 2), ('STRL', 2), ('RMBS', 2), ('NVDA', 2), ('MLR', 2), ('PKX', 2), ('GVA', 2), ('ACLS', 2), ('OI', 2), ('AXON', 1), ('HY', 1), ('THR', 1), ('AIR', 1), ('LSCC', 1), ('ATCO', 1), ('TMHC', 1), ('LW', 1), ('ACGL', 1), ('PGR', 1), ('CCEP', 1), ('DCI', 1), ('BA', 1)]]\n",
      "**** finish lookback slices [(90, 120, 120), (60, 120, 120), (0, 120, 120)] ****\n",
      "\n",
      "top 20 ranked symbols and frequency from set [(90, 120, 120), (60, 120, 120), (0, 120, 120)]:\n",
      "[('SHV', 9), ('FTSM', 8), ('NVDA', 7), ('GE', 6), ('HY', 6), ('LNTH', 6), ('PDFS', 6), ('PERI', 6), ('SGEN', 6), ('TA', 6), ('ACLS', 5), ('WST', 5), ('AMPH', 4), ('COTY', 4), ('FCN', 4), ('GBTC', 4), ('NTRA', 4), ('AJRD', 3), ('ANET', 3), ('BURL', 3)]\n",
      "top 20 ranked symbols from set [(90, 120, 120), (60, 120, 120), (0, 120, 120)]:\n",
      "['SHV', 'FTSM', 'NVDA', 'GE', 'HY', 'LNTH', 'PDFS', 'PERI', 'SGEN', 'TA']\n",
      "===== finish top 20 ranked symbols from days_lookback set [(90, 120, 120), (60, 120, 120), (0, 120, 120)] =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grp_top_set_syms_n_freq is a list of lists of top_set_syms_n_freq, e.g.\n",
    "#   [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)],\n",
    "#    [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "#   where each list is the best performing symbols from a lb_slices, e.g.\n",
    "#     [(483, 513, 523), (453, 513, 523), (393, 513, 523)]  \n",
    "grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "grp_top_set_syms = []  # grp_top_set_syms_n_freq without the frequency count\n",
    "\n",
    "# lb_slices, e.g  [(483, 513, 523), (453, 513, 523), (393, 513, 523)],\n",
    "#  is one max_lookback_slice, e.g. (393, 513, 523), along with\n",
    "#  the remaining slices of the days_lookbacks, e.g. (483, 513, 523), (453, 513, 523)  \n",
    "for i, lb_slices in enumerate(sets_lookback_slices):\n",
    "  print(f'\\n########## {i + 1} of {len(sets_lookback_slices)} lb_slices in sets_lookcak_slices ##########')\n",
    "  # unsorted list of the most frequent symbols in performance metrics of the lb_slices  \n",
    "  grp_most_freq_syms = []\n",
    "  for j, lb_slice in enumerate(lb_slices):  # lb_slice, e.g. (246, 276, 286)\n",
    "    iloc_start_train = lb_slice[0]     # iloc of start of training period\n",
    "    iloc_end_train   = lb_slice[1]     # iloc of end of training period\n",
    "    iloc_start_eval  = iloc_end_train  # iloc of start of evaluation period\n",
    "    iloc_end_eval    = lb_slice[2]     # iloc of end of evaluation period\n",
    "    lookback         = iloc_end_train - iloc_start_train\n",
    "    d_eval           = iloc_end_eval - iloc_start_eval\n",
    "\n",
    "    _df = df.iloc[iloc_start_train:iloc_end_train]\n",
    "    date_start_df_train = _df.index[0].strftime('%Y-%m-%d')\n",
    "    date_end_df_train = _df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    if verbose:\n",
    "      print(f'days lookback:       {lookback},  {j + 1} of {len(days_lookbacks)} days_lookbacks: {days_lookbacks}')\n",
    "      print(f'lb_slices:           {lb_slices}')\n",
    "      print(f'lb_slice:            {lb_slice}')\n",
    "      print(f'days eval:           {d_eval}')    \n",
    "      print(f'iloc_start_train:    {iloc_start_train}')\n",
    "      print(f'iloc_end_train:      {iloc_end_train}')\n",
    "      print(f'date_start_df_train: {date_start_df_train}')\n",
    "      print(f'date_end_df_train:   {date_end_df_train}')\n",
    "\n",
    "\n",
    "    perf_ranks, most_freq_syms = _5_perf_ranks(_df, n_top_syms=n_top_syms)\n",
    "    # unsorted list of the most frequent symbols in performance metrics of the lb_slices  \n",
    "    grp_most_freq_syms.append(most_freq_syms)  \n",
    "    if verbose:    \n",
    "      # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "      print(f'perf_ranks: {perf_ranks}')  \n",
    "      # most common symbols of perf_ranks \n",
    "      print(f'most_freq_syms: {most_freq_syms}')     \n",
    "      # grp_perf_ranks[lookback] = perf_ranks\n",
    "      print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "  if verbose:\n",
    "    print(f'grp_most_freq_syms: {grp_most_freq_syms}')\n",
    "    # grp_most_freq_syms a is list of lists of tuples of \n",
    "    #  the most-common-symbols symbol:frequency cumulated from\n",
    "    #  each days_lookback  \n",
    "    print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "  # flatten list of lists of (symbol:frequency)\n",
    "  flat_grp_most_freq_syms = [val for sublist in grp_most_freq_syms for val in sublist]\n",
    "  # return \"symbol, frequency\" pairs of the most frequent symbols, i.e. best performing symbols,\n",
    "  #  in flat_grp_most_freq_syms. The paris are sorted in descending frequency.   \n",
    "  set_most_freq_syms = _6_grp_tuples_sort_sum(flat_grp_most_freq_syms, reverse=True)\n",
    "  # get the top n_top_syms of the most frequent \"symbol, frequency\" pairs\n",
    "  top_set_syms_n_freq = set_most_freq_syms[0:n_top_syms]\n",
    "  # get symbols from top_set_syms_n_freq, i[0] = symbol, i[1]=symbol's frequency count\n",
    "  top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]  \n",
    "\n",
    "  # grp_top_set_syms_n_freq is a list of lists of top_set_syms_n_freq, e.g.\n",
    "  #   [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)],\n",
    "  #    [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "  #   where each list is the best performing symbols from a lb_slices, e.g.\n",
    "  #     [(483, 513, 523), (453, 513, 523), (393, 513, 523)]    \n",
    "  grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "  grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "  if verbose:  \n",
    "    print(f'top {n_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "    print(f'top {n_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "    print(f'===== finish top {n_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7700ccdd",
   "metadata": {
    "papermill": {
     "duration": 0.009,
     "end_time": "2023-03-23T04:04:06.765060",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.756060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Output the best performing symbols for each set in sets_lookback_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0686dd87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:06.784061Z",
     "iopub.status.busy": "2023-03-23T04:04:06.784061Z",
     "iopub.status.idle": "2023-03-23T04:04:06.809060Z",
     "shell.execute_reply": "2023-03-23T04:04:06.808062Z"
    },
    "papermill": {
     "duration": 0.039007,
     "end_time": "2023-03-23T04:04:06.812065",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.773058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_lookback_slices: [(90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "max_lookback_slices: [(0, 120, 120)]\n",
      "\n",
      "data below will be added to df_picks\n",
      "date_end_df_train:   2023-03-22\n",
      "max_days_lookbacks:  120\n",
      "days_lookbacks:      [30, 60, 120]\n",
      "sym_freq_15:         []\n",
      "sym_freq_14:         []\n",
      "sym_freq_13:         []\n",
      "sym_freq_12:         []\n",
      "sym_freq_11:         []\n",
      "sym_freq_10:         []\n",
      "sym_freq_9:          ['SHV']\n",
      "sym_freq_8:          ['FTSM']\n",
      "sym_freq_7:          ['NVDA']\n",
      "sym_freq_6:          ['GE', 'HY', 'LNTH', 'PDFS', 'PERI', 'SGEN', 'TA']\n",
      "sym_freq_5:          ['ACLS', 'WST']\n",
      "sym_freq_4:          ['AMPH', 'COTY', 'FCN', 'GBTC', 'NTRA']\n",
      "sym_freq_3:          ['AJRD', 'ANET', 'BURL']\n",
      "sym_freq_2:          []\n",
      "\n",
      "row_picks_total: ['2023-03-22', 120, '[30, 60, 120]', '[]', '[]', '[]', '[]', '[]', '[]', \"['SHV']\", \"['FTSM']\", \"['NVDA']\", \"['GE', 'HY', 'LNTH', 'PDFS', 'PERI', 'SGEN', 'TA']\", \"['ACLS', 'WST']\", \"['AMPH', 'COTY', 'FCN', 'GBTC', 'NTRA']\", \"['AJRD', 'ANET', 'BURL']\", '[]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appended row_picks_total to df_picks:\n",
      "['2023-03-22', 120, '[30, 60, 120]', '[]', '[]', '[]', '[]', '[]', '[]', \"['SHV']\", \"['FTSM']\", \"['NVDA']\", \"['GE', 'HY', 'LNTH', 'PDFS', 'PERI', 'SGEN', 'TA']\", \"['ACLS', 'WST']\", \"['AMPH', 'COTY', 'FCN', 'GBTC', 'NTRA']\", \"['AJRD', 'ANET', 'BURL']\", '[]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, top_set_syms_n_freq in enumerate(grp_top_set_syms_n_freq):\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(top_set_syms_n_freq)\n",
    "  if verbose:\n",
    "    print(f'set_lookback_slices: {sets_lookback_slices[i]}')\n",
    "    print(f'max_lookback_slices: {max_lookback_slices}\\n')\n",
    "\n",
    "    if run_type == 'current':\n",
    "      print(f'data below will be added to {fp_df_picks}')\n",
    " \n",
    "    print(f'date_end_df_train:   {date_end_df_train}')    \n",
    "    print(f'max_days_lookbacks:  {max_days_lookbacks}')   \n",
    "    print(f'days_lookbacks:      {days_lookbacks}')\n",
    "    print(f'sym_freq_15:         {l_sym_freq_cnt[0]}')\n",
    "    print(f'sym_freq_14:         {l_sym_freq_cnt[1]}')\n",
    "    print(f'sym_freq_13:         {l_sym_freq_cnt[2]}')\n",
    "    print(f'sym_freq_12:         {l_sym_freq_cnt[3]}')\n",
    "    print(f'sym_freq_11:         {l_sym_freq_cnt[4]}')\n",
    "    print(f'sym_freq_10:         {l_sym_freq_cnt[5]}')\n",
    "    print(f'sym_freq_9:          {l_sym_freq_cnt[6]}')\n",
    "    print(f'sym_freq_8:          {l_sym_freq_cnt[7]}')\n",
    "    print(f'sym_freq_7:          {l_sym_freq_cnt[8]}')\n",
    "    print(f'sym_freq_6:          {l_sym_freq_cnt[9]}')\n",
    "    print(f'sym_freq_5:          {l_sym_freq_cnt[10]}')\n",
    "    print(f'sym_freq_4:          {l_sym_freq_cnt[11]}')\n",
    "    print(f'sym_freq_3:          {l_sym_freq_cnt[12]}')\n",
    "    print(f'sym_freq_2:          {l_sym_freq_cnt[13]}\\n')\n",
    "\n",
    "if run_type == 'current':  # record results to df\n",
    "  row_picks0      = [date_end_df_train, max_days_lookbacks, str(days_lookbacks)]\n",
    "  row_picks1      = [str(l_sym_freq_cnt[0]),  str(l_sym_freq_cnt[1]), str(l_sym_freq_cnt[2]),  str(l_sym_freq_cnt[3])]\n",
    "  row_picks2      = [str(l_sym_freq_cnt[4]),  str(l_sym_freq_cnt[5]), str(l_sym_freq_cnt[6]),  str(l_sym_freq_cnt[7])]\n",
    "  row_picks3      = [str(l_sym_freq_cnt[8]),  str(l_sym_freq_cnt[9]), str(l_sym_freq_cnt[10]), str(l_sym_freq_cnt[11])]\n",
    "  row_picks4      = [str(l_sym_freq_cnt[12]), str(l_sym_freq_cnt[13])]\n",
    "  row_picks_total = row_picks0 + row_picks1 + row_picks2 + row_picks3 + row_picks4\n",
    "  print(f'row_picks_total: {row_picks_total}')\n",
    "\n",
    "  df_picks.loc[len(df_picks)] = row_picks_total\n",
    "  pickle_dump(df_picks, path_data_dump, fp_df_picks)\n",
    "  print(f'appended row_picks_total to df_picks:\\n{row_picks_total}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af2d6f07",
   "metadata": {
    "papermill": {
     "duration": 0.011,
     "end_time": "2023-03-23T04:04:06.832061",
     "exception": false,
     "start_time": "2023-03-23T04:04:06.821061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Evaluate performance of symbols in set_lookback_slices versus SPY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8782107",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab766ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T04:04:06.853059Z",
     "iopub.status.busy": "2023-03-23T04:04:06.853059Z",
     "iopub.status.idle": "2023-03-23T04:04:07.901061Z",
     "shell.execute_reply": "2023-03-23T04:04:07.900059Z"
    },
    "papermill": {
     "duration": 1.060993,
     "end_time": "2023-03-23T04:04:07.903060",
     "exception": true,
     "start_time": "2023-03-23T04:04:06.842067",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms_n_freq:\n",
      "1 of 1 max_lookback_slice: (0, 120, 120)\n",
      "\n",
      "len(idx_train): 120\n",
      "idx_train: DatetimeIndex(['2022-09-29', '2022-09-30', '2022-10-03', '2022-10-04', '2022-10-05', '2022-10-06', '2022-10-07', '2022-10-10', '2022-10-11', '2022-10-12',\n",
      "               ...\n",
      "               '2023-03-09', '2023-03-10', '2023-03-13', '2023-03-14', '2023-03-15', '2023-03-16', '2023-03-17', '2023-03-20', '2023-03-21', '2023-03-22'], dtype='datetime64[ns]', name='Date', length=120, freq=None)\n",
      "df_train_dates (inclusive): 2022-09-29 - 2023-03-22\n",
      "\n",
      "run_type: current, idx_eval is empty: True\n",
      "top_set_syms_n_freq: [('SHV', 9), ('FTSM', 8), ('NVDA', 7), ('GE', 6), ('HY', 6), ('LNTH', 6), ('PDFS', 6), ('PERI', 6), ('SGEN', 6), ('TA', 6), ('ACLS', 5), ('WST', 5), ('AMPH', 4), ('COTY', 4), ('FCN', 4), ('GBTC', 4), ('NTRA', 4), ('AJRD', 3), ('ANET', 3), ('BURL', 3)]\n",
      "\n",
      "set_lookback_slices: [(90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "max_lookback_slice:  (0, 120, 120)\n",
      "days_lookbacks:      [30, 60, 120]\n",
      "date_end_df_train:   2023-03-22\n",
      "sym_freq_15:         []\n",
      "sym_freq_14:         []\n",
      "sym_freq_13:         []\n",
      "sym_freq_12:         []\n",
      "sym_freq_10:         []\n",
      "sym_freq_9:          ['SHV']\n",
      "sym_freq_8:          ['FTSM']\n",
      "sym_freq_7:          ['NVDA']\n",
      "sym_freq_6:          ['GE', 'HY', 'LNTH', 'PDFS', 'PERI', 'SGEN', 'TA']\n",
      "sym_freq_5:          ['ACLS', 'WST']\n",
      "sym_freq_4:          ['AMPH', 'COTY', 'FCN', 'GBTC', 'NTRA']\n",
      "sym_freq_3:          ['AJRD', 'ANET', 'BURL']\n",
      "sym_freq_2:          []\n",
      "\n",
      "df_picks:\n",
      "  date_end_df_train  max_days_lookbacks days_lookbacks sym_freq_15 sym_freq_14 sym_freq_13 sym_freq_12 sym_freq_11 sym_freq_10 sym_freq_9 sym_freq_8 sym_freq_7       sym_freq_6       sym_freq_5       sym_freq_4       sym_freq_3 sym_freq_2\n",
      "0       2023-03-22               120     [30, 60, 120]          []          []          []          []          []          []    ['SHV']   ['FTSM']   ['NVDA']  ['GE', 'HY',...  ['ACLS', 'WST']  ['AMPH', 'CO...  ['AJRD', 'AN...         []\n",
      "1       2023-03-22               120     [30, 60, 120]          []          []          []          []          []          []    ['SHV']   ['FTSM']   ['NVDA']  ['GE', 'HY',...  ['ACLS', 'WST']  ['AMPH', 'CO...  ['AJRD', 'AN...         []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\.venv\\lib\\site-packages\\numpy\\core\\_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 91\u001b[0m\n\u001b[0;32m     71\u001b[0m _sym_idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPY\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     72\u001b[0m df_SPY \u001b[38;5;241m=\u001b[39m df[iloc_start_eval:iloc_end_eval][_sym_idx]\n\u001b[0;32m     74\u001b[0m (\n\u001b[0;32m     75\u001b[0m   _symbols,\n\u001b[0;32m     76\u001b[0m   _period_yr,\n\u001b[0;32m     77\u001b[0m   _retn,\n\u001b[0;32m     78\u001b[0m   _DD,\n\u001b[0;32m     79\u001b[0m   _UI,\n\u001b[0;32m     80\u001b[0m   _MDD,\n\u001b[0;32m     81\u001b[0m   _retnMean,\n\u001b[0;32m     82\u001b[0m   _retnStd,\n\u001b[0;32m     83\u001b[0m   _retnStd_div_UI,\n\u001b[0;32m     84\u001b[0m   _CAGR,\n\u001b[0;32m     85\u001b[0m   _CAGR_div_retnStd,\n\u001b[0;32m     86\u001b[0m   _CAGR_div_UI,\n\u001b[0;32m     87\u001b[0m   SPY_retnStd_d_UI,     \n\u001b[0;32m     88\u001b[0m   SPY_CAGR,\n\u001b[0;32m     89\u001b[0m   SPY_CAGR_d_retnStd,\n\u001b[0;32m     90\u001b[0m   SPY_CAGR_d_UI,\n\u001b[1;32m---> 91\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43msymb_perf_stats_vectorized_v8\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_SPY\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSPY: retnStd/UI, CAGR/retnStd, CAGR/UI, CAGR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSPY_retnStd_d_UI[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>17,.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSPY_CAGR_d_retnStd[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>17,.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSPY_CAGR_d_UI[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>17.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSPY_CAGR[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>17.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# drop list with frequency count 2 or less, in l_sym_freq_cnt from zip\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\myUtils.py:3167\u001b[0m, in \u001b[0;36msymb_perf_stats_vectorized_v8\u001b[1;34m(df_symbols_close)\u001b[0m\n\u001b[0;32m   3163\u001b[0m arr_returns_std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(\n\u001b[0;32m   3164\u001b[0m     arr_returns[\u001b[38;5;241m1\u001b[39m:, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3165\u001b[0m )  \u001b[38;5;66;03m# drop first row\u001b[39;00m\n\u001b[0;32m   3166\u001b[0m arr_returns_0 \u001b[38;5;241m=\u001b[39m arr_returns\n\u001b[1;32m-> 3167\u001b[0m \u001b[43marr_returns_0\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# set first row to 0\u001b[39;00m\n\u001b[0;32m   3168\u001b[0m arr_cum_returns \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m arr_returns_0)\u001b[38;5;241m.\u001b[39mcumprod(\n\u001b[0;32m   3169\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3170\u001b[0m )  \u001b[38;5;66;03m# cumulative product of column elements\u001b[39;00m\n\u001b[0;32m   3171\u001b[0m \u001b[38;5;66;03m# accumulative max value of column elements\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from myUtils import symb_perf_stats_vectorized_v8\n",
    "\n",
    "print('z_grp_top_set_syms_n_freq:')\n",
    "# zip max_lookback_slices with top performing symbols:freq pairs\n",
    "z_grp_top_set_syms_n_freq = zip(max_lookback_slices, grp_top_set_syms_n_freq)\n",
    "\n",
    "idx_train = pd.Index([])\n",
    "idx_eval = pd.Index([])\n",
    "for i, (_lookback_slice, _top_set_syms_n_freq) in enumerate(z_grp_top_set_syms_n_freq):\n",
    "  iloc_start_train = _lookback_slice[0]\n",
    "  iloc_end_train = _lookback_slice[1]\n",
    "  iloc_start_eval = iloc_end_train\n",
    "  iloc_end_eval = _lookback_slice[2]\n",
    "\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice: {_lookback_slice}\\n')\n",
    "  # print(f'max_lookback_slice: {_lookback_slice}\\n')\n",
    "  # dates correspond to max_lookback_slice\n",
    "  idx_train = df.index[iloc_start_train:iloc_end_train]\n",
    "  date_start_df_train = idx_train[0].strftime('%Y-%m-%d')\n",
    "  date_end_df_train = idx_train[-1].strftime('%Y-%m-%d')\n",
    "  print(f'len(idx_train): {len(idx_train)}')\n",
    "  print(f'idx_train: {idx_train}')\n",
    "  print(f'df_train_dates (inclusive): {date_start_df_train} - {date_end_df_train}\\n')     \n",
    "\n",
    "  if run_type != 'current':\n",
    "    idx_eval = df.index[iloc_start_eval:iloc_end_eval]\n",
    "    date_start_df_eval = idx_eval[0].strftime('%Y-%m-%d')\n",
    "    date_end_df_eval = idx_eval[-1].strftime('%Y-%m-%d')\n",
    "    print(f'len(idx_eval): {len(idx_eval)}')\n",
    "    print(f'idx_eval: {idx_eval}')\n",
    "    print(f'df_eval dates (inclusive): {date_start_df_eval} - {date_end_df_eval}\\n')\n",
    "  else: # run_type == \"current'\n",
    "    print(f'run_type: {run_type}, idx_eval is empty: {idx_eval.empty}')\n",
    "\n",
    "  print(f'top_set_syms_n_freq: {_top_set_syms_n_freq}\\n')   \n",
    "\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(_top_set_syms_n_freq)\n",
    "  if verbose:\n",
    "    print(f'set_lookback_slices: {sets_lookback_slices[i]}')    \n",
    "    print(f'max_lookback_slice:  {_lookback_slice}')\n",
    "    print(f'days_lookbacks:      {days_lookbacks}')\n",
    "    print(f'date_end_df_train:   {date_end_df_train}')\n",
    "    print(f'sym_freq_15:         {l_sym_freq_cnt[0]}')\n",
    "    print(f'sym_freq_14:         {l_sym_freq_cnt[1]}')\n",
    "    print(f'sym_freq_13:         {l_sym_freq_cnt[2]}')\n",
    "    print(f'sym_freq_12:         {l_sym_freq_cnt[4]}')\n",
    "    print(f'sym_freq_10:         {l_sym_freq_cnt[5]}')\n",
    "    print(f'sym_freq_9:          {l_sym_freq_cnt[6]}')\n",
    "    print(f'sym_freq_8:          {l_sym_freq_cnt[7]}')\n",
    "    print(f'sym_freq_7:          {l_sym_freq_cnt[8]}')\n",
    "    print(f'sym_freq_6:          {l_sym_freq_cnt[9]}')\n",
    "    print(f'sym_freq_5:          {l_sym_freq_cnt[10]}')\n",
    "    print(f'sym_freq_4:          {l_sym_freq_cnt[11]}')\n",
    "    print(f'sym_freq_3:          {l_sym_freq_cnt[12]}')\n",
    "    print(f'sym_freq_2:          {l_sym_freq_cnt[13]}\\n') \n",
    "\n",
    "  if idx_eval.empty:\n",
    "    if run_type == 'current':\n",
    "      msg_stop = f'\\n\\n**** Normal termination for run_type \"{run_type}\". Wrote current picks to df_picks ****'\n",
    "      print(f'df_picks:\\n{df_picks}')\n",
    "\n",
    "\n",
    "      exit(msg_stop)\n",
    "      # raise SystemExit(msg_stop)\n",
    "\n",
    "\n",
    "    else:\n",
    "      msg_stop = f'\\n\\n**** STOPPED df_eval is empty but run_type != \"current\", the run_type is \"{run_type}\" ****'\n",
    "      raise SystemExit(msg_stop)    \n",
    "\n",
    "  _sym_idx = ['SPY']\n",
    "  df_SPY = df[iloc_start_eval:iloc_end_eval][_sym_idx]\n",
    "\n",
    "  (\n",
    "    _symbols,\n",
    "    _period_yr,\n",
    "    _retn,\n",
    "    _DD,\n",
    "    _UI,\n",
    "    _MDD,\n",
    "    _retnMean,\n",
    "    _retnStd,\n",
    "    _retnStd_div_UI,\n",
    "    _CAGR,\n",
    "    _CAGR_div_retnStd,\n",
    "    _CAGR_div_UI,\n",
    "    SPY_retnStd_d_UI,     \n",
    "    SPY_CAGR,\n",
    "    SPY_CAGR_d_retnStd,\n",
    "    SPY_CAGR_d_UI,\n",
    "  ) = symb_perf_stats_vectorized_v8(df_SPY)  \n",
    "\n",
    "  print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI, CAGR: {SPY_retnStd_d_UI[0]:>17,.1f}, {SPY_CAGR_d_retnStd[0]:>17,.1f}, {SPY_CAGR_d_UI[0]:>17.1f}, {SPY_CAGR[0]:>17.1f}')\n",
    "\n",
    "  # drop list with frequency count 2 or less, in l_sym_freq_cnt from zip\n",
    "  zip_cnt_n_syms = zip([15,14,13,12,11,10,9,8,7,6,5,4,3], l_sym_freq_cnt[:-1])\n",
    "  for item in zip_cnt_n_syms:\n",
    "    sym_freq_cnt = item[0]\n",
    "    syms = item[1]\n",
    "    if syms:  # iterate ONLY if there are symbols in syms\n",
    "      df_eval = df[iloc_start_eval:iloc_end_eval][syms]      \n",
    "\n",
    "      if verbose:\n",
    "        print(f'iloc_start_eval: {iloc_start_eval:>6},  df_eval first date: {date_start_df_eval:>10}') \n",
    "        print(f'iloc_end_eval:   {iloc_end_eval:>6},  df_eval last date:  {date_end_df_eval:>10}')        \n",
    "        print(f'frequency count of symbol(s): {sym_freq_cnt}')      \n",
    "\n",
    "        syms_n_SPY = syms + ['SPY']\n",
    "        df_eval_n_SPY = df[iloc_start_eval:iloc_end_eval][syms_n_SPY]   \n",
    "        print(f'\\ndf_eval_n_SPY:\\n{df_eval_n_SPY}\\n')\n",
    "\n",
    "      (\n",
    "        _symbols,\n",
    "        _period_yr,\n",
    "        _retn,\n",
    "        _DD,\n",
    "        _UI,\n",
    "        _MDD,\n",
    "        _retnMean,\n",
    "        _retnStd,\n",
    "        _retnStd_div_UI,\n",
    "        _CAGR,\n",
    "        _CAGR_div_retnStd,\n",
    "        _CAGR_div_UI,\n",
    "        grp_retnStd_d_UI,     \n",
    "        grp_CAGR,\n",
    "        grp_CAGR_d_retnStd,\n",
    "        grp_CAGR_d_UI,\n",
    "      ) = symb_perf_stats_vectorized_v8(df_eval)  \n",
    "      print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]  :>17,.1f}, {grp_retnStd_d_UI[1]  :>17,.1f}, {grp_retnStd_d_UI[2]  :>17,.1f}')\n",
    "      print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>17,.1f}, {grp_CAGR_d_retnStd[1]:>17,.1f}, {grp_CAGR_d_retnStd[2]:>17,.1f}')\n",
    "      print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]     :>17,.1f}, {grp_CAGR_d_UI[1]     :>17,.1f}, {grp_CAGR_d_UI[2]     :>17,.1f}')\n",
    "      print(f'grp(CAGR):         mean, std, mean/std: {grp_CAGR[0]          :>17,.1f}, {grp_CAGR[1]          :>17,.1f}, {grp_CAGR[2]          :>17,.1f}\\n')\n",
    "\n",
    "      if store_results:  # record results to df\n",
    "        row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, sym_freq_cnt]\n",
    "        row_add1      = [grp_CAGR[0],           grp_CAGR[1],           grp_CAGR[2]]\n",
    "        row_add2      = [grp_CAGR_d_UI[0],      grp_CAGR_d_UI[1],      grp_CAGR_d_UI[2]]\n",
    "        row_add3      = [grp_CAGR_d_retnStd[0], grp_CAGR_d_retnStd[1], grp_CAGR_d_retnStd[2]]\n",
    "        row_add4      = [grp_retnStd_d_UI[0],   grp_retnStd_d_UI[1],   grp_retnStd_d_UI[2]]\n",
    "        row_add5      = [SPY_CAGR[0], SPY_CAGR_d_UI[0], SPY_CAGR_d_retnStd[0], SPY_retnStd_d_UI[0]]\n",
    "        row_add_total = row_add0 + row_add1 + row_add2 + row_add3 + row_add4 + row_add5\n",
    "        print(f'row_add_total: {row_add_total}')\n",
    "        df_eval_results.loc[len(df_eval_results)] = row_add_total\n",
    "        print(f'appended row_add to df_eval_results:\\n{row_add_total}\\n')\n",
    "  \n",
    "  print('='*50, '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c1e69",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if store_results:  # record results to df\n",
    "  pickle_dump(df_eval_results, path_data_dump, fp_df_eval_results)\n",
    "  print(f'Save results to: {fp_df_eval_results}')\n",
    "\n",
    "df = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f3346",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pickle_load(path_data_dump, fp_df_picks)\n",
    "# df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.014714,
   "end_time": "2023-03-23T04:04:08.268320",
   "environment_variables": {},
   "exception": true,
   "input_path": "yf_7a.ipynb",
   "output_path": "yf_7aPM_out.ipynb",
   "parameters": {
    "days_eval": 0,
    "days_lookbacks": [
     30,
     60,
     120
    ],
    "drop_last_n_rows": 0,
    "fp_df_eval_results": "Not_Applicable",
    "n_samples": 1,
    "n_top_syms": 20,
    "run_type": "current",
    "store_results": true,
    "syms_end": 10,
    "syms_start": 0,
    "verbose": true
   },
   "start_time": "2023-03-23T04:04:02.253606",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}