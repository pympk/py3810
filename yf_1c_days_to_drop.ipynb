{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of days_to_drop from df_close_clean such that the last date in the df is a date in dates_missing_in_df_picks<br>Pickle the list of days_to_drop to \"l_days_to_drop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", 11)\n",
    "pd.set_option(\"display.max_colwidth\", 16)\n",
    "pd.set_option(\"display.width\", 145)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "fp_df_close_clean = \"df_close_clean\"\n",
    "fp_dates_missing_in_df_picks = \"dates_missing_in_df_picks\"\n",
    "# list of integers that are days_to_drop from df_close_clean\n",
    "#  s.t. the last date in the df is a date in dates_missing_in_df_picks\n",
    "fp_l_days_to_drop = \"l_days_to_drop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_close_clean:\n",
      "                     A         AA        AAL        AAP        AAPL  ...       ZION        ZTO         ZTS       ZUMZ        ZWS\n",
      "Date                                                                 ...                                                        \n",
      "2017-11-29   65.633354  40.366665  48.002308  91.965721   40.065674  ...  41.108860  14.851051   68.809448  20.850000  23.835058\n",
      "2017-11-30   66.158897  40.630943  49.210892  92.931862   40.625946  ...  41.158691  14.991067   69.462852  21.799999  24.145109\n",
      "2017-12-01   65.633354  40.758194  47.758636  91.349251   40.436832  ...  41.598953  14.935060   69.472473  19.950001  23.747854\n",
      "2017-12-04   63.292377  40.905018  48.665073  95.710609   40.141315  ...  42.977825  14.776375   68.242531  21.350000  24.145109\n",
      "2017-12-05   62.900620  40.307930  48.216740  93.069862   40.103497  ...  42.263470  14.571016   68.079170  20.650000  24.154795\n",
      "...                ...        ...        ...        ...         ...  ...        ...        ...         ...        ...        ...\n",
      "2023-11-08  109.389999  25.530001  12.010000  57.639999  182.649368  ...  33.759998  24.049999  170.869995  15.910000  28.299999\n",
      "2023-11-09  107.739998  24.580000  11.750000  56.139999  182.169998  ...  32.549999  23.690001  170.630005  15.340000  28.049999\n",
      "2023-11-10  108.470001  24.639999  11.800000  56.130001  186.399994  ...  32.919998  24.120001  169.320007  15.740000  28.799999\n",
      "2023-11-13  107.459999  24.600000  11.780000  55.939999  184.800003  ...  32.709999  24.020000  168.830002  15.730000  28.600000\n",
      "2023-11-14  111.610001  26.170000  12.250000  58.400002  187.440002  ...  35.369999  24.389999  172.649994  17.709999  29.950001\n",
      "\n",
      "[1500 rows x 1276 columns]\n",
      "\n",
      "df_close_clean_index:\n",
      "DatetimeIndex(['2017-11-29', '2017-11-30', '2017-12-01', '2017-12-04', '2017-12-05', '2017-12-06', '2017-12-07', '2017-12-08', '2017-12-11',\n",
      "               '2017-12-12',\n",
      "               ...\n",
      "               '2023-11-01', '2023-11-02', '2023-11-03', '2023-11-06', '2023-11-07', '2023-11-08', '2023-11-09', '2023-11-10', '2023-11-13',\n",
      "               '2023-11-14'],\n",
      "              dtype='datetime64[ns]', name='Date', length=1500, freq=None)\n"
     ]
    }
   ],
   "source": [
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)\n",
    "# Sort the DataFrame by the date index in place\n",
    "df_close_clean.sort_index(inplace=True)\n",
    "print(f'df_close_clean:\\n{df_close_clean}\\n')\n",
    "df_close_clean_index = df_close_clean.index\n",
    "print(f'df_close_clean_index:\\n{df_close_clean_index}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates_missing_in_df_picks, len(26):\n",
      "['2023-07-17', '2023-07-19', '2023-07-24', '2023-07-28', '2023-07-31', '2023-08-16', '2023-08-21', '2023-08-22', '2023-08-23', '2023-08-24', '2023-08-28', '2023-08-29', '2023-08-30', '2023-08-31', '2023-09-06', '2023-09-07', '2023-09-19', '2023-09-26', '2023-09-27', '2023-10-03', '2023-10-09', '2023-10-10', '2023-10-11', '2023-10-13', '2023-10-16', '2023-10-18']\n"
     ]
    }
   ],
   "source": [
    "dates_missing_in_df_picks = pickle_load(path_data_dump, fp_dates_missing_in_df_picks)\n",
    "print(f'dates_missing_in_df_picks, len({len(dates_missing_in_df_picks)}):\\n{dates_missing_in_df_picks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================================\n",
      "+ def pickle_dump(file_to_pickle, path_pickle_dump, filename_pickle)\n",
      "\n",
      "Wrote pickled file to C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/l_days_to_drop\n",
      "- def pickle_dump(file_to_pickle, path_pickle_dump, filename_pickle)\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "dates_missing_in_df_picks : ['2023-07-17', '2023-07-19', '2023-07-24', '2023-07-28', '2023-07-31', '2023-08-16', '2023-08-21', '2023-08-22', '2023-08-23', '2023-08-24', '2023-08-28', '2023-08-29', '2023-08-30', '2023-08-31', '2023-09-06', '2023-09-07', '2023-09-19', '2023-09-26', '2023-09-27', '2023-10-03', '2023-10-09', '2023-10-10', '2023-10-11', '2023-10-13', '2023-10-16', '2023-10-18']\n",
      "l_days_to_drop : [85, 83, 80, 76, 75, 63, 60, 59, 58, 57, 55, 54, 53, 52, 49, 48, 40, 35, 34, 30, 26, 25, 24, 22, 21, 19]\n"
     ]
    }
   ],
   "source": [
    "# list to store days_to_drop from df_close_clean\n",
    "l_days_to_drop = []\n",
    "\n",
    "# Calculate the number of days to drop from the date index.\n",
    "for i in range(len(dates_missing_in_df_picks)):\n",
    "  date = dates_missing_in_df_picks[i]\n",
    "  last_date_index = df_close_clean_index.get_loc(date)\n",
    "  # number of days to drop from df such that the last date is a missing date    \n",
    "  days_to_drop = len(df_close_clean_index) - last_date_index - 1\n",
    "  # print(f'i: {i}, date: {date}, days_to_drop: {days_to_drop}')\n",
    "  l_days_to_drop.append(days_to_drop)  \n",
    "\n",
    "pickle_dump(l_days_to_drop, path_data_dump, fp_l_days_to_drop, verbose=True)    \n",
    "print(f'\\ndates_missing_in_df_picks : {dates_missing_in_df_picks}')\n",
    "print(f'l_days_to_drop : {l_days_to_drop}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to df's last dates are same as dates_missing_in_df_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_l_days_to_drop: ['2023-07-17', '2023-07-19', '2023-07-24', '2023-07-28', '2023-07-31', '2023-08-16', '2023-08-21', '2023-08-22', '2023-08-23', '2023-08-24', '2023-08-28', '2023-08-29', '2023-08-30', '2023-08-31', '2023-09-06', '2023-09-07', '2023-09-19', '2023-09-26', '2023-09-27', '2023-10-03', '2023-10-09', '2023-10-10', '2023-10-11', '2023-10-13', '2023-10-16', '2023-10-18']\n",
      "The lists are equal.\n"
     ]
    }
   ],
   "source": [
    "check_l_days_to_drop = []\n",
    "for n in l_days_to_drop:\n",
    "  df_current = df_close_clean.copy()  \n",
    "  # Drop the last n rows\n",
    "  df_current = df_current.drop(df_current.index[-n:])\n",
    "  # Print the index of the last row\n",
    "  # print(df_current.index[-1].strftime(\"%Y-%m-%d\"))\n",
    "  check_l_days_to_drop.append(df_current.index[-1].strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "print(f'check_l_days_to_drop: {check_l_days_to_drop}')\n",
    "\n",
    "def compare_lists(list1, list2):\n",
    "    if list1 != list2:\n",
    "        raise ValueError(\"The lists are not equal!\")\n",
    "    else:\n",
    "        print(\"The lists are equal.\")\n",
    "\n",
    "try:\n",
    "    compare_lists(dates_missing_in_df_picks, check_l_days_to_drop)\n",
    "except ValueError as error:\n",
    "    print(error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
