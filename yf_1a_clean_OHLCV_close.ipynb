{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/pandas-groupby-a-simple-but-detailed-tutorial-314b8f37005d\n",
    "# https://towardsdatascience.com/accessing-data-in-a-multiindex-dataframe-in-pandas-569e8767201d\n",
    "# https://towardsdatascience.com/summarizing-data-with-pandas-crosstab-efc8b9abecf\n",
    "# https://towardsdatascience.com/how-to-flatten-multiindex-columns-and-rows-in-pandas-f5406c50e569\n",
    "# https://datascientyst.com/list-aggregation-functions-aggfunc-groupby-pandas/\n",
    "# https://stackoverflow.com/questions/25929319/how-to-iterate-over-pandas-multiindex-dataframe-using-index\n",
    "# https://stackoverflow.com/questions/24495695/pandas-get-unique-multiindex-level-values-by-label\n",
    "# https://stackoverflow.com/questions/55706391/pandas-crosstab-on-multiple-columns-then-groupby\n",
    "\n",
    "# https://matplotlib.org/stable/gallery/pyplots/pyplot_text.html#sphx-glr-gallery-pyplots-pyplot-text-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "# # filename_symbols = path_data_dump + 'vg_symbols_4chars_max.csv'  # symbols text file\n",
    "# filename_symbols = path_data_dump + 'my_symbols.csv'  # symbols text file\n",
    "\n",
    "# _filename_pickled_df_OHLCVA_downloaded = 'df_OHLCVA_downloaded '  # OHLCVA downloaded from Yahoo\n",
    "filename_pickled_df_adjOHLCV = 'df_adjOHLCV'  # adjusted OHLCV\n",
    "filename_pickled_df_symbols_close = \"df_symbols_close\"  # symbols' adjusted close\n",
    "filename_pickled_symbols_df_adjOHLCV =  'symbols_df_adjOHLCV'  # symbols in df_adjOHLCV\n",
    "filename_pickled_perf_rank_dict =  'perf_rank_dict'  # store symbols from performance rank results\n",
    "filename_pickled_r_all_ranks =  'r_all_ranks'  # list of top 100 most common symbols from performance rank results\n",
    "filename_pickled_df_a = 'df_OHLCV_clean'  # df adjusted OHLCV, dropped symbols with no vol and close\n",
    "filename_pickled_df_c = 'df_close_clean'  # df close, dropped symbols with no vol and close\n",
    "\n",
    "verbose = False  # True prints more output\n",
    "\n",
    "#################\n",
    "# look_back_days = -250 * 60  # subset df iloc days\n",
    "look_back_days = -250 * 6  # subset df iloc days, 6 years of data\n",
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path to pickled df_symbols_close:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_symbols_close\n",
      "Full path to pickled df_adjOHLCV:  C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_adjOHLCV\n"
     ]
    }
   ],
   "source": [
    "print(f\"Full path to pickled df_symbols_close:  {path_data_dump}{filename_pickled_df_symbols_close}\")\n",
    "df_close = pickle_load(path_data_dump, filename_pickled_df_symbols_close, verbose=verbose)\n",
    "print(f\"Full path to pickled df_adjOHLCV:  {path_data_dump}{filename_pickled_df_adjOHLCV}\")\n",
    "df_adjOHLCV = pickle_load(path_data_dump, filename_pickled_df_adjOHLCV, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbols with no volume:\n",
      "Index(['AMCR', 'AVT', 'BIIB', 'BKR', 'CCI', 'CHD', 'CNC', 'CNXC', 'DISH',\n",
      "       'ESAB', 'FCFS', 'GEN', 'IBKR', 'JJC', 'NSTG', 'PEAK', 'PFG', 'SBNY',\n",
      "       'SRPT', 'SSB', 'VC', 'VNT', 'WH', 'XEL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/63826291/pandas-series-find-column-by-value\n",
    "df = df_adjOHLCV[look_back_days::]\n",
    "df_v = df.xs('Volume', level=1, axis=1)  # select only Volume columns\n",
    "rows, cols = np.where(df_v == 0)  # row index, column index where trading volumes are zero\n",
    "idx_no_volume = list(set(cols))\n",
    "idx_no_volume.sort()\n",
    "symbols_no_volume = df_v.columns[idx_no_volume]\n",
    "print(f'symbols with no volume:\\n{symbols_no_volume}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbols with same volume:\n",
      "Index(['ABM', 'ACM', 'ACN', 'AGCO', 'ALE', 'ALRM', 'AMCR', 'AMED', 'AMG',\n",
      "       'AMGN',\n",
      "       ...\n",
      "       'VRSK', 'VSAT', 'WDAY', 'WERN', 'WEX', 'WSFS', 'WTS', 'WTW', 'XEL',\n",
      "       'XENE'],\n",
      "      dtype='object', length=253)\n"
     ]
    }
   ],
   "source": [
    "df_dif = df_v - df_v.shift(periods=1)\n",
    "rows, cols = np.where(df_dif == 0)\n",
    "idx_same_volume = list(set(cols))\n",
    "idx_same_volume.sort()\n",
    "idx_same_volume\n",
    "symbols_same_volume = df_v.columns[idx_same_volume]\n",
    "print(f'symbols with same volume:\\n{symbols_same_volume}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbols with NaN close:\n",
      "Index(['ABNB', 'AIRC', 'ALGM', 'BJ', 'BRBR', 'BTC-USD', 'BVH', 'CARR', 'CDAY',\n",
      "       'CEG', 'CHK', 'CHX', 'CNXC', 'CR', 'CRWD', 'CTVA', 'DDOG', 'DISH',\n",
      "       'DOW', 'DT', 'DTM', 'ESAB', 'ETH-USD', 'ETRN', 'FOX', 'FOXA', 'FYBR',\n",
      "       'GEHC', 'GFS', 'GO', 'GXO', 'JJC', 'KD', 'LCID', 'MP', 'MRNA', 'NARI',\n",
      "       'NSTG', 'NVST', 'NVT', 'OGN', 'OTIS', 'PDD', 'PGNY', 'RIVN', 'SEAS',\n",
      "       'SGOV', 'SHC', 'SITM', 'SRC', 'SWAV', 'VMW', 'VNT', 'VSCO', 'WH',\n",
      "       'YETI', 'ZM', 'ZS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_c = df.xs('Close', level=1, axis=1)  # select only Close columns\n",
    "df_c = df_c.fillna(0).copy()  # convert NaNs to zeros\n",
    "rows, cols = np.where(df_c == 0)  # row index, column index where trading volumes are zero\n",
    "idx_no_close = list(set(cols))\n",
    "idx_no_close.sort()\n",
    "symbols_no_close = df_c.columns[idx_no_close]\n",
    "print(f'symbols with NaN close:\\n{symbols_no_close}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique symbols with bad data, e.g. no volume, same volume and $0 close, includes duplicate symbols: 315\n"
     ]
    }
   ],
   "source": [
    "symbols_bad_data = list(symbols_no_close) + list(symbols_no_volume) + list(symbols_same_volume) # combine symbols with no volume and no close\n",
    "unique_symbols_bad_data = sorted(list(set(symbols_bad_data)))  # unique symbols\n",
    "print(f'unique symbols with bad data, e.g. no volume, same volume and $0 close, includes duplicate symbols: {len(unique_symbols_bad_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_end_df_train</th>\n",
       "      <th>max_days_lookbacks</th>\n",
       "      <th>days_lookbacks</th>\n",
       "      <th>sym_freq_15</th>\n",
       "      <th>sym_freq_14</th>\n",
       "      <th>sym_freq_13</th>\n",
       "      <th>sym_freq_12</th>\n",
       "      <th>sym_freq_11</th>\n",
       "      <th>sym_freq_10</th>\n",
       "      <th>sym_freq_9</th>\n",
       "      <th>sym_freq_8</th>\n",
       "      <th>sym_freq_7</th>\n",
       "      <th>sym_freq_6</th>\n",
       "      <th>sym_freq_5</th>\n",
       "      <th>sym_freq_4</th>\n",
       "      <th>sym_freq_3</th>\n",
       "      <th>sym_freq_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-15</td>\n",
       "      <td>120</td>\n",
       "      <td>[30, 60, 120]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['SHV', 'SMCI']</td>\n",
       "      <td>['ANF']</td>\n",
       "      <td>['AGO', 'FATE', 'FTSM', 'META', 'NTNX', 'WING']</td>\n",
       "      <td>['CLS', 'COHR', 'ICHR', 'PGR']</td>\n",
       "      <td>['COST', 'DOOR', 'EXP', 'GBTC', 'GDDY', 'HA', ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_end_df_train  max_days_lookbacks days_lookbacks sym_freq_15  \\\n",
       "0        2024-02-15                 120  [30, 60, 120]          []   \n",
       "\n",
       "  sym_freq_14 sym_freq_13 sym_freq_12 sym_freq_11 sym_freq_10 sym_freq_9  \\\n",
       "0          []          []          []          []          []         []   \n",
       "\n",
       "  sym_freq_8       sym_freq_7 sym_freq_6  \\\n",
       "0         []  ['SHV', 'SMCI']    ['ANF']   \n",
       "\n",
       "                                        sym_freq_5  \\\n",
       "0  ['AGO', 'FATE', 'FTSM', 'META', 'NTNX', 'WING']   \n",
       "\n",
       "                       sym_freq_4  \\\n",
       "0  ['CLS', 'COHR', 'ICHR', 'PGR']   \n",
       "\n",
       "                                          sym_freq_3 sym_freq_2  \n",
       "0  ['COST', 'DOOR', 'EXP', 'GBTC', 'GDDY', 'HA', ...         []  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get symbols of past model picks\n",
    "df_picks = pickle_load(path_data_dump, 'df_picks', verbose=verbose)\n",
    "df_picks.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sym_freq_15</th>\n",
       "      <th>sym_freq_14</th>\n",
       "      <th>sym_freq_13</th>\n",
       "      <th>sym_freq_12</th>\n",
       "      <th>sym_freq_11</th>\n",
       "      <th>sym_freq_10</th>\n",
       "      <th>sym_freq_9</th>\n",
       "      <th>sym_freq_8</th>\n",
       "      <th>sym_freq_7</th>\n",
       "      <th>sym_freq_6</th>\n",
       "      <th>sym_freq_5</th>\n",
       "      <th>sym_freq_4</th>\n",
       "      <th>sym_freq_3</th>\n",
       "      <th>sym_freq_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['SHV', 'SMCI']</td>\n",
       "      <td>['ANF']</td>\n",
       "      <td>['AGO', 'FATE', 'FTSM', 'META', 'NTNX', 'WING']</td>\n",
       "      <td>['CLS', 'COHR', 'ICHR', 'PGR']</td>\n",
       "      <td>['COST', 'DOOR', 'EXP', 'GBTC', 'GDDY', 'HA', ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sym_freq_15 sym_freq_14 sym_freq_13 sym_freq_12 sym_freq_11 sym_freq_10  \\\n",
       "0          []          []          []          []          []          []   \n",
       "\n",
       "  sym_freq_9 sym_freq_8       sym_freq_7 sym_freq_6  \\\n",
       "0         []         []  ['SHV', 'SMCI']    ['ANF']   \n",
       "\n",
       "                                        sym_freq_5  \\\n",
       "0  ['AGO', 'FATE', 'FTSM', 'META', 'NTNX', 'WING']   \n",
       "\n",
       "                       sym_freq_4  \\\n",
       "0  ['CLS', 'COHR', 'ICHR', 'PGR']   \n",
       "\n",
       "                                          sym_freq_3 sym_freq_2  \n",
       "0  ['COST', 'DOOR', 'EXP', 'GBTC', 'GDDY', 'HA', ...         []  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only columns with symbols of past picks\n",
    "df_picks.drop(columns=[\"date_end_df_train\", \"max_days_lookbacks\", \"days_lookbacks\"], inplace=True)\n",
    "df_picks.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sym_freq_15', 'sym_freq_14', 'sym_freq_13', 'sym_freq_12',\n",
       "       'sym_freq_11', 'sym_freq_10', 'sym_freq_9', 'sym_freq_8', 'sym_freq_7',\n",
       "       'sym_freq_6', 'sym_freq_5', 'sym_freq_4', 'sym_freq_3', 'sym_freq_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_picks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol count from model picks: 56640\n",
      "unique symbol count from model picks: 1005\n"
     ]
    }
   ],
   "source": [
    "list_of_lists = []\n",
    "\n",
    "for col in df_picks.columns:\n",
    "  # convert column values from string to list, e.g. '[]', '[]', '[\"A\", \"B\", ..]' ... to [], [], [\"A\", \"B\", ..], ...\n",
    "  l_series = df_picks[col].apply(ast.literal_eval)\n",
    "  # list_of_lists = [l_item for l_item in l_series if l_item]  # this doesn't works  \n",
    "  for l_item in l_series:\n",
    "      if l_item:  # \n",
    "        list_of_lists.append(l_item)  \n",
    "\n",
    "symbols_picks = [val for sublist in list_of_lists for val in sublist]\n",
    "print(f'symbol count from model picks: {len(symbols_picks)}')\n",
    "# list sorted unique symbols\n",
    "unique_symbols_picks = sorted(list(set(symbols_picks)))\n",
    "print(f'unique symbol count from model picks: {len(unique_symbols_picks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'c', 'd']\n"
     ]
    }
   ],
   "source": [
    "def find_common_items(list1, list2):\n",
    "  \"\"\"Finds the common items between two lists.\n",
    "\n",
    "  Args:\n",
    "    list1: The first list.\n",
    "    list2: The second list.\n",
    "\n",
    "  Returns:\n",
    "    A list of the common items between the two lists.\n",
    "  \"\"\"\n",
    "\n",
    "  common_items = []\n",
    "  for item in list1:\n",
    "    if item in list2:\n",
    "      common_items.append(item)\n",
    "  return common_items\n",
    "\n",
    "\n",
    "# code in if block runs only from command line, code will NOT be executed if imported as a module\n",
    "if __name__ == \"__main__\": \n",
    "  list1 = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "  list2 = [\"b\", \"c\", \"d\", \"f\", \"g\"]\n",
    "  common_items = find_common_items(list1, list2)\n",
    "  print(common_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALE', 'ARCH', 'AZPN', 'BTC-USD', 'CHT', 'CMG', 'CVBF', 'CVLT', 'DISH', 'DVA', 'ETH-USD', 'HOLI', 'HY', 'LOB', 'MLKN', 'MLR', 'NSTG', 'OSIS', 'PKX', 'PTMN', 'RRC', 'SEAS', 'SFBS', 'SRPT', 'TRGP', 'TX', 'VNO', 'WDAY', 'XENE']\n"
     ]
    }
   ],
   "source": [
    "# symbols are in past picks but also have bad data \n",
    "common_symbols = find_common_items(unique_symbols_picks, unique_symbols_bad_data)\n",
    "print(common_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_items(list1, list2):\n",
    "  \"\"\"Subtracts items in list2 from items in list1.\n",
    "\n",
    "  Args:\n",
    "    list1: The first list.\n",
    "    list2: The second list.\n",
    "\n",
    "  Returns:\n",
    "    A list of the items in list1 that are not in list2.\n",
    "  \"\"\"\n",
    "\n",
    "  subtracted_items = []\n",
    "  for item in list1:\n",
    "    if item not in list2:\n",
    "      subtracted_items.append(item)\n",
    "  return subtracted_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_symbols_bad_data): 315\n",
      "len(common_symbols): 29\n",
      "len(symbols_drop): 286\n"
     ]
    }
   ],
   "source": [
    "symbols_drop = subtract_items(unique_symbols_bad_data, common_symbols)  # don't drop symbols in past picks\n",
    "symbols_drop .sort()\n",
    "print(f'len(unique_symbols_bad_data): {len(unique_symbols_bad_data)}')\n",
    "print(f'len(common_symbols): {len(common_symbols)}')\n",
    "print(f'len(symbols_drop): {len(symbols_drop)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique symbols dropped from df_a (adjOLHLV) and df_c (Close): 286\n"
     ]
    }
   ],
   "source": [
    "# symbols_drop = list(symbols_no_close) + list(symbols_no_volume) + list(symbols_same_volume) # combine symbols with no volume and no close\n",
    "# print(f'combined symbols with no volume, same volume and no close, inculdes duplicate symbols: {len(symbols_drop)}')\n",
    "# symbols_drop = list(set(symbols_drop))  # drop duplicate symbols\n",
    "# symbols_drop .sort()\n",
    "\n",
    "\n",
    "df_a = df.drop(symbols_drop, axis=1, level=0)  # drop symbols from OHLCA df\n",
    "df_c = df_close.iloc[look_back_days::]\n",
    "df_c = df_c.drop(symbols_drop, axis=1)\n",
    "print(f'unique symbols dropped from df_a (adjOLHLV) and df_c (Close): {len(symbols_drop)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbols with no volume:      24\n",
      "symbols with same volume:   253\n",
      "symbols with no close:       58\n",
      "\n",
      "symbols total before drop:                                        1,548\n",
      "unique symbols dropped from df OHLCVA (df_a) and df Close (df_c):   286\n",
      "\n",
      "                                          symbols     rows\n",
      "df adjOHLCV (df_a) after dropped symbols:   1,262    1,500\n",
      "df Close (df_c) after dropped symbols:      1,262    1,500\n"
     ]
    }
   ],
   "source": [
    "print(f'symbols with no volume:   {len(symbols_no_volume):>5,}')\n",
    "print(f'symbols with same volume: {len(symbols_same_volume):>5,}')\n",
    "print(f'symbols with no close:    {len(symbols_no_close):>5,}\\n')\n",
    "print(f'symbols total before drop:                                        {len(df_close.columns):>5,}')\n",
    "print(f'unique symbols dropped from df OHLCVA (df_a) and df Close (df_c): {len(symbols_drop):>5,}\\n')\n",
    "print('                                          symbols     rows')\n",
    "print(f'df adjOHLCV (df_a) after dropped symbols:   {len(df_a.columns)/5:>5,.0f}    {len(df_a):>5,}')\n",
    "print(f'df Close (df_c) after dropped symbols:      {len(df_c.columns):>5,}    {len(df_c):>5,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickled df adjOHLCV after dropping symbols with no volume, same volume, and no close:\n",
      "C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_OHLCV_clean\n",
      "pickled df Close after dropping symbols with no volume, same volume, and no close:\n",
      "C:/Users/ping/MyDrive/stocks/yfinance/VSCode_dump/df_close_clean\n"
     ]
    }
   ],
   "source": [
    "pickle_dump(df_a, path_data_dump, filename_pickled_df_a)\n",
    "print(f'pickled df adjOHLCV after dropping symbols with no volume, same volume, and no close:\\n{path_data_dump}{filename_pickled_df_a}')\n",
    "pickle_dump(df_c, path_data_dump, filename_pickled_df_c)\n",
    "print(f'pickled df Close after dropping symbols with no volume, same volume, and no close:\\n{path_data_dump}{filename_pickled_df_c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myUtils import list_dump\n",
    "\n",
    "f_symbols_df_close_clean = 'symbols_df_close_clean.csv'  # symbols text file\n",
    "symbols_df_c = list(df_c)  # column names in df_c\n",
    "list_dump(symbols_df_c, path_data_dump, f_symbols_df_close_clean)# df_c.columns.to_csv(f_symbols_df_close_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">A</th>\n",
       "      <th colspan=\"5\" halign=\"left\">AA</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ZUMZ</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ZWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-12</th>\n",
       "      <td>133.279999</td>\n",
       "      <td>133.279999</td>\n",
       "      <td>130.380005</td>\n",
       "      <td>132.309998</td>\n",
       "      <td>1231800.0</td>\n",
       "      <td>27.100000</td>\n",
       "      <td>28.094999</td>\n",
       "      <td>26.870001</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>4374600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.450001</td>\n",
       "      <td>19.260000</td>\n",
       "      <td>18.450001</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>163900.0</td>\n",
       "      <td>32.209999</td>\n",
       "      <td>32.400002</td>\n",
       "      <td>31.799999</td>\n",
       "      <td>32.330002</td>\n",
       "      <td>1513400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-13</th>\n",
       "      <td>130.339996</td>\n",
       "      <td>131.639999</td>\n",
       "      <td>128.259995</td>\n",
       "      <td>129.759995</td>\n",
       "      <td>1031100.0</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>27.200001</td>\n",
       "      <td>25.575001</td>\n",
       "      <td>25.850000</td>\n",
       "      <td>7264200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.120001</td>\n",
       "      <td>18.270000</td>\n",
       "      <td>17.670000</td>\n",
       "      <td>17.870001</td>\n",
       "      <td>182700.0</td>\n",
       "      <td>31.230000</td>\n",
       "      <td>31.549999</td>\n",
       "      <td>30.719999</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>1483100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-14</th>\n",
       "      <td>131.000000</td>\n",
       "      <td>132.330002</td>\n",
       "      <td>130.210007</td>\n",
       "      <td>132.240005</td>\n",
       "      <td>1405200.0</td>\n",
       "      <td>26.209999</td>\n",
       "      <td>26.990000</td>\n",
       "      <td>25.870001</td>\n",
       "      <td>26.790001</td>\n",
       "      <td>5100600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.230000</td>\n",
       "      <td>18.230000</td>\n",
       "      <td>17.639999</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>89000.0</td>\n",
       "      <td>31.360001</td>\n",
       "      <td>31.830000</td>\n",
       "      <td>31.170000</td>\n",
       "      <td>31.700001</td>\n",
       "      <td>921800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-15</th>\n",
       "      <td>132.990005</td>\n",
       "      <td>135.600006</td>\n",
       "      <td>132.679993</td>\n",
       "      <td>134.750000</td>\n",
       "      <td>1514500.0</td>\n",
       "      <td>27.040001</td>\n",
       "      <td>27.639999</td>\n",
       "      <td>26.920000</td>\n",
       "      <td>27.389999</td>\n",
       "      <td>4385500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.170000</td>\n",
       "      <td>18.559999</td>\n",
       "      <td>18.040001</td>\n",
       "      <td>18.480000</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>31.799999</td>\n",
       "      <td>32.240002</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>32.070000</td>\n",
       "      <td>1479700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-16</th>\n",
       "      <td>133.589996</td>\n",
       "      <td>136.270004</td>\n",
       "      <td>133.589996</td>\n",
       "      <td>134.839996</td>\n",
       "      <td>1035790.0</td>\n",
       "      <td>27.340000</td>\n",
       "      <td>28.030001</td>\n",
       "      <td>27.160000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>4382574.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.240000</td>\n",
       "      <td>18.549999</td>\n",
       "      <td>18.190001</td>\n",
       "      <td>18.309999</td>\n",
       "      <td>89355.0</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>30.969999</td>\n",
       "      <td>30.969999</td>\n",
       "      <td>1053922.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A                                                 \\\n",
       "                  Open        High         Low       Close     Volume   \n",
       "Date                                                                    \n",
       "2024-02-12  133.279999  133.279999  130.380005  132.309998  1231800.0   \n",
       "2024-02-13  130.339996  131.639999  128.259995  129.759995  1031100.0   \n",
       "2024-02-14  131.000000  132.330002  130.210007  132.240005  1405200.0   \n",
       "2024-02-15  132.990005  135.600006  132.679993  134.750000  1514500.0   \n",
       "2024-02-16  133.589996  136.270004  133.589996  134.839996  1035790.0   \n",
       "\n",
       "                   AA                                              ...  \\\n",
       "                 Open       High        Low      Close     Volume  ...   \n",
       "Date                                                               ...   \n",
       "2024-02-12  27.100000  28.094999  26.870001  27.900000  4374600.0  ...   \n",
       "2024-02-13  26.900000  27.200001  25.575001  25.850000  7264200.0  ...   \n",
       "2024-02-14  26.209999  26.990000  25.870001  26.790001  5100600.0  ...   \n",
       "2024-02-15  27.040001  27.639999  26.920000  27.389999  4385500.0  ...   \n",
       "2024-02-16  27.340000  28.030001  27.160000  27.400000  4382574.0  ...   \n",
       "\n",
       "                 ZUMZ                                                   ZWS  \\\n",
       "                 Open       High        Low      Close    Volume       Open   \n",
       "Date                                                                          \n",
       "2024-02-12  18.450001  19.260000  18.450001  19.000000  163900.0  32.209999   \n",
       "2024-02-13  18.120001  18.270000  17.670000  17.870001  182700.0  31.230000   \n",
       "2024-02-14  18.230000  18.230000  17.639999  18.000000   89000.0  31.360001   \n",
       "2024-02-15  18.170000  18.559999  18.040001  18.480000  135000.0  31.799999   \n",
       "2024-02-16  18.240000  18.549999  18.190001  18.309999   89355.0  31.750000   \n",
       "\n",
       "                                                        \n",
       "                 High        Low      Close     Volume  \n",
       "Date                                                    \n",
       "2024-02-12  32.400002  31.799999  32.330002  1513400.0  \n",
       "2024-02-13  31.549999  30.719999  30.950001  1483100.0  \n",
       "2024-02-14  31.830000  31.170000  31.700001   921800.0  \n",
       "2024-02-15  32.240002  31.750000  32.070000  1479700.0  \n",
       "2024-02-16  31.750000  30.969999  30.969999  1053922.0  \n",
       "\n",
       "[5 rows x 6310 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AB</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABR</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>...</th>\n",
       "      <th>YY</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZD</th>\n",
       "      <th>ZG</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTO</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZUMZ</th>\n",
       "      <th>ZWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-12</th>\n",
       "      <td>132.309998</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>14.93</td>\n",
       "      <td>66.050003</td>\n",
       "      <td>187.149994</td>\n",
       "      <td>34.160000</td>\n",
       "      <td>173.070007</td>\n",
       "      <td>12.67</td>\n",
       "      <td>112.529999</td>\n",
       "      <td>83.099998</td>\n",
       "      <td>...</td>\n",
       "      <td>33.810001</td>\n",
       "      <td>125.849998</td>\n",
       "      <td>259.399994</td>\n",
       "      <td>68.519997</td>\n",
       "      <td>53.669998</td>\n",
       "      <td>40.810200</td>\n",
       "      <td>17.459999</td>\n",
       "      <td>196.690002</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>32.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-13</th>\n",
       "      <td>129.759995</td>\n",
       "      <td>25.850000</td>\n",
       "      <td>14.61</td>\n",
       "      <td>64.430000</td>\n",
       "      <td>185.039993</td>\n",
       "      <td>33.439999</td>\n",
       "      <td>173.289993</td>\n",
       "      <td>12.21</td>\n",
       "      <td>111.339996</td>\n",
       "      <td>84.059998</td>\n",
       "      <td>...</td>\n",
       "      <td>31.850000</td>\n",
       "      <td>123.160004</td>\n",
       "      <td>245.800003</td>\n",
       "      <td>64.480003</td>\n",
       "      <td>52.060001</td>\n",
       "      <td>38.930000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>183.490005</td>\n",
       "      <td>17.870001</td>\n",
       "      <td>30.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-14</th>\n",
       "      <td>132.240005</td>\n",
       "      <td>26.790001</td>\n",
       "      <td>14.86</td>\n",
       "      <td>64.260002</td>\n",
       "      <td>184.149994</td>\n",
       "      <td>33.560001</td>\n",
       "      <td>174.419998</td>\n",
       "      <td>12.74</td>\n",
       "      <td>112.059998</td>\n",
       "      <td>84.870003</td>\n",
       "      <td>...</td>\n",
       "      <td>33.099998</td>\n",
       "      <td>121.839996</td>\n",
       "      <td>252.960007</td>\n",
       "      <td>65.709999</td>\n",
       "      <td>56.029999</td>\n",
       "      <td>40.419998</td>\n",
       "      <td>17.920000</td>\n",
       "      <td>184.080002</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>31.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-15</th>\n",
       "      <td>134.750000</td>\n",
       "      <td>27.389999</td>\n",
       "      <td>14.90</td>\n",
       "      <td>64.650002</td>\n",
       "      <td>183.860001</td>\n",
       "      <td>33.709999</td>\n",
       "      <td>176.589996</td>\n",
       "      <td>13.12</td>\n",
       "      <td>113.639999</td>\n",
       "      <td>87.400002</td>\n",
       "      <td>...</td>\n",
       "      <td>33.570000</td>\n",
       "      <td>124.400002</td>\n",
       "      <td>283.750000</td>\n",
       "      <td>67.699997</td>\n",
       "      <td>55.830002</td>\n",
       "      <td>41.520000</td>\n",
       "      <td>18.129999</td>\n",
       "      <td>189.649994</td>\n",
       "      <td>18.480000</td>\n",
       "      <td>32.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-16</th>\n",
       "      <td>134.839996</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>14.64</td>\n",
       "      <td>64.489998</td>\n",
       "      <td>182.309998</td>\n",
       "      <td>32.610001</td>\n",
       "      <td>177.490005</td>\n",
       "      <td>13.99</td>\n",
       "      <td>114.010002</td>\n",
       "      <td>86.110001</td>\n",
       "      <td>...</td>\n",
       "      <td>33.139999</td>\n",
       "      <td>124.709999</td>\n",
       "      <td>275.459991</td>\n",
       "      <td>66.790001</td>\n",
       "      <td>52.750000</td>\n",
       "      <td>40.639999</td>\n",
       "      <td>18.480000</td>\n",
       "      <td>188.389999</td>\n",
       "      <td>18.309999</td>\n",
       "      <td>30.969999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         AA    AAL        AAP        AAPL         AB  \\\n",
       "Date                                                                         \n",
       "2024-02-12  132.309998  27.900000  14.93  66.050003  187.149994  34.160000   \n",
       "2024-02-13  129.759995  25.850000  14.61  64.430000  185.039993  33.439999   \n",
       "2024-02-14  132.240005  26.790001  14.86  64.260002  184.149994  33.560001   \n",
       "2024-02-15  134.750000  27.389999  14.90  64.650002  183.860001  33.709999   \n",
       "2024-02-16  134.839996  27.400000  14.64  64.489998  182.309998  32.610001   \n",
       "\n",
       "                  ABBV    ABR         ABT       ACGL  ...         YY  \\\n",
       "Date                                                  ...              \n",
       "2024-02-12  173.070007  12.67  112.529999  83.099998  ...  33.810001   \n",
       "2024-02-13  173.289993  12.21  111.339996  84.059998  ...  31.850000   \n",
       "2024-02-14  174.419998  12.74  112.059998  84.870003  ...  33.099998   \n",
       "2024-02-15  176.589996  13.12  113.639999  87.400002  ...  33.570000   \n",
       "2024-02-16  177.490005  13.99  114.010002  86.110001  ...  33.139999   \n",
       "\n",
       "                   ZBH        ZBRA         ZD         ZG       ZION  \\\n",
       "Date                                                                  \n",
       "2024-02-12  125.849998  259.399994  68.519997  53.669998  40.810200   \n",
       "2024-02-13  123.160004  245.800003  64.480003  52.060001  38.930000   \n",
       "2024-02-14  121.839996  252.960007  65.709999  56.029999  40.419998   \n",
       "2024-02-15  124.400002  283.750000  67.699997  55.830002  41.520000   \n",
       "2024-02-16  124.709999  275.459991  66.790001  52.750000  40.639999   \n",
       "\n",
       "                  ZTO         ZTS       ZUMZ        ZWS  \n",
       "Date                                                     \n",
       "2024-02-12  17.459999  196.690002  19.000000  32.330002  \n",
       "2024-02-13  17.400000  183.490005  17.870001  30.950001  \n",
       "2024-02-14  17.920000  184.080002  18.000000  31.700001  \n",
       "2024-02-15  18.129999  189.649994  18.480000  32.070000  \n",
       "2024-02-16  18.480000  188.389999  18.309999  30.969999  \n",
       "\n",
       "[5 rows x 1262 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
