{"cells":[{"cell_type":"markdown","metadata":{},"source":["### [The spelled-out intro to neural networks and backpropagation: building micrograd](https://www.youtube.com/watch?v=VMj-3S1tku0&t=3356s)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### [chatGPT-4, released on 2023-03-14, has 1 trillion paramaters and cost $100 million to train](https://en.wikipedia.org/wiki/GPT-4)"]},{"cell_type":"code","execution_count":466,"metadata":{},"outputs":[],"source":["import math, random, torch\n","import numpy as np\n","# import random\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":467,"metadata":{},"outputs":[],"source":["# verbose = True   # print calculation output and weights and bias matrices \n","verbose = False  # print calculation output only"]},{"cell_type":"code","execution_count":468,"metadata":{},"outputs":[],"source":["def plot_losses(losses):\n","  # import matplotlib.pyplot as plt\n","  \n","  # Create a list of iterations\n","  iterations = range(len(losses))\n","\n","  # Plot the loss as a function of iteration\n","  plt.plot(iterations, losses)\n","\n","  # Add a title to the plot\n","  plt.title('Loss vs. Iteration')\n","\n","  # Add labels to the x-axis and y-axis\n","  plt.xlabel('Iteration')\n","  plt.ylabel('Loss')"]},{"cell_type":"code","execution_count":469,"metadata":{},"outputs":[],"source":["def print_parameters(parameters):\n","  # number of parameters (e.g sum (weights + bias to each neuron and output))\n","  # MLP(3, [4, 4, 1]) --> 4_neurons(3_inputs + 1_bias) + 4_neurons(4_neurons + 1_bias) + 1_output(4_neurons + 1_bias) = 41_parameters \n","  # print(f'Number of parameters in MLP(2, [3, 3, 1]): {len(parameters())}\\n')\n","  print(f'Total parameters: {len(parameters())}\\n')  \n","\n","  # print first 5 parameters\n","  for i, v in enumerate(parameters()):\n","    if i < 5:\n","      print(f'i: {i:>2}, {v.data:>14.10f}')\n","  \n","  print('---')\n","\n","  # print last 5 parameters   \n","  for i, v in enumerate(parameters()):\n","    if i >= len(parameters()) - 5:\n","      print(f'i: {i:>2}, {v.data:>14.10f}')"]},{"cell_type":"code","execution_count":470,"metadata":{},"outputs":[],"source":["def get_wt_n_b_mats(layers, verbose=False):\n","  ''' Get neuron's weights and bias for each layer.\n","  Inputs: If n = MLP(2, [3, 3, 1]), input is n.layers.\n","\n","  return: two lists of np.arrays. The first list is weight matrix for each layer\n","          The second list is the bias matrix for each layer \n","  '''\n","  layer_cnt = len(layers)  # number of layers\n","  w_mats = []  # list of weights matrix for each layer \n","  b_mats = []  # list of bias matrix for each layer\n","  if verbose:\n","    print(f'layer_cnt: {layer_cnt}\\n')\n","  for i, layer in enumerate(layers):\n","      neuron_cnt = len(layer.neurons)  # numbers of neurons in the layer\n","      if verbose: \n","        print(f'layer: {i}, neuron_cnt: {neuron_cnt}')\n","\n","        print('----')\n","      b_mat = []  # accumulate neuon's bias for each row     \n","      for j, neuron in enumerate(layer.neurons):\n","          if verbose:\n","            print(f'layer: {i}, neuron {j}')\n","          b = neuron.b.data  # bias of neuron \n","          w_row = []  # accumulate neuon's weights for each row\n","          b_row = []  # accumulate neuon's bias for each row\n","          for k, w in enumerate(neuron.w):\n","              w_row.append(w.data)\n","              if verbose:\n","                print(f'w{k}: {w.data:10.7f},   w{k}.grad: {w.grad:10.7f}')\n","          if j == 0:            \n","              w_mat = np.array([w_row])\n","          else:\n","              w_mat = np.vstack((w_mat, w_row))\n","          \n","          b_mat.append(b)\n","          if verbose:\n","            print(f'b:  {b:10.7f}\\n')\n","            print(f'b:  {b:10.7f}')        \n","            print(f'b_mat:  {b_mat}\\n')\n","      w_mats.append(w_mat)  \n","      b_mats.append(np.array([b_mat]))        \n","      if verbose:\n","          print('------')\n","\n","  zipped_w_n_b = zip(w_mats, b_mats)\n","  if verbose:\n","    for i, w_n_b in enumerate(zipped_w_n_b):\n","      print(f'layer: {i}')  # 1st layer is 0    \n","      print(f'w_mat{w_n_b[0].shape}:\\n{w_n_b[0]}')\n","      print(f'b_mat{w_n_b[1].shape}:\\n{w_n_b[1]}\\n')  \n","\n","  return w_mats, b_mats"]},{"cell_type":"code","execution_count":471,"metadata":{},"outputs":[],"source":["def forward_pass(layers, verbose=verbose):\n","  # Get Neural Network's Weights and Biases Matrices\n","  # w_mats, b_mats = get_wt_n_b_mats(n.layers, verbose=verbose)\n","  w_mats, b_mats = get_wt_n_b_mats(layers, verbose=verbose)\n","\n","  # Calculate Neural Network Output and Loss with Matrix Multiplication\n","  for layer in range(len(layers)):\n","    if layer == 0:  # first layer, use given inputs xs as inputs\n","      input = xs_mats_T[layer]\n","    else:  # after first layer, use outputs from preceding layers as inputs\n","      input = output\n","\n","    weights = w_mats[layer]\n","    bias = np.transpose(b_mats[layer])\n","\n","    weights_x_input = np.matmul(weights, input)\n","    weights_x_input_plus_bias = weights_x_input + bias\n","\n","    # output = np.tanh(np.matmul(weights, input) + bias)\n","    output = np.tanh(weights_x_input_plus_bias)\n","\n","    print(f'{\"-\"*50}')\n","    print(f'Calculate Output of Layer: {layer}')    \n","    print(f'weights {weights.shape}:\\n{weights}\\n')\n","    print(f'input {input.shape}:\\n{input}\\n')\n","\n","    print(f'weights_x_inputs {weights_x_input.shape}:\\n{weights_x_input}\\n')\n","    print(f'bias {bias.shape}:\\n{bias}\\n')\n","    print(f'weights_x_inputs_+_bias {weights_x_input_plus_bias.shape}:\\n{weights_x_input_plus_bias}\\n')    \n","\n","    # print(f'output = tanh(weights_x_inputs_+_bias) {output.shape}:\\n{output}\\n')    \n","    print(f'Layer {layer} Output = tanh(weights_x_inputs_+_bias) {output.shape}:\\n{output}\\n')    \n","\n","  yout = output[0]\n","  err = (yout - ys)\n","  err_sq = (err**2)\n","  loss_sum = err_sq.sum()\n","  loss_mean = err_sq.mean()\n","\n","  # print(f'-- Manual calculation results of neural network output and prediction error --')\n","  print(f'-- Results of neural network outputs and Loss --')  \n","  print(f'yout:           {yout}')   \n","  print(f'desired output: {ys}')   \n","  print(f'err:            {err}')\n","  print(f'err_sq:         {err_sq}')\n","  print(f'loss_sum:       {loss_sum}')\n","  print(f'loss_mean:      {loss_mean}')\n","\n","  return yout, err, err_sq, loss_sum, loss_mean, w_mats, b_mats\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Micrograd Classes and Functions<br>* limited to neural network with one output, e.g. MLP(2, [3, 1])<br>* neural network with multiple outputs, e.g.  MLP(2, [3, 3]), will produce errors in backward pass "]},{"cell_type":"code","execution_count":472,"metadata":{},"outputs":[],"source":["from graphviz import Digraph\n","\n","def trace(root):\n","  \"\"\"Builds a set of all nodes and edges in a graph.\"\"\"\n","  nodes, edges = set(), set()\n","\n","  def build(v):\n","    if v not in nodes:\n","      nodes.add(v)\n","      for child in v._prev:\n","        edges.add((child, v))\n","        build(child)\n","\n","  build(root)\n","  return nodes, edges\n","\n","def draw_dot(root):\n","  \"\"\"Creates a Digraph representation of the graph.\"\"\"\n","  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'})  # LR = left to right\n","\n","  nodes, edges = trace(root)\n","  for n in nodes:\n","    uid = str(id(n))\n","    # For any value in the graph, create a rectangular ('record') node for it.\n","    dot.node(name=uid, label=\"{ %s | data %.4f | grad % .4f }\" % (n.label, n.data, n.grad), shape=\"record\")\n","\n","    if n._op:\n","      # If this value is a result of some operation, create an op node.\n","      dot.node(name=uid + n._op, label=n._op)\n","      # And connect this node to it\n","      dot.edge(uid + n._op, uid)\n","\n","  for n1, n2 in edges:\n","    # Connect nl to the op node of n2.\n","    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n","\n","  return dot"]},{"cell_type":"code","execution_count":473,"metadata":{},"outputs":[],"source":["class Value:\n","\n","    def __init__(self, data, _children=(), _op='', label=''):\n","        self.data = data\n","        self.grad = 0.0\n","        self._backward = lambda : None\n","        self._prev = set(_children)\n","        self._op = _op\n","        self.label = label\n","\n","    def __repr__(self) -> str:\n","        return f\"Value(data = {self.data})\"\n","    \n","    def __add__(self, other):\n","        other = other if isinstance(other, Value) else Value(other)\n","        out = Value(self.data + other.data, (self, other), '+')\n","\n","        def _backward():\n","            self.grad += 1.0 * out.grad\n","            other.grad += 1.0 * out.grad\n","        out._backward = _backward    \n","\n","        return out\n","\n","    def __radd__(self, other): # other + self\n","        return self + other\n","\n","    def __mul__(self, other):\n","        other = other if isinstance(other, Value) else Value(other)        \n","        out = Value(self.data * other.data, (self, other), '*')\n","\n","        def _backward():\n","            self.grad += other.data * out.grad\n","            other.grad += self.data * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def __rmul__(self, other):  # other * self\n","        return self * other\n","\n","    def __pow__(self, other):\n","        assert isinstance(other, (int, float)), \"only support int/float power for now\"\n","        out = Value(self.data**other, (self,), f'**{other}')\n","\n","        def _backward():\n","            self.grad += other * (self.data ** (other - 1)) * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def __truediv__(self, other):  # self / other\n","        return self * other**-1\n","\n","    def __neg__(self):  # -self\n","        return self * -1\n","    \n","    def __sub__(self, other):  # self - other\n","        return self + (-other)\n","\n","    def __rsub__(self, other): # other - self\n","        return other + (-self)\n","\n","    def tanh(self):\n","        x = self.data\n","        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n","        out = Value(t, (self, ), 'tanh')\n","\n","        def _backward():\n","            self.grad += (1 - t**2) * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    # https://en.wikipedia.org/wiki/Hyperbolic_functions\n","    def exp(self):\n","        x = self.data\n","        out = Value(math.exp(x), (self, ), 'exp')\n","\n","        def _backward():\n","            self.grad += out.data * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def backward(self):\n","        topo = []\n","        visited = set()\n","\n","        # topological sort\n","        def build_topo(v):\n","            if v not in visited:\n","                visited.add(v)\n","                for child in v._prev:\n","                    build_topo(child)\n","                topo.append(v)\n","        build_topo(self)\n","\n","        self.grad = 1  # initialize\n","        for node in reversed(topo):\n","            node._backward()    "]},{"cell_type":"code","execution_count":474,"metadata":{},"outputs":[],"source":["class Neuron:\n","    \n","    def __init__(self, nin):\n","        # random numbers evenly distributed between -1 and 1    \n","        self.w = [Value(random.uniform(-1, 1)) for _ in range(nin)]  \n","        self.b = Value(random.uniform(-1,1))\n","\n","#### my add ##########################################\n","    def __repr__(self) -> str:\n","        return f\"Neuron(w = {self.w}, b = {self.b})\"\n","######################################################\n","\n","    def __call__(self, x):\n","        # w * x + b\n","        # print(list(zip(self.w, x)), self.b)\n","        act = sum((wi*xi for wi,xi in zip(self.w, x)), self.b) \n","        out = act.tanh()\n","        return out\n","\n","    def parameters(self):\n","        # print(f'w: {self.w}, b: {[self.b]}')\n","        return self.w + [self.b]\n","\n","\n","class Layer:\n","    def __init__(self, nin, nout):\n","        self.neurons = [Neuron(nin) for _ in range(nout)]\n","\n","#### my add ##########################################\n","    def __repr__(self) -> str:\n","        return f\"Layer(neurons = {self.neurons})\"\n","######################################################\n","\n","    def __call__(self, x):\n","        outs = [n(x) for n in self.neurons]\n","        return outs[0] if len(outs) == 1 else outs\n","\n","    def parameters(self):\n","        # params = []\n","        # for neuron in self.neurons:\n","        #     ps = neuron.parameters()\n","        #     params.extend(ps)\n","        # return params\n","        return [p for neuron in self.neurons for p in neuron.parameters()]\n","\n","class MLP:\n","    def __init__(self, nin, nouts):\n","        sz = [nin] + nouts\n","        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n","\n","    def __call__(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def parameters(self):\n","        params = []\n","        # for layer in self.layers:\n","        #     ps = layer.parameters()\n","        #     params.extend(ps)\n","        # return params\n","        return [p for layer in self.layers for p in layer.parameters()]"]},{"cell_type":"markdown","metadata":{},"source":["#   &nbsp;\n","# - Human Brain and Artificial Neural Network - "]},{"cell_type":"markdown","metadata":{},"source":["### Neurons in Human Brain\n","![](..\\karpathy\\img\\neuron_of_human_brain.png)"]},{"cell_type":"markdown","metadata":{},"source":["### Simple Artificial Neural Network<br>* input layer: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2 nodes<br>* hidden layer 1: &nbsp;3 nodes<br>* hidden layer 2:&nbsp;&nbsp;3 nodes<br>*  output layer: &nbsp;&nbsp;&nbsp; 1 node<br>* node's bias and activation function are not shown\n","\n","<!-- ![Getting Started](..\\karpathy\\img\\Nertual_Network_Neuron.PNG) -->\n","<img src=\"..\\karpathy\\img\\MLP (2, [3, 3, 1]).png\">"]},{"cell_type":"markdown","metadata":{},"source":["### Artificial Neuron Function\n","\n","<img src=\"..\\karpathy\\img\\Artificial Neuron Function.png\">"]},{"cell_type":"markdown","metadata":{},"source":["# &nbsp;\n","# - Visualize Math Operations in a Hidden Layer -"]},{"cell_type":"markdown","metadata":{},"source":["### * Assume hidden layer with two inputs (X0, X1), and three neurons (b0, b1, b2)<br>* Two sets of inputs (X0, X1) are shown in different shades of gray<br>* Two sets of outputs (Y0, Y1, Y2) are shown in corresponding shades of gray<br>* Multiple sets of inputs are processed in one matrix operation \n","\n","<img src=\"..\\karpathy\\img\\Hidden Layer Matrix Operations.png\">"]},{"cell_type":"markdown","metadata":{},"source":["# &nbsp;\n","# - Create Simple Neural Network with Micrograd -\n","##### MLP(2, [3, 3, 1])<br>* 2 input nodes<br>* 3 neurons in hidden layer 1<br>* 3 neurons in hidden layer 2<br>* 1 output node\n","##### Initialize Neurons Parameters <br>* parameters in layer 1: 3 neurons * (2 inputs + 1 bias) = &nbsp;&nbsp;&nbsp;&nbsp;  9<br>* parameters in layer 2: 3 neurons * (3 neurons + 1 bias) = 12<br>* parameters in layer 3: 1 output * (3 neurons + 1 bias) = &nbsp;&nbsp;&nbsp; 4<br>*  total parameters: 25"]},{"cell_type":"code","execution_count":475,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Neuron parameters, initialized with random numbers\n","Total parameters: 25\n","\n","i:  0,  -0.7613894381\n","i:  1,  -0.4310515994\n","i:  2,  -0.7431304436\n","i:  3,  -0.7613844654\n","i:  4,   0.7400073489\n","---\n","i: 20,   0.3099642638\n","i: 21,  -0.3383758175\n","i: 22,   0.0289552771\n","i: 23,   0.8870724851\n","i: 24,  -0.0013436152\n"]}],"source":["# create neural network and initialize weights and biases\n","n = MLP(2, [3, 3, 1])\n","\n","# if verbose:\n","if True:\n","  print(\"Neuron parameters, initialized with random numbers\")\n","  print_parameters(n.parameters)"]},{"cell_type":"markdown","metadata":{},"source":["# &nbsp;\n","# - Set Inputs, Desired Outputs, Learning Rate -\n","##### Inputs<br>* 1st set: [2.0, 1.0]<br>* 2nd set: [3.0, -2.0]\n","##### Desired Outputs<br>* [1.0, -1.0] for all input sets\n","##### Learning Rate<br>* 0.05"]},{"cell_type":"code","execution_count":476,"metadata":{},"outputs":[],"source":["# inputs\n","xs = [\n","  [2.0, 1.0],\n","  [3.0, -2.0]\n","]\n","\n","# desired targets\n","ys = [1.0, -1.0]\n","\n","# learning rate (i.e. step size)\n","learning_rate = 0.05"]},{"cell_type":"code","execution_count":477,"metadata":{},"outputs":[],"source":["# if True:\n","if verbose:\n","\t# print weights and bias of each layer\n","\tfor i, layer in enumerate(n.layers):\n","\t\tneuron_cnt = len(layer.neurons)  # numbers of neurons in the layer \n","\t\tprint(f'layer: {i}, neuron_cnt: {neuron_cnt}, layer: {layer}')"]},{"cell_type":"markdown","metadata":{},"source":["# &nbsp;\n","# - Calculate Neural Network Outputs and Loss (i.e. Prediction Errors) -\n","##### * transpose inputs<br>* select activation function<br>* calculate output, (a.k.a) Forward Pass<br>* calculate Loss"]},{"cell_type":"markdown","metadata":{},"source":["##### Transpose Inputs"]},{"cell_type":"code","execution_count":478,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["xs_mats[0].shape: (2, 2)\n","xs_mats:\n","[array([[ 2.,  1.],\n","       [ 3., -2.]])]\n","\n","xs_mats_T[0].shape: (2, 2)\n","xs_mats_T:\n","[array([[ 2.,  3.],\n","       [ 1., -2.]])]\n"]}],"source":["xs_mats = [np.array(xs)]  # convert xs to list of np.arrays\n","xs_mats_T = []\n","for mat in xs_mats:\n","  mat_transpose = np.transpose(mat)\n","  xs_mats_T.append(mat_transpose)\n","\n","print(f'xs_mats[0].shape: {xs_mats[0].shape}')\n","print(f'xs_mats:\\n{xs_mats}\\n')\n","print(f'xs_mats_T[0].shape: {xs_mats_T[0].shape}')\n","print(f'xs_mats_T:\\n{xs_mats_T}')"]},{"cell_type":"markdown","metadata":{},"source":["##### Common Activation Functions"]},{"cell_type":"code","execution_count":479,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x300 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Common Activation Functions\n","x = np.arange(-5, 5, 0.2)\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n","\n","ax1.plot(x, np.tanh(x))\n","ax1.set_title(\"Tanh\")\n","ax1.grid()\n","\n","a = x[x < 0]*0.01\n","b = x[x >= 0]\n","y = np.concatenate((a, b))\n","ax2.grid()\n","ax2.plot(x, y)\n","ax2.set_title(\"Leaky ReLU\")\n","\n","plt_title = \"Common Activation Functions\\nIntroduce non-linearity into the network\\nto learn complex relationships\"\n","plt.suptitle(plt_title , fontsize=12, y=1.2)\n","plt.subplots_adjust(wspace=0.3)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["##### Calculate Outputs and Loss Using Tanh Activation"]},{"cell_type":"code","execution_count":480,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------\n","Calculate Output of Layer: 0\n","weights (3, 2):\n","[[-0.76138944 -0.4310516 ]\n"," [-0.76138447  0.74000735]\n"," [ 0.7285488  -0.69404317]]\n","\n","input (2, 2):\n","[[ 2.  3.]\n"," [ 1. -2.]]\n","\n","weights_x_inputs (3, 2):\n","[[-1.95383048 -1.42206512]\n"," [-0.78276158 -3.76416809]\n"," [ 0.76305442  3.57373273]]\n","\n","bias (3, 1):\n","[[-0.74313044]\n"," [-0.12322464]\n"," [ 0.00326915]]\n","\n","weights_x_inputs_+_bias (3, 2):\n","[[-2.69696092 -2.16519556]\n"," [-0.90598622 -3.88739274]\n"," [ 0.76632357  3.57700188]]\n","\n","Layer 0 Output = tanh(weights_x_inputs_+_bias) (3, 2):\n","[[-0.99095288 -0.9740172 ]\n"," [-0.71920019 -0.99915996]\n"," [ 0.64478658  0.99843777]]\n","\n","--------------------------------------------------\n","Calculate Output of Layer: 1\n","weights (3, 3):\n","[[ 0.58987046 -0.13246351 -0.02439937]\n"," [ 0.60178347  0.72143806 -0.75271091]\n"," [ 0.13188911 -0.74411    -0.18773959]]\n","\n","input (3, 2):\n","[[-0.99095288 -0.9740172 ]\n"," [-0.71920019 -0.99915996]\n"," [ 0.64478658  0.99843777]]\n","\n","weights_x_inputs (3, 2):\n","[[-0.50499844 -0.466553  ]\n"," [-1.60053534 -2.05851446]\n"," [ 0.28341619  0.42757636]]\n","\n","bias (3, 1):\n","[[-0.65455652]\n"," [-0.92531834]\n"," [ 0.30996426]]\n","\n","weights_x_inputs_+_bias (3, 2):\n","[[-1.15955497 -1.12110952]\n"," [-2.52585368 -2.98383281]\n"," [ 0.59338046  0.73754063]]\n","\n","Layer 1 Output = tanh(weights_x_inputs_+_bias) (3, 2):\n","[[-0.82089479 -0.8079545 ]\n"," [-0.98728456 -0.99489265]\n"," [ 0.53232251  0.62765697]]\n","\n","--------------------------------------------------\n","Calculate Output of Layer: 2\n","weights (1, 3):\n","[[-0.33837582  0.02895528  0.88707249]]\n","\n","input (3, 2):\n","[[-0.82089479 -0.8079545 ]\n"," [-0.98728456 -0.99489265]\n"," [ 0.53232251  0.62765697]]\n","\n","weights_x_inputs (1, 2):\n","[[0.7213925 0.8013621]]\n","\n","bias (1, 1):\n","[[-0.00134362]]\n","\n","weights_x_inputs_+_bias (1, 2):\n","[[0.72004889 0.80001848]]\n","\n","Layer 2 Output = tanh(weights_x_inputs_+_bias) (1, 2):\n","[[0.61693958 0.6640471 ]]\n","\n","-- Results of neural network outputs and Loss --\n","yout:           [0.61693958 0.6640471 ]\n","desired output: [1.0, -1.0]\n","err:            [-0.38306042  1.6640471 ]\n","err_sq:         [0.14673528 2.76905276]\n","loss_sum:       2.9157880420356603\n","loss_mean:      1.4578940210178302\n"]}],"source":["yout, err, err_sq, loss_sum, loss_mean, w_mats, b_mats = forward_pass(n.layers, verbose=verbose)"]},{"cell_type":"code","execution_count":481,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-- Neural network outputs and Loss --\n","yout:           [0.61693958 0.6640471 ] <-- neural network output\n","desired output: [1.0, -1.0]\n","err:            [-0.38306042  1.6640471 ]\n","err_sq:         [0.14673528 2.76905276]\n","loss_sum:       2.9157880420356603 <-- sum(prediction_error)^2\n","loss_mean:      1.4578940210178302 <-- mean(prediction_error)^2\n"]}],"source":["print(f'-- Neural network outputs and Loss --')\n","print(f'yout:           {yout} <-- neural network output')   \n","print(f'desired output: {ys}')   \n","print(f'err:            {err}')\n","print(f'err_sq:         {err_sq}')\n","print(f'loss_sum:       {loss_sum} <-- sum(prediction_error)^2')\n","print(f'loss_mean:      {loss_mean} <-- mean(prediction_error)^2')\n"]},{"cell_type":"markdown","metadata":{},"source":["##### Save original parameters"]},{"cell_type":"code","execution_count":482,"metadata":{},"outputs":[],"source":["# save original parameters\n","param_org = [p.data for p in n.parameters()]"]},{"cell_type":"markdown","metadata":{},"source":["#   &nbsp;\n","# - How Artificial Neural Network Learns -\n","\n","##### * calculate gradients (i.e. changes in Loss w.r.t. changes in each parameter)<br>* use gradients to adjust parameters in direction of less Loss<br>* repeat the steps"]},{"cell_type":"markdown","metadata":{},"source":["##### Example of calculating gradient for parameter W0<br>* calculate outputs and Loss<br>* increase W0 by small amount, e.g. 0.00001<br>* recalculate outputs and Loss<br>* calculate gradient (W0_grad = changes_in_Loss / changes_in_W0)\n","##### Increase W0 by small amount"]},{"cell_type":"code","execution_count":483,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loss_mean before increase Wo:   1.4578940\n","W0_before:                     -0.7613894\n","W0_after:                      -0.7613794\n","W0_dif:                         0.0000100 <-- increased W0 by a small amount\n"]}],"source":["# Increase W1 by h\n","h = .00001\n","loss_mean_before = loss_mean\n","print(f'loss_mean before increase Wo:  {loss_mean_before:10.7f}')\n","W0_before = n.parameters()[0].data  # W1\n","print(f'W0_before:                     {W0_before:10.7f}')\n","n.parameters()[0].data += h\n","W0_after = n.parameters()[0].data\n","print(f'W0_after:                      {W0_after:10.7f}') \n","W0_dif = W0_after - W0_before\n","print(f'W0_dif:                        {W0_dif:10.7f} <-- increased W0 by a small amount') "]},{"cell_type":"markdown","metadata":{},"source":["##### Recalculate output and Loss with small changes in W0"]},{"cell_type":"code","execution_count":484,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------\n","Calculate Output of Layer: 0\n","weights (3, 2):\n","[[-0.76137944 -0.4310516 ]\n"," [-0.76138447  0.74000735]\n"," [ 0.7285488  -0.69404317]]\n","\n","input (2, 2):\n","[[ 2.  3.]\n"," [ 1. -2.]]\n","\n","weights_x_inputs (3, 2):\n","[[-1.95381048 -1.42203512]\n"," [-0.78276158 -3.76416809]\n"," [ 0.76305442  3.57373273]]\n","\n","bias (3, 1):\n","[[-0.74313044]\n"," [-0.12322464]\n"," [ 0.00326915]]\n","\n","weights_x_inputs_+_bias (3, 2):\n","[[-2.69694092 -2.16516556]\n"," [-0.90598622 -3.88739274]\n"," [ 0.76632357  3.57700188]]\n","\n","Layer 0 Output = tanh(weights_x_inputs_+_bias) (3, 2):\n","[[-0.99095252 -0.97401566]\n"," [-0.71920019 -0.99915996]\n"," [ 0.64478658  0.99843777]]\n","\n","--------------------------------------------------\n","Calculate Output of Layer: 1\n","weights (3, 3):\n","[[ 0.58987046 -0.13246351 -0.02439937]\n"," [ 0.60178347  0.72143806 -0.75271091]\n"," [ 0.13188911 -0.74411    -0.18773959]]\n","\n","input (3, 2):\n","[[-0.99095252 -0.97401566]\n"," [-0.71920019 -0.99915996]\n"," [ 0.64478658  0.99843777]]\n","\n","weights_x_inputs (3, 2):\n","[[-0.50499823 -0.46655209]\n"," [-1.60053512 -2.05851354]\n"," [ 0.28341624  0.42757657]]\n","\n","bias (3, 1):\n","[[-0.65455652]\n"," [-0.92531834]\n"," [ 0.30996426]]\n","\n","weights_x_inputs_+_bias (3, 2):\n","[[-1.15955475 -1.12110861]\n"," [-2.52585347 -2.98383188]\n"," [ 0.5933805   0.73754083]]\n","\n","Layer 1 Output = tanh(weights_x_inputs_+_bias) (3, 2):\n","[[-0.82089473 -0.80795418]\n"," [-0.98728455 -0.99489264]\n"," [ 0.53232255  0.62765709]]\n","\n","--------------------------------------------------\n","Calculate Output of Layer: 2\n","weights (1, 3):\n","[[-0.33837582  0.02895528  0.88707249]]\n","\n","input (3, 2):\n","[[-0.82089473 -0.80795418]\n"," [-0.98728455 -0.99489264]\n"," [ 0.53232255  0.62765709]]\n","\n","weights_x_inputs (1, 2):\n","[[0.72139251 0.8013621 ]]\n","\n","bias (1, 1):\n","[[-0.00134362]]\n","\n","weights_x_inputs_+_bias (1, 2):\n","[[0.72004889 0.80001848]]\n","\n","Layer 2 Output = tanh(weights_x_inputs_+_bias) (1, 2):\n","[[0.61693959 0.6640471 ]]\n","\n","-- Results of neural network outputs and Loss --\n","yout:           [0.61693959 0.6640471 ]\n","desired output: [1.0, -1.0]\n","err:            [-0.38306041  1.6640471 ]\n","err_sq:         [0.14673528 2.76905276]\n","loss_sum:       2.9157880438508035\n","loss_mean:      1.4578940219254017\n"]}],"source":["yout, err, err_sq, loss_sum, loss_mean, w_mats, b_mats = forward_pass(n.layers, verbose=verbose)"]},{"cell_type":"markdown","metadata":{},"source":["##### Calculate gradient"]},{"cell_type":"code","execution_count":485,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-- Calculate outputs and changes in Loss --\n","yout:              [0.61693959 0.6640471 ]\n","desired output:    [1.0, -1.0]\n","err:               [-0.38306041  1.6640471 ]\n","err_sq:            [0.14673528 2.76905276]\n","loss_mean_before:  1.4578940210178302\n","loss_mean_after:   1.4578940219254017\n","\n","-- Calcuclate gradient --\n","loss_mean_dif:     9.075715734496725e-10 <-- change in loss_mean\n","W0_dif:            9.99999999995449e-06 <-- change in W0\n","W0_grad:           9.07571573453803e-05 <-- (changes in loss_mean) / (changes in W0), manual calculation\n"]}],"source":["loss_mean_after = loss_mean\n","loss_mean_dif = loss_mean_after - loss_mean_before\n","W0_grad = loss_mean_dif / W0_dif\n","\n","print(f'-- Calculate outputs and changes in Loss --')\n","print(f'yout:              {yout}')   \n","print(f'desired output:    {ys}')   \n","print(f'err:               {err}')\n","print(f'err_sq:            {err_sq}')\n","print(f'loss_mean_before:  {loss_mean_before}')\n","print(f'loss_mean_after:   {loss_mean_after}\\n')\n","print(f'-- Calcuclate gradient --')\n","print(f'loss_mean_dif:     {loss_mean_dif} <-- change in loss_mean')\n","print(f'W0_dif:            {W0_dif} <-- change in W0')\n","print(f'W0_grad:           {W0_grad} <-- (changes in loss_mean) / (changes in W0), manual calculation')"]},{"cell_type":"markdown","metadata":{},"source":["##### Calculate output and Loss with Micrograd<br>* change W0 back to initial value<br>* compare manual calculation vs Micrograd "]},{"cell_type":"code","execution_count":486,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-- Calculate neural network Loss and gradient using Micrograd --\n","W0:          -0.7613894380557737\n","ypred_data:  [0.616939583813781, 0.664047102574594]\n","ys:          [1.0, -1.0]\n","err_sq:      [0.14673528 2.76905276]\n","loss_mean:   Value(data = 1.4578940210178302) <-- loss_mean, Micrograd calculation same as manual calc. 1.4578940210178302\n"]}],"source":["# change W1 back before Micrograd calculation\n","n.parameters()[0].data = W0_before\n","\n","ypred = [n(x) for x in xs]\n","ypred_data = [v.data for v in ypred]  # extract data \n","loss_mean = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred)) / len(ys) # low loss is better, perfect is loss = 0\n","\n","print(f'-- Calculate neural network Loss and gradient using Micrograd --')\n","print(f'W0:          {n.parameters()[0].data}')\n","print(f'ypred_data:  {ypred_data}')\n","print(f'ys:          {ys}')\n","print(f'err_sq:      {err_sq}')\n","print(f'loss_mean:   {loss_mean} <-- loss_mean, Micrograd calculation same as manual calc. {loss_mean_before}')"]},{"cell_type":"markdown","metadata":{},"source":["##### Calculate gradients and adjust parameters using Micrograd"]},{"cell_type":"code","execution_count":487,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-- adjust parameters,  parameter_adjusted = parameter_before - gradient * learning_rate --\n","  0     -0.7613894381     0.0000907614           0.05000        -0.7613939761 <-- gradient same as manual calc. W0_grad  0.0000907572\n","  1     -0.4310515994    -0.0002518448           0.05000        -0.4310390072\n","  2     -0.7431304436     0.0000029199           0.05000        -0.7431305896\n","  3     -0.7613844654     0.1030908215           0.05000        -0.7665390064\n","  4      0.7400073489     0.0536465525           0.05000         0.7373250213\n","  5     -0.1232246417     0.0518455739           0.05000        -0.1258169204\n","  6      0.7285487951     0.0316377023           0.05000         0.7269669100\n","  7     -0.6940431715     0.0168179411           0.05000        -0.6948840685\n","  8      0.0032691487     0.0159615783           0.05000         0.0024710697\n","  9      0.5898704636     0.0805090802           0.05000         0.5858450096\n"," 10     -0.1324635070     0.0903723821           0.05000        -0.1369821261\n"," 11     -0.0243993714    -0.0922418273           0.05000        -0.0197872800\n"," 12     -0.6545565238    -0.0831119907           0.05000        -0.6504009243\n"," 13      0.6017834687    -0.0000952836           0.05000         0.6017882329\n"," 14      0.7214380583    -0.0001493599           0.05000         0.7214455263\n"," 15     -0.7527109057     0.0001620799           0.05000        -0.7527190096\n"," 16     -0.9253183447     0.0001008439           0.05000        -0.9253233869\n"," 17      0.1318891105    -0.3376620050           0.05000         0.1487722107\n"," 18     -0.7441100034    -0.3912245352           0.05000        -0.7245487766\n"," 19     -0.1877395870     0.4020870618           0.05000        -0.2078439401\n"," 20      0.3099642638     0.3492919758           0.05000         0.2924996650\n"," 21     -0.3383758175    -0.5568496684           0.05000        -0.3105333341\n"," 22      0.0289552771    -0.6912748858           0.05000         0.0635190214\n"," 23      0.8870724851     0.4575913115           0.05000         0.8641929195\n"," 24     -0.0013436152     0.6930092112           0.05000        -0.0359940758\n"]}],"source":["# backward pass to calculate gradients\n","for p in n.parameters():\n","  p.grad = 0.0  # zero the gradient \n","loss_mean.backward()\n","\n","# update weights and bias\n","print('-- adjust parameters,  parameter_adjusted = parameter_before - gradient * learning_rate --')\n","for i, p in enumerate(n.parameters()):\n","  p_before = p.data\n","  p.data += -learning_rate * p.grad\n","\n","  if i == 0:  \n","    print(f'{i:>3}  {p_before:>16.10f}   {p.grad:>14.10f}    {learning_rate:>14.5f}       {p.data:>14.10f} <-- gradient same as manual calc. W0_grad {W0_grad:13.10f}')\n","  else:\n","    print(f'{i:>3}  {p_before:>16.10f}   {p.grad:>14.10f}    {learning_rate:>14.5f}       {p.data:>14.10f}')    "]},{"cell_type":"markdown","metadata":{},"source":["##### Repeat the steps using Micrograd:<br>* calculate Loss<br>* calculate gradient<br>* adjust parameters in direction of less Loss"]},{"cell_type":"code","execution_count":488,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ypred: [Value(data = 0.5222526724684586), Value(data = 0.5729869382616601)]\n","step: 0, loss_mean: 1.3512652084526608\n","ypred: [Value(data = 0.4093362605728397), Value(data = 0.45941231772334307)]\n","step: 1, loss_mean: 1.2393839830983484\n","ypred: [Value(data = 0.2909909750763239), Value(data = 0.3335770894421227)]\n","step: 2, loss_mean: 1.1405608254540724\n","ypred: [Value(data = 0.1873283828973493), Value(data = 0.21556551240766314)]\n","step: 3, loss_mean: 1.069017336099571\n","ypred: [Value(data = 0.11249777102541421), Value(data = 0.12212693089347026)]\n","step: 4, loss_mean: 1.0234145277356286\n","ypred: [Value(data = 0.06702972873173504), Value(data = 0.05619938626443023)]\n","step: 5, loss_mean: 0.9929953353078695\n","ypred: [Value(data = 0.04380302293882582), Value(data = 0.011392404421639165)]\n","step: 6, loss_mean: 0.9686136273313561\n","ypred: [Value(data = 0.035452531007566915), Value(data = -0.020094039705836602)]\n","step: 7, loss_mean: 0.9452837554798676\n","ypred: [Value(data = 0.03690790069492736), Value(data = -0.044273050180338426)]\n","step: 8, loss_mean: 0.920480197177723\n","ypred: [Value(data = 0.0452819082772083), Value(data = -0.06520661454865807)]\n","step: 9, loss_mean: 0.892662654073195\n","ypred: [Value(data = 0.05920361958055235), Value(data = -0.0855873299075867)]\n","step: 10, loss_mean: 0.8606241803179354\n","ypred: [Value(data = 0.07821731057452527), Value(data = -0.10726690103770845)]\n","step: 11, loss_mean: 0.8233278562536389\n","ypred: [Value(data = 0.10229592045017195), Value(data = -0.13157984125311825)]\n","step: 12, loss_mean: 0.7800130932791816\n","ypred: [Value(data = 0.13141272214402647), Value(data = -0.15946318483609673)]\n","step: 13, loss_mean: 0.7304729984495639\n","ypred: [Value(data = 0.16517066329672098), Value(data = -0.19140008741161474)]\n","step: 14, loss_mean: 0.6753869200291907\n","ypred: [Value(data = 0.20259338786569606), Value(data = -0.22725705338635865)]\n","step: 15, loss_mean: 0.6164944833083206\n","ypred: [Value(data = 0.24220709709294874), Value(data = -0.26616735797912205)]\n","step: 16, loss_mean: 0.5563802150958188\n","ypred: [Value(data = 0.2823827402655917), Value(data = -0.3066472649447501)]\n","step: 17, loss_mean: 0.49785627333865845\n","ypred: [Value(data = 0.3217063909656606), Value(data = -0.3469849787918304)]\n","step: 18, loss_mean: 0.44325541899016774\n","ypred: [Value(data = 0.359171711296121), Value(data = -0.3856977077393568)]\n","step: 19, loss_mean: 0.39401410093991135\n","ypred: [Value(data = 0.39418557857380715), Value(data = -0.42180125661898216)]\n","step: 20, loss_mean: 0.3506624500276705\n","ypred: [Value(data = 0.4264836782911175), Value(data = -0.4548268754427014)]\n","step: 21, loss_mean: 0.31306735350302717\n","ypred: [Value(data = 0.45603011123489906), Value(data = -0.4846917046540994)]\n","step: 22, loss_mean: 0.2807229395677071\n","ypred: [Value(data = 0.48293111262302485), Value(data = -0.5115443373859254)]\n","step: 23, loss_mean: 0.25297458431650877\n","ypred: [Value(data = 0.507370560843684), Value(data = -0.5356452169181308)]\n","step: 24, loss_mean: 0.22915456444723808\n","ypred: [Value(data = 0.5295662525772533), Value(data = -0.5572915382148617)]\n","step: 25, loss_mean: 0.20864934642518596\n","ypred: [Value(data = 0.5497427098946772), Value(data = -0.5767764387566574)]\n","step: 26, loss_mean: 0.19092490504224308\n","ypred: [Value(data = 0.5681157282271314), Value(data = -0.5943698286159844)]\n","step: 27, loss_mean: 0.17552993007090345\n","ypred: [Value(data = 0.5848845928272834), Value(data = -0.6103113862257757)]\n","step: 28, loss_mean: 0.16208900848872337\n","ypred: [Value(data = 0.6002289759502992), Value(data = -0.6248098026456518)]\n","step: 29, loss_mean: 0.1502922779302706\n","ypred: [Value(data = 0.614308513205365), Value(data = -0.6380449167860424)]\n","step: 30, loss_mean: 0.13988470262513958\n","ypred: [Value(data = 0.627263799151281), Value(data = -0.6501709567502681)]\n","step: 31, loss_mean: 0.13065631746207965\n","ypred: [Value(data = 0.6392180464746217), Value(data = -0.6613199943711485)]\n","step: 32, loss_mean: 0.12243388210117356\n","ypred: [Value(data = 0.6502789755074256), Value(data = -0.6716052012091976)]\n","step: 33, loss_mean: 0.11507396942249368\n","ypred: [Value(data = 0.6605406984936139), Value(data = -0.6811237436286433)]\n","step: 34, loss_mean: 0.1084573421283074\n","ypred: [Value(data = 0.6700854802224238), Value(data = -0.6899592780808521)]\n","step: 35, loss_mean: 0.10248441980410757\n","ypred: [Value(data = 0.6789853239838226), Value(data = -0.698184064856745)]\n","step: 36, loss_mean: 0.09707164046208441\n","ypred: [Value(data = 0.6873033690614955), Value(data = -0.7058607416453768)]\n","step: 37, loss_mean: 0.09214854315284954\n","ypred: [Value(data = 0.6950951055090339), Value(data = -0.7130438044689664)]\n","step: 38, loss_mean: 0.08765542641909599\n","ypred: [Value(data = 0.7024094212657174), Value(data = -0.7197808419583627)]\n","step: 39, loss_mean: 0.08354146454248469\n","ypred: [Value(data = 0.7092895002478717), Value(data = -0.7261135640959742)]\n","step: 40, loss_mean: 0.07976318721917111\n","ypred: [Value(data = 0.715773590540461), Value(data = -0.7320786607706219)]\n","step: 41, loss_mean: 0.07628324792436252\n","ypred: [Value(data = 0.721895660739305), Value(data = -0.7377085198321452)]\n","step: 42, loss_mean: 0.07306942204213594\n","ypred: [Value(data = 0.7276859607237024), Value(data = -0.7430318292523399)]\n","step: 43, loss_mean: 0.07009378838218577\n","ypred: [Value(data = 0.7331715011495462), Value(data = -0.7480740836324552)]\n","step: 44, loss_mean: 0.0673320575682069\n","ypred: [Value(data = 0.738376463995254), Value(data = -0.7528580116391398)]\n","step: 45, loss_mean: 0.0647630185012931\n","ypred: [Value(data = 0.7433225546884027), Value(data = -0.7574039379310301)]\n","step: 46, loss_mean: 0.062368080131529766\n","ypred: [Value(data = 0.7480293047387037), Value(data = -0.7617300906675862)]\n","step: 47, loss_mean: 0.06013089048186887\n","ypred: [Value(data = 0.7525143324124595), Value(data = -0.7658528636804051)]\n","step: 48, loss_mean: 0.05803701855395879\n","ypred: [Value(data = 0.7567935677945072), Value(data = -0.76978704075372)]\n","step: 49, loss_mean: 0.05607368763552717\n","ypred: [Value(data = 0.760881447576335), Value(data = -0.7735459881350598)]\n","step: 50, loss_mean: 0.05422955080145774\n","ypred: [Value(data = 0.7647910840609824), Value(data = -0.7771418203205687)]\n","step: 51, loss_mean: 0.05249450119361877\n","ypred: [Value(data = 0.768534412164056), Value(data = -0.7805855432842812)]\n","step: 52, loss_mean: 0.05085951108404656\n","ypred: [Value(data = 0.772122317594936), Value(data = -0.7838871786076999)]\n","step: 53, loss_mean: 0.049316494854221724\n","ypred: [Value(data = 0.775564748904591), Value(data = -0.7870558713839065)]\n","step: 54, loss_mean: 0.04785819192316331\n","ypred: [Value(data = 0.7788708156704373), Value(data = -0.7900999842939345)]\n","step: 55, loss_mean: 0.04647806637783215\n","ypred: [Value(data = 0.7820488747407544), Value(data = -0.793027179861948)]\n","step: 56, loss_mean: 0.0451702206388349\n","ypred: [Value(data = 0.7851066061699462), Value(data = -0.7958444925737342)]\n","step: 57, loss_mean: 0.04392932096213732\n","ypred: [Value(data = 0.7880510802317869), Value(data = -0.7985583922770624)]\n","step: 58, loss_mean: 0.04275053295645715\n","ypred: [Value(data = 0.79088881669283), Value(data = -0.8011748400622162)]\n","step: 59, loss_mean: 0.04162946560420509\n","ypred: [Value(data = 0.7936258373557619), Value(data = -0.8036993376379828)]\n","step: 60, loss_mean: 0.04056212252543856\n","ypred: [Value(data = 0.796267712737198), Value(data = -0.8061369710658987)]\n","step: 61, loss_mean: 0.03954485943041855\n","ypred: [Value(data = 0.7988196036217468), Value(data = -0.8084924495880795)]\n","step: 62, loss_mean: 0.03857434687584267\n","ypred: [Value(data = 0.8012862981303482), Value(data = -0.8107701401771038)]\n","step: 63, loss_mean: 0.03764753757966689\n","ypred: [Value(data = 0.803672244852861), Value(data = -0.8129740983465815)]\n","step: 64, loss_mean: 0.03676163766519455\n","ypred: [Value(data = 0.805981582520047), Value(data = -0.8151080956852721)]\n","step: 65, loss_mean: 0.03591408130127591\n","ypred: [Value(data = 0.8082181666263712), Value(data = -0.8171756445135656)]\n","step: 66, loss_mean: 0.03510250828559022\n","ypred: [Value(data = 0.8103855933606278), Value(data = -0.8191800200068201)]\n","step: 67, loss_mean: 0.03432474418496759\n","ypred: [Value(data = 0.8124872211548613), Value(data = -0.8211242800838666)]\n","step: 68, loss_mean: 0.03357878270287045\n","ypred: [Value(data = 0.8145261901221427), Value(data = -0.8230112833196299)]\n","step: 69, loss_mean: 0.03286276999138594\n","ypred: [Value(data = 0.8165054396194714), Value(data = -0.8248437051071659)]\n","step: 70, loss_mean: 0.03217499066491446\n","ypred: [Value(data = 0.8184277241425452), Value(data = -0.8266240522655941)]\n","step: 71, loss_mean: 0.03151385530642956\n","ypred: [Value(data = 0.8202956277336703), Value(data = -0.8283546762656433)]\n","step: 72, loss_mean: 0.03087788928575387\n","ypred: [Value(data = 0.8221115770620451), Value(data = -0.8300377852232137)]\n","step: 73, loss_mean: 0.030265722733591585\n","ypred: [Value(data = 0.8238778533165727), Value(data = -0.8316754547929691)]\n","step: 74, loss_mean: 0.02967608153576623\n","ypred: [Value(data = 0.8255966030347809), Value(data = -0.8332696380780628)]\n","step: 75, loss_mean: 0.02910777922981399\n","ypred: [Value(data = 0.8272698479770182), Value(data = -0.8348221746583115)]\n","step: 76, loss_mean: 0.02855970970124587\n","ypred: [Value(data = 0.8288994941425346), Value(data = -0.8363347988271601)]\n","step: 77, loss_mean: 0.028030840589813352\n","ypred: [Value(data = 0.830487340013081), Value(data = -0.8378091471173436)]\n","step: 78, loss_mean: 0.02752020732732216\n","ypred: [Value(data = 0.8320350841000735), Value(data = -0.8392467651860728)]\n","step: 79, loss_mean: 0.027026907738205496\n","ypred: [Value(data = 0.8335443318629558), Value(data = -0.8406491141226135)]\n","step: 80, loss_mean: 0.026550097142428827\n","ypred: [Value(data = 0.8350166020590125), Value(data = -0.84201757623417)]\n","step: 81, loss_mean: 0.026088983907540268\n","ypred: [Value(data = 0.8364533325783943), Value(data = -0.8433534603598848)]\n","step: 82, loss_mean: 0.02564282540296775\n","ypred: [Value(data = 0.837855885812399), Value(data = -0.8446580067573938)]\n","step: 83, loss_mean: 0.025210924315133852\n","ypred: [Value(data = 0.8392255535980038), Value(data = -0.8459323916016538)]\n","step: 84, loss_mean: 0.02479262528672726\n","ypred: [Value(data = 0.8405635617771836), Value(data = -0.847177731131595)]\n","step: 85, loss_mean: 0.024387311847632508\n","ypred: [Value(data = 0.8418710744056118), Value(data = -0.8483950854764639)]\n","step: 86, loss_mean: 0.023994403608662118\n","ypred: [Value(data = 0.8431491976418252), Value(data = -0.8495854621904673)]\n","step: 87, loss_mean: 0.023613353692429288\n","ypred: [Value(data = 0.84439898334484), Value(data = -0.8507498195214384)]\n","step: 88, loss_mean: 0.023243646378501306\n","ypred: [Value(data = 0.8456214324054377), Value(data = -0.8518890694366819)]\n","step: 89, loss_mean: 0.022884794942440438\n","ypred: [Value(data = 0.8468174978338774), Value(data = -0.853004080426875)]\n","step: 90, loss_mean: 0.022536339670511392\n","ypred: [Value(data = 0.8479880876245987), Value(data = -0.8540956801068715)]\n","step: 91, loss_mean: 0.02219784603375153\n","ypred: [Value(data = 0.8491340674165196), Value(data = -0.8551646576304429)]\n","step: 92, loss_mean: 0.02186890300679503\n","ypred: [Value(data = 0.8502562629657812), Value(data = -0.8562117659343734)]\n","step: 93, loss_mean: 0.02154912151834235\n","ypred: [Value(data = 0.8513554624462196), Value(data = -0.8572377238258851)]\n","step: 94, loss_mean: 0.021238133021495735\n","ypred: [Value(data = 0.8524324185914437), Value(data = -0.8582432179260645)]\n","step: 95, loss_mean: 0.020935588173364064\n","ypred: [Value(data = 0.8534878506911259), Value(data = -0.8592289044808061)]\n","step: 96, loss_mean: 0.020641155614389915\n","ypred: [Value(data = 0.8545224464529898), Value(data = -0.8601954110497464)]\n","step: 97, loss_mean: 0.020354520838786295\n","ypred: [Value(data = 0.855536863740943), Value(data = -0.8611433380827188)]\n","step: 98, loss_mean: 0.020075385148306507\n","ypred: [Value(data = 0.8565317321988933), Value(data = -0.8620732603924198)]\n","step: 99, loss_mean: 0.019803464682313643\n","ypred: [Value(data = 0.857507654768954), Value(data = -0.8629857285312135)]\n","step: 100, loss_mean: 0.01953848951778297\n","ypred: [Value(data = 0.8584652091119866), Value(data = -0.8638812700793184)]\n","step: 101, loss_mean: 0.01928020283346657\n","ypred: [Value(data = 0.8594049489377649), Value(data = -0.864760390850992)]\n","step: 102, loss_mean: 0.01902836013298448\n","ypred: [Value(data = 0.8603274052514142), Value(data = -0.8656235760247792)]\n","step: 103, loss_mean: 0.018782728522085488\n","ypred: [Value(data = 0.8612330875222396), Value(data = -0.8664712912033713)]\n","step: 104, loss_mean: 0.018543086035752644\n","ypred: [Value(data = 0.8621224847805389), Value(data = -0.8673039834081686)]\n","step: 105, loss_mean: 0.01830922101121616\n","ypred: [Value(data = 0.8629960666475469), Value(data = -0.8681220820132183)]\n","step: 106, loss_mean: 0.018080931503285866\n","ypred: [Value(data = 0.8638542843032383), Value(data = -0.8689259996228245)]\n","step: 107, loss_mean: 0.01785802473872964\n","ypred: [Value(data = 0.864697571396336), Value(data = -0.8697161328967733)]\n","step: 108, loss_mean: 0.01764031660671042\n","ypred: [Value(data = 0.8655263449005297), Value(data = -0.870492863326811)]\n","step: 109, loss_mean: 0.017427631182549676\n","ypred: [Value(data = 0.8663410059205936), Value(data = -0.8712565579677197)]\n","step: 110, loss_mean: 0.017219800282318953\n","ypred: [Value(data = 0.8671419404518044), Value(data = -0.8720075701260809)]\n","step: 111, loss_mean: 0.017016663045971\n","ypred: [Value(data = 0.8679295200958013), Value(data = -0.8727462400095695)]\n","step: 112, loss_mean: 0.01681806554691373\n","ypred: [Value(data = 0.8687041027357864), Value(data = -0.8734728953394129)]\n","step: 113, loss_mean: 0.01662386042610306\n","ypred: [Value(data = 0.8694660331737492), Value(data = -0.8741878519284446)]\n","step: 114, loss_mean: 0.016433906548887864\n","ypred: [Value(data = 0.8702156437321933), Value(data = -0.8748914142269992)]\n","step: 115, loss_mean: 0.016248068682984635\n","ypred: [Value(data = 0.8709532548226648), Value(data = -0.8755838758387336)]\n","step: 116, loss_mean: 0.016066217196087862\n","ypred: [Value(data = 0.8716791754832072), Value(data = -0.8762655200082992)]\n","step: 117, loss_mean: 0.015888227771743077\n","ypred: [Value(data = 0.8723937038867191), Value(data = -0.8769366200826553)]\n","step: 118, loss_mean: 0.015713981142215526\n","ypred: [Value(data = 0.8730971278220434), Value(data = -0.8775974399476814)]\n","step: 119, loss_mean: 0.015543362837188131\n","ypred: [Value(data = 0.8737897251494885), Value(data = -0.8782482344416277)]\n","step: 120, loss_mean: 0.015376262947211256\n","ypred: [Value(data = 0.8744717642323622), Value(data = -0.8788892497468345)]\n","step: 121, loss_mean: 0.015212575900910153\n","ypred: [Value(data = 0.8751435043459839), Value(data = -0.8795207237610523)]\n","step: 122, loss_mean: 0.01505220025503101\n","ypred: [Value(data = 0.875805196065547), Value(data = -0.8801428864495968)]\n","step: 123, loss_mean: 0.014895038496475737\n","ypred: [Value(data = 0.8764570816340967), Value(data = -0.8807559601794949)]\n","step: 124, loss_mean: 0.014740996855539226\n","ypred: [Value(data = 0.8770993953118161), Value(data = -0.8813601600366895)]\n","step: 125, loss_mean: 0.014589985129620585\n","ypred: [Value(data = 0.8777323637077187), Value(data = -0.8819556941273102)]\n","step: 126, loss_mean: 0.014441916516733365\n","ypred: [Value(data = 0.8783562060947828), Value(data = -0.8825427638639359)]\n","step: 127, loss_mean: 0.014296707458189034\n","ypred: [Value(data = 0.878971134709487), Value(data = -0.883121564237727)]\n","step: 128, loss_mean: 0.014154277489872462\n","ypred: [Value(data = 0.879577355036648), Value(data = -0.8836922840772341)]\n","step: 129, loss_mean: 0.014014549101570167\n","ypred: [Value(data = 0.8801750660803975), Value(data = -0.8842551062946485)]\n","step: 130, loss_mean: 0.013877447603850103\n","ypred: [Value(data = 0.8807644606220827), Value(data = -0.8848102081202021)]\n","step: 131, loss_mean: 0.013742901002027018\n","ypred: [Value(data = 0.8813457254658312), Value(data = -0.8853577613253825)]\n","step: 132, loss_mean: 0.013610839876778932\n","ypred: [Value(data = 0.8819190416724583), Value(data = -0.8858979324355852)]\n","step: 133, loss_mean: 0.01348119727101246\n","ypred: [Value(data = 0.8824845847823686), Value(data = -0.8864308829327875)]\n","step: 134, loss_mean: 0.013353908582599269\n","ypred: [Value(data = 0.8830425250280504), Value(data = -0.8869567694487864)]\n","step: 135, loss_mean: 0.013228911462634526\n","ypred: [Value(data = 0.8835930275367322), Value(data = -0.8874757439495172)]\n","step: 136, loss_mean: 0.013106145718889298\n","ypred: [Value(data = 0.8841362525237291), Value(data = -0.8879879539109319)]\n","step: 137, loss_mean: 0.0129855532241523\n","ypred: [Value(data = 0.8846723554769784), Value(data = -0.8884935424868841)]\n","step: 138, loss_mean: 0.01286707782917638\n","ypred: [Value(data = 0.8852014873332337), Value(data = -0.8889926486694513)]\n","step: 139, loss_mean: 0.012750665279962794\n","ypred: [Value(data = 0.8857237946463538), Value(data = -0.8894854074420878)]\n","step: 140, loss_mean: 0.012636263139135032\n","ypred: [Value(data = 0.8862394197481035), Value(data = -0.8899719499259806)]\n","step: 141, loss_mean: 0.012523820711169552\n","ypred: [Value(data = 0.8867485009018506), Value(data = -0.890452403519967)]\n","step: 142, loss_mean: 0.012413288971265129\n","ypred: [Value(data = 0.887251172449529), Value(data = -0.8909268920343365)]\n","step: 143, loss_mean: 0.012304620497647568\n","ypred: [Value(data = 0.8877475649522077), Value(data = -0.8913955358188349)]\n","step: 144, loss_mean: 0.012197769407118395\n","ypred: [Value(data = 0.8882378053245943), Value(data = -0.8918584518851614)]\n","step: 145, loss_mean: 0.012092691293668613\n","ypred: [Value(data = 0.8887220169637742), Value(data = -0.8923157540242362)]\n","step: 146, loss_mean: 0.011989343169989678\n","ypred: [Value(data = 0.8892003198724765), Value(data = -0.8927675529184976)]\n","step: 147, loss_mean: 0.011887683411724366\n","ypred: [Value(data = 0.889672830777137), Value(data = -0.8932139562494771)]\n","step: 148, loss_mean: 0.011787671704309423\n","ypred: [Value(data = 0.8901396632410128), Value(data = -0.8936550688008824)]\n","step: 149, loss_mean: 0.011689268992271564\n","ypred: [Value(data = 0.8906009277725943), Value(data = -0.894090992557408)]\n","step: 150, loss_mean: 0.011592437430846075\n","ypred: [Value(data = 0.8910567319295379), Value(data = -0.8945218267994811)]\n","step: 151, loss_mean: 0.011497140339795611\n","ypred: [Value(data = 0.8915071804183397), Value(data = -0.8949476681941358)]\n","step: 152, loss_mean: 0.01140334215931404\n","ypred: [Value(data = 0.8919523751899505), Value(data = -0.8953686108822045)]\n","step: 153, loss_mean: 0.011311008407906373\n","ypred: [Value(data = 0.8923924155315269), Value(data = -0.895784746561995)]\n","step: 154, loss_mean: 0.011220105642143586\n","ypred: [Value(data = 0.8928273981545001), Value(data = -0.8961961645696241)]\n","step: 155, loss_mean: 0.011130601418195305\n","ypred: [Value(data = 0.8932574172791342), Value(data = -0.8966029519561618)]\n","step: 156, loss_mean: 0.01104246425505033\n","ypred: [Value(data = 0.8936825647157398), Value(data = -0.8970051935617337)]\n","step: 157, loss_mean: 0.010955663599339398\n","ypred: [Value(data = 0.8941029299426928), Value(data = -0.8974029720867216)]\n","step: 158, loss_mean: 0.010870169791680128\n","ypred: [Value(data = 0.8945186001814102), Value(data = -0.897796368160196)]\n","step: 159, loss_mean: 0.010785954034467696\n","ypred: [Value(data = 0.8949296604684179), Value(data = -0.8981854604057063)]\n","step: 160, loss_mean: 0.010702988361039964\n","ypred: [Value(data = 0.8953361937246441), Value(data = -0.8985703255045473)]\n","step: 161, loss_mean: 0.010621245606149356\n","ypred: [Value(data = 0.8957382808220611), Value(data = -0.8989510382566136)]\n","step: 162, loss_mean: 0.010540699377677883\n","ypred: [Value(data = 0.8961360006477963), Value(data = -0.8993276716389553)]\n","step: 163, loss_mean: 0.010461324029534286\n","ypred: [Value(data = 0.8965294301658233), Value(data = -0.8997002968621285)]\n","step: 164, loss_mean: 0.010383094635677194\n","ypred: [Value(data = 0.8969186444763393), Value(data = -0.9000689834244426)]\n","step: 165, loss_mean: 0.010305986965209828\n","ypred: [Value(data = 0.8973037168729316), Value(data = -0.9004337991641971)]\n","step: 166, loss_mean: 0.010229977458495213\n","ypred: [Value(data = 0.8976847188976281), Value(data = -0.9007948103099901)]\n","step: 167, loss_mean: 0.01015504320424411\n","ypred: [Value(data = 0.8980617203939243), Value(data = -0.9011520815291876)]\n","step: 168, loss_mean: 0.010081161917529426\n","ypred: [Value(data = 0.8984347895578716), Value(data = -0.9015056759746268)]\n","step: 169, loss_mean: 0.010008311918684516\n","ypred: [Value(data = 0.8988039929873142), Value(data = -0.9018556553296341)]\n","step: 170, loss_mean: 0.009936472113043573\n","ypred: [Value(data = 0.8991693957293464), Value(data = -0.9022020798514236)]\n","step: 171, loss_mean: 0.009865621971486233\n","ypred: [Value(data = 0.8995310613260726), Value(data = -0.9025450084129473)]\n","step: 172, loss_mean: 0.009795741511748949\n","ypred: [Value(data = 0.8998890518587345), Value(data = -0.9028844985432619)]\n","step: 173, loss_mean: 0.009726811280468428\n","ypred: [Value(data = 0.9002434279902786), Value(data = -0.9032206064664726)]\n","step: 174, loss_mean: 0.009658812335924048\n","ypred: [Value(data = 0.900594249006425), Value(data = -0.9035533871393121)]\n","step: 175, loss_mean: 0.009591726231448019\n","ypred: [Value(data = 0.9009415728553016), Value(data = -0.9038828942874118)]\n","step: 176, loss_mean: 0.00952553499947319\n","ypred: [Value(data = 0.9012854561857002), Value(data = -0.9042091804403187)]\n","step: 177, loss_mean: 0.009460221136190364\n","ypred: [Value(data = 0.9016259543840122), Value(data = -0.9045322969653081)]\n","step: 178, loss_mean: 0.009395767586788287\n","ypred: [Value(data = 0.9019631216098959), Value(data = -0.9048522941000389)]\n","step: 179, loss_mean: 0.00933215773125078\n","ypred: [Value(data = 0.9022970108307274), Value(data = -0.9051692209841024)]\n","step: 180, loss_mean: 0.009269375370686502\n","ypred: [Value(data = 0.9026276738548832), Value(data = -0.9054831256895038)]\n","step: 181, loss_mean: 0.009207404714168563\n","ypred: [Value(data = 0.9029551613638991), Value(data = -0.9057940552501212)]\n","step: 182, loss_mean: 0.009146230366062037\n","ypred: [Value(data = 0.9032795229435542), Value(data = -0.9061020556901814)]\n","step: 183, loss_mean: 0.009085837313818127\n","ypred: [Value(data = 0.9036008071139168), Value(data = -0.9064071720517908)]\n","step: 184, loss_mean: 0.009026210916215686\n","ypred: [Value(data = 0.9039190613583958), Value(data = -0.9067094484215592)]\n","step: 185, loss_mean: 0.008967336892030713\n","ypred: [Value(data = 0.9042343321518357), Value(data = -0.9070089279563499)]\n","step: 186, loss_mean: 0.008909201309116127\n","ypred: [Value(data = 0.9045466649876918), Value(data = -0.9073056529081911)]\n","step: 187, loss_mean: 0.008851790573874346\n","ypred: [Value(data = 0.90485610440432), Value(data = -0.9075996646483789)]\n","step: 188, loss_mean: 0.008795091421106849\n","ypred: [Value(data = 0.9051626940104166), Value(data = -0.9078910036908056)]\n","step: 189, loss_mean: 0.008739090904224533\n","ypred: [Value(data = 0.905466476509639), Value(data = -0.9081797097145369)]\n","step: 190, loss_mean: 0.008683776385804677\n","ypred: [Value(data = 0.9057674937244377), Value(data = -0.9084658215856751)]\n","step: 191, loss_mean: 0.008629135528479676\n","ypred: [Value(data = 0.9060657866191313), Value(data = -0.9087493773785248)]\n","step: 192, loss_mean: 0.00857515628614473\n","ypred: [Value(data = 0.9063613953222507), Value(data = -0.9090304143960939)]\n","step: 193, loss_mean: 0.008521826895471108\n","ypred: [Value(data = 0.9066543591481795), Value(data = -0.9093089691899526)]\n","step: 194, loss_mean: 0.008469135867713012\n","ypred: [Value(data = 0.9069447166181182), Value(data = -0.9095850775794727)]\n","step: 195, loss_mean: 0.008417071980796153\n","ypred: [Value(data = 0.9072325054803952), Value(data = -0.9098587746704728)]\n","step: 196, loss_mean: 0.008365624271676746\n","ypred: [Value(data = 0.9075177627301497), Value(data = -0.9101300948732854)]\n","step: 197, loss_mean: 0.008314782028960778\n","ypred: [Value(data = 0.9078005246284077), Value(data = -0.9103990719202748)]\n","step: 198, loss_mean: 0.008264534785772475\n","ypred: [Value(data = 0.9080808267205753), Value(data = -0.9106657388828164)]\n","step: 199, loss_mean: 0.008214872312863018\n"]}],"source":["# Create a list of losses\n","losses_mean = []\n","for k in range(200):\n","  # forward pass\n","  ypred = [n(x) for x in xs]\n","  # loss is mean-square-errors\n","  loss_mean = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred)) / len(ys) # low loss is better, perfect is loss = 0  \n","  losses_mean.append(loss_mean.data)\n","\n","  # backward pass to calculate gradients\n","  for p in n.parameters():\n","    p.grad = 0.0  # zero the gradient \n","  loss_mean.backward()\n","\n","  # update weights and bias\n","  for p in n.parameters():\n","      p.data += -learning_rate * p.grad\n","\n","  # print(f'x: {x}')\n","  print(f'ypred: {ypred}')\n","  print(f'step: {k}, loss_mean: {loss_mean.data}')   \n","  # print('-------')"]},{"cell_type":"markdown","metadata":{},"source":["##### Plot Loss"]},{"cell_type":"code","execution_count":489,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plot_losses(losses_mean)"]},{"cell_type":"markdown","metadata":{},"source":["##### Calculate outputs and Loss after last parameter adjustment"]},{"cell_type":"code","execution_count":490,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","- Calculate outputs and Loss at end of iteration -\n","ypred_data: [0.9083587038543676, -0.910930128187766]\n","loss_mean: 0.008165784611949653\n","\n","\n","Calculate outputs and Loss using optimized parameters\n","--------------------------------------------------\n","Calculate Output of Layer: 0\n","weights (3, 2):\n","[[-0.78187986 -0.41049081]\n"," [-0.99469716  0.62141451]\n"," [ 0.06414302 -1.10565638]]\n","\n","input (2, 2):\n","[[ 2.  3.]\n"," [ 1. -2.]]\n","\n","weights_x_inputs (3, 2):\n","[[-1.97425053 -1.52465797]\n"," [-1.3679798  -4.22692049]\n"," [-0.97737035  2.40374181]]\n","\n","bias (3, 1):\n","[[-0.7489748 ]\n"," [-0.24015763]\n"," [-0.34027807]]\n","\n","weights_x_inputs_+_bias (3, 2):\n","[[-2.72322533 -2.27363277]\n"," [-1.60813743 -4.46707811]\n"," [-1.31764842  2.06346374]]\n","\n","Layer 0 Output = tanh(weights_x_inputs_+_bias) (3, 2):\n","[[-0.99141386 -0.97902992]\n"," [-0.92288431 -0.99973642]\n"," [-0.86619793  0.9682475 ]]\n","\n","--------------------------------------------------\n","Calculate Output of Layer: 1\n","weights (3, 3):\n","[[ 0.5589364  -0.18170489  0.15430924]\n"," [ 0.58179734  0.70356474 -0.76731925]\n"," [ 0.34118322 -0.3977866  -1.36280647]]\n","\n","input (3, 2):\n","[[-0.99141386 -0.97902992]\n"," [-0.92288431 -0.99973642]\n"," [-0.86619793  0.9682475 ]]\n","\n","weights_x_inputs (3, 2):\n","[[-0.52010705 -0.21614893]\n"," [-0.56146047 -2.01593125]\n"," [ 1.20931738 -1.2558808 ]]\n","\n","bias (3, 1):\n","[[-0.62100759]\n"," [-0.90519758]\n"," [ 0.08200828]]\n","\n","weights_x_inputs_+_bias (3, 2):\n","[[-1.14111464 -0.83715652]\n"," [-1.46665804 -2.92112883]\n"," [ 1.29132566 -1.17387252]]\n","\n","Layer 1 Output = tanh(weights_x_inputs_+_bias) (3, 2):\n","[[-0.81478909 -0.68430003]\n"," [-0.89893802 -0.99421223]\n"," [ 0.85947333 -0.82550965]]\n","\n","--------------------------------------------------\n","Calculate Output of Layer: 2\n","weights (1, 3):\n","[[-0.31559356  0.18398482  1.77586958]]\n","\n","input (3, 2):\n","[[-0.81478909 -0.68430003]\n"," [-0.89893802 -0.99421223]\n"," [ 0.85947333 -0.82550965]]\n","\n","weights_x_inputs (1, 2):\n","[[ 1.61806378 -1.43295676]]\n","\n","bias (1, 1):\n","[[-0.10000537]]\n","\n","weights_x_inputs_+_bias (1, 2):\n","[[ 1.51805842 -1.53296212]]\n","\n","Layer 2 Output = tanh(weights_x_inputs_+_bias) (1, 2):\n","[[ 0.9083587  -0.91093013]]\n","\n","-- Results of neural network outputs and Loss --\n","yout:           [ 0.9083587  -0.91093013]\n","desired output: [1.0, -1.0]\n","err:            [-0.0916413   0.08906987]\n","err_sq:         [0.00839813 0.00793344]\n","loss_sum:       0.016331569223899306\n","loss_mean:      0.008165784611949653\n"]}],"source":["# calculate outputs and Loss after last parameter adjustment\n","ypred = [n(x) for x in xs]\n","loss_mean = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred)) / len(ys) # low loss is better, perfect is loss = 0\n","ypred_data = [value.data for value in ypred]\n","\n","print(f'\\n- Calculate outputs and Loss at end of iteration -')\n","print(f'ypred_data: {ypred_data}')\n","print(f'loss_mean: {loss_mean.data}\\n\\n')\n","\n","# check calculation using forward pass function\n","print(f'Calculate outputs and Loss using optimized parameters')\n","yout, err, err_sq, loss_sum, loss_mean, w_mats, b_mats = forward_pass(n.layers, verbose=verbose)"]},{"cell_type":"markdown","metadata":{},"source":["##### Changes in parameters after optimization"]},{"cell_type":"code","execution_count":491,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["i   param_optimized      param_org      param_dif\n","0     -0.7818798619  -0.7613894381  -0.0204904238\n","1     -0.4104908061  -0.4310515994   0.0205607934\n","2     -0.7489747976  -0.7431304436  -0.0058443540\n","3     -0.9946971558  -0.7613844654  -0.2333126904\n","4      0.6214145089   0.7400073489  -0.1185928400\n","5     -0.2401576290  -0.1232246417  -0.1169329873\n","6      0.0641430164   0.7285487951  -0.6644057787\n","7     -1.1056563808  -0.6940431715  -0.4116132093\n","8     -0.3402780721   0.0032691487  -0.3435472208\n","9      0.5589364032   0.5898704636  -0.0309340604\n","10    -0.1817048905  -0.1324635070  -0.0492413835\n","11     0.1543092430  -0.0243993714   0.1787086144\n","12    -0.6210075930  -0.6545565238   0.0335489308\n","13     0.5817973429   0.6017834687  -0.0199861259\n","14     0.7035647415   0.7214380583  -0.0178733168\n","15    -0.7673192487  -0.7527109057  -0.0146083430\n","16    -0.9051975793  -0.9253183447   0.0201207654\n","17     0.3411832238   0.1318891105   0.2092941133\n","18    -0.3977865953  -0.7441100034   0.3463234081\n","19    -1.3628064680  -0.1877395870  -1.1750668810\n","20     0.0820082798   0.3099642638  -0.2279559840\n","21    -0.3155935550  -0.3383758175   0.0227822625\n","22     0.1839848224   0.0289552771   0.1550295453\n","23     1.7758695805   0.8870724851   0.8887970954\n","24    -0.1000053657  -0.0013436152  -0.0986617505\n"]}],"source":["# save parameters\n","param_optmz = [p.data for p in n.parameters()]\n","param_comp = zip(param_org, param_optmz)\n","\n","# print(f'i        param_new      param_org      param_dif')\n","print(f'i   param_optimized      param_org      param_dif')\n","for i, param_org_new in enumerate(param_comp):\n","  p_org = param_org_new[0]\n","  p_new = param_org_new[1]  \n","  p_dif = p_new - p_org\n","  print(f'{i:<4} {p_new:>14.10f} {p_org:>14.10f} {p_dif:>14.10f}')  \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#   &nbsp;\n","# - Build Same Model with PyTorch -"]},{"cell_type":"code","execution_count":492,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predictions:\n","tensor([[0.0106],\n","        [0.0542]])\n","Epoch 0 loss: 1.0451178550720215\n","Predictions:\n","tensor([[ 0.1409],\n","        [-0.0995]])\n","Epoch 10 loss: 0.7744830250740051\n","Predictions:\n","tensor([[ 0.4650],\n","        [-0.4179]])\n","Epoch 20 loss: 0.3125457763671875\n","Predictions:\n","tensor([[ 0.8115],\n","        [-0.7636]])\n","Epoch 30 loss: 0.04571077227592468\n","Predictions:\n","tensor([[ 0.9478],\n","        [-0.9256]])\n","Epoch 40 loss: 0.0041314996778965\n","Predictions:\n","tensor([[ 0.9860],\n","        [-0.9787]])\n","Epoch 50 loss: 0.00032483195536769927\n","Predictions:\n","tensor([[ 0.9962],\n","        [-0.9941]])\n","Epoch 60 loss: 2.4594533897470683e-05\n","Predictions:\n","tensor([[ 0.9990],\n","        [-0.9984]])\n","Epoch 70 loss: 1.8431974240229465e-06\n","Predictions:\n","tensor([[ 0.9997],\n","        [-0.9996]])\n","Epoch 80 loss: 1.3778208085568622e-07\n","Predictions:\n","tensor([[ 0.9999],\n","        [-0.9999]])\n","Epoch 90 loss: 1.027098051054054e-08\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Epoch 100 loss: 7.677982694076491e-10\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Epoch 110 loss: 5.7411853049416095e-11\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Epoch 120 loss: 4.526157226791838e-12\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Epoch 130 loss: 5.631051180898794e-13\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Epoch 140 loss: 3.694822225952521e-13\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Epoch 150 loss: 3.694822225952521e-13\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Epoch 160 loss: 4.440892098500626e-13\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Epoch 170 loss: 3.694822225952521e-13\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Epoch 180 loss: 3.694822225952521e-13\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Epoch 190 loss: 3.019806626980426e-13\n","\n","Predictions:\n","tensor([[ 1.0000],\n","        [-1.0000]])\n","Loss: 3.019806626980426e-13\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","class MLP_torch(nn.Module):\n","    def __init__(self):\n","        super(MLP_torch, self).__init__()\n","        self.fc1 = nn.Linear(2, 3)\n","        self.fc2 = nn.Linear(3, 3)\n","        self.fc3 = nn.Linear(3, 1)\n","\n","    def forward(self, x):\n","        x = torch.tanh(self.fc1(x))\n","        x = torch.tanh(self.fc2(x))\n","        x = self.fc3(x)  \n","        return x\n","\n","model = MLP_torch()\n","\n","# # inputs\n","# xs = [\n","#   [2.0, 3.0, -1.0],\n","#   [3.0, -1.0, 0.5]\n","# ]\n","\n","# # desired targets\n","# ys = [1.0, -1.0]\n","\n","# convert to tensor\n","t_xs = torch.tensor(xs)\n","\n","# add a dimension to the index=1 position to target tensor,\n","#  e.g. change size from [2] to [2, 1]\n","t_ys = torch.unsqueeze(torch.tensor(ys), 1)\n","\n","# # learning rate (i.e. step size)\n","# learning_rate = 0.05\n","\n","losses = []\n","for epoch in range(200):\n","    # forward pass\n","    predictions = model(t_xs)\n","\n","    # calculate loss\n","    loss = torch.nn.functional.mse_loss(predictions, t_ys)\n","\n","    # remove loss gradient \n","    losses.append(loss.detach())\n","\n","    # backpropagate\n","    loss.backward()\n","\n","    # update weights\n","    for p in model.parameters():\n","        p.data -= learning_rate * p.grad.data\n","\n","    # zero gradients\n","    for p in model.parameters():\n","        p.grad.data.zero_()\n","\n","    if epoch % 10 == 0:\n","        print(f\"Predictions:\\n{predictions.detach()}\")\n","        print(f\"Epoch {epoch} loss: {loss}\")\n","\n","predictions = model(t_xs)\n","print('')\n","print(f\"Predictions:\\n{predictions.detach()}\")\n","print(f\"Loss: {loss}\")"]},{"cell_type":"code","execution_count":493,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plot_losses(losses)"]},{"cell_type":"code","execution_count":494,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["input xs:\n","[[2.0, 1.0], [3.0, -2.0]]\n","\n","target ys:\n","[1.0, -1.0]\n","---------\n","\n","layer: 0.0,  i: 0\n","\n","w,  torch.Size([3, 2]):\n","tensor([[-0.2375, -0.2410],\n","        [ 0.4590, -0.2237],\n","        [ 0.2821,  0.8610]])\n","\n","input,  torch.Size([2, 2]):\n","tensor([[ 2.,  3.],\n","        [ 1., -2.]])\n","\n","w * input,  torch.Size([3, 2]):\n","tensor([[-0.7160, -0.2306],\n","        [ 0.6944,  1.8245],\n","        [ 1.4252, -0.8758]])\n","\n","bT,  torch.Size([3, 1]):\n","tensor([[ 0.4176],\n","        [ 0.5807],\n","        [-0.4454]])\n","\n","w * input + bT,  torch.Size([3, 2]):\n","tensor([[-0.2984,  0.1870],\n","        [ 1.2751,  2.4052],\n","        [ 0.9798, -1.3212]])\n","\n","output,  torch.Size([3, 2]):\n","tensor([[-0.2898,  0.1848],\n","        [ 0.8552,  0.9838],\n","        [ 0.7530, -0.8671]])\n","\n","\n","layer: 1.0,  i: 2\n","\n","w,  torch.Size([3, 3]):\n","tensor([[ 0.5506,  0.1965, -1.0038],\n","        [ 0.4122, -0.4259, -0.3148],\n","        [-0.4236, -0.0245, -0.6675]])\n","\n","input,  torch.Size([3, 2]):\n","tensor([[-0.2898,  0.1848],\n","        [ 0.8552,  0.9838],\n","        [ 0.7530, -0.8671]])\n","\n","w * input,  torch.Size([3, 2]):\n","tensor([[-0.7473,  1.1655],\n","        [-0.7208, -0.0699],\n","        [-0.4008,  0.4763]])\n","\n","bT,  torch.Size([3, 1]):\n","tensor([[-0.1286],\n","        [-0.2945],\n","        [ 0.3364]])\n","\n","w * input + bT,  torch.Size([3, 2]):\n","tensor([[-0.8759,  1.0369],\n","        [-1.0153, -0.3644],\n","        [-0.0644,  0.8127]])\n","\n","output,  torch.Size([3, 2]):\n","tensor([[-0.7044,  0.7767],\n","        [-0.7680, -0.3491],\n","        [-0.0643,  0.6711]])\n","\n","\n","layer: 2.0,  i: 4\n","\n","w,  torch.Size([1, 3]):\n","tensor([[-1.0280,  0.0361, -0.6698]])\n","\n","input,  torch.Size([3, 2]):\n","tensor([[-0.7044,  0.7767],\n","        [-0.7680, -0.3491],\n","        [-0.0643,  0.6711]])\n","\n","w * input,  torch.Size([1, 2]):\n","tensor([[ 0.7395, -1.2605]])\n","\n","bT,  torch.Size([1, 1]):\n","tensor([[0.2605]])\n","\n","w * input + bT,  torch.Size([1, 2]):\n","tensor([[ 1.0000, -1.0000]])\n","\n","output,  torch.Size([1, 2]):\n","tensor([[ 1.0000, -1.0000]])\n","\n","\n"]}],"source":["print(f'input xs:\\n{xs}\\n')\n","print(f'target ys:\\n{ys}')\n","print('---------\\n')\n","\n","# l_items is a list of [weight matrix, bias matrix, ..., weight matrix, bias matrix] \n","l_items = list(model.parameters())\n","if len(l_items) % 2 == 0:  # True divisible by 2\n","  for i in range(0, len(l_items), 2):  # i: 0, 2, ..., len(l_items)-2\n","    if i == 0:  # use transposed t_xs as input only at the first time\n","      x0 = torch.clone(t_xs).detach()  # clone t_xs without autograd history\n","      input = torch.transpose(x0, 0, 1)  # columns of x0 becomes rows of input\n","    else:  # use previous output as input \n","      input = output\n","\n","    w = l_items[i].detach()  # remove gradient\n","    b_ = l_items[i + 1].detach()  # remove gradient\n","    b = torch.clone(b_).detach()  # remove gradient\n","    bT = torch.unsqueeze(b, 1)  # add a dimension to index 1 position\n","    w_input = torch.matmul(w, input)\n","    w_input_bT = torch.add(w_input, bT)\n","\n","    if i == len(l_items) - 2:  # skip tanh activation on output node\n","      output = w_input_bT\n","    else:  \n","      output = torch.tanh(w_input_bT)      \n","\n","    print(f'layer: {i / 2},  i: {i}\\n')\n","    print(f'w,  {w.shape}:\\n{w}\\n')\n","    print(f'input,  {input.shape}:\\n{input}\\n')\n","    print(f'w * input,  {w_input.shape}:\\n{w_input}\\n')        \n","    print(f'bT,  {bT.shape}:\\n{bT}\\n')\n","    print(f'w * input + bT,  {w_input_bT.shape}:\\n{w_input_bT}\\n')\n","    print(f'output,  {output.shape}:\\n{output}\\n')            \n","    print('')\n","else:\n","  raise ValueError(f\"len(l_items) {len(l_items)} is not divisible by 2.\")"]},{"cell_type":"code","execution_count":531,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MLP_torch\n","Linear\n","Linear\n","Linear\n"]}],"source":["for module in model.modules():\n","  classname = module.__class__.__name__\n","  print(classname)\n","  # if 'Linear' in classname:\n","  #   # module = nn.Sequential(...)\n","  #   print(classname)\n"]},{"cell_type":"code","execution_count":537,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([2, 2])"]},"execution_count":537,"metadata":{},"output_type":"execute_result"}],"source":["t_xs.shape"]},{"cell_type":"code","execution_count":540,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                 [-1, 2, 3]               9\n","            Linear-2                 [-1, 2, 3]              12\n","            Linear-3                 [-1, 2, 1]               4\n","================================================================\n","Total params: 25\n","Trainable params: 25\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.00\n","----------------------------------------------------------------\n"]}],"source":["from torchsummary import summary\n","summary(model, t_xs.shape)"]},{"cell_type":"code","execution_count":524,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["name: fc1.weight\n","param: tensor([[-0.2375, -0.2410],\n","        [ 0.4590, -0.2237],\n","        [ 0.2821,  0.8610]])\n","weight matrix\n","\n","\n","name: fc1.bias\n","param: tensor([ 0.4176,  0.5807, -0.4454])\n","bias matrix\n","\n","\n","name: fc2.weight\n","param: tensor([[ 0.5506,  0.1965, -1.0038],\n","        [ 0.4122, -0.4259, -0.3148],\n","        [-0.4236, -0.0245, -0.6675]])\n","weight matrix\n","\n","\n","name: fc2.bias\n","param: tensor([-0.1286, -0.2945,  0.3364])\n","bias matrix\n","\n","\n","name: fc3.weight\n","param: tensor([[-1.0280,  0.0361, -0.6698]])\n","weight matrix\n","\n","\n","name: fc3.bias\n","param: tensor([0.2605])\n","bias matrix\n","\n","\n"]}],"source":["for name, param in model.named_parameters():\n","  param = param.detach()  # remove grad\n","  print(f'name: {name}')\n","  print(f'param: {param}')\n","\n","  if name.find('weight') !=-1: # found\n","    print(f'weight matrix')\n","  elif name.find('bias') !=-1: # found\n","    print(f'bias matrix')\n","  else:\n","    raise ValueError(f\"parameter name does not have 'weight' or 'bias' in the name\")\n"," \n","  print('\\n')  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t_ys = torch.tensor(ys)\n","t_ys_ = torch.unsqueeze(t_ys, 0)\n","t_ys_.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t_ys = torch.tensor(ys)\n","t_ys_ = torch.unsqueeze(t_ys, 0)\n","t_ys_.shape\n","\n","print(output, output.shape)\n","print(t_ys_, t_ys_.shape)\n","\n","difference = output - t_ys_\n","squared_difference = torch.pow(difference, 2)\n","# loss = torch.sum(squared_difference) / len(squared_difference)\n","\n","# loss = torch.sum(squared_difference)\n","loss = torch.mean(squared_difference)\n","loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(output, output.shape)\n","print(torch.tensor(ys), torch.tensor(ys).shape)\n","\n","difference = output - torch.tensor(ys)\n","print(f'difference: {difference}')\n","squared_difference = torch.pow(difference, 2)\n","print(f'squared_difference: {squared_difference}')\n","# loss = torch.sum(squared_difference) / len(squared_difference)\n","loss = torch.mean(squared_difference)\n","loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# for item in output.item:\n","#   print(item)\n","# type(output)\n","output.tolist()[0]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","def mse_loss(y_true, y_pred):\n","  \"\"\"Calculates the mean squared error loss.\n","\n","  Args:\n","    y_true: The ground truth labels.\n","    y_pred: The predicted labels.\n","\n","  Returns:\n","    The mean squared error loss.\n","  \"\"\"\n","\n","  loss = np.mean((y_true - y_pred)**2)\n","  return loss\n","\n","def main():\n","  \"\"\"Main function.\"\"\"\n","\n","  # y_true = np.array([1, 2, 3, 4, 5])\n","  y_true = np.array([1.0, -1.0])\n","\n","  # y_pred = np.array([0, 1, 2, 3, 4])\n","  # y_pred = np.array([0.9997345209121704, -0.9980572462081909])\n","  y_pred = np.array(output.tolist()[0])  \n","\n","  loss = mse_loss(y_true, y_pred)\n","  print(loss)\n","\n","if __name__ == \"__main__\":\n","  main()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(squared_difference)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t_ys = torch.tensor(ys)\n","t_ys_ = torch.unsqueeze(t_ys, 0)\n","t_ys_.shape\n","\n","torch.nn.functional.mse_loss(output, t_ys_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.sum((output - torch.tensor(ys))**2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Check Output and Gradient Calculation with PyTorch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x0 = torch.Tensor([-3.0]).double();      x0.requires_grad = True\n","x1 = torch.Tensor([0.0]).double();       x1.requires_grad = True\n","x2 = torch.Tensor([0.5]).double();       x2.requires_grad = True\n","w0 = torch.Tensor([2.0]).double();       w0.requires_grad = True\n","w1 = torch.Tensor([1.0]).double();       w1.requires_grad = True\n","w2 = torch.Tensor([1.0]).double();       w2.requires_grad = True\n","b = torch.Tensor([4.61862664]).double(); b.requires_grad  = True\n","n = x0*w0 + x1*w1 + x2*w2 + b\n","o3 = torch.tanh(n)\n","o3.backward()\n","\n","print('---- torch results matched backward pass results ----')\n","print(f'x0.data.item()  = {x0.data.item():>9.6f}')\n","print(f'x0.grad.item()  = {x0.grad.item():>9.6f}')\n","print(f'w0.data.item()  = {w0.data.item():>9.6f}')\n","print(f'w0.grad.item()  = {w0.grad.item():>9.6f} <-- result matched micrograd')\n","print('---')\n","print(f'x1.data.item()  = {x1.data.item():>9.6f}')\n","print(f'x1.grad.item()  = {x1.grad.item():>9.6f}')\n","print(f'w1.data.item()  = {w1.data.item():>9.6f}')\n","print(f'w1.grad.item()  = {w1.grad.item():>9.6f}')\n","print('---')\n","print(f'x2.data.item()  = {x2.data.item():>9.6f}')\n","print(f'x2.grad.item()  = {x2.grad.item():>9.6f}')\n","print(f'w2.data.item()  = {w2.data.item():>9.6f}')\n","print(f'w2.grad.item()  = {w2.grad.item():>9.6f}')\n","print('---')\n","print(f'out.data.item() = {o3.data.item():>9.6f} <-- result matched micrograd')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Neural Network MLP(3, [4, 4, 1])\n","    input layer:     3 nodes\n","    hidden layer 1:  4 nodes\n","    hidden layer 2:  4 nodes\n","    output layer:    1 node\n","\n","<!-- ![Getting Started](..\\karpathy\\img\\Nertual_Network_Neuron.PNG) -->\n","<img src=\"..\\karpathy\\img\\neural_network_neuron.PNG\">"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Create neural work, initialize weights and biases, define inputs and desired outputs "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create neural network and initialize weights and biases\n","n = MLP(3, [4, 4, 1])\n","\n","# inputs\n","xs = [\n","  [2.0, 3.0, -1.0],\n","  [3.0, -1.0, 0.5]\n","]\n","\n","# desired targets\n","ys = [1.0, -1.0]\n","\n","# learning rate (i.e. step size)\n","learning_rate = 0.05"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# number of parameters (e.g sum (weights + bias to each neuron and output))\n","# MLP(3, [4, 4, 1]) --> 4_neurons(3_inputs + 1_bias) + 4_neurons(4_neurons + 1_bias) + 1_output(4_neurons + 1_bias) = 41_parameters \n","print(f'parameters in MLP: {len(n.parameters())}\\n')\n","\n","# print first 5 parameters\n","for i, v in enumerate(n.parameters()):\n","  if i < 5:\n","    print(f'i: {i:>2}, {v.data:>14.10f}')\n"," \n","print('---')\n","\n","# print last 5 parameters   \n","for i, v in enumerate(n.parameters()):\n","  if i >= len(n.parameters()) - 5:\n","    print(f'i: {i:>2}, {v.data:>14.10f}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### ---- Start: Calculate Neural Network Output and Loss with Matrix Multiplication ----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Transpose inputs xs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["xs_mats = [np.array(xs)]  # convert xs to list of np.arrays\n","xs_mats_T = []\n","for mat in xs_mats:\n","  mat_transpose = np.transpose(mat)\n","  xs_mats_T.append(mat_transpose)\n","\n","print(f'xs_mats[0].shape: {xs_mats[0].shape}')\n","print(f'xs_mats:\\n{xs_mats}\\n')\n","print(f'xs_mats_T[0].shape: {xs_mats_T[0].shape}')\n","print(f'xs_mats_T:\\n{xs_mats_T}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Get Neural Network's Weights and Biases Matrices"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["layer_cnt = len(n.layers)\n","w_mats = []  # list of weights matrix for each layer \n","b_mats = []  # list of bias matrix for each layer\n","print(f'layer_cnt: {layer_cnt}\\n')\n","for i, layer in enumerate(n.layers):\n","    neuron_cnt = len(layer.neurons)\n","    print(f'layer: {i}, neuron_cnt: {neuron_cnt}')\n","\n","    print('----')\n","    b_mat = []  # accumulate neuon's bias for each row     \n","    for j, neuron in enumerate(layer.neurons):\n","        print(f'layer: {i}, neuron {j}')\n","        b = neuron.b.data  # bias of neuron \n","        w_row = []  # accumulate neuon's weights for each row\n","        # b_row = []  # accumulate neuon's bias for each row\n","        for k, w in enumerate(neuron.w):\n","            w_row.append(w.data)\n","            print(f'w{k}: {w.data:10.7f},   w{k}.grad: {w.grad:10.7f}')\n","        if j == 0:            \n","            w_mat = np.array([w_row])\n","        else:\n","            w_mat = np.vstack((w_mat, w_row))\n","        \n","        b_mat.append(b)\n","        print(f'b:  {b:10.7f}\\n')\n","        # print(f'b:  {b:10.7f}')        \n","        # print(f'b_mat:  {b_mat}\\n')\n","    w_mats.append(w_mat)  \n","    b_mats.append(np.array([b_mat]))        \n","    print('------')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Print Neural Network's Weights and Biases Matrices"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["zipped_w_n_b = zip(w_mats, b_mats)\n","for i, w_n_b in enumerate(zipped_w_n_b):\n","  print(f'i: {i}')    \n","  print(f'w_mat{w_n_b[0].shape}:\\n{w_n_b[0]}')\n","  print(f'b_mat{w_n_b[1].shape}:\\n{w_n_b[1]}\\n')  \n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Calculate Neural Network Output and Loss with Matrix Multiplication"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<img src=\"..\\karpathy\\img\\neural_mat.PNG\">"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["verbose = True   # print calculation output and weights and bias matrices \n","# verbose = False  # print calculation output only\n","\n","for layer in range(len(n.layers)):\n","  if layer == 0:  # first layer, use given inputs xs as inputs\n","    input = xs_mats_T[layer]\n","  else:  # after first layer, use outputs from preceding layers as inputs\n","    input = output\n","\n","  weights = w_mats[layer]\n","  bias = np.transpose(b_mats[layer])\n","\n","  weights_x_input = np.matmul(weights, input)\n","  weights_x_input_plus_bias = weights_x_input + bias\n","\n","  # output = np.tanh(np.matmul(weights, input) + bias)\n","  output = np.tanh(weights_x_input_plus_bias)\n","\n","  if verbose:\n","    print(f'{\"-\"*50}')\n","    print(f'layer: {layer}')\n","    print(f'weights {weights.shape}:\\n{weights}\\n')\n","    print(f'input {input.shape}:\\n{input}\\n')\n","\n","    print(f'weights_x_inputs {weights_x_input.shape}:\\n{weights_x_input}\\n')\n","    print(f'bias {bias.shape}:\\n{bias}\\n')\n","    print(f'weights_x_inputs_plus_bias {weights_x_input_plus_bias.shape}:\\n{weights_x_input_plus_bias}\\n')\n","\n","    print(f'output {output.shape}:\\n{output}\\n')    \n","\n","yout = output[0]\n","loss = sum((yout - ys)**2)\n","\n","print(f'-- manual forward pass calculation --')\n","print(f'manual calculation: {yout}')   \n","print(f'desired output:     {ys}')   \n","print(f'loss:               {loss}')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### ### ---- End: Calculate Neural Network Output and Loss with Matrix Multiplication ---- ----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Prediction with Micrograd Neural Network"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Micrograd Forward Pass Results, Same as Matrix Multiplication"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ypred = [n(x) for x in xs]\n","loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))  # low loss is better, perfect is loss = 0\n","ypred_data = [v.data for v in ypred] \n","loss_data = loss.data\n","\n","print(f'-- micrograd forward pass calculation --')\n","print(f'ypred_data:         {ypred_data}')\n","print(f'ys:                 {ys}')\n","print(f'loss_data:          {loss_data}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Micrograd backward pass and update parameters"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# backward pass to calculate gradients\n","for p in n.parameters():\n","  p.grad = 0.0  # zero the gradient \n","loss.backward()\n","\n","# update weights and bias\n","if verbose:\n","  print('=== update parameters ===')\n","  print(f'  i  parameter before         gradient     learning rate      parameter after')\n","for i, p in enumerate(n.parameters()):\n","  p_before = p.data\n","  p.data += -learning_rate * p.grad\n","  if verbose:    \n","    print(f'{i:>3}  {p_before:>16.10f}   {p.grad:>14.10f}    {learning_rate:>14.5f}       {p.data:>14.10f}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Improve Prediction with Parameter Iteration "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a list of losses\n","losses = []\n","for k in range(200):\n","  # forward pass\n","  ypred = [n(x) for x in xs]\n","  loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))  # low loss is better, perfect is loss = 0\n","  losses.append(loss.data)\n","\n","  # backward pass to calculate gradients\n","  for p in n.parameters():\n","    p.grad = 0.0  # zero the gradient \n","  loss.backward()\n","\n","  # update weights and bias\n","  for p in n.parameters():\n","      p.data += -learning_rate * p.grad\n","\n","  # print(f'x: {x}')\n","  print(f'ypred: {ypred}')\n","  print(f'step: {k}, loss: {loss.data}')   \n","  print('-------')  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_losses(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Build same model with pyTorch "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class MLP_torch(nn.Module):\n","    def __init__(self):\n","        super(MLP_torch, self).__init__()\n","        self.fc1 = nn.Linear(3, 4)\n","        self.fc2 = nn.Linear(4, 4)\n","        # self.fc3 = nn.Linear(4, 4)\n","        self.fc4 = nn.Linear(4, 1)        \n","\n","    def forward(self, x):\n","        x = torch.tanh(self.fc1(x))\n","        x = torch.tanh(self.fc2(x))\n","        # x = torch.tanh(self.fc3(x))        \n","        x = self.fc4(x)  \n","        return x\n","\n","\n","\n","model = MLP_torch()\n","\n","# inputs\n","xs = [\n","  [2.0, 3.0, -1.0],\n","  [3.0, -1.0, 0.5]\n","]\n","\n","# desired targets\n","ys = [1.0, -1.0]\n","\n","# convert to tensor\n","t_xs = torch.tensor(xs)\n","\n","# add a dimension to the index=1 position to target tensor,\n","#  e.g. change size from [2] to [2, 1]\n","t_ys = torch.unsqueeze(torch.tensor(ys), 1)\n","\n","# learning rate (i.e. step size)\n","learning_rate = 0.05\n","\n","losses = []\n","for epoch in range(40):\n","    # forward pass\n","    outputs = model(t_xs)\n","\n","    # calculate loss\n","    loss = torch.nn.functional.mse_loss(outputs, t_ys)\n","\n","    # remove loss gradient \n","    losses.append(loss.detach())\n","\n","    # backpropagate\n","    loss.backward()\n","\n","    # update weights\n","    for p in model.parameters():\n","        p.data -= learning_rate * p.grad.data\n","\n","    # zero gradients\n","    for p in model.parameters():\n","        p.grad.data.zero_()\n","\n","    if epoch % 10 == 0:\n","        print(f\"Epoch {epoch} loss: {loss}\")\n","\n","prediction = model(t_xs)\n","print('')\n","print(f\"Prediction:\\n{prediction.detach()}\")\n","print(f\"Loss: {loss}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_losses(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f'input xs:\\n{xs}\\n')\n","print(f'target ys:\\n{ys}')\n","print('---------\\n')\n","l_items = list(model.parameters())\n","if len(l_items) % 2 == 0:\n","  for i in range(0, len(l_items), 2):\n","    if i == 0:\n","      x0 = torch.clone(t_xs).detach() \n","      input = torch.transpose(x0, 0, 1)\n","    else:\n","      input = output\n","\n","    w = l_items[i].detach()  # remove gradient\n","    b_ = l_items[i + 1].detach()  # remove gradient\n","    b = torch.clone(b_).detach()  # remove gradient\n","    bT = torch.unsqueeze(b, 1)  # add a dimension to index 1 position\n","    w_input = torch.matmul(w, input)\n","    w_input_bT = torch.add(w_input, bT)\n","\n","    if i == len(l_items) - 2:  # skip tanh activation on output node\n","      output = w_input_bT\n","    else:  \n","      output = torch.tanh(w_input_bT)      \n","\n","    print(f'layer: {i / 2},  i: {i}\\n')\n","    print(f'w,  {w.shape}:\\n{w}\\n')\n","    print(f'input,  {input.shape}:\\n{input}\\n')\n","    print(f'w * input,  {w_input.shape}:\\n{w_input}\\n')        \n","    print(f'bT,  {bT.shape}:\\n{bT}\\n')\n","    print(f'w * input + bT,  {w_input_bT.shape}:\\n{w_input_bT}\\n')\n","    print(f'output,  {output.shape}:\\n{output}\\n')            \n","    print('')\n","else:\n","  raise ValueError(f\"len(l_items) {len(l_items)} is not divisible by 2.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t_ys = torch.tensor(ys)\n","t_ys_ = torch.unsqueeze(t_ys, 0)\n","t_ys_.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t_ys = torch.tensor(ys)\n","t_ys_ = torch.unsqueeze(t_ys, 0)\n","t_ys_.shape\n","\n","print(output, output.shape)\n","print(t_ys_, t_ys_.shape)\n","\n","difference = output - t_ys_\n","squared_difference = torch.pow(difference, 2)\n","# loss = torch.sum(squared_difference) / len(squared_difference)\n","loss = torch.sum(squared_difference)\n","loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(output, output.shape)\n","print(torch.tensor(ys), torch.tensor(ys).shape)\n","\n","difference = output - torch.tensor(ys)\n","print(f'difference: {difference}')\n","squared_difference = torch.pow(difference, 2)\n","print(f'squared_difference: {squared_difference}')\n","# loss = torch.sum(squared_difference) / len(squared_difference)\n","loss = torch.sum(squared_difference) / 2\n","loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["difference\n","len(squared_difference)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t_ys = torch.tensor(ys)\n","t_ys_ = torch.unsqueeze(t_ys, 0)\n","t_ys_.shape\n","\n","torch.nn.functional.mse_loss(output, t_ys_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.sum((output - torch.tensor(ys))**2)"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
