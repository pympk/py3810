{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Understanding PyTorch with an example: a step-by-step tutorial](https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation, random data around the line y = 2x + 1\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(100, 1)  # uniform distribution [0, 1]\n",
    "y = 1 + 2*x + 0.1*np.random.randn(100, 1)  # normal distribution, mean 0 and variance 1\n",
    "\n",
    "# Shuffles the indices\n",
    "idx = np.arange(100)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Use first 80 random indices for training\n",
    "train_idx = idx[:80]\n",
    "# Use remaining indices for validation\n",
    "val_idx = idx[80:]\n",
    "\n",
    "# Generate train and validation sets\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the x and y values for the first plot\n",
    "x1 = x_train\n",
    "y1 = y_train\n",
    "\n",
    "# Define the x and y values for the second plot\n",
    "x2 = x_val\n",
    "y2 = y_val\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Space the plots further apart\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "# Plot the first plot\n",
    "ax1.plot(x1, y1, marker=\"o\", color=\"blue\", linestyle=\"None\")\n",
    "ax1.set_title(\"Generated Data - Train\")\n",
    "\n",
    "# Plot the second plot\n",
    "ax2.plot(x2, y2, marker=\"o\", color=\"red\", linestyle=\"None\")\n",
    "ax2.set_title(\"Generated Data - Validation\")\n",
    "\n",
    "# Add a title to the figure\n",
    "# fig.suptitle(\"Two Plots Side by Side\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# n_epochs: 1000\n",
    "# len(losses): 5000\n",
    "# len(val_losses): 2000\n",
    "# i: 0  len(items): 2\n",
    "# j: 0  len(item): 16\n",
    "# j: 1  len(item): 16\n",
    "# ===\n",
    "# i: 1  len(items): 2\n",
    "# j: 0  len(item): 16\n",
    "# j: 1  len(item): 16\n",
    "# ===\n",
    "# i: 2  len(items): 2\n",
    "# j: 0  len(item): 16\n",
    "# j: 1  len(item): 16\n",
    "# ===\n",
    "# i: 3  len(items): 2\n",
    "# j: 0  len(item): 16\n",
    "# j: 1  len(item): 16\n",
    "# ===\n",
    "# i: 4  len(items): 2\n",
    "# j: 0  len(item): 16\n",
    "# j: 1  len(item): 16\n",
    "# ===\n",
    "# i: 5  len(items): 2\n",
    "# j: 0  len(item): 10\n",
    "# j: 1  len(item): 10\n",
    "# ===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('a', tensor([1.0076])), ('b', tensor([1.9877]))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a and b after initialization\n",
      "a: [0.49671415], b: [-0.1382643]\n",
      "\n",
      "a and b after our gradient descent\n",
      "a: [1.02354094], b: [1.96896411]\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters \"a\" and \"b\" randomly\n",
    "np.random.seed(42)\n",
    "a = np.random.randn(1)\n",
    "b = np.random.randn(1)\n",
    "print('a and b after initialization')\n",
    "print(f'a: {a}, b: {b}\\n')\n",
    "\n",
    "# Set learning rate\n",
    "lr = 1e-1\n",
    "\n",
    "# Define number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  # Compute predicted output\n",
    "  yhat = a + b*x_train\n",
    "\n",
    "  # Calculate error\n",
    "  error = (y_train - yhat)\n",
    "\n",
    "  # Calcualte loss\n",
    "  loss = (error**2).mean()\n",
    "\n",
    "  # Calculate gradients for \"a\" (a constant) and \"b\" (the slope)\n",
    "  a_grad = -2*error.mean()\n",
    "  b_grad = -2*(x_train*error).mean()\n",
    "\n",
    "  # Update parameters a and b using gradients and learning rate\n",
    "  a += -lr*a_grad\n",
    "  b += -lr*b_grad\n",
    "\n",
    "print('a and b after our gradient descent')\n",
    "print(f'a: {a}, b: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: do we get the same results as our model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linr = LinearRegression()\n",
    "linr.fit(x_train, y_train)\n",
    "print('intercept and coef. from  Scikit-Learn')\n",
    "print(f'linr.intercept_: {linr.intercept_},  linr.coef_[0]: {linr.coef_[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Transform data from numpy arrays to pytorch tensors\n",
    "# and send them to chosen device\n",
    "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "\n",
    "print(f'type(x_train):         {type(x_train)}')\n",
    "print(f'type(x_train_tensor):  {type(x_train_tensor)}')\n",
    "print(f'x_train_tensor.type(): {x_train_tensor.type()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "print(f'a: {a}\\nb: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this won't work if device is GPU\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "print(f'a: {a}\\nb: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works if device is GPU\n",
    "a = torch.randn(1, dtype=torch.float).to(device)\n",
    "b = torch.randn(1, dtype=torch.float).to(device)\n",
    "a.requires_grad_()  # _ makes changes in-place\n",
    "b.requires_grad_()  # _ makes changes in-place\n",
    "print(f'a: {a}\\nb: {b}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch recommends specifying device at creation\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(f'a: {a}\\nb: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "for epach in range(n_epochs):\n",
    "  yhat = a + b*x_train_tensor\n",
    "  error = y_train_tensor - yhat\n",
    "  loss = (error**2).mean()\n",
    "  loss.backward()  # no more manual computation of gradients\n",
    "  print(f'a.grad: {a.grad},  b.grad: {b.grad}')\n",
    "\n",
    "  # Use no_grad to keep the update out of the gradient computation\n",
    "  with torch.no_grad():\n",
    "    a += -lr*a.grad\n",
    "    b += -lr*b.grad\n",
    "\n",
    "  a.grad.zero_()\n",
    "  b.grad.zero_()\n",
    "\n",
    "print(f'a: {a},  b: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "yhat = a + b*x_train_tensor\n",
    "error = y_train_tensor - yhat\n",
    "loss = (error**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_nograd = torch.randn(1, requires_grad=False, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "yhat = a_nograd + b*x_train_tensor\n",
    "print(f'a_nograd: no gradients, no graph')\n",
    "make_dot(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-sense code to demo control flow statements\n",
    "yhat = a + b*x_train_tensor\n",
    "error = y_train_tensor - yhat\n",
    "loss = (error**2).mean()\n",
    "if loss > 0:\n",
    "  yhat2 = b*x_train_tensor\n",
    "  error2 = y_train_tensor - yhat2\n",
    "loss += error2.mean()\n",
    "make_dot(loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print('a and b before optimizing')\n",
    "print(f'a: {a},  b: {b}\\n')\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "# Use SGD optimizer to update parameters\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "print('Peform batch gradient descent since x_train_tensor has all the data')\n",
    "print(f'len(x_train_tensor): {len(x_train_tensor)}\\n')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  yhat = a + b*x_train_tensor\n",
    "  error = y_train_tensor - yhat\n",
    "  loss = (error**2).mean()\n",
    "\n",
    "  loss.backward()  # calculate gradients\n",
    "  optimizer.step()  # update parameters\n",
    "  optimizer.zero_grad()  # zero out gradients\n",
    "\n",
    "print('a and b after optimizing')\n",
    "print(f'a: {a},  b: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pytorch loss functions\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print('a and b before optimizing')\n",
    "print(f'a: {a},  b: {b}\\n')\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "# Use MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Use SGD optimizer to update parameters\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "print('Peform batch gradient descent, matrix multiplication with x_train_tensor process all the data at onnce')\n",
    "print(f'len(x_train_tensor): {len(x_train_tensor)}\\n')\n",
    "\n",
    "for epoch in range(n_epochs):  # all training data is processed in an epoch\n",
    "  yhat = a + b*x_train_tensor\n",
    "  error = y_train_tensor - yhat\n",
    "\n",
    "  # loss = (error**2).mean()\n",
    "  loss = loss_fn(y_train_tensor, yhat)\n",
    "\n",
    "  loss.backward()  # calculate gradients\n",
    "  optimizer.step()  # update parameters\n",
    "  optimizer.zero_grad()  # zero out gradients\n",
    "\n",
    "print('a and b after optimizing')\n",
    "print(f'a: {a},  b: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple model\n",
    "class ManualLinearRegression(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # Wrap \"a\" and \"b\" in nn.Parameter to make them model parameters\n",
    "    # Allow model's parameters() method to retrieve an iterator for model's parameters\n",
    "    # Get current values for all parameters with state_dict() method \n",
    "    self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "    self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Compute predictions\n",
    "    return self.a + self.b*x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create model and send it to device\n",
    "model = ManualLinearRegression().to(device=device)\n",
    "# Alternate model using pytorch vs writing our own class\n",
    "# model = nn.Sequential(nn.Linear(in_features=1, out_features=1)).to(device=device)\n",
    "\n",
    "# Print parameters\n",
    "print(f'model.state_dict():\\n {model.state_dict()}\\n')\n",
    "\n",
    "\n",
    "# a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "# b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "# print('a and b before optimizing')\n",
    "# print(f'a: {a},  b: {b}\\n')\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "# Use MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Use SGD optimizer to update parameters\n",
    "# optimizer = optim.SGD([a, b], lr=lr)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "print('Peform batch gradient descent, matrix multiplication with x_train_tensor process all the data at onnce')\n",
    "print(f'len(x_train_tensor): {len(x_train_tensor)}\\n')\n",
    "\n",
    "for epoch in range(n_epochs):  # all training data is processed in an epoch\n",
    "  # yhat = a + b*x_train_tensor\n",
    "  # error = y_train_tensor - yhat\n",
    "  model.train()  # set model to training mode vs other mode like Dropout\n",
    "\n",
    "  # No more manual predictions!\n",
    "  # yhat = a + b*x_train_tensor\n",
    "  yhat = model(x_train_tensor)\n",
    "\n",
    "  # loss = (error**2).mean()\n",
    "  loss = loss_fn(y_train_tensor, yhat)\n",
    "\n",
    "  loss.backward()  # calculate gradients\n",
    "  optimizer.step()  # update parameters\n",
    "  optimizer.zero_grad()  # zero out gradients\n",
    "\n",
    "# print('a and b after optimizing')\n",
    "# print(f'a: {a},  b: {b}')\n",
    "print(f'model.state_dict():\\n{model.state_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a nested model\n",
    "class LayerLinearRegression(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # Wrap \"a\" and \"b\" in nn.Parameter to make them model parameters\n",
    "    # Allow model's parameters() method to retrieve an iterator for model's parameters\n",
    "    # Get current values for all parameters with state_dict() method \n",
    "    self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "    self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Compute predictions\n",
    "    # return self.a + self.b*x\n",
    "    #\n",
    "    # Change to taking a call to the layer to make predictions      \n",
    "    return self.linear(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "  # Build function that performs a step in the training loop\n",
    "  def train_step(x, y):\n",
    "    # Set model to TRAIN mode\n",
    "    model.train()\n",
    "    # Make predictions\n",
    "    yhat = model(x)\n",
    "    # Compute loss\n",
    "    loss = loss_fn(y, yhat)\n",
    "    # Compute gradients\n",
    "    loss.backward()\n",
    "    # Update parameters and zeroes gradients\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    # Return the loss\n",
    "    return loss.item()\n",
    "\n",
    "  # Return the function that will be called inside the training loop\n",
    "  return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  # Perform one train step and return loss\n",
    "  loss = train_step(x_train_tensor, y_train_tensor)\n",
    "  losses.append(loss)\n",
    "\n",
    "# Check model's parameters\n",
    "print(f'model.state_dict():\\n{model.state_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple dataset\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "class CustomerDataset(Dataset):\n",
    "  def __init__(self, x_tensor, y_tensor):\n",
    "    self.x = x_tensor\n",
    "    self.y = y_tensor\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return (self.x[index], self.y[index])\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this a CPU tensor? Where is .to(device)?\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_data = CustomerDataset(x_train_tensor, y_train_tensor)\n",
    "print(f'train_data[0]: {train_data[0]}')\n",
    "\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "print(f'train_data[0]: {train_data[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_data:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a sample mini-batch\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dataloader to load mini-batch\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  # # Perform one train step and return loss\n",
    "  # loss = train_step(x_train_tensor, y_train_tensor)\n",
    "  # losses.append(loss)\n",
    "\n",
    "  # For bigger datasets, loading data sample by sample (into a CPU tensor)\n",
    "  # using Datasets __get_item__ and then sending all samples that belong\n",
    "  # to the same mini-batch at once to your GPU (device) is the way to go\n",
    "  # in order to make the best use of your graphics cards RAM.\n",
    "\n",
    "  for x_batch, y_batch in train_loader:\n",
    "    # the dataset \"lives\" in the CPU, so do out mini-batches\n",
    "    # we need to send those mini-batches to the device where\n",
    "    # the model \"lives\"\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)    \n",
    "    loss = train_step(x_batch, y_batch)\n",
    "    losses.append(loss)\n",
    "\n",
    "# Check model's parameters\n",
    "print(f'model.state_dict():\\n{model.state_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random split\n",
    "from torch.utils.data.dataset import random_split\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "train_data, val_data = random_split(dataset, [80, 20])\n",
    "\n",
    "# val_loader results\n",
    "# dataset items = 2, => returns 2 tensors\n",
    "# val_data = 10      => each tensor has 10 values total\n",
    "# batch_size = 3     => returns 2 tensors, each with 3 values (last batch with 1 values)\n",
    "# [tensor([[0.1987], [0.7722], [0.5248]]),\n",
    "#  tensor([[1.2654], [2.4208], [2.0167]])]\n",
    "# [tensor([[0.1818], [0.1834], [0.7069]]),\n",
    "#  tensor([[1.3734], [1.4637], [2.4388]])]\n",
    "# [tensor([[0.8155], [0.0977], [0.1079]]),\n",
    "#  tensor([[2.6606], [1.4417], [1.2985]])]\n",
    "# [tensor([[0.5201]]), tensor([[1.9000]])]\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, batch in enumerate(val_loader):\n",
    "  print(f'batch: {j}')  \n",
    "  for i, tensor in enumerate(batch):\n",
    "    print(f'tensor: {i}, tensor.shape: {tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in val_loader:\n",
    "  print(f'{item}\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with shape (4, 3, 2) and all elements set to 0\n",
    "tensor = torch.zeros((4, 3, 2))\n",
    "# Print the tensor\n",
    "print(tensor.shape)\n",
    "# (4,3,2) tenssor: 4 x 3 matrix, each cell with 2 values\n",
    "# [[[0., 0.], [0., 0.], [0., 0.]],\n",
    "#  [[0., 0.], [0., 0.], [0., 0.]],\n",
    "#  [[0., 0.], [0., 0.], [0., 0.]],\n",
    "#  [[0., 0.], [0., 0.], [0., 0.]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "losses = []\n",
    "val_losses = []\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  for x_batch, y_batch in train_loader:\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    loss = train_step(x_batch, y_batch)\n",
    "    losses.append(loss)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for x_val, y_val in val_loader:\n",
    "      x_val = x_val.to(device)\n",
    "      y_val = y_val.to(device)\n",
    "\n",
    "      model.eval()\n",
    "\n",
    "      yhat = model(x_val)\n",
    "      val_loss = loss_fn(y_val, yhat)\n",
    "      val_losses.append(val_loss)\n",
    "\n",
    "# Check model's parameters\n",
    "print(f'model.state_dict():\\n{model.state_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'len(train_data): {len(train_data)}')\n",
    "print(f'len(train_loader): {len(train_loader)}')\n",
    "print(f'n_epochs: {n_epochs}')\n",
    "print(f'len(losses): {len(losses)}')\n",
    "print(f'len(val_losses): {len(val_losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, items in enumerate(train_loader):\n",
    "  print(f'i: {i}  len(items): {len(items)}')\n",
    "  for j, item in enumerate(items):\n",
    "    print(f'j: {j}  len(item): {len(item)}')\n",
    "  print('===')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
