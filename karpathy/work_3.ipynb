{"cells":[{"cell_type":"markdown","metadata":{},"source":["## [The spelled-out intro to neural networks and backpropagation: building micrograd](https://www.youtube.com/watch?v=VMj-3S1tku0&t=3356s)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["### Micrograd Classes and Functions"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["from graphviz import Digraph\n","\n","def trace(root):\n","  \"\"\"Builds a set of all nodes and edges in a graph.\"\"\"\n","  nodes, edges = set(), set()\n","\n","  def build(v):\n","    if v not in nodes:\n","      nodes.add(v)\n","      for child in v._prev:\n","        edges.add((child, v))\n","        build(child)\n","\n","  build(root)\n","  return nodes, edges\n","\n","def draw_dot(root):\n","  \"\"\"Creates a Digraph representation of the graph.\"\"\"\n","  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'})  # LR = left to right\n","\n","  nodes, edges = trace(root)\n","  for n in nodes:\n","    uid = str(id(n))\n","    # For any value in the graph, create a rectangular ('record') node for it.\n","    dot.node(name=uid, label=\"{ %s | data %.4f | grad % .4f }\" % (n.label, n.data, n.grad), shape=\"record\")\n","\n","    if n._op:\n","      # If this value is a result of some operation, create an op node.\n","      dot.node(name=uid + n._op, label=n._op)\n","      # And connect this node to it\n","      dot.edge(uid + n._op, uid)\n","\n","  for n1, n2 in edges:\n","    # Connect nl to the op node of n2.\n","    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n","\n","  return dot"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["class Value:\n","\n","    def __init__(self, data, _children=(), _op='', label=''):\n","        self.data = data\n","        self.grad = 0.0\n","        self._backward = lambda : None\n","        self._prev = set(_children)\n","        self._op = _op\n","        self.label = label\n","\n","    def __repr__(self) -> str:\n","        return f\"Value(data = {self.data})\"\n","    \n","    def __add__(self, other):\n","        other = other if isinstance(other, Value) else Value(other)\n","        out = Value(self.data + other.data, (self, other), '+')\n","\n","        def _backward():\n","            self.grad += 1.0 * out.grad\n","            other.grad += 1.0 * out.grad\n","        out._backward = _backward    \n","\n","        return out\n","\n","    def __radd__(self, other): # other + self\n","        return self + other\n","\n","    def __mul__(self, other):\n","        other = other if isinstance(other, Value) else Value(other)        \n","        out = Value(self.data * other.data, (self, other), '*')\n","\n","        def _backward():\n","            self.grad += other.data * out.grad\n","            other.grad += self.data * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def __rmul__(self, other):  # other * self\n","        return self * other\n","\n","    def __pow__(self, other):\n","        assert isinstance(other, (int, float)), \"only support int/float power for now\"\n","        out = Value(self.data**other, (self,), f'**{other}')\n","\n","        def _backward():\n","            self.grad += other * (self.data ** (other - 1)) * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def __truediv__(self, other):  # self / other\n","        return self * other**-1\n","\n","    def __neg__(self):  # -self\n","        return self * -1\n","    \n","    def __sub__(self, other):  # self - other\n","        return self + (-other)\n","\n","    def __rsub__(self, other): # other - self\n","        return other + (-self)\n","\n","    def tanh(self):\n","        x = self.data\n","        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n","        out = Value(t, (self, ), 'tanh')\n","\n","        def _backward():\n","            self.grad += (1 - t**2) * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    # https://en.wikipedia.org/wiki/Hyperbolic_functions\n","    def exp(self):\n","        x = self.data\n","        out = Value(math.exp(x), (self, ), 'exp')\n","\n","        def _backward():\n","            self.grad += out.data * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def backward(self):\n","        topo = []\n","        visited = set()\n","\n","        # topological sort\n","        def build_topo(v):\n","            if v not in visited:\n","                visited.add(v)\n","                for child in v._prev:\n","                    build_topo(child)\n","                topo.append(v)\n","        build_topo(self)\n","\n","        self.grad = 1  # initialize\n","        for node in reversed(topo):\n","            node._backward()    "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["import random\n","\n","class Neuron:\n","    \n","    def __init__(self, nin):\n","#### my add ##########################################        \n","        # random.seed(12345)  # WARNING: all neurons will have the same weights and bias\n","######################################################        \n","        self.w = [Value(random.uniform(-1, 1)) for _ in range(nin)]\n","        self.b = Value(random.uniform(-1,1))\n","\n","#### my add ##########################################\n","    def __repr__(self) -> str:\n","        return f\"Neuron(w = {self.w}, b = {self.b})\"\n","######################################################\n","\n","    def __call__(self, x):\n","        # w * x + b\n","        # print(list(zip(self.w, x)), self.b)\n","        act = sum((wi*xi for wi,xi in zip(self.w, x)), self.b) \n","        out = act.tanh()\n","        return out\n","\n","    def parameters(self):\n","        # print(f'w: {self.w}, b: {[self.b]}')\n","        return self.w + [self.b]\n","\n","\n","class Layer:\n","    def __init__(self, nin, nout):\n","        self.neurons = [Neuron(nin) for _ in range(nout)]\n","\n","#### my add ##########################################\n","    def __repr__(self) -> str:\n","        return f\"Layer(neurons = {self.neurons})\"\n","######################################################\n","\n","    def __call__(self, x):\n","        outs = [n(x) for n in self.neurons]\n","        return outs[0] if len(outs) == 1 else outs\n","\n","    def parameters(self):\n","        # params = []\n","        # for neuron in self.neurons:\n","        #     ps = neuron.parameters()\n","        #     params.extend(ps)\n","        # return params\n","        return [p for neuron in self.neurons for p in neuron.parameters()]\n","\n","class MLP:\n","    def __init__(self, nin, nouts):\n","        sz = [nin] + nouts\n","        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n","\n","    def __call__(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def parameters(self):\n","        params = []\n","        # for layer in self.layers:\n","        #     ps = layer.parameters()\n","        #     params.extend(ps)\n","        # return params\n","        return [p for layer in self.layers for p in layer.parameters()]"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate Forward and Backward Pass on a Single Neuron\n","<!-- ### Simple Neural Network: Single Neuron with 3 Inputs -->\n","<img src=\"..\\karpathy\\img\\Nertual_Network_1_Neuron_3_Inputs.png\">"]},{"cell_type":"markdown","metadata":{},"source":["#### Activation Function: Tanh"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 400x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["_num = np.arange(-5, 5, 0.2)\n","plt.figure(figsize=(4, 2))\n","plt.plot(_num, np.tanh(_num))\n","plt.title(\"Tanh Activation\")\n","plt.grid()"]},{"cell_type":"markdown","metadata":{},"source":["##### Calculate Forward Pass and Backward Pass with Micrograd"]},{"cell_type":"code","execution_count":138,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["w0.grad: -1.500000004284097\n"]},{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.46.0 (20210118.1747)\n"," -->\n","<!-- Pages: 1 -->\n","<svg width=\"1995pt\" height=\"265pt\"\n"," viewBox=\"0.00 0.00 1995.00 265.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 261)\">\n","<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-261 1991,-261 1991,4 -4,4\"/>\n","<!-- 2631372902464 -->\n","<g id=\"node1\" class=\"node\">\n","<title>2631372902464</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"327,-55.5 327,-91.5 549,-91.5 549,-55.5 327,-55.5\"/>\n","<text text-anchor=\"middle\" x=\"353.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0*w0</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"380,-55.5 380,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"423\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"466,-55.5 466,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"507.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2631377372448+ -->\n","<g id=\"node17\" class=\"node\">\n","<title>2631377372448+</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"612\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"612\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n","</g>\n","<!-- 2631372902464&#45;&gt;2631377372448+ -->\n","<g id=\"edge8\" class=\"edge\">\n","<title>2631372902464&#45;&gt;2631377372448+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M516.4,-91.52C527.42,-94.57 538.56,-97.92 549,-101.5 559.33,-105.04 570.34,-109.57 580.16,-113.9\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"578.98,-117.21 589.53,-118.13 581.86,-110.83 578.98,-117.21\"/>\n","</g>\n","<!-- 2631372902464* -->\n","<g id=\"node2\" class=\"node\">\n","<title>2631372902464*</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"264\" cy=\"-73.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"264\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n","</g>\n","<!-- 2631372902464*&#45;&gt;2631372902464 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>2631372902464*&#45;&gt;2631372902464</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M291.12,-73.5C298.66,-73.5 307.41,-73.5 316.81,-73.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"316.82,-77 326.81,-73.5 316.81,-70 316.82,-77\"/>\n","</g>\n","<!-- 2631375828544 -->\n","<g id=\"node3\" class=\"node\">\n","<title>2631375828544</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1,-55.5 1,-91.5 200,-91.5 200,-55.5 1,-55.5\"/>\n","<text text-anchor=\"middle\" x=\"16\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"31,-55.5 31,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"74\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;3.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"117,-55.5 117,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"158.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n","</g>\n","<!-- 2631375828544&#45;&gt;2631372902464* -->\n","<g id=\"edge14\" class=\"edge\">\n","<title>2631375828544&#45;&gt;2631372902464*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M200.1,-73.5C209.5,-73.5 218.57,-73.5 226.75,-73.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"226.95,-77 236.95,-73.5 226.95,-70 226.95,-77\"/>\n","</g>\n","<!-- 2631375849024 -->\n","<g id=\"node4\" class=\"node\">\n","<title>2631375849024</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1077.5,-192.5 1077.5,-228.5 1265.5,-228.5 1265.5,-192.5 1077.5,-192.5\"/>\n","<text text-anchor=\"middle\" x=\"1089.5\" y=\"-206.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1101.5,-192.5 1101.5,-228.5 \"/>\n","<text text-anchor=\"middle\" x=\"1142\" y=\"-206.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 4.6186</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1182.5,-192.5 1182.5,-228.5 \"/>\n","<text text-anchor=\"middle\" x=\"1224\" y=\"-206.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2631374248688+ -->\n","<g id=\"node13\" class=\"node\">\n","<title>2631374248688+</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"1388\" cy=\"-182.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"1388\" y=\"-178.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n","</g>\n","<!-- 2631375849024&#45;&gt;2631374248688+ -->\n","<g id=\"edge12\" class=\"edge\">\n","<title>2631375849024&#45;&gt;2631374248688+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1265.65,-198.34C1295.85,-194.4 1327.56,-190.26 1350.99,-187.2\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1351.68,-190.64 1361.14,-185.88 1350.77,-183.7 1351.68,-190.64\"/>\n","</g>\n","<!-- 2631372255344 -->\n","<g id=\"node5\" class=\"node\">\n","<title>2631372255344</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"675,-165.5 675,-201.5 892,-201.5 892,-165.5 675,-165.5\"/>\n","<text text-anchor=\"middle\" x=\"701.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2*w2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"728,-165.5 728,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"768.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.5000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"809,-165.5 809,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"850.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2631374246576+ -->\n","<g id=\"node9\" class=\"node\">\n","<title>2631374246576+</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"955\" cy=\"-155.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"955\" y=\"-151.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n","</g>\n","<!-- 2631372255344&#45;&gt;2631374246576+ -->\n","<g id=\"edge13\" class=\"edge\">\n","<title>2631372255344&#45;&gt;2631374246576+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M892.33,-165.69C901.68,-164.14 910.63,-162.67 918.66,-161.34\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"919.36,-164.77 928.66,-159.69 918.22,-157.86 919.36,-164.77\"/>\n","</g>\n","<!-- 2631372255344* -->\n","<g id=\"node6\" class=\"node\">\n","<title>2631372255344*</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"612\" cy=\"-183.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"612\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n","</g>\n","<!-- 2631372255344*&#45;&gt;2631372255344 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>2631372255344*&#45;&gt;2631372255344</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M639.11,-183.5C646.55,-183.5 655.16,-183.5 664.4,-183.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"664.66,-187 674.66,-183.5 664.66,-180 664.66,-187\"/>\n","</g>\n","<!-- 2631375830176 -->\n","<g id=\"node7\" class=\"node\">\n","<title>2631375830176</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"2,-165.5 2,-201.5 199,-201.5 199,-165.5 2,-165.5\"/>\n","<text text-anchor=\"middle\" x=\"18.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w1</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"35,-165.5 35,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"75.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 1.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"116,-165.5 116,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"157.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n","</g>\n","<!-- 2631375954272* -->\n","<g id=\"node20\" class=\"node\">\n","<title>2631375954272*</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"264\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"264\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n","</g>\n","<!-- 2631375830176&#45;&gt;2631375954272* -->\n","<g id=\"edge17\" class=\"edge\">\n","<title>2631375830176&#45;&gt;2631375954272*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M173.4,-165.46C182.75,-162.68 192.16,-159.67 201,-156.5 211.53,-152.72 222.76,-147.9 232.72,-143.34\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"234.25,-146.48 241.83,-139.07 231.29,-140.14 234.25,-146.48\"/>\n","</g>\n","<!-- 2631374246576 -->\n","<g id=\"node8\" class=\"node\">\n","<title>2631374246576</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1018,-137.5 1018,-173.5 1325,-173.5 1325,-137.5 1018,-137.5\"/>\n","<text text-anchor=\"middle\" x=\"1087\" y=\"-151.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0w0 + x1w1 + x2w2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1156,-137.5 1156,-173.5 \"/>\n","<text text-anchor=\"middle\" x=\"1199\" y=\"-151.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;5.5000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1242,-137.5 1242,-173.5 \"/>\n","<text text-anchor=\"middle\" x=\"1283.5\" y=\"-151.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2631374246576&#45;&gt;2631374248688+ -->\n","<g id=\"edge16\" class=\"edge\">\n","<title>2631374246576&#45;&gt;2631374248688+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1315.57,-173.51C1328.6,-175.15 1340.83,-176.69 1351.36,-178.01\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1350.94,-181.49 1361.3,-179.26 1351.81,-174.54 1350.94,-181.49\"/>\n","</g>\n","<!-- 2631374246576+&#45;&gt;2631374246576 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>2631374246576+&#45;&gt;2631374246576</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M982.3,-155.5C989.69,-155.5 998.31,-155.5 1007.71,-155.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1007.77,-159 1017.77,-155.5 1007.77,-152 1007.77,-159\"/>\n","</g>\n","<!-- 2631374468816 -->\n","<g id=\"node10\" class=\"node\">\n","<title>2631374468816</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"3.5,-110.5 3.5,-146.5 197.5,-146.5 197.5,-110.5 3.5,-110.5\"/>\n","<text text-anchor=\"middle\" x=\"18.5\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"33.5,-110.5 33.5,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"74\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"114.5,-110.5 114.5,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"156\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2631374468816&#45;&gt;2631375954272* -->\n","<g id=\"edge20\" class=\"edge\">\n","<title>2631374468816&#45;&gt;2631375954272*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M197.78,-128.5C207.96,-128.5 217.8,-128.5 226.61,-128.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"226.81,-132 236.81,-128.5 226.81,-125 226.81,-132\"/>\n","</g>\n","<!-- 2631375830224 -->\n","<g id=\"node11\" class=\"node\">\n","<title>2631375830224</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"341,-220.5 341,-256.5 535,-256.5 535,-220.5 341,-220.5\"/>\n","<text text-anchor=\"middle\" x=\"356\" y=\"-234.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"371,-220.5 371,-256.5 \"/>\n","<text text-anchor=\"middle\" x=\"411.5\" y=\"-234.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.5000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"452,-220.5 452,-256.5 \"/>\n","<text text-anchor=\"middle\" x=\"493.5\" y=\"-234.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2631375830224&#45;&gt;2631372255344* -->\n","<g id=\"edge15\" class=\"edge\">\n","<title>2631375830224&#45;&gt;2631372255344*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M520,-220.42C529.85,-217.69 539.71,-214.71 549,-211.5 559.58,-207.85 570.81,-203.07 580.78,-198.49\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"582.32,-201.63 589.87,-194.21 579.33,-195.3 582.32,-201.63\"/>\n","</g>\n","<!-- 2631374248688 -->\n","<g id=\"node12\" class=\"node\">\n","<title>2631374248688</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1451,-164.5 1451,-200.5 1643,-200.5 1643,-164.5 1451,-164.5\"/>\n","<text text-anchor=\"middle\" x=\"1462.5\" y=\"-178.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">n</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1474,-164.5 1474,-200.5 \"/>\n","<text text-anchor=\"middle\" x=\"1517\" y=\"-178.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;0.8814</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1560,-164.5 1560,-200.5 \"/>\n","<text text-anchor=\"middle\" x=\"1601.5\" y=\"-178.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2631374247152tanh -->\n","<g id=\"node15\" class=\"node\">\n","<title>2631374247152tanh</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"1706\" cy=\"-182.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"1706\" y=\"-178.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tanh</text>\n","</g>\n","<!-- 2631374248688&#45;&gt;2631374247152tanh -->\n","<g id=\"edge9\" class=\"edge\">\n","<title>2631374248688&#45;&gt;2631374247152tanh</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1643.4,-182.5C1652.32,-182.5 1660.93,-182.5 1668.75,-182.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1668.86,-186 1678.86,-182.5 1668.86,-179 1668.86,-186\"/>\n","</g>\n","<!-- 2631374248688+&#45;&gt;2631374248688 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>2631374248688+&#45;&gt;2631374248688</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1415.28,-182.5C1422.78,-182.5 1431.44,-182.5 1440.67,-182.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1440.87,-186 1450.87,-182.5 1440.87,-179 1440.87,-186\"/>\n","</g>\n","<!-- 2631374247152 -->\n","<g id=\"node14\" class=\"node\">\n","<title>2631374247152</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1769,-164.5 1769,-200.5 1987,-200.5 1987,-164.5 1769,-164.5\"/>\n","<text text-anchor=\"middle\" x=\"1793.5\" y=\"-178.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">out_0</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1818,-164.5 1818,-200.5 \"/>\n","<text text-anchor=\"middle\" x=\"1861\" y=\"-178.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;0.7071</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1904,-164.5 1904,-200.5 \"/>\n","<text text-anchor=\"middle\" x=\"1945.5\" y=\"-178.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n","</g>\n","<!-- 2631374247152tanh&#45;&gt;2631374247152 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>2631374247152tanh&#45;&gt;2631374247152</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1733.19,-182.5C1740.65,-182.5 1749.28,-182.5 1758.56,-182.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1758.84,-186 1768.84,-182.5 1758.84,-179 1758.84,-186\"/>\n","</g>\n","<!-- 2631377372448 -->\n","<g id=\"node16\" class=\"node\">\n","<title>2631377372448</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"689,-110.5 689,-146.5 878,-146.5 878,-110.5 689,-110.5\"/>\n","<text text-anchor=\"middle\" x=\"699\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"> </text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"709,-110.5 709,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"752\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"795,-110.5 795,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"836.5\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2631377372448&#45;&gt;2631374246576+ -->\n","<g id=\"edge19\" class=\"edge\">\n","<title>2631377372448&#45;&gt;2631374246576+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M878.17,-143.42C892.5,-145.7 906.49,-147.93 918.47,-149.84\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"918.01,-153.31 928.44,-151.43 919.11,-146.4 918.01,-153.31\"/>\n","</g>\n","<!-- 2631377372448+&#45;&gt;2631377372448 -->\n","<g id=\"edge6\" class=\"edge\">\n","<title>2631377372448+&#45;&gt;2631377372448</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M639.11,-128.5C650.28,-128.5 664.11,-128.5 678.74,-128.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"678.97,-132 688.97,-128.5 678.97,-125 678.97,-132\"/>\n","</g>\n","<!-- 2631374470976 -->\n","<g id=\"node18\" class=\"node\">\n","<title>2631374470976</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-36.5 201,-36.5 201,-0.5 0,-0.5\"/>\n","<text text-anchor=\"middle\" x=\"16.5\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w0</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"33,-0.5 33,-36.5 \"/>\n","<text text-anchor=\"middle\" x=\"73.5\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 2.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"114,-0.5 114,-36.5 \"/>\n","<text text-anchor=\"middle\" x=\"157.5\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;1.5000</text>\n","</g>\n","<!-- 2631374470976&#45;&gt;2631372902464* -->\n","<g id=\"edge18\" class=\"edge\">\n","<title>2631374470976&#45;&gt;2631372902464*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M170.4,-36.57C180.73,-39.66 191.2,-43 201,-46.5 211.28,-50.17 222.28,-54.73 232.11,-59.06\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"230.93,-62.37 241.48,-63.27 233.79,-55.98 230.93,-62.37\"/>\n","</g>\n","<!-- 2631375954272 -->\n","<g id=\"node19\" class=\"node\">\n","<title>2631375954272</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"329.5,-110.5 329.5,-146.5 546.5,-146.5 546.5,-110.5 329.5,-110.5\"/>\n","<text text-anchor=\"middle\" x=\"356\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1*w1</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"382.5,-110.5 382.5,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"423\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"463.5,-110.5 463.5,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"505\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2631375954272&#45;&gt;2631377372448+ -->\n","<g id=\"edge11\" class=\"edge\">\n","<title>2631375954272&#45;&gt;2631377372448+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M546.95,-128.5C556.82,-128.5 566.28,-128.5 574.76,-128.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"574.92,-132 584.92,-128.5 574.92,-125 574.92,-132\"/>\n","</g>\n","<!-- 2631375954272*&#45;&gt;2631375954272 -->\n","<g id=\"edge7\" class=\"edge\">\n","<title>2631375954272*&#45;&gt;2631375954272</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M291.12,-128.5C299.31,-128.5 308.94,-128.5 319.28,-128.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"319.39,-132 329.39,-128.5 319.39,-125 319.39,-132\"/>\n","</g>\n","<!-- 2631375827872 -->\n","<g id=\"node21\" class=\"node\">\n","<title>2631375827872</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"339.5,-165.5 339.5,-201.5 536.5,-201.5 536.5,-165.5 339.5,-165.5\"/>\n","<text text-anchor=\"middle\" x=\"356\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"372.5,-165.5 372.5,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"413\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 1.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"453.5,-165.5 453.5,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"495\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.2500</text>\n","</g>\n","<!-- 2631375827872&#45;&gt;2631372255344* -->\n","<g id=\"edge10\" class=\"edge\">\n","<title>2631375827872&#45;&gt;2631372255344*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M536.56,-183.5C550,-183.5 563.07,-183.5 574.4,-183.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"574.69,-187 584.69,-183.5 574.69,-180 574.69,-187\"/>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.graphs.Digraph at 0x264aa0c1670>"]},"execution_count":138,"metadata":{},"output_type":"execute_result"}],"source":["# inputs\n","x0 = Value(-3.0, label='x0')\n","x1 = Value(0.0, label='x1')\n","x2 = Value(0.5, label='x2')\n","\n","# weights\n","w0 = Value(2.0, label='w0')\n","w1 = Value(1.0, label='w1')\n","w2 = Value(1.0, label='w2')\n","\n","# bias\n","b = Value(4.618626415, label='b')\n","\n","# forward pass\n","# x0*w0 + x1*w1 + x2*w2 + b\n","x0w0 = x0*w0; x0w0.label = 'x0*w0'\n","x1w1 = x1*w1; x1w1.label = 'x1*w1'\n","x2w2 = x2*w2; x2w2.label = 'x2*w2'\n","n_sum = x0w0 + x1w1 + x2w2; n_sum.label = 'x0w0 + x1w1 + x2w2'\n","n = n_sum + b; n.label = 'n'\n","out_0 = n.tanh(); out_0.label = 'out_0'\n","\n","# backward pass to calculate gradient\n","out_0.backward()\n","  \n","out_0_grad = w0.grad  # store w0.grad, further calculation with w0 will reset w0.grad to zero\n","print(f'w0.grad: {w0.grad}')\n","draw_dot(out_0)"]},{"cell_type":"markdown","metadata":{},"source":["##### Check Backward Pass Gradient Calculation: d(output) / d(x0)"]},{"cell_type":"code","execution_count":139,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["---- w0.grad from backward pass is same as d(out)/d(w0) calculation ----\n","out_1: -0.7071082802, out_0: -0.7071067802, d(out): -0.0000015000, d(w0): 0.0000010000, d(out)/d(w0): -1.4999968224\n","d(out) / d(w0):             -1.4999968224\n","w0.grad from backward pass: -1.5000000043\n"]}],"source":["h = 0.000001\n","w0 += h  # increment x0 by h\n","\n","# x0*w0 + x1*w1 + x2*w2 + b\n","x0w0 = x0*w0; x0w0.label = 'x0*w0'\n","x1w1 = x1*w1; x1w1.label = 'x1*w1'\n","x2w2 = x2*w2; x2w2.label = 'x2*w2'\n","n_sum = x0w0 + x1w1 + x2w2; n_sum.label = 'x0w0 + x1w1 + x2w2'\n","n = n_sum + b; n.label = 'n'\n","out_1 = n.tanh(); out_1.label = 'out_1'\n","out_grad = (out_1 - out_0) / h \n","\n","print(f'---- w0.grad from backward pass is same as d(out)/d(w0) calculation ----')\n","print(f'out_1: {out_1.data:<12.10f}, out_0: {out_0.data:<12.10f}, d(out): {out_1.data-out_0.data:<12.10f}, d(w0): {h:<12.10f}, d(out)/d(w0): {(out_1.data-out_0.data)/h:<12.10f}')\n","print(f'd(out) / d(w0):             {out_grad.data:<12.10f}')\n","print(f'w0.grad from backward pass: {out_0_grad:<12.10f}')"]},{"cell_type":"markdown","metadata":{},"source":["##### Check Calculation with Pytorch"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":140,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["---- torch results matched backward pass results ----\n","x0.data.item()  = -3.000000\n","x0.grad.item()  =  1.000000\n","w0.data.item()  =  2.000000\n","w0.grad.item()  = -1.500000\n","---\n","x1.data.item()  =  0.000000\n","x1.grad.item()  =  0.500000\n","w1.data.item()  =  1.000000\n","w1.grad.item()  =  0.000000\n","---\n","x2.data.item()  =  0.500000\n","x2.grad.item()  =  0.500000\n","w2.data.item()  =  1.000000\n","w2.grad.item()  =  0.250000\n","---\n","out.data.item() = -0.707107\n"]}],"source":["x0 = torch.Tensor([-3.0]).double();      x0.requires_grad = True\n","x1 = torch.Tensor([0.0]).double();       x1.requires_grad = True\n","x2 = torch.Tensor([0.5]).double();       x2.requires_grad = True\n","w0 = torch.Tensor([2.0]).double();       w0.requires_grad = True\n","w1 = torch.Tensor([1.0]).double();       w1.requires_grad = True\n","w2 = torch.Tensor([1.0]).double();       w2.requires_grad = True\n","b = torch.Tensor([4.61862664]).double(); b.requires_grad  = True\n","n = x0*w0 + x1*w1 + x2*w2 + b\n","o3 = torch.tanh(n)\n","o3.backward()\n","\n","print('---- torch results matched backward pass results ----')\n","print(f'x0.data.item()  = {x0.data.item():>9.6f}')\n","print(f'x0.grad.item()  = {x0.grad.item():>9.6f}')\n","print(f'w0.data.item()  = {w0.data.item():>9.6f}')\n","print(f'w0.grad.item()  = {w0.grad.item():>9.6f}')\n","print('---')\n","print(f'x1.data.item()  = {x1.data.item():>9.6f}')\n","print(f'x1.grad.item()  = {x1.grad.item():>9.6f}')\n","print(f'w1.data.item()  = {w1.data.item():>9.6f}')\n","print(f'w1.grad.item()  = {w1.grad.item():>9.6f}')\n","print('---')\n","print(f'x2.data.item()  = {x2.data.item():>9.6f}')\n","print(f'x2.grad.item()  = {x2.grad.item():>9.6f}')\n","print(f'w2.data.item()  = {w2.data.item():>9.6f}')\n","print(f'w2.grad.item()  = {w2.grad.item():>9.6f}')\n","print('---')\n","print(f'out.data.item() = {o3.data.item():>9.6f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Neural Network MLP(3, [4, 4, 1])\n","    input layer:     3 nodes\n","    hidden layer 1:  4 nodes\n","    hidden layer 2:  4 nodes\n","    output layer:    1 node\n","\n","<!-- ![Getting Started](..\\karpathy\\img\\Nertual_Network_Neuron.PNG) -->\n","<img src=\"..\\karpathy\\img\\neural_network_neuron.PNG\">"]},{"cell_type":"markdown","metadata":{},"source":["### Create neural work, define inputs and targets, initialize weights and biases "]},{"cell_type":"code","execution_count":141,"metadata":{},"outputs":[],"source":["# create neural network and initialize weights and biases\n","n = MLP(3, [4, 4, 1])\n","\n","# inputs\n","xs = [\n","  [2.0, 3.0, -1.0],\n","  [3.0, -1.0, 0.5]\n","]\n","\n","# desired targets\n","ys = [1.0, -1.0]"]},{"cell_type":"code","execution_count":143,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["len(n.parameters()): 41\n"]},{"data":{"text/plain":["[Value(data = 0.7873267075995096),\n"," Value(data = 0.28264816313702656),\n"," Value(data = -0.8684015948314985),\n"," Value(data = 0.02323647056832301),\n"," Value(data = 0.0021405014275279743),\n"," Value(data = -0.22377399521401053),\n"," Value(data = 0.6750914475419012),\n"," Value(data = 0.20132289500915257),\n"," Value(data = 0.9287483603130826),\n"," Value(data = 0.8503800610801633),\n"," Value(data = 0.15911471848607617),\n"," Value(data = 0.40485419231583664),\n"," Value(data = -0.6093288132069568),\n"," Value(data = 0.6830429695913582),\n"," Value(data = -0.6506469076359516),\n"," Value(data = 0.5002977001875062),\n"," Value(data = -0.582806077304602),\n"," Value(data = 0.00481730242237699),\n"," Value(data = -0.9262098806321524),\n"," Value(data = -0.22292682097313055),\n"," Value(data = 0.8195826795179717),\n"," Value(data = 0.8315383832625862),\n"," Value(data = 0.8142623613228162),\n"," Value(data = -0.1263135161554505),\n"," Value(data = -0.35055854752213533),\n"," Value(data = -0.10697745180195617),\n"," Value(data = 0.01635885107204471),\n"," Value(data = 0.37527728097557844),\n"," Value(data = 0.7258408314418752),\n"," Value(data = 0.6921989786472693),\n"," Value(data = -0.671754552074336),\n"," Value(data = -0.8482441818186763),\n"," Value(data = 0.8355448760313517),\n"," Value(data = 0.8764591566540318),\n"," Value(data = -0.6817381726395941),\n"," Value(data = -0.17727838385955086),\n"," Value(data = 0.09635228661516737),\n"," Value(data = 0.7444782611264242),\n"," Value(data = 0.9431178928375712),\n"," Value(data = 0.5818332552645968),\n"," Value(data = -0.22683123239541447)]"]},"execution_count":143,"metadata":{},"output_type":"execute_result"}],"source":["# number of parameters (e.g sum (weights + bias to each neuron and output))\n","# MLP(3, [4, 4, 1]) --> 4_neurons(3_inputs + 1_bias) + 4_neurons(4_neurons + 1_bias) + 1_output(4_neurons + 1_bias) = 41_parameters \n","print(f'len(n.parameters()): {len(n.parameters())}')\n","n.parameters()"]},{"cell_type":"markdown","metadata":{},"source":["#### ---- Start: Manual calculation of a forward pass ----"]},{"cell_type":"markdown","metadata":{},"source":["##### Transpose inputs xs"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["xs_mats:\n","[array([[ 2. ,  3. , -1. ],\n","       [ 3. , -1. ,  0.5]])]\n","\n","xs_mats_T[0].shape: (3, 2)\n","xs_mats_T:\n","[array([[ 2. ,  3. ],\n","       [ 3. , -1. ],\n","       [-1. ,  0.5]])]\n"]}],"source":["xs_mats = [np.array(xs)]  # convert xs to list of np.arrays\n","xs_mats_T = []\n","for mat in xs_mats:\n","  mat_transpose = np.transpose(mat)\n","  xs_mats_T.append(mat_transpose)\n","\n","print(f'xs_mats:\\n{xs_mats}\\n')\n","print(f'xs_mats_T[0].shape: {xs_mats_T[0].shape}')\n","print(f'xs_mats_T:\\n{xs_mats_T}')"]},{"cell_type":"markdown","metadata":{},"source":["##### Get neural network's weights and biases matrices"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["layer_cnt: 3\n","\n","layer: 0, neuron_cnt: 4\n","----\n","neuron 0\n","w0:  0.2188894,   w0.grad:  0.0000000\n","w1:  0.7148999,   w1.grad:  0.0000000\n","w2:  0.4333685,   w2.grad:  0.0000000\n","b:  -0.5810447\n","b_mat:  [-0.5810446674163146]\n","neuron 1\n","w0: -0.9629271,   w0.grad:  0.0000000\n","w1:  0.3421236,   w1.grad:  0.0000000\n","w2:  0.1991534,   w2.grad:  0.0000000\n","b:  -0.7568472\n","b_mat:  [-0.5810446674163146, -0.7568472031590823]\n","neuron 2\n","w0: -0.7789264,   w0.grad:  0.0000000\n","w1: -0.0467433,   w1.grad:  0.0000000\n","w2: -0.9740169,   w2.grad:  0.0000000\n","b:  -0.8104291\n","b_mat:  [-0.5810446674163146, -0.7568472031590823, -0.8104290797347571]\n","neuron 3\n","w0:  0.5577067,   w0.grad:  0.0000000\n","w1: -0.3254468,   w1.grad:  0.0000000\n","w2: -0.3454287,   w2.grad:  0.0000000\n","b:  -0.7061335\n","b_mat:  [-0.5810446674163146, -0.7568472031590823, -0.8104290797347571, -0.7061335305683769]\n","----\n","layer: 1, neuron_cnt: 4\n","----\n","neuron 0\n","w0:  0.0230296,   w0.grad:  0.0000000\n","w1:  0.8004156,   w1.grad:  0.0000000\n","w2:  0.7551908,   w2.grad:  0.0000000\n","w3: -0.6152813,   w3.grad:  0.0000000\n","b:  -0.7200118\n","b_mat:  [-0.7200117650748248]\n","neuron 1\n","w0: -0.1086624,   w0.grad:  0.0000000\n","w1:  0.4574873,   w1.grad:  0.0000000\n","w2: -0.5773168,   w2.grad:  0.0000000\n","w3: -0.8429280,   w3.grad:  0.0000000\n","b:  -0.3766802\n","b_mat:  [-0.7200117650748248, -0.3766801913086337]\n","neuron 2\n","w0:  0.0487287,   w0.grad:  0.0000000\n","w1: -0.6189102,   w1.grad:  0.0000000\n","w2: -0.7641083,   w2.grad:  0.0000000\n","w3:  0.3803785,   w3.grad:  0.0000000\n","b:  -0.6482235\n","b_mat:  [-0.7200117650748248, -0.3766801913086337, -0.6482234762074772]\n","neuron 3\n","w0: -0.5820607,   w0.grad:  0.0000000\n","w1:  0.5551805,   w1.grad:  0.0000000\n","w2: -0.7104120,   w2.grad:  0.0000000\n","w3: -0.0127889,   w3.grad:  0.0000000\n","b:  -0.0558440\n","b_mat:  [-0.7200117650748248, -0.3766801913086337, -0.6482234762074772, -0.05584404702002188]\n","----\n","layer: 2, neuron_cnt: 1\n","----\n","neuron 0\n","w0:  0.0858221,   w0.grad:  0.0000000\n","w1: -0.6807706,   w1.grad:  0.0000000\n","w2: -0.3995186,   w2.grad:  0.0000000\n","w3:  0.8627469,   w3.grad:  0.0000000\n","b:   0.7939658\n","b_mat:  [0.793965828495786]\n","----\n"]}],"source":["layer_cnt = len(n.layers)\n","w_mats = []  # list of weights matrix for each layer \n","b_mats = []  # list of bias matrix for each layer\n","print(f'layer_cnt: {layer_cnt}\\n')\n","for i, layer in enumerate(n.layers):\n","    neuron_cnt = len(layer.neurons)\n","    print(f'layer: {i}, neuron_cnt: {neuron_cnt}')\n","\n","    print('----')\n","    b_mat = []  # accumulate neuon's bias for each row     \n","    for j, neuron in enumerate(layer.neurons):\n","        print(f'neuron {j}')\n","        b = neuron.b.data  # bias of neuron \n","        w_row = []  # accumulate neuon's weights for each row\n","        # b_row = []  # accumulate neuon's bias for each row\n","        for k, w in enumerate(neuron.w):\n","            w_row.append(w.data)\n","            print(f'w{k}: {w.data:10.7f},   w{k}.grad: {w.grad:10.7f}')\n","        if j == 0:            \n","            w_mat = np.array([w_row])\n","        else:\n","            w_mat = np.vstack((w_mat, w_row))\n","        \n","        b_mat.append(b)\n","        print(f'b:  {b:10.7f}')\n","        print(f'b_mat:  {b_mat}')\n","    w_mats.append(w_mat)  \n","    b_mats.append(np.array([b_mat]))        \n","    print('----')"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["type(w_mats): <class 'list'>\n","type(w_mats[0]): <class 'numpy.ndarray'>\n","w_mats[0].shape: (4, 3)\n","w_mats[0]: [[ 0.21888943  0.71489987  0.43336847]\n"," [-0.96292707  0.34212355  0.19915338]\n"," [-0.77892637 -0.04674328 -0.97401694]\n"," [ 0.55770666 -0.32544681 -0.34542873]]\n","\n","type(xs_mats): <class 'list'>\n","type(xs_mats[0]): <class 'numpy.ndarray'>\n","xs_mats[0].shape: (2, 3)\n","xs_mats[0]: [[ 2.   3.  -1. ]\n"," [ 3.  -1.   0.5]]\n","\n","type(b_mats): <class 'list'>\n","type(b_mats[0]): <class 'numpy.ndarray'>\n","b_mats[0].shape: (1, 4)\n","b_mats[0]: [[-0.58104467 -0.7568472  -0.81042908 -0.70613353]]\n","\n"]}],"source":["print(f'type(w_mats): {type(w_mats)}')\n","print(f'type(w_mats[0]): {type(w_mats[0])}')\n","print(f'w_mats[0].shape: {w_mats[0].shape}')\n","print(f'w_mats[0]: {w_mats[0]}\\n')\n","print(f'type(xs_mats): {type(xs_mats)}')\n","print(f'type(xs_mats[0]): {type(xs_mats[0])}')\n","print(f'xs_mats[0].shape: {xs_mats[0].shape}')\n","print(f'xs_mats[0]: {xs_mats[0]}\\n')\n","print(f'type(b_mats): {type(b_mats)}')\n","print(f'type(b_mats[0]): {type(b_mats[0])}')\n","print(f'b_mats[0].shape: {b_mats[0].shape}')\n","print(f'b_mats[0]: {b_mats[0]}\\n')"]},{"cell_type":"markdown","metadata":{},"source":["##### Calculation for a forward pass"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"..\\karpathy\\img\\neural_mat.PNG\">"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["layer: 0\n","weights:\n","[[ 0.21888943  0.71489987  0.43336847]\n"," [-0.96292707  0.34212355  0.19915338]\n"," [-0.77892637 -0.04674328 -0.97401694]\n"," [ 0.55770666 -0.32544681 -0.34542873]]\n","\n","input:\n","[[ 2.   3. ]\n"," [ 3.  -1. ]\n"," [-1.   0.5]]\n","\n","bias:\n","[[-0.58104467]\n"," [-0.7568472 ]\n"," [-0.81042908]\n"," [-0.70613353]]\n","\n","output:\n","[[ 0.91671748 -0.39911181]\n"," [-0.95225976 -0.99916127]\n"," [-0.91119062 -0.99847012]\n"," [-0.21807292  0.80747112]]\n","\n","layer: 1\n","weights:\n","[[ 0.02302959  0.80041559  0.75519077 -0.61528135]\n"," [-0.1086624   0.45748735 -0.57731679 -0.84292802]\n"," [ 0.04872865 -0.61891025 -0.76410834  0.38037848]\n"," [-0.58206068  0.55518053 -0.71041199 -0.0127889 ]]\n","\n","input:\n","[[ 0.91671748 -0.39911181]\n"," [-0.95225976 -0.99916127]\n"," [-0.91119062 -0.99847012]\n"," [-0.21807292  0.80747112]]\n","\n","bias:\n","[[-0.72001177]\n"," [-0.37668019]\n"," [-0.64822348]\n"," [-0.05584405]]\n","\n","output:\n","[[-0.96507561 -0.99232898]\n"," [-0.19936797 -0.71366906]\n"," [ 0.53641479  0.77019359]\n"," [-0.43657843  0.31018206]]\n","\n","layer: 2\n","weights:\n","[[ 0.08582207 -0.68077059 -0.39951862  0.86274688]]\n","\n","input:\n","[[-0.96507561 -0.99232898]\n"," [-0.19936797 -0.71366906]\n"," [ 0.53641479  0.77019359]\n"," [-0.43657843  0.31018206]]\n","\n","bias:\n","[[0.79396583]]\n","\n","output:\n","[[0.25045717 0.81925545]]\n","\n","-- manual forward pass calculation --\n","manual calculation: [0.25045717 0.81925545]\n","desired output:     [1.0, -1.0]\n","loss:               3.87150482898254\n"]}],"source":["verbose = True   # print calculation output and weights and bias matrices \n","# verbose = False  # print calculation output only\n","\n","for layer in range(len(n.layers)):\n","  if layer == 0:  # first layer, use given inputs as inputs\n","    input = xs_mats_T[layer]\n","  else:  # after first layer, use outputs from preceding layers as inputs\n","    input = output\n","\n","  weights = w_mats[layer]\n","  bias = np.transpose(b_mats[layer])\n","  output = np.tanh(np.matmul(weights, input) + bias)\n","\n","  if verbose:\n","    print(f'layer: {layer}')\n","    print(f'weights:\\n{weights}\\n')\n","    # print(f'xs_mats_T[layer]:\\n{xs_mats_T[layer]}\\n')\n","    print(f'input:\\n{input}\\n')    \n","    print(f'bias:\\n{bias}\\n')\n","    print(f'output:\\n{output}\\n')    \n","\n","yout = output[0]\n","ys = ys\n","loss = sum((yout - ys)**2)\n","\n","print(f'-- manual forward pass calculation --')\n","print(f'manual calculation: {yout}')   \n","print(f'desired output:     {ys}')   \n","print(f'loss:               {loss}')"]},{"cell_type":"markdown","metadata":{},"source":["#### ---- End: Manual calculation of a forward pass ----"]},{"cell_type":"markdown","metadata":{},"source":["#### Micrograd results are same as manual calculation"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-- micrograd forward pass calculation --\n","ypred_data:         [0.2504571728301796, 0.8192554463903117]\n","ys:                 [1.0, -1.0]\n","loss_data:          3.8715048289825393\n"]}],"source":["ypred = [n(x) for x in xs]\n","loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))  # low loss is better, perfect is loss = 0\n","ypred_data = [v.data for v in ypred] \n","loss_data = loss.data\n","\n","print(f'-- micrograd forward pass calculation --')\n","print(f'ypred_data:         {ypred_data}')\n","print(f'ys:                 {ys}')\n","print(f'loss_data:          {loss_data}')"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["# initialize\n","# step = 0"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ypred: [Value(data = 0.2504571728301796), Value(data = 0.8192554463903117)]\n","step: 0, loss: 3.8715048289825393\n","-------\n","ypred: [Value(data = 0.48554200931192065), Value(data = 0.7707327833376594)]\n","step: 1, loss: 3.40016161416955\n","-------\n","ypred: [Value(data = 0.39014758199328364), Value(data = 0.6014109864894416)]\n","step: 2, loss: 2.9364371193977252\n","-------\n","ypred: [Value(data = 0.17724481851740315), Value(data = 0.27520826706622326)]\n","step: 3, loss: 2.303082213050501\n","-------\n","ypred: [Value(data = -0.0022009545497690933), Value(data = 0.020509428929388205)]\n","step: 4, loss: 2.045846247834254\n","-------\n","ypred: [Value(data = -0.007924817166299157), Value(data = -0.020306648485320444)]\n","step: 5, loss: 1.9757115000617829\n","-------\n","ypred: [Value(data = 0.013495653550262469), Value(data = -0.02925405593763035)]\n","step: 6, loss: 1.9155385134777652\n","-------\n","ypred: [Value(data = 0.03935794895221084), Value(data = -0.04055644676755123)]\n","step: 7, loss: 1.8433650820806098\n","-------\n","ypred: [Value(data = 0.07762589383792624), Value(data = -0.05825578278065264)]\n","step: 8, loss: 1.7376561623843656\n","-------\n","ypred: [Value(data = 0.14330389011070543), Value(data = -0.08864931243997631)]\n","step: 9, loss: 1.564488300415578\n","-------\n","ypred: [Value(data = 0.2561611526764582), Value(data = -0.145721430642426)]\n","step: 10, loss: 1.2830881048512386\n","-------\n","ypred: [Value(data = 0.41172178235443846), Value(data = -0.2510523080655081)]\n","step: 11, loss: 0.9069939066102414\n","-------\n","ypred: [Value(data = 0.5666525718261678), Value(data = -0.39622031849038675)]\n","step: 12, loss: 0.5523398973087247\n","-------\n","ypred: [Value(data = 0.6932606412720101), Value(data = -0.5254146521875674)]\n","step: 13, loss: 0.319320286551106\n","-------\n","ypred: [Value(data = 0.7704915148266614), Value(data = -0.6171624326609665)]\n","step: 14, loss: 0.1992387477326296\n","-------\n","ypred: [Value(data = 0.8142939681431677), Value(data = -0.6774474189348976)]\n","step: 15, loss: 0.1385268978197703\n","-------\n","ypred: [Value(data = 0.841373577097442), Value(data = -0.7184725069333063)]\n","step: 16, loss: 0.10442007139527842\n","-------\n","ypred: [Value(data = 0.8597270442037727), Value(data = -0.7480555335565284)]\n","step: 17, loss: 0.08315251629929592\n","-------\n","ypred: [Value(data = 0.8730603209544462), Value(data = -0.7704697543990636)]\n","step: 18, loss: 0.06879781576181439\n","-------\n","ypred: [Value(data = 0.8832505217307772), Value(data = -0.7881205561460658)]\n","step: 19, loss: 0.05852333940398817\n","-------\n","ypred: [Value(data = 0.8913387016638524), Value(data = -0.8024435798945191)]\n","step: 20, loss: 0.05083581688099053\n","-------\n","ypred: [Value(data = 0.8979472522131853), Value(data = -0.8143448841296671)]\n","step: 21, loss: 0.044882585379665954\n","-------\n","ypred: [Value(data = 0.9034713829730882), Value(data = -0.8244242919948979)]\n","step: 22, loss: 0.040144603146621105\n","-------\n","ypred: [Value(data = 0.9081745452434107), Value(data = -0.8330951111123144)]\n","step: 23, loss: 0.036289156075865116\n","-------\n","ypred: [Value(data = 0.9122394740721319), Value(data = -0.8406518457037655)]\n","step: 24, loss: 0.033093744188752564\n","-------\n","ypred: [Value(data = 0.9157971607154858), Value(data = -0.8473103748344193)]\n","step: 25, loss: 0.03040423977677927\n","-------\n","ypred: [Value(data = 0.9189441390420711), Value(data = -0.8532328102716517)]\n","step: 26, loss: 0.028110660576388107\n","-------\n","ypred: [Value(data = 0.921753244392094), Value(data = -0.8585434435449316)]\n","step: 27, loss: 0.02613251212728931\n","-------\n","ypred: [Value(data = 0.9242805559325996), Value(data = -0.863339304179542)]\n","step: 28, loss: 0.02440957999200793\n","-------\n","ypred: [Value(data = 0.9265700180963519), Value(data = -0.8676973454903281)]\n","step: 29, loss: 0.02289595463267571\n","-------\n","ypred: [Value(data = 0.9286566015992557), Value(data = -0.871679455190178)]\n","step: 30, loss: 0.02155604271565687\n","-------\n","ypred: [Value(data = 0.9305685176348947), Value(data = -0.875336025067057)]\n","step: 31, loss: 0.020361837389497376\n","-------\n","ypred: [Value(data = 0.9323288018458206), Value(data = -0.8787085431878947)]\n","step: 32, loss: 0.01929100855522502\n","-------\n","ypred: [Value(data = 0.9339564688870426), Value(data = -0.8818315087889513)]\n","step: 33, loss: 0.018325540316963852\n","-------\n","ypred: [Value(data = 0.9354673682373347), Value(data = -0.8847338687957802)]\n","step: 34, loss: 0.017450741565004174\n","-------\n","ypred: [Value(data = 0.9368748282251649), Value(data = -0.8874401106070736)]\n","step: 35, loss: 0.01665451601175026\n","-------\n","ypred: [Value(data = 0.938190147356167), Value(data = -0.8899711039919486)]\n","step: 36, loss: 0.015926815840602945\n","-------\n","ypred: [Value(data = 0.9394229738396302), Value(data = -0.892344757242526)]\n","step: 37, loss: 0.01525922739160477\n","-------\n","ypred: [Value(data = 0.9405816021037536), Value(data = -0.8945765340064404)]\n","step: 38, loss: 0.014644653190651865\n","-------\n","ypred: [Value(data = 0.9416732068811802), Value(data = -0.8966798643635077)]\n","step: 39, loss: 0.014077065223468783\n","-------\n","ypred: [Value(data = 0.9427040297878525), Value(data = -0.8986664747356434)]\n","step: 40, loss: 0.013551311545053285\n","-------\n","ypred: [Value(data = 0.943679529357074), Value(data = -0.9005466548648923)]\n","step: 41, loss: 0.013062963272003547\n","-------\n","ypred: [Value(data = 0.9446045026781756), Value(data = -0.9023294755356112)]\n","step: 42, loss: 0.01260819247268103\n","-------\n","ypred: [Value(data = 0.945483184765999), Value(data = -0.9040229674056736)]\n","step: 43, loss: 0.012183673928870601\n","-------\n","ypred: [Value(data = 0.9463193303142355), Value(data = -0.9056342688789383)]\n","step: 44, loss: 0.011786505507924669\n","-------\n","ypred: [Value(data = 0.9471162814008439), Value(data = -0.9071697491449087)]\n","step: 45, loss: 0.011414143166693912\n","-------\n","ypred: [Value(data = 0.9478770239064798), Value(data = -0.9086351111568506)]\n","step: 46, loss: 0.01106434755016673\n","-------\n","ypred: [Value(data = 0.9486042348001993), Value(data = -0.9100354782942112)]\n","step: 47, loss: 0.010735139846224397\n","-------\n","ypred: [Value(data = 0.9493003219865833), Value(data = -0.9113754676721684)]\n","step: 48, loss: 0.010424765080991001\n","-------\n","ypred: [Value(data = 0.9499674580564367), Value(data = -0.912659252458312)]\n","step: 49, loss: 0.010131661434475296\n","-------\n","ypred: [Value(data = 0.9506076090117692), Value(data = -0.9138906150887582)]\n","step: 50, loss: 0.009854434457326651\n","-------\n","ypred: [Value(data = 0.9512225588248092), Value(data = -0.9150729929104856)]\n","step: 51, loss: 0.009591835300781625\n","-------\n","ypred: [Value(data = 0.9518139305256882), Value(data = -0.9162095174890565)]\n","step: 52, loss: 0.009342742250799925\n","-------\n","ypred: [Value(data = 0.9523832043833159), Value(data = -0.9173030485930899)]\n","step: 53, loss: 0.00910614499679792\n","-------\n","ypred: [Value(data = 0.9529317336407611), Value(data = -0.9183562036852998)]\n","step: 54, loss: 0.008881131174740512\n","-------\n","ypred: [Value(data = 0.9534607581840988), Value(data = -0.9193713836043953)]\n","step: 55, loss: 0.0086668748106685\n","-------\n","ypred: [Value(data = 0.953971416457587), Value(data = -0.9203507950048359)]\n","step: 56, loss: 0.008462626359282575\n","-------\n","ypred: [Value(data = 0.9544647558846919), Value(data = -0.9212964700263848)]\n","step: 57, loss: 0.008267704086948442\n","-------\n","ypred: [Value(data = 0.9549417420112006), Value(data = -0.922210283587993)]\n","step: 58, loss: 0.008081486592445682\n","-------\n","ypred: [Value(data = 0.9554032665513822), Value(data = -0.9230939686372008)]\n","step: 59, loss: 0.007903406294262916\n","-------\n","ypred: [Value(data = 0.9558501544892478), Value(data = -0.9239491296341682)]\n","step: 60, loss: 0.007732943742023838\n","-------\n","ypred: [Value(data = 0.9562831703631773), Value(data = -0.9247772545064461)]\n","step: 61, loss: 0.007569622633082959\n","-------\n","ypred: [Value(data = 0.9567030238425189), Value(data = -0.9255797252749564)]\n","step: 62, loss: 0.007413005434532454\n","-------\n","ypred: [Value(data = 0.9571103746884523), Value(data = -0.9263578275219589)]\n","step: 63, loss: 0.007262689526650503\n","-------\n","ypred: [Value(data = 0.9575058371778119), Value(data = -0.9271127588469991)]\n","step: 64, loss: 0.007118303796854347\n","-------\n","ypred: [Value(data = 0.9578899840571944), Value(data = -0.9278456364360116)]\n","step: 65, loss: 0.006979505624027561\n","-------\n","ypred: [Value(data = 0.958263350085129), Value(data = -0.9285575038512616)]\n","step: 66, loss: 0.006845978202079009\n","-------\n","ypred: [Value(data = 0.9586264352120474), Value(data = -0.9292493371350085)]\n","step: 67, loss: 0.006717428159098607\n","-------\n","ypred: [Value(data = 0.9589797074409945), Value(data = -0.9299220503072484)]\n","step: 68, loss: 0.006593583434766228\n","-------\n","ypred: [Value(data = 0.9593236054062544), Value(data = -0.9305765003272489)]\n","step: 69, loss: 0.006474191383958566\n","-------\n","ypred: [Value(data = 0.9596585407021649), Value(data = -0.9312134915794964)]\n","step: 70, loss: 0.006359017078962895\n","-------\n","ypred: [Value(data = 0.9599848999902093), Value(data = -0.9318337799369271)]\n","step: 71, loss: 0.0062478417864808376\n","-------\n","ypred: [Value(data = 0.9603030469088943), Value(data = -0.932438076447642)]\n","step: 72, loss: 0.006140461598812113\n","-------\n","ypred: [Value(data = 0.9606133238078526), Value(data = -0.9330270506855939)]\n","step: 73, loss: 0.006036686201335083\n","-------\n","ypred: [Value(data = 0.9609160533249629), Value(data = -0.9336013338007906)]\n","step: 74, loss: 0.005936337760731181\n","-------\n","ypred: [Value(data = 0.9612115398230047), Value(data = -0.9341615213003017)]\n","step: 75, loss: 0.005839249920392977\n","-------\n","ypred: [Value(data = 0.9615000707003879), Value(data = -0.9347081755876577)]\n","step: 76, loss: 0.005745266891167264\n","-------\n","ypred: [Value(data = 0.9617819175887944), Value(data = -0.935241828285023)]\n","step: 77, loss: 0.00565424262705615\n","-------\n","ypred: [Value(data = 0.9620573374490777), Value(data = -0.9357629823597347)]\n","step: 78, loss: 0.005566040076768921\n","-------\n","ypred: [Value(data = 0.9623265735754789), Value(data = -0.9362721140743593)]\n","step: 79, loss: 0.00548053050311528\n","-------\n","ypred: [Value(data = 0.9625898565170815), Value(data = -0.9367696747772938)]\n","step: 80, loss: 0.005397592863181747\n","-------\n","ypred: [Value(data = 0.9628474049244488), Value(data = -0.9372560925490719)]\n","step: 81, loss: 0.0053171132430585005\n","-------\n","ypred: [Value(data = 0.9630994263285129), Value(data = -0.9377317737178954)]\n","step: 82, loss: 0.005238984341604231\n","-------\n","ypred: [Value(data = 0.963346117858031), Value(data = -0.9381971042564787)]\n","step: 83, loss: 0.0051631049983619105\n","-------\n","ypred: [Value(data = 0.9635876669012531), Value(data = -0.9386524510710166)]\n","step: 84, loss: 0.005089379761288115\n","-------\n","ypred: [Value(data = 0.9638242517168527), Value(data = -0.9390981631919729)]\n","step: 85, loss: 0.005017718490437196\n","-------\n","ypred: [Value(data = 0.9640560419986594), Value(data = -0.939534572875392)]\n","step: 86, loss: 0.004948035994163422\n","-------\n","ypred: [Value(data = 0.9642831993982601), Value(data = -0.9399619966225627)]\n","step: 87, loss: 0.004880251694773613\n","-------\n","ypred: [Value(data = 0.9645058780091369), Value(data = -0.9403807361250808)]\n","step: 88, loss: 0.004814289320889521\n","-------\n","ypred: [Value(data = 0.9647242248156415), Value(data = -0.9407910791416665)]\n","step: 89, loss: 0.004750076624065807\n","-------\n","ypred: [Value(data = 0.9649383801097846), Value(data = -0.9411933003124786)]\n","step: 90, loss: 0.004687545117464276\n","-------\n","ypred: [Value(data = 0.9651484778785325), Value(data = -0.9415876619161148)]\n","step: 91, loss: 0.0046266298346092465\n","-------\n","ypred: [Value(data = 0.9653546461640451), Value(data = -0.9419744145739981)]\n","step: 92, loss: 0.004567269106448758\n","-------\n","ypred: [Value(data = 0.9655570073990624), Value(data = -0.942353797906413)]\n","step: 93, loss: 0.0045094043551229136\n","-------\n","ypred: [Value(data = 0.9657556787194393), Value(data = -0.9427260411440576)]\n","step: 94, loss: 0.004452979902998447\n","-------\n","ypred: [Value(data = 0.965950772255648), Value(data = -0.9430913636986282)]\n","step: 95, loss: 0.0043979427956685625\n","-------\n","ypred: [Value(data = 0.9661423954048985), Value(data = -0.9434499756956386)]\n","step: 96, loss: 0.0043442426377421\n","-------\n","ypred: [Value(data = 0.9663306510853844), Value(data = -0.9438020784723863)]\n","step: 97, loss: 0.004291831440357955\n","-------\n","ypred: [Value(data = 0.9665156379740231), Value(data = -0.9441478650437242)]\n","step: 98, loss: 0.0042406634794607346\n","-------\n","ypred: [Value(data = 0.9666974507289444), Value(data = -0.9444875205380695)]\n","step: 99, loss: 0.00419069516396234\n","-------\n","ypred: [Value(data = 0.9668761801978687), Value(data = -0.9448212226058642)]\n","step: 100, loss: 0.004141884912995657\n","-------\n","ypred: [Value(data = 0.9670519136134219), Value(data = -0.9451491418025199)]\n","step: 101, loss: 0.004094193041537487\n","-------\n","ypred: [Value(data = 0.9672247347763424), Value(data = -0.9454714419477075)]\n","step: 102, loss: 0.004047581653743333\n","-------\n","ypred: [Value(data = 0.9673947242274605), Value(data = -0.945788280462697)]\n","step: 103, loss: 0.004002014543394546\n","-------\n","ypred: [Value(data = 0.9675619594092507), Value(data = -0.9460998086873104)]\n","step: 104, loss: 0.003957457100911642\n","-------\n","ypred: [Value(data = 0.9677265148176994), Value(data = -0.9464061721779302)]\n","step: 105, loss: 0.0039138762264338345\n","-------\n","ypred: [Value(data = 0.9678884621451654), Value(data = -0.9467075109878812)]\n","step: 106, loss: 0.0038712402485092763\n","-------\n","ypred: [Value(data = 0.9680478704148575), Value(data = -0.9470039599314065)]\n","step: 107, loss: 0.003829518847977704\n","-------\n","ypred: [Value(data = 0.9682048061075055), Value(data = -0.9472956488323557)]\n","step: 108, loss: 0.0037886829866636868\n","-------\n","ypred: [Value(data = 0.9683593332807546), Value(data = -0.9475827027586214)]\n","step: 109, loss: 0.0037487048405293938\n","-------\n","ypred: [Value(data = 0.9685115136817724), Value(data = -0.9478652422432787)]\n","step: 110, loss: 0.0037095577369652185\n","-------\n","ypred: [Value(data = 0.9686614068535181), Value(data = -0.9481433834933054)]\n","step: 111, loss: 0.0036712160959231134\n","-------\n","ypred: [Value(data = 0.9688090702350953), Value(data = -0.948417238586702)]\n","step: 112, loss: 0.0036336553746204397\n","-------\n","ypred: [Value(data = 0.9689545592565689), Value(data = -0.9486869156587606)]\n","step: 113, loss: 0.003596852015565036\n","-------\n","ypred: [Value(data = 0.9690979274286085), Value(data = -0.9489525190781849)]\n","step: 114, loss: 0.003560783397670627\n","-------\n","ypred: [Value(data = 0.9692392264272842), Value(data = -0.9492141496137043)]\n","step: 115, loss: 0.003525427790251099\n","-------\n","ypred: [Value(data = 0.9693785061743263), Value(data = -0.9494719045917833)]\n","step: 116, loss: 0.0034907643096976195\n","-------\n","ypred: [Value(data = 0.9695158149131282), Value(data = -0.9497258780459822)]\n","step: 117, loss: 0.003456772878658112\n","-------\n","ypred: [Value(data = 0.9696511992807613), Value(data = -0.9499761608584861)]\n","step: 118, loss: 0.0034234341875521205\n","-------\n","ypred: [Value(data = 0.9697847043762438), Value(data = -0.9502228408942821)]\n","step: 119, loss: 0.003390729658266937\n","-------\n","ypred: [Value(data = 0.9699163738252932), Value(data = -0.9504660031284298)]\n","step: 120, loss: 0.0033586414098922355\n","-------\n","ypred: [Value(data = 0.9700462498417748), Value(data = -0.9507057297668442)]\n","step: 121, loss: 0.003327152226360767\n","-------\n","ypred: [Value(data = 0.9701743732860422), Value(data = -0.9509421003609747)]\n","step: 122, loss: 0.0032962455258730332\n","-------\n","ypred: [Value(data = 0.9703007837203558), Value(data = -0.9511751919167419)]\n","step: 123, loss: 0.0032659053319920666\n","-------\n","ypred: [Value(data = 0.9704255194615495), Value(data = -0.951405078998069)]\n","step: 124, loss: 0.0032361162463030967\n","-------\n","ypred: [Value(data = 0.9705486176311069), Value(data = -0.9516318338253207)]\n","step: 125, loss: 0.0032068634225401404\n","-------\n","ypred: [Value(data = 0.9706701142027939), Value(data = -0.9518555263689442)]\n","step: 126, loss: 0.0031781325420885765\n","-------\n","ypred: [Value(data = 0.9707900440479919), Value(data = -0.9520762244385839)]\n","step: 127, loss: 0.0031499097907792427\n","-------\n","ypred: [Value(data = 0.9709084409788556), Value(data = -0.9522939937679266)]\n","step: 128, loss: 0.003122181836895355\n","-------\n","ypred: [Value(data = 0.971025337789425), Value(data = -0.9525088980955176)]\n","step: 129, loss: 0.0030949358103188503\n","-------\n","ypred: [Value(data = 0.9711407662947977), Value(data = -0.9527209992417704)]\n","step: 130, loss: 0.003068159282748153\n","-------\n","ypred: [Value(data = 0.9712547573684753), Value(data = -0.9529303571823793)]\n","step: 131, loss: 0.0030418402489236166\n","-------\n","ypred: [Value(data = 0.9713673409779794), Value(data = -0.953137030118333)]\n","step: 132, loss: 0.0030159671088013317\n","-------\n","ypred: [Value(data = 0.9714785462188334), Value(data = -0.9533410745427141)]\n","step: 133, loss: 0.0029905286506197817\n","-------\n","ypred: [Value(data = 0.9715884013469978), Value(data = -0.9535425453044528)]\n","step: 134, loss: 0.0029655140348080985\n","-------\n","ypred: [Value(data = 0.9716969338098395), Value(data = -0.9537414956692037)]\n","step: 135, loss: 0.002940912778686905\n","-------\n","ypred: [Value(data = 0.9718041702757169), Value(data = -0.9539379773774929)]\n","step: 136, loss: 0.0029167147419171275\n","-------\n","ypred: [Value(data = 0.9719101366622487), Value(data = -0.9541320407002805)]\n","step: 137, loss: 0.002892910112654274\n","-------\n","ypred: [Value(data = 0.9720148581633389), Value(data = -0.954323734492072)]\n","step: 138, loss: 0.002869489394368776\n","-------\n","ypred: [Value(data = 0.9721183592750194), Value(data = -0.9545131062417088)]\n","step: 139, loss: 0.0028464433932949636\n","-------\n","ypred: [Value(data = 0.9722206638201737), Value(data = -0.9547002021209505)]\n","step: 140, loss: 0.0028237632064745423\n","-------\n","ypred: [Value(data = 0.9723217949721952), Value(data = -0.9548850670309664)]\n","step: 141, loss: 0.0028014402103615924\n","-------\n","ypred: [Value(data = 0.972421775277637), Value(data = -0.9550677446468402)]\n","step: 142, loss: 0.0027794660499587147\n","-------\n","ypred: [Value(data = 0.9725206266779023), Value(data = -0.9552482774601866)]\n","step: 143, loss: 0.002757832628455659\n","-------\n","ypred: [Value(data = 0.9726183705300226), Value(data = -0.9554267068199742)]\n","step: 144, loss: 0.0027365320973436655\n","-------\n","ypred: [Value(data = 0.9727150276265704), Value(data = -0.9556030729716425)]\n","step: 145, loss: 0.0027155568469801206\n","-------\n","ypred: [Value(data = 0.9728106182147457), Value(data = -0.9557774150945991)]\n","step: 146, loss: 0.0026948994975797085\n","-------\n","ypred: [Value(data = 0.9729051620146814), Value(data = -0.9559497713381706)]\n","step: 147, loss: 0.002674552890610122\n","-------\n","ypred: [Value(data = 0.9729986782369993), Value(data = -0.9561201788560876)]\n","step: 148, loss: 0.0026545100805708413\n","-------\n","ypred: [Value(data = 0.9730911855996577), Value(data = -0.95628867383957)]\n","step: 149, loss: 0.002634764327135567\n","-------\n","ypred: [Value(data = 0.9731827023441211), Value(data = -0.9564552915490809)]\n","step: 150, loss: 0.0026153090876395516\n","-------\n","ypred: [Value(data = 0.9732732462508852), Value(data = -0.9566200663448113)]\n","step: 151, loss: 0.002596138009894393\n","-------\n","ypred: [Value(data = 0.9733628346543878), Value(data = -0.9567830317159542)]\n","step: 152, loss: 0.0025772449253137013\n","-------\n","ypred: [Value(data = 0.973451484457332), Value(data = -0.956944220308827)]\n","step: 153, loss: 0.0025586238423341125\n","-------\n"]},{"name":"stdout","output_type":"stream","text":["ypred: [Value(data = 0.9735392121444528), Value(data = -0.9571036639538923)]\n","step: 154, loss: 0.002540268940116867\n","-------\n","ypred: [Value(data = 0.9736260337957477), Value(data = -0.9572613936917299)]\n","step: 155, loss: 0.0025221745625163437\n","-------\n","ypred: [Value(data = 0.9737119650992003), Value(data = -0.9574174397980072)]\n","step: 156, loss: 0.002504335212302003\n","-------\n","ypred: [Value(data = 0.9737970213630158), Value(data = -0.9575718318074906)]\n","step: 157, loss: 0.002486745545622114\n","-------\n","ypred: [Value(data = 0.9738812175273941), Value(data = -0.9577245985371479)]\n","step: 158, loss: 0.0024694003666966263\n","-------\n","ypred: [Value(data = 0.9739645681758577), Value(data = -0.9578757681083724)]\n","step: 159, loss: 0.002452294622729176\n","-------\n","ypred: [Value(data = 0.974047087546157), Value(data = -0.9580253679683766)]\n","step: 160, loss: 0.0024354233990270284\n","-------\n","ypred: [Value(data = 0.9741287895407684), Value(data = -0.9581734249107882)]\n","step: 161, loss: 0.0024187819143193295\n","-------\n","ypred: [Value(data = 0.9742096877370071), Value(data = -0.9583199650954808)]\n","step: 162, loss: 0.0024023655162646214\n","-------\n","ypred: [Value(data = 0.9742897953967673), Value(data = -0.9584650140676776)]\n","step: 163, loss: 0.0023861696771383086\n","-------\n","ypred: [Value(data = 0.9743691254759078), Value(data = -0.9586085967763565)]\n","step: 164, loss: 0.0023701899896920067\n","-------\n","ypred: [Value(data = 0.9744476906332992), Value(data = -0.9587507375919869)]\n","step: 165, loss: 0.0023544221631767075\n","-------\n","ypred: [Value(data = 0.9745255032395439), Value(data = -0.9588914603236264)]\n","step: 166, loss: 0.0023388620195224728\n","-------\n","ypred: [Value(data = 0.9746025753853866), Value(data = -0.9590307882354049)]\n","step: 167, loss: 0.0023235054896672074\n","-------\n","ypred: [Value(data = 0.9746789188898252), Value(data = -0.9591687440624227)]\n","step: 168, loss: 0.002308348610027995\n","-------\n","ypred: [Value(data = 0.9747545453079355), Value(data = -0.9593053500260862)]\n","step: 169, loss: 0.0022933875191084455\n","-------\n","ypred: [Value(data = 0.9748294659384235), Value(data = -0.9594406278489028)]\n","step: 170, loss: 0.002278618454236182\n","-------\n","ypred: [Value(data = 0.9749036918309125), Value(data = -0.9595745987687608)]\n","step: 171, loss: 0.00226403774842448\n","-------\n","ypred: [Value(data = 0.9749772337929805), Value(data = -0.9597072835527132)]\n","step: 172, loss: 0.0022496418273526145\n","-------\n","ypred: [Value(data = 0.9750501023969537), Value(data = -0.9598387025102856)]\n","step: 173, loss: 0.002235427206459839\n","-------\n","ypred: [Value(data = 0.9751223079864694), Value(data = -0.9599688755063287)]\n","step: 174, loss: 0.0022213904881478955\n","-------\n","ypred: [Value(data = 0.9751938606828158), Value(data = -0.9600978219734316)]\n","step: 175, loss: 0.0022075283590875087\n","-------\n","ypred: [Value(data = 0.9752647703910574), Value(data = -0.9602255609239169)]\n","step: 176, loss: 0.002193837587624159\n","-------\n","ypred: [Value(data = 0.9753350468059561), Value(data = -0.9603521109614291)]\n","step: 177, loss: 0.0021803150212792058\n","-------\n","ypred: [Value(data = 0.9754046994176936), Value(data = -0.9604774902921386)]\n","step: 178, loss: 0.0021669575843420025\n","-------\n","ypred: [Value(data = 0.9754737375174058), Value(data = -0.9606017167355703)]\n","step: 179, loss: 0.0021537622755493494\n","-------\n","ypred: [Value(data = 0.9755421702025341), Value(data = -0.9607248077350762)]\n","step: 180, loss: 0.002140726165848543\n","-------\n","ypred: [Value(data = 0.9756100063820013), Value(data = -0.9608467803679637)]\n","step: 181, loss: 0.0021278463962404897\n","-------\n","ypred: [Value(data = 0.9756772547812206), Value(data = -0.9609676513552913)]\n","step: 182, loss: 0.0021151201756997523\n","-------\n","ypred: [Value(data = 0.975743923946941), Value(data = -0.9610874370713485)]\n","step: 183, loss: 0.0021025447791680483\n","-------\n","ypred: [Value(data = 0.975810022251938), Value(data = -0.9612061535528283)]\n","step: 184, loss: 0.002090117545618466\n","-------\n","ypred: [Value(data = 0.9758755578995537), Value(data = -0.9613238165077064)]\n","step: 185, loss: 0.002077835876187351\n","-------\n","ypred: [Value(data = 0.9759405389280935), Value(data = -0.9614404413238348)]\n","step: 186, loss: 0.0020656972323712126\n","-------\n","ypred: [Value(data = 0.9760049732150832), Value(data = -0.9615560430772657)]\n","step: 187, loss: 0.0020536991342859252\n","-------\n","ypred: [Value(data = 0.9760688684813926), Value(data = -0.9616706365403108)]\n","step: 188, loss: 0.0020418391589858394\n","-------\n","ypred: [Value(data = 0.9761322322952308), Value(data = -0.9617842361893483)]\n","step: 189, loss: 0.0020301149388403405\n","-------\n","ypred: [Value(data = 0.9761950720760165), Value(data = -0.9618968562123865)]\n","step: 190, loss: 0.002018524159965596\n","-------\n","ypred: [Value(data = 0.9762573950981298), Value(data = -0.9620085105163928)]\n","step: 191, loss: 0.002007064560709347\n","-------\n","ypred: [Value(data = 0.9763192084945486), Value(data = -0.9621192127343962)]\n","step: 192, loss: 0.0019957339301865953\n","-------\n","ypred: [Value(data = 0.976380519260373), Value(data = -0.962228976232373)]\n","step: 193, loss: 0.0019845301068642553\n","-------\n","ypred: [Value(data = 0.9764413342562446), Value(data = -0.9623378141159211)]\n","step: 194, loss: 0.001973450977192906\n","-------\n","ypred: [Value(data = 0.9765016602116608), Value(data = -0.962445739236733)]\n","step: 195, loss: 0.0019624944742836947\n","-------\n","ypred: [Value(data = 0.9765615037281904), Value(data = -0.9625527641988723)]\n","step: 196, loss: 0.0019516585766288963\n","-------\n","ypred: [Value(data = 0.9766208712825935), Value(data = -0.9626589013648628)]\n","step: 197, loss: 0.0019409413068641117\n","-------\n","ypred: [Value(data = 0.9766797692298474), Value(data = -0.9627641628615957)]\n","step: 198, loss: 0.0019303407305709375\n","-------\n","ypred: [Value(data = 0.9767382038060856), Value(data = -0.9628685605860615)]\n","step: 199, loss: 0.0019198549551181967\n","-------\n"]}],"source":["learning_rate = 0.05\n","\n","# Create a list of losses\n","losses = []\n","for k in range(200):\n","  # forward pass\n","  ypred = [n(x) for x in xs]\n","  loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))  # low loss is better, perfect is loss = 0\n","  losses.append(loss.data)\n","\n","  # backward pass to calculate gradients\n","  for p in n.parameters():\n","    p.grad = 0.0  # zero the gradient \n","  loss.backward()\n","\n","  # update weights and bias\n","  for p in n.parameters():\n","      p.data += -learning_rate * p.grad\n","\n","  # print(f'x: {x}')\n","  print(f'ypred: {ypred}')\n","  print(f'step: {k}, loss: {loss.data}')   \n","  print('-------')  "]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"data":{"text/plain":["Text(0, 0.5, 'Loss')"]},"execution_count":78,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","# Create a list of iterations\n","iterations = range(len(losses))\n","\n","# Plot the loss as a function of iteration\n","plt.plot(iterations, losses)\n","\n","# Add a title to the plot\n","plt.title('Loss vs. Iteration')\n","\n","# Add labels to the x-axis and y-axis\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
