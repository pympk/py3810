{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from graphviz import Digraph\n","\n","def trace(root):\n","  \"\"\"Builds a set of all nodes and edges in a graph.\"\"\"\n","  nodes, edges = set(), set()\n","\n","  def build(v):\n","    if v not in nodes:\n","      nodes.add(v)\n","      for child in v._prev:\n","        edges.add((child, v))\n","        build(child)\n","\n","  build(root)\n","  return nodes, edges\n","\n","def draw_dot(root):\n","  \"\"\"Creates a Digraph representation of the graph.\"\"\"\n","  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'})  # LR = left to right\n","\n","  nodes, edges = trace(root)\n","  for n in nodes:\n","    uid = str(id(n))\n","    # For any value in the graph, create a rectangular ('record') node for it.\n","    dot.node(name=uid, label=\"{ %s | data %.4f | grad % .4f }\" % (n.label, n.data, n.grad), shape=\"record\")\n","\n","    if n._op:\n","      # If this value is a result of some operation, create an op node.\n","      dot.node(name=uid + n._op, label=n._op)\n","      # And connect this node to it\n","      dot.edge(uid + n._op, uid)\n","\n","  for n1, n2 in edges:\n","    # Connect nl to the op node of n2.\n","    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n","\n","  return dot"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class Value:\n","\n","    def __init__(self, data, _children=(), _op='', label=''):\n","        self.data = data\n","        self.grad = 0.0\n","        self._backward = lambda : None\n","        self._prev = set(_children)\n","        self._op = _op\n","        self.label = label\n","\n","    def __repr__(self) -> str:\n","        return f\"Value(data = {self.data})\"\n","    \n","    def __add__(self, other):\n","        other = other if isinstance(other, Value) else Value(other)\n","        out = Value(self.data + other.data, (self, other), '+')\n","\n","        def _backward():\n","            self.grad += 1.0 * out.grad\n","            other.grad += 1.0 * out.grad\n","        out._backward = _backward    \n","\n","        return out\n","\n","    def __radd__(self, other): # other + self\n","        return self + other\n","\n","    def __mul__(self, other):\n","        other = other if isinstance(other, Value) else Value(other)        \n","        out = Value(self.data * other.data, (self, other), '*')\n","\n","        def _backward():\n","            self.grad += other.data * out.grad\n","            other.grad += self.data * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def __rmul__(self, other):  # other * self\n","        return self * other\n","\n","    def __pow__(self, other):\n","        assert isinstance(other, (int, float)), \"only support int/float power for now\"\n","        out = Value(self.data**other, (self,), f'**{other}')\n","\n","        def _backward():\n","            self.grad += other * (self.data ** (other - 1)) * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def __truediv__(self, other):  # self / other\n","        return self * other**-1\n","\n","    def __neg__(self):  # -self\n","        return self * -1\n","    \n","    def __sub__(self, other):  # self - other\n","        return self + (-other)\n","\n","    def __rsub__(self, other): # other - self\n","        return other + (-self)\n","\n","    def tanh(self):\n","        x = self.data\n","        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n","        out = Value(t, (self, ), 'tanh')\n","\n","        def _backward():\n","            self.grad += (1 - t**2) * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    # https://en.wikipedia.org/wiki/Hyperbolic_functions\n","    def exp(self):\n","        x = self.data\n","        out = Value(math.exp(x), (self, ), 'exp')\n","\n","        def _backward():\n","            self.grad += out.data * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def backward(self):\n","        topo = []\n","        visited = set()\n","\n","        # topological sort\n","        def build_topo(v):\n","            if v not in visited:\n","                visited.add(v)\n","                for child in v._prev:\n","                    build_topo(child)\n","                topo.append(v)\n","        build_topo(self)\n","\n","        self.grad = 1  # initialize\n","        for node in reversed(topo):\n","            node._backward()    "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import random\n","\n","class Neuron:\n","    \n","    def __init__(self, nin):\n","#### my add ##########################################        \n","        # random.seed(12345)  # WARNING: all neurons will have the same weights and bias\n","######################################################        \n","        self.w = [Value(random.uniform(-1, 1)) for _ in range(nin)]\n","        self.b = Value(random.uniform(-1,1))\n","\n","#### my add ##########################################\n","    def __repr__(self) -> str:\n","        return f\"Neuron(w = {self.w}, b = {self.b})\"\n","######################################################\n","\n","    def __call__(self, x):\n","        # w * x + b\n","        # print(list(zip(self.w, x)), self.b)\n","        act = sum((wi*xi for wi,xi in zip(self.w, x)), self.b) \n","        out = act.tanh()\n","        return out\n","\n","    def parameters(self):\n","        # print(f'w: {self.w}, b: {[self.b]}')\n","        return self.w + [self.b]\n","\n","\n","class Layer:\n","    def __init__(self, nin, nout):\n","        self.neurons = [Neuron(nin) for _ in range(nout)]\n","\n","#### my add ##########################################\n","    def __repr__(self) -> str:\n","        return f\"Layer(neurons = {self.neurons})\"\n","######################################################\n","\n","    def __call__(self, x):\n","        outs = [n(x) for n in self.neurons]\n","        return outs[0] if len(outs) == 1 else outs\n","\n","    def parameters(self):\n","        # params = []\n","        # for neuron in self.neurons:\n","        #     ps = neuron.parameters()\n","        #     params.extend(ps)\n","        # return params\n","        return [p for neuron in self.neurons for p in neuron.parameters()]\n","\n","class MLP:\n","    def __init__(self, nin, nouts):\n","        sz = [nin] + nouts\n","        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n","\n","    def __call__(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def parameters(self):\n","        params = []\n","        # for layer in self.layers:\n","        #     ps = layer.parameters()\n","        #     params.extend(ps)\n","        # return params\n","        return [p for layer in self.layers for p in layer.parameters()]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.46.0 (20210118.1747)\n"," -->\n","<!-- Pages: 1 -->\n","<svg width=\"1579pt\" height=\"210pt\"\n"," viewBox=\"0.00 0.00 1579.00 210.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 206)\">\n","<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-206 1575,-206 1575,4 -4,4\"/>\n","<!-- 2185533188608 -->\n","<g id=\"node1\" class=\"node\">\n","<title>2185533188608</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"712.5,-137.5 712.5,-173.5 900.5,-173.5 900.5,-137.5 712.5,-137.5\"/>\n","<text text-anchor=\"middle\" x=\"724.5\" y=\"-151.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"736.5,-137.5 736.5,-173.5 \"/>\n","<text text-anchor=\"middle\" x=\"777\" y=\"-151.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 6.8814</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"817.5,-137.5 817.5,-173.5 \"/>\n","<text text-anchor=\"middle\" x=\"859\" y=\"-151.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2185533678496+ -->\n","<g id=\"node12\" class=\"node\">\n","<title>2185533678496+</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"1000\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"1000\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n","</g>\n","<!-- 2185533188608&#45;&gt;2185533678496+ -->\n","<g id=\"edge13\" class=\"edge\">\n","<title>2185533188608&#45;&gt;2185533678496+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M900.73,-141.87C923.15,-138.59 945.76,-135.28 963.63,-132.67\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"964.17,-136.13 973.56,-131.22 963.16,-129.2 964.17,-136.13\"/>\n","</g>\n","<!-- 2185533188656 -->\n","<g id=\"node2\" class=\"node\">\n","<title>2185533188656</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"4,-55.5 4,-91.5 198,-91.5 198,-55.5 4,-55.5\"/>\n","<text text-anchor=\"middle\" x=\"19\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"34,-55.5 34,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"74.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"115,-55.5 115,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"156.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2185533188416* -->\n","<g id=\"node10\" class=\"node\">\n","<title>2185533188416*</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"265\" cy=\"-73.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"265\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n","</g>\n","<!-- 2185533188656&#45;&gt;2185533188416* -->\n","<g id=\"edge10\" class=\"edge\">\n","<title>2185533188656&#45;&gt;2185533188416*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M198.11,-73.5C208.59,-73.5 218.72,-73.5 227.76,-73.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"227.84,-77 237.84,-73.5 227.84,-70 227.84,-77\"/>\n","</g>\n","<!-- 2185533678688 -->\n","<g id=\"node3\" class=\"node\">\n","<title>2185533678688</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1376,-109.5 1376,-145.5 1571,-145.5 1571,-109.5 1376,-109.5\"/>\n","<text text-anchor=\"middle\" x=\"1391.5\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">o1</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1407,-109.5 1407,-145.5 \"/>\n","<text text-anchor=\"middle\" x=\"1447.5\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.7071</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1488,-109.5 1488,-145.5 \"/>\n","<text text-anchor=\"middle\" x=\"1529.5\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n","</g>\n","<!-- 2185533678688tanh -->\n","<g id=\"node4\" class=\"node\">\n","<title>2185533678688tanh</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"1313\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"1313\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tanh</text>\n","</g>\n","<!-- 2185533678688tanh&#45;&gt;2185533678688 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>2185533678688tanh&#45;&gt;2185533678688</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1340.17,-127.5C1347.66,-127.5 1356.32,-127.5 1365.56,-127.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1365.78,-131 1375.78,-127.5 1365.78,-124 1365.78,-131\"/>\n","</g>\n","<!-- 2185533188752 -->\n","<g id=\"node5\" class=\"node\">\n","<title>2185533188752</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"328,-110.5 328,-146.5 550,-146.5 550,-110.5 328,-110.5\"/>\n","<text text-anchor=\"middle\" x=\"354.5\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1*w1</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"381,-110.5 381,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"424\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"467,-110.5 467,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"508.5\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2185533678544+ -->\n","<g id=\"node15\" class=\"node\">\n","<title>2185533678544+</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"613\" cy=\"-100.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"613\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n","</g>\n","<!-- 2185533188752&#45;&gt;2185533678544+ -->\n","<g id=\"edge12\" class=\"edge\">\n","<title>2185533188752&#45;&gt;2185533678544+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M550.39,-110.53C559.67,-109.02 568.54,-107.58 576.51,-106.28\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"577.12,-109.72 586.43,-104.66 575.99,-102.82 577.12,-109.72\"/>\n","</g>\n","<!-- 2185533188752* -->\n","<g id=\"node6\" class=\"node\">\n","<title>2185533188752*</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"265\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"265\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n","</g>\n","<!-- 2185533188752*&#45;&gt;2185533188752 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>2185533188752*&#45;&gt;2185533188752</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M292.12,-128.5C299.66,-128.5 308.41,-128.5 317.81,-128.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"317.82,-132 327.81,-128.5 317.81,-125 317.82,-132\"/>\n","</g>\n","<!-- 2185533187216 -->\n","<g id=\"node7\" class=\"node\">\n","<title>2185533187216</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"2,-165.5 2,-201.5 200,-201.5 200,-165.5 2,-165.5\"/>\n","<text text-anchor=\"middle\" x=\"17\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"32,-165.5 32,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"72.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 2.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"113,-165.5 113,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"156.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;1.5000</text>\n","</g>\n","<!-- 2185533187216&#45;&gt;2185533188752* -->\n","<g id=\"edge8\" class=\"edge\">\n","<title>2185533187216&#45;&gt;2185533188752*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M174.26,-165.48C183.66,-162.7 193.11,-159.68 202,-156.5 212.53,-152.73 223.76,-147.91 233.72,-143.34\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"235.26,-146.49 242.83,-139.08 232.29,-140.15 235.26,-146.49\"/>\n","</g>\n","<!-- 2185533188848 -->\n","<g id=\"node8\" class=\"node\">\n","<title>2185533188848</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"2.5,-0.5 2.5,-36.5 199.5,-36.5 199.5,-0.5 2.5,-0.5\"/>\n","<text text-anchor=\"middle\" x=\"19\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"35.5,-0.5 35.5,-36.5 \"/>\n","<text text-anchor=\"middle\" x=\"76\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 1.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"116.5,-0.5 116.5,-36.5 \"/>\n","<text text-anchor=\"middle\" x=\"158\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n","</g>\n","<!-- 2185533188848&#45;&gt;2185533188416* -->\n","<g id=\"edge11\" class=\"edge\">\n","<title>2185533188848&#45;&gt;2185533188416*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M171.25,-36.55C181.63,-39.64 192.15,-42.99 202,-46.5 212.29,-50.16 223.28,-54.72 233.11,-59.05\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"231.93,-62.36 242.49,-63.26 234.8,-55.97 231.93,-62.36\"/>\n","</g>\n","<!-- 2185533188416 -->\n","<g id=\"node9\" class=\"node\">\n","<title>2185533188416</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"330.5,-55.5 330.5,-91.5 547.5,-91.5 547.5,-55.5 330.5,-55.5\"/>\n","<text text-anchor=\"middle\" x=\"357\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2*w2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"383.5,-55.5 383.5,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"424\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"464.5,-55.5 464.5,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"506\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2185533188416&#45;&gt;2185533678544+ -->\n","<g id=\"edge14\" class=\"edge\">\n","<title>2185533188416&#45;&gt;2185533678544+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M547.95,-90.45C558.13,-92.04 567.86,-93.57 576.53,-94.93\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"576.12,-98.41 586.54,-96.5 577.2,-91.49 576.12,-98.41\"/>\n","</g>\n","<!-- 2185533188416*&#45;&gt;2185533188416 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>2185533188416*&#45;&gt;2185533188416</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M292.12,-73.5C300.31,-73.5 309.94,-73.5 320.28,-73.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"320.39,-77 330.39,-73.5 320.39,-70 320.39,-77\"/>\n","</g>\n","<!-- 2185533678496 -->\n","<g id=\"node11\" class=\"node\">\n","<title>2185533678496</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1063,-109.5 1063,-145.5 1250,-145.5 1250,-109.5 1063,-109.5\"/>\n","<text text-anchor=\"middle\" x=\"1074.5\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">n</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1086,-109.5 1086,-145.5 \"/>\n","<text text-anchor=\"middle\" x=\"1126.5\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.8814</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1167,-109.5 1167,-145.5 \"/>\n","<text text-anchor=\"middle\" x=\"1208.5\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2185533678496&#45;&gt;2185533678688tanh -->\n","<g id=\"edge6\" class=\"edge\">\n","<title>2185533678496&#45;&gt;2185533678688tanh</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1250.05,-127.5C1259.06,-127.5 1267.79,-127.5 1275.7,-127.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1275.95,-131 1285.95,-127.5 1275.95,-124 1275.95,-131\"/>\n","</g>\n","<!-- 2185533678496+&#45;&gt;2185533678496 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>2185533678496+&#45;&gt;2185533678496</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1027.21,-127.5C1034.73,-127.5 1043.43,-127.5 1052.67,-127.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1052.89,-131 1062.89,-127.5 1052.89,-124 1052.89,-131\"/>\n","</g>\n","<!-- 2185533186496 -->\n","<g id=\"node13\" class=\"node\">\n","<title>2185533186496</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"0,-110.5 0,-146.5 202,-146.5 202,-110.5 0,-110.5\"/>\n","<text text-anchor=\"middle\" x=\"16.5\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w1</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"33,-110.5 33,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"76\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;3.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"119,-110.5 119,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"160.5\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n","</g>\n","<!-- 2185533186496&#45;&gt;2185533188752* -->\n","<g id=\"edge7\" class=\"edge\">\n","<title>2185533186496&#45;&gt;2185533188752*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M202.29,-128.5C211.28,-128.5 219.93,-128.5 227.77,-128.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"227.91,-132 237.91,-128.5 227.91,-125 227.91,-132\"/>\n","</g>\n","<!-- 2185533678544 -->\n","<g id=\"node14\" class=\"node\">\n","<title>2185533678544</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"676,-82.5 676,-118.5 937,-118.5 937,-82.5 676,-82.5\"/>\n","<text text-anchor=\"middle\" x=\"722\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1w1 + x2w2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"768,-82.5 768,-118.5 \"/>\n","<text text-anchor=\"middle\" x=\"811\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"854,-82.5 854,-118.5 \"/>\n","<text text-anchor=\"middle\" x=\"895.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2185533678544&#45;&gt;2185533678496+ -->\n","<g id=\"edge9\" class=\"edge\">\n","<title>2185533678544&#45;&gt;2185533678496+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M935.23,-118.51C945.27,-119.92 954.77,-121.26 963.23,-122.46\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"962.96,-125.95 973.35,-123.88 963.93,-119.02 962.96,-125.95\"/>\n","</g>\n","<!-- 2185533678544+&#45;&gt;2185533678544 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>2185533678544+&#45;&gt;2185533678544</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M640.23,-100.5C647.68,-100.5 656.35,-100.5 665.74,-100.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"665.76,-104 675.76,-100.5 665.76,-97 665.76,-104\"/>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.graphs.Digraph at 0x1fcdbedef40>"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# https://en.wikipedia.org/wiki/Hyperbolic_functions\n","# input x1, x2\n","x1 = Value(2.0, label='x1')\n","x2 = Value(0.0, label='x2')\n","# weights w1, w2\n","w1 = Value(-3.0, label='w1')\n","w2 = Value(1.0, label='w2')\n","# bias of neuron\n","b = Value(6.8813735870195432, label='b')\n","# x1*w1 + x2*w2 + b\n","x1w1 = x1*w1; x1w1.label = 'x1*w1'\n","x2w2 = x2*w2; x2w2.label = 'x2*w2'\n","x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1w1 + x2w2'\n","n = x1w1x2w2 + b; n.label = 'n'\n","o1 = n.tanh(); o1.label = 'o1'\n","o1.backward()\n","o1_grad = x1.grad  # store x1.grad, more calculation with x1 will reset x1.grad to zero\n","draw_dot(o1)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["h = 0.0001\n","x1 += h  # increment x1 by h\n","\n","x1w1 = x1*w1; x1w1.label = 'x1*w1'\n","x2w2 = x2*w2; x2w2.label = 'x2*w2'\n","x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1w1 + x2w2'\n","n = x1w1x2w2 + b; n.label = 'n'\n","o2 = n.tanh(); o2.label = 'o2'\n","o_grad = (o2 - o1) / h \n","\n","print(f'calculation of derivative of \"o\" with respect to \"x1\" = {o_grad.data}')\n","print(f'o2: {o.data}, o1: {o1.data}, o2-o1: {o2.data-o1.data}, h: {h}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### Neural Network MLP(3, [4, 4, 1])\n","* input layer - 3 nodes\n","* hidden layer 1 - 4 nodes\n","* hidden layer 2 - 4 nodes\n","* output layer - 2 nodes\n","\n","<!-- ![Getting Started](..\\karpathy\\img\\Nertual_Network_Neuron.PNG) -->\n","<img src=\"..\\karpathy\\img\\neural_network_neuron.PNG\">"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# create neural network and initialize weights and biases\n","n = MLP(3, [4, 4, 1])\n","\n","# inputs\n","xs = [\n","  [2.0, 3.0, -1.0],\n","  [3.0, -1.0, 0.5]\n","]\n","\n","# desired targets\n","ys = [1.0, -1.0]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["len(n.parameters()): 41\n"]},{"data":{"text/plain":["[Value(data = 0.8735929368001456),\n"," Value(data = -0.5138530211711041),\n"," Value(data = 0.39263108152759263),\n"," Value(data = -0.14072333806887238),\n"," Value(data = 0.2897097604681296),\n"," Value(data = -0.5370433592427473),\n"," Value(data = 0.058772149040092314),\n"," Value(data = 0.32367739552314534),\n"," Value(data = 0.5083631386487744),\n"," Value(data = -0.48509682723714387),\n"," Value(data = -0.8327317873276883),\n"," Value(data = 0.6158606674980869),\n"," Value(data = 0.7273299694070476),\n"," Value(data = 0.8278672867741526),\n"," Value(data = 0.3367504489221185),\n"," Value(data = 0.8407916689255228),\n"," Value(data = -0.4882617627567254),\n"," Value(data = -0.2307859447893139),\n"," Value(data = 0.21710460159349432),\n"," Value(data = 0.7741193900189551),\n"," Value(data = 0.36748102030695096),\n"," Value(data = 0.1228881289439463),\n"," Value(data = -0.22774155292134446),\n"," Value(data = 0.39493683385364897),\n"," Value(data = -0.005813456818641871),\n"," Value(data = -0.6696635742164365),\n"," Value(data = 0.5057299527869183),\n"," Value(data = 0.15172557207969462),\n"," Value(data = -0.020296466173014727),\n"," Value(data = -0.07911026559334089),\n"," Value(data = 0.07058050599237808),\n"," Value(data = -0.4036815426171392),\n"," Value(data = -0.9841260712726818),\n"," Value(data = -0.4189641241334754),\n"," Value(data = -0.2679668383683782),\n"," Value(data = -0.5692798755444666),\n"," Value(data = -0.4688007884448253),\n"," Value(data = -0.41514718072602474),\n"," Value(data = 0.7606234137874734),\n"," Value(data = 0.6606266748359384),\n"," Value(data = 0.8580977284675906)]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# number of parameters (e.g sum (weights + bias to each neuron))\n","print(f'len(n.parameters()): {len(n.parameters())}')\n","n.parameters()"]},{"cell_type":"markdown","metadata":{},"source":["#### ---- Start: Manual calculation of a forward pass ----"]},{"cell_type":"markdown","metadata":{},"source":["##### Transpose inputs xs"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["xs_mats:\n","[array([[ 2. ,  3. , -1. ],\n","       [ 3. , -1. ,  0.5]])]\n","\n","xs_mats_T[0].shape: (3, 2)\n","xs_mats_T:\n","[array([[ 2. ,  3. ],\n","       [ 3. , -1. ],\n","       [-1. ,  0.5]])]\n"]}],"source":["xs_mats = [np.array(xs)]  # convert xs to list of np.arrays\n","xs_mats_T = []\n","for mat in xs_mats:\n","  mat_transpose = np.transpose(mat)\n","  xs_mats_T.append(mat_transpose)\n","\n","print(f'xs_mats:\\n{xs_mats}\\n')\n","print(f'xs_mats_T[0].shape: {xs_mats_T[0].shape}')\n","print(f'xs_mats_T:\\n{xs_mats_T}')"]},{"cell_type":"markdown","metadata":{},"source":["##### Get neural network's weights and biases matrices"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["layer_cnt: 3\n","\n","layer: 0, neuron_cnt: 4\n","----\n","neuron 0\n","w0:  0.8735929,   w0.grad:  0.0000000\n","w1: -0.5138530,   w1.grad:  0.0000000\n","w2:  0.3926311,   w2.grad:  0.0000000\n","b:  -0.1407233\n","b_mat:  [-0.14072333806887238]\n","neuron 1\n","w0:  0.2897098,   w0.grad:  0.0000000\n","w1: -0.5370434,   w1.grad:  0.0000000\n","w2:  0.0587721,   w2.grad:  0.0000000\n","b:   0.3236774\n","b_mat:  [-0.14072333806887238, 0.32367739552314534]\n","neuron 2\n","w0:  0.5083631,   w0.grad:  0.0000000\n","w1: -0.4850968,   w1.grad:  0.0000000\n","w2: -0.8327318,   w2.grad:  0.0000000\n","b:   0.6158607\n","b_mat:  [-0.14072333806887238, 0.32367739552314534, 0.6158606674980869]\n","neuron 3\n","w0:  0.7273300,   w0.grad:  0.0000000\n","w1:  0.8278673,   w1.grad:  0.0000000\n","w2:  0.3367504,   w2.grad:  0.0000000\n","b:   0.8407917\n","b_mat:  [-0.14072333806887238, 0.32367739552314534, 0.6158606674980869, 0.8407916689255228]\n","----\n","layer: 1, neuron_cnt: 4\n","----\n","neuron 0\n","w0: -0.4882618,   w0.grad:  0.0000000\n","w1: -0.2307859,   w1.grad:  0.0000000\n","w2:  0.2171046,   w2.grad:  0.0000000\n","w3:  0.7741194,   w3.grad:  0.0000000\n","b:   0.3674810\n","b_mat:  [0.36748102030695096]\n","neuron 1\n","w0:  0.1228881,   w0.grad:  0.0000000\n","w1: -0.2277416,   w1.grad:  0.0000000\n","w2:  0.3949368,   w2.grad:  0.0000000\n","w3: -0.0058135,   w3.grad:  0.0000000\n","b:  -0.6696636\n","b_mat:  [0.36748102030695096, -0.6696635742164365]\n","neuron 2\n","w0:  0.5057300,   w0.grad:  0.0000000\n","w1:  0.1517256,   w1.grad:  0.0000000\n","w2: -0.0202965,   w2.grad:  0.0000000\n","w3: -0.0791103,   w3.grad:  0.0000000\n","b:   0.0705805\n","b_mat:  [0.36748102030695096, -0.6696635742164365, 0.07058050599237808]\n","neuron 3\n","w0: -0.4036815,   w0.grad:  0.0000000\n","w1: -0.9841261,   w1.grad:  0.0000000\n","w2: -0.4189641,   w2.grad:  0.0000000\n","w3: -0.2679668,   w3.grad:  0.0000000\n","b:  -0.5692799\n","b_mat:  [0.36748102030695096, -0.6696635742164365, 0.07058050599237808, -0.5692798755444666]\n","----\n","layer: 2, neuron_cnt: 1\n","----\n","neuron 0\n","w0: -0.4688008,   w0.grad:  0.0000000\n","w1: -0.4151472,   w1.grad:  0.0000000\n","w2:  0.7606234,   w2.grad:  0.0000000\n","w3:  0.6606267,   w3.grad:  0.0000000\n","b:   0.8580977\n","b_mat:  [0.8580977284675906]\n","----\n"]}],"source":["layer_cnt = len(n.layers)\n","w_mats = []  # list of weights matrix for each layer \n","b_mats = []  # list of bias matrix for each layer\n","print(f'layer_cnt: {layer_cnt}\\n')\n","for i, layer in enumerate(n.layers):\n","    neuron_cnt = len(layer.neurons)\n","    print(f'layer: {i}, neuron_cnt: {neuron_cnt}')\n","\n","    print('----')\n","    b_mat = []  # accumulate neuon's bias for each row     \n","    for j, neuron in enumerate(layer.neurons):\n","        print(f'neuron {j}')\n","        b = neuron.b.data  # bias of neuron \n","        w_row = []  # accumulate neuon's weights for each row\n","        # b_row = []  # accumulate neuon's bias for each row\n","        for k, w in enumerate(neuron.w):\n","            w_row.append(w.data)\n","            print(f'w{k}: {w.data:10.7f},   w{k}.grad: {w.grad:10.7f}')\n","        if j == 0:            \n","            w_mat = np.array([w_row])\n","        else:\n","            w_mat = np.vstack((w_mat, w_row))\n","        \n","        b_mat.append(b)\n","        print(f'b:  {b:10.7f}')\n","        print(f'b_mat:  {b_mat}')\n","    w_mats.append(w_mat)  \n","    b_mats.append(np.array([b_mat]))        \n","    print('----')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["type(w_mats): <class 'list'>\n","type(w_mats[0]): <class 'numpy.ndarray'>\n","w_mats[0].shape: (4, 3)\n","w_mats[0]: [[ 0.87359294 -0.51385302  0.39263108]\n"," [ 0.28970976 -0.53704336  0.05877215]\n"," [ 0.50836314 -0.48509683 -0.83273179]\n"," [ 0.72732997  0.82786729  0.33675045]]\n","\n","type(xs_mats): <class 'list'>\n","type(xs_mats[0]): <class 'numpy.ndarray'>\n","xs_mats[0].shape: (2, 3)\n","xs_mats[0]: [[ 2.   3.  -1. ]\n"," [ 3.  -1.   0.5]]\n","\n","type(b_mats): <class 'list'>\n","type(b_mats[0]): <class 'numpy.ndarray'>\n","b_mats[0].shape: (1, 4)\n","b_mats[0]: [[-0.14072334  0.3236774   0.61586067  0.84079167]]\n","\n"]}],"source":["print(f'type(w_mats): {type(w_mats)}')\n","print(f'type(w_mats[0]): {type(w_mats[0])}')\n","print(f'w_mats[0].shape: {w_mats[0].shape}')\n","print(f'w_mats[0]: {w_mats[0]}\\n')\n","print(f'type(xs_mats): {type(xs_mats)}')\n","print(f'type(xs_mats[0]): {type(xs_mats[0])}')\n","print(f'xs_mats[0].shape: {xs_mats[0].shape}')\n","print(f'xs_mats[0]: {xs_mats[0]}\\n')\n","print(f'type(b_mats): {type(b_mats)}')\n","print(f'type(b_mats[0]): {type(b_mats[0])}')\n","print(f'b_mats[0].shape: {b_mats[0].shape}')\n","print(f'b_mats[0]: {b_mats[0]}\\n')"]},{"cell_type":"markdown","metadata":{},"source":["##### Calculation for a forward pass"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"..\\karpathy\\img\\neural_mat.PNG\">"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["layer: 0\n","weights:\n","[[ 0.87359294 -0.51385302  0.39263108]\n"," [ 0.28970976 -0.53704336  0.05877215]\n"," [ 0.50836314 -0.48509683 -0.83273179]\n"," [ 0.72732997  0.82786729  0.33675045]]\n","\n","input:\n","[[ 2.   3. ]\n"," [ 3.  -1. ]\n"," [-1.   0.5]]\n","\n","bias:\n","[[-0.14072334]\n"," [ 0.3236774 ]\n"," [ 0.61586067]\n"," [ 0.84079167]]\n","\n","output:\n","[[-0.31647746  0.996617  ]\n"," [-0.64506795  0.94241763]\n"," [ 0.7657737   0.97620274]\n"," [ 0.99972303  0.98244207]]\n","\n","layer: 1\n","weights:\n","[[-0.48826176 -0.23078594  0.2171046   0.77411939]\n"," [ 0.12288813 -0.22774155  0.39493683 -0.00581346]\n"," [ 0.50572995  0.15172557 -0.02029647 -0.07911027]\n"," [-0.40368154 -0.98412607 -0.41896412 -0.26796684]]\n","\n","input:\n","[[-0.31647746  0.996617  ]\n"," [-0.64506795  0.94241763]\n"," [ 0.7657737   0.97620274]\n"," [ 0.99972303  0.98244207]]\n","\n","bias:\n","[[ 0.36748102]\n"," [-0.66966357]\n"," [ 0.07058051]\n"," [-0.56927988]]\n","\n","output:\n","[[ 0.9233129   0.56206031]\n"," [-0.25899022 -0.36443598]\n"," [-0.27473272  0.55116542]\n"," [-0.37602325 -0.98838313]]\n","\n","layer: 2\n","weights:\n","[[-0.46880079 -0.41514718  0.76062341  0.66062667]]\n","\n","input:\n","[[ 0.9233129   0.56206031]\n"," [-0.25899022 -0.36443598]\n"," [-0.27473272  0.55116542]\n"," [-0.37602325 -0.98838313]]\n","\n","bias:\n","[[0.85809773]]\n","\n","output:\n","[[0.07524535 0.47163816]]\n","\n","-- manual forward pass calculation --\n","manual calculation: [0.07524535 0.47163816]\n","desired output:     [1.0, -1.0]\n","loss:               3.0208900319011525\n"]}],"source":["verbose = True   # print calculation output and weights and bias matrices \n","# verbose = False  # print calculation output only\n","\n","for layer in range(len(n.layers)):\n","  if layer == 0:  # first layer, use given inputs as inputs\n","    input = xs_mats_T[layer]\n","  else:  # after first layer, use outputs from preceding layers as inputs\n","    input = output\n","\n","  weights = w_mats[layer]\n","  bias = np.transpose(b_mats[layer])\n","  output = np.tanh(np.matmul(weights, input) + bias)\n","\n","  if verbose:\n","    print(f'layer: {layer}')\n","    print(f'weights:\\n{weights}\\n')\n","    # print(f'xs_mats_T[layer]:\\n{xs_mats_T[layer]}\\n')\n","    print(f'input:\\n{input}\\n')    \n","    print(f'bias:\\n{bias}\\n')\n","    print(f'output:\\n{output}\\n')    \n","\n","yout = output[0]\n","ys = ys\n","loss = sum((yout - ys)**2)\n","\n","print(f'-- manual forward pass calculation --')\n","print(f'manual calculation: {yout}')   \n","print(f'desired output:     {ys}')   \n","print(f'loss:               {loss}')"]},{"cell_type":"markdown","metadata":{},"source":["#### ---- End: Manual calculation of a forward pass ----"]},{"cell_type":"markdown","metadata":{},"source":["#### Micrograd results are same as manual calculation"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-- micrograd forward pass calculation --\n","ypred_data:         [0.07524534874752317, 0.4716381575944757]\n","ys:                 [1.0, -1.0]\n","loss_data:          3.0208900319011525\n"]}],"source":["ypred = [n(x) for x in xs]\n","loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))  # low loss is better, perfect is loss = 0\n","ypred_data = [v.data for v in ypred] \n","loss_data = loss.data\n","\n","print(f'-- micrograd forward pass calculation --')\n","print(f'ypred_data:         {ypred_data}')\n","print(f'ys:                 {ys}')\n","print(f'loss_data:          {loss_data}')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# initialize\n","# step = 0"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ypred: [Value(data = 0.07524534874752317), Value(data = 0.4716381575944757)]\n","step: 0, loss: 3.0208900319011525\n","-------\n","ypred: [Value(data = 0.3526632368820801), Value(data = 0.18401509731242097)]\n","step: 1, loss: 1.8209366355477277\n","-------\n","ypred: [Value(data = 0.4842863206807364), Value(data = -0.23972712384692885)]\n","step: 2, loss: 0.8439754452510753\n","-------\n","ypred: [Value(data = 0.6264590762729584), Value(data = -0.4794114590371637)]\n","step: 3, loss: 0.4105452506806663\n","-------\n","ypred: [Value(data = 0.7049421444361733), Value(data = -0.5951730017611762)]\n","step: 4, loss: 0.2509440366329807\n","-------\n","ypred: [Value(data = 0.7503355682406776), Value(data = -0.6617128058003595)]\n","step: 5, loss: 0.17677055424517063\n","-------\n","ypred: [Value(data = 0.7802125459665725), Value(data = -0.7052332199344794)]\n","step: 6, loss: 0.135193979580691\n","-------\n","ypred: [Value(data = 0.801615094994701), Value(data = -0.7362477144889771)]\n","step: 7, loss: 0.10892183864624967\n","-------\n","ypred: [Value(data = 0.8178587074698459), Value(data = -0.7596743395435044)]\n","step: 8, loss: 0.09093187351840598\n","-------\n","ypred: [Value(data = 0.8307077934433871), Value(data = -0.7781205272648177)]\n","step: 9, loss: 0.0778903516220494\n","-------\n","ypred: [Value(data = 0.8411908687536833), Value(data = -0.7931029215009707)]\n","step: 10, loss: 0.06802674125864332\n","-------\n","ypred: [Value(data = 0.8499504190674251), Value(data = -0.8055675674651996)]\n","step: 11, loss: 0.060318847559441044\n","-------\n","ypred: [Value(data = 0.8574100415034066), Value(data = -0.8161374812703958)]\n","step: 12, loss: 0.0541373220576543\n","-------\n","ypred: [Value(data = 0.8638613314111487), Value(data = -0.825241065268903)]\n","step: 13, loss: 0.049074422353492915\n","-------\n","ypred: [Value(data = 0.8695122131608783), Value(data = -0.8331834494162617)]\n","step: 14, loss: 0.04485482406282898\n","-------\n","ypred: [Value(data = 0.8745153521824274), Value(data = -0.8401883993303041)]\n","step: 15, loss: 0.041286144546510584\n","-------\n","ypred: [Value(data = 0.8789856422781726), Value(data = -0.8464240980134173)]\n","step: 16, loss: 0.038230032445818865\n","-------\n","ypred: [Value(data = 0.8830113937509123), Value(data = -0.8520196347812451)]\n","step: 17, loss: 0.035584522482380164\n","-------\n","ypred: [Value(data = 0.8866617320449784), Value(data = -0.857075905805767)]\n","step: 18, loss: 0.033272859684286255\n","-------\n","ypred: [Value(data = 0.8899916321654289), Value(data = -0.8616730289234035)]\n","step: 19, loss: 0.031236191920851877\n","-------\n","ypred: [Value(data = 0.8930454307567331), Value(data = -0.8658755143448366)]\n","step: 20, loss: 0.029428657534274906\n","-------\n","ypred: [Value(data = 0.8958593304526556), Value(data = -0.8697359501091823)]\n","step: 21, loss: 0.027814001747726632\n","-------\n","ypred: [Value(data = 0.8984632206684434), Value(data = -0.8732976802558898)]\n","step: 22, loss: 0.026363195385563948\n","-------\n","ypred: [Value(data = 0.9008820245539811), Value(data = -0.8765967849107604)]\n","step: 23, loss: 0.025052726550878722\n","-------\n","ypred: [Value(data = 0.9031367110434132), Value(data = -0.8796635671083476)]\n","step: 24, loss: 0.023863353828574393\n","-------\n","ypred: [Value(data = 0.9052450660257848), Value(data = -0.8825236849505227)]\n","step: 25, loss: 0.022779182110061927\n","-------\n","ypred: [Value(data = 0.9072222875024397), Value(data = -0.8851990247060645)]\n","step: 26, loss: 0.021786967864718745\n","-------\n","ypred: [Value(data = 0.9090814502673052), Value(data = -0.8877083819550551)]\n","step: 27, loss: 0.02087559016864829\n","-------\n","ypred: [Value(data = 0.9108338725880123), Value(data = -0.8900679986286617)]\n","step: 28, loss: 0.020035643203158753\n","-------\n","ypred: [Value(data = 0.9124894083908713), Value(data = -0.8922919905630088)]\n","step: 29, loss: 0.01925911894065869\n","-------\n","ypred: [Value(data = 0.9140566821860437), Value(data = -0.8943926909477223)]\n","step: 30, loss: 0.01853915760213398\n","-------\n","ypred: [Value(data = 0.9155432795295751), Value(data = -0.8963809285058081)]\n","step: 31, loss: 0.017869849609937934\n","-------\n","ypred: [Value(data = 0.9169559026312263), Value(data = -0.8982662545437456)]\n","step: 32, loss: 0.017246077072352324\n","-------\n","ypred: [Value(data = 0.9183004983996552), Value(data = -0.9000571295962492)]\n","step: 33, loss: 0.01666338590628567\n","-------\n","ypred: [Value(data = 0.9195823645123538), Value(data = -0.9017610778798846)]\n","step: 34, loss: 0.016117881916746044\n","-------\n","ypred: [Value(data = 0.9208062378310521), Value(data = -0.9033848159043717)]\n","step: 35, loss: 0.015606145764304035\n","-------\n","ypred: [Value(data = 0.9219763685323263), Value(data = -0.9049343601904292)]\n","step: 36, loss: 0.015125162939806414\n","-------\n","ypred: [Value(data = 0.9230965826024933), Value(data = -0.9064151179824744)]\n","step: 37, loss: 0.01467226574964932\n","-------\n","ypred: [Value(data = 0.9241703347949665), Value(data = -0.9078319640340626)]\n","step: 38, loss: 0.0142450849789258\n","-------\n","ypred: [Value(data = 0.9252007537236155), Value(data = -0.9091893059195418)]\n","step: 39, loss: 0.013841509402889772\n","-------\n","ypred: [Value(data = 0.9261906804358421), Value(data = -0.910491139840601)]\n","step: 40, loss: 0.013459651701558824\n","-------\n","ypred: [Value(data = 0.9271427015510117), Value(data = -0.9117410985172457)]\n","step: 41, loss: 0.013097819628227472\n","-------\n","ypred: [Value(data = 0.9280591778465604), Value(data = -0.9129424924541659)]\n","step: 42, loss: 0.012754491512205778\n","-------\n","ypred: [Value(data = 0.9289422690128669), Value(data = -0.914098345636833)]\n","step: 43, loss: 0.01242829535536878\n","-------\n","ypred: [Value(data = 0.929793955169341), Value(data = -0.9152114265229533)]\n","step: 44, loss: 0.012117990923037045\n","-------\n","ypred: [Value(data = 0.9306160556309323), Value(data = -0.9162842750435402)]\n","step: 45, loss: 0.011822454341195516\n","-------\n","ypred: [Value(data = 0.9314102453309485), Value(data = -0.9173192262057822)]\n","step: 46, loss: 0.011540664800771282\n","-------\n","ypred: [Value(data = 0.9321780692384735), Value(data = -0.9183184307908959)]\n","step: 47, loss: 0.01127169304068296\n","-------\n","ypred: [Value(data = 0.9329209550535592), Value(data = -0.9192838735594785)]\n","step: 48, loss: 0.01101469133848888\n","-------\n","ypred: [Value(data = 0.9336402244182068), Value(data = -0.9202173893108353)]\n","step: 49, loss: 0.010768884783644772\n","-------\n","ypred: [Value(data = 0.93433710284399), Value(data = -0.9211206770884207)]\n","step: 50, loss: 0.010533563645909948\n","-------\n","ypred: [Value(data = 0.935012728526442), Value(data = -0.9219953127786538)]\n","step: 51, loss: 0.01030807668207798\n","-------\n","ypred: [Value(data = 0.9356681601908341), Value(data = -0.9228427603131353)]\n","step: 52, loss: 0.010091825249328475\n","-------\n","ypred: [Value(data = 0.9363043840927062), Value(data = -0.9236643816532807)]\n","step: 53, loss: 0.009884258114185487\n","-------\n","ypred: [Value(data = 0.9369223202787358), Value(data = -0.9244614457104582)]\n","step: 54, loss: 0.009684866863172444\n","-------\n","ypred: [Value(data = 0.937522828198593), Value(data = -0.9252351363329631)]\n","step: 55, loss: 0.009493181835453146\n","-------\n","ypred: [Value(data = 0.9381067117458498), Value(data = -0.9259865594728378)]\n","step: 56, loss: 0.0093087685095791\n","-------\n","ypred: [Value(data = 0.9386747237953669), Value(data = -0.9267167496300666)]\n","step: 57, loss: 0.009131224286356892\n","-------\n","ypred: [Value(data = 0.9392275702955611), Value(data = -0.9274266756585489)]\n","step: 58, loss: 0.008960175618150427\n","-------\n","ypred: [Value(data = 0.9397659139662763), Value(data = -0.9281172460071002)]\n","step: 59, loss: 0.008795275441921779\n","-------\n","ypred: [Value(data = 0.9402903776464153), Value(data = -0.9287893134592061)]\n","step: 60, loss: 0.008636200879218901\n","-------\n","ypred: [Value(data = 0.940801547329898), Value(data = -0.9294436794271178)]\n","step: 61, loss: 0.008482651171317631\n","-------\n","ypred: [Value(data = 0.9412999749236727), Value(data = -0.9300810978488906)]\n","step: 62, loss: 0.008334345821977868\n","-------\n","ypred: [Value(data = 0.9417861807573811), Value(data = -0.9307022787309605)]\n","step: 63, loss: 0.008191022923893806\n","-------\n","ypred: [Value(data = 0.9422606558706847), Value(data = -0.9313078913736788)]\n","step: 64, loss: 0.008052437648013808\n","-------\n","ypred: [Value(data = 0.9427238641011761), Value(data = -0.9318985673127363)]\n","step: 65, loss: 0.00791836087755844\n","-------\n","ypred: [Value(data = 0.9431762439931081), Value(data = -0.9324749030055385)]\n","step: 66, loss: 0.007788577970842224\n","-------\n","ypred: [Value(data = 0.9436182105448419), Value(data = -0.9330374622882143)]\n","step: 67, loss: 0.007662887638968108\n","-------\n","ypred: [Value(data = 0.9440501568108846), Value(data = -0.9335867786260119)]\n","step: 68, loss: 0.007541100926156956\n","-------\n","ypred: [Value(data = 0.9444724553726079), Value(data = -0.9341233571772658)]\n","step: 69, loss: 0.007423040281941115\n","-------\n","ypred: [Value(data = 0.9448854596901882), Value(data = -0.9346476766888892)]\n","step: 70, loss: 0.007308538715721829\n","-------\n","ypred: [Value(data = 0.9452895053469457), Value(data = -0.9351601912393764)]\n","step: 71, loss: 0.007197439025296123\n","-------\n","ypred: [Value(data = 0.9456849111960655), Value(data = -0.9356613318435815)]\n","step: 72, loss: 0.007089593091921039\n","-------\n","ypred: [Value(data = 0.9460719804186255), Value(data = -0.936151507932017)]\n","step: 73, loss: 0.006984861235324404\n","-------\n","ypred: [Value(data = 0.9464510015009311), Value(data = -0.9366311087160925)]\n","step: 74, loss: 0.0068831116228049785\n","-------\n","ypred: [Value(data = 0.9468222491383321), Value(data = -0.9371005044495183)]\n","step: 75, loss: 0.006784219727210683\n","-------\n","ypred: [Value(data = 0.9471859850719754), Value(data = -0.9375600475950695)]\n","step: 76, loss: 0.006688067829147593\n","-------\n","ypred: [Value(data = 0.947542458864294), Value(data = -0.9380100739049723)]\n","step: 77, loss: 0.006594544559271288\n","-------\n","ypred: [Value(data = 0.9478919086184718), Value(data = -0.9384509034223565)]\n","step: 78, loss: 0.006503544476949778\n","-------\n","ypred: [Value(data = 0.9482345616466017), Value(data = -0.938882841410491)]\n","step: 79, loss: 0.006414967681974667\n","-------\n","ypred: [Value(data = 0.9485706350908129), Value(data = -0.9393061792158653)]\n","step: 80, loss: 0.006328719456338986\n","-------\n","ypred: [Value(data = 0.9489003365012282), Value(data = -0.9397211950706018)]\n","step: 81, loss: 0.006244709933404152\n","-------\n","ypred: [Value(data = 0.9492238643742563), Value(data = -0.9401281548391692)]\n","step: 82, loss: 0.006162853792046412\n","-------\n","ypred: [Value(data = 0.9495414086543987), Value(data = -0.9405273127138999)]\n","step: 83, loss: 0.006083069973612641\n","-------\n","ypred: [Value(data = 0.949853151202457), Value(data = -0.9409189118634023)]\n","step: 84, loss: 0.006005281419728075\n","-------\n","ypred: [Value(data = 0.9501592662327714), Value(data = -0.9413031850375853)]\n","step: 85, loss: 0.00592941482918772\n","-------\n","ypred: [Value(data = 0.9504599207218817), Value(data = -0.9416803551326824)]\n","step: 86, loss: 0.0058554004323322865\n","-------\n","ypred: [Value(data = 0.9507552747907942), Value(data = -0.9420506357193524)]\n","step: 87, loss: 0.005783171781461377\n","-------\n","ypred: [Value(data = 0.9510454820628458), Value(data = -0.9424142315366779)]\n","step: 88, loss: 0.005712665555970494\n","-------\n","ypred: [Value(data = 0.9513306899989863), Value(data = -0.9427713389546213)]\n","step: 89, loss: 0.005643821381021621\n","-------\n","ypred: [Value(data = 0.9516110402121452), Value(data = -0.943122146407296)]\n","step: 90, loss: 0.005576581658663708\n","-------\n","ypred: [Value(data = 0.951886668762208), Value(data = -0.9434668347991929)]\n","step: 91, loss: 0.005510891410419241\n","-------\n","ypred: [Value(data = 0.9521577064329992), Value(data = -0.9438055778863375)]\n","step: 92, loss: 0.005446698130439569\n","-------\n","ypred: [Value(data = 0.9524242789925579), Value(data = -0.944138542634181)]\n","step: 93, loss: 0.005383951648411188\n","-------\n","ypred: [Value(data = 0.9526865074378816), Value(data = -0.9444658895538798)]\n","step: 94, loss: 0.005322604001467509\n","-------\n","ypred: [Value(data = 0.9529445082252256), Value(data = -0.9447877730184928)]\n","step: 95, loss: 0.0052626093144233325\n","-------\n","ypred: [Value(data = 0.9531983934869518), Value(data = -0.9451043415604885)]\n","step: 96, loss: 0.005203923687709706\n","-------\n","ypred: [Value(data = 0.9534482712358489), Value(data = -0.9454157381518576)]\n","step: 97, loss: 0.005146505092437666\n","-------\n","ypred: [Value(data = 0.9536942455577685), Value(data = -0.9457221004680166)]\n","step: 98, loss: 0.0050903132720683236\n","-------\n","ypred: [Value(data = 0.953936416793361), Value(data = -0.9460235611365964)]\n","step: 99, loss: 0.0050353096502097\n","-------\n","ypred: [Value(data = 0.9541748817096318), Value(data = -0.9463202479721268)]\n","step: 100, loss: 0.004981457244100196\n","-------\n","ypred: [Value(data = 0.9544097336619847), Value(data = -0.9466122841975538)]\n","step: 101, loss: 0.0049287205833739335\n","-------\n","ypred: [Value(data = 0.9546410627473718), Value(data = -0.9468997886534488)]\n","step: 102, loss: 0.004877065633736265\n","-------\n","ypred: [Value(data = 0.9548689559491199), Value(data = -0.9471828759957096)]\n","step: 103, loss: 0.004826459725207068\n","-------\n","ypred: [Value(data = 0.955093497273963), Value(data = -0.9474616568824943)]\n","step: 104, loss: 0.00477687148461633\n","-------\n","ypred: [Value(data = 0.9553147678817714), Value(data = -0.9477362381510721)]\n","step: 105, loss: 0.004728270772061421\n","-------\n","ypred: [Value(data = 0.9555328462084366), Value(data = -0.9480067229852247)]\n","step: 106, loss: 0.004680628621057713\n","-------\n","ypred: [Value(data = 0.955747808082329), Value(data = -0.948273211073793)]\n","step: 107, loss: 0.004633917182134758\n","-------\n","ypred: [Value(data = 0.9559597268347276), Value(data = -0.9485357987609097)]\n","step: 108, loss: 0.004588109669649398\n","-------\n","ypred: [Value(data = 0.9561686734045846), Value(data = -0.9487945791884349)]\n","step: 109, loss: 0.004543180311603437\n","-------\n","ypred: [Value(data = 0.9563747164379639), Value(data = -0.9490496424310625)]\n","step: 110, loss: 0.004499104302270645\n","-------\n","ypred: [Value(data = 0.9565779223824753), Value(data = -0.9493010756245381)]\n","step: 111, loss: 0.004455857757451141\n","-------\n","ypred: [Value(data = 0.9567783555769935), Value(data = -0.9495489630874036)]\n","step: 112, loss: 0.004413417672184975\n","-------\n","ypred: [Value(data = 0.9569760783369429), Value(data = -0.9497933864366458)]\n","step: 113, loss: 0.004371761880768859\n","-------\n","ypred: [Value(data = 0.9571711510354016), Value(data = -0.9500344246976079)]\n","step: 114, loss: 0.004330869018931394\n","-------\n","ypred: [Value(data = 0.957363632180267), Value(data = -0.9502721544084979)]\n","step: 115, loss: 0.004290718488031841\n","-------\n","ypred: [Value(data = 0.9575535784877052), Value(data = -0.9505066497198007)]\n","step: 116, loss: 0.004251290421157909\n","-------\n","ypred: [Value(data = 0.9577410449520952), Value(data = -0.9507379824888903)]\n","step: 117, loss: 0.004212565651005715\n","-------\n","ypred: [Value(data = 0.9579260849126638), Value(data = -0.9509662223701068)]\n","step: 118, loss: 0.004174525679434193\n","-------\n","ypred: [Value(data = 0.9581087501169944), Value(data = -0.951191436900558)]\n","step: 119, loss: 0.004137152648592634\n","-------\n","ypred: [Value(data = 0.9582890907815813), Value(data = -0.9514136915818792)]\n","step: 120, loss: 0.004100429313527925\n","-------\n","ypred: [Value(data = 0.9584671556495922), Value(data = -0.9516330499581769)]\n","step: 121, loss: 0.004064339016183417\n","-------\n","ypred: [Value(data = 0.958642992045987), Value(data = -0.9518495736903609)]\n","step: 122, loss: 0.004028865660708274\n","-------\n","ypred: [Value(data = 0.9588166459301387), Value(data = -0.9520633226270653)]\n","step: 123, loss: 0.003993993690000392\n","-------\n","ypred: [Value(data = 0.9589881619460839), Value(data = -0.9522743548723385)]\n","step: 124, loss: 0.00395970806341212\n","-------\n","ypred: [Value(data = 0.959157583470534), Value(data = -0.952482726850274)]\n","step: 125, loss: 0.003925994235552064\n","-------\n","ypred: [Value(data = 0.9593249526587595), Value(data = -0.9526884933667477)]\n","step: 126, loss: 0.003892838136120436\n","-------\n","ypred: [Value(data = 0.9594903104884596), Value(data = -0.9528917076684079)]\n","step: 127, loss: 0.003860226150720147\n","-------\n","ypred: [Value(data = 0.9596536968017216), Value(data = -0.9530924214990655)]\n","step: 128, loss: 0.0038281451025887416\n","-------\n","ypred: [Value(data = 0.9598151503451665), Value(data = -0.9532906851536166)]\n","step: 129, loss: 0.0037965822352001447\n","-------\n","ypred: [Value(data = 0.959974708808373), Value(data = -0.9534865475296237)]\n","step: 130, loss: 0.00376552519568849\n","-------\n","ypred: [Value(data = 0.9601324088606665), Value(data = -0.9536800561766754)]\n","step: 131, loss: 0.0037349620190490077\n","-------\n","ypred: [Value(data = 0.9602882861863556), Value(data = -0.9538712573436366)]\n","step: 132, loss: 0.003704881113073788\n","-------\n","ypred: [Value(data = 0.9604423755184918), Value(data = -0.9540601960238932)]\n","step: 133, loss: 0.003675271243983133\n","-------\n","ypred: [Value(data = 0.9605947106712246), Value(data = -0.9542469159986939)]\n","step: 134, loss: 0.00364612152271507\n","-------\n","ypred: [Value(data = 0.9607453245708232), Value(data = -0.9544314598786786)]\n","step: 135, loss: 0.0036174213918384957\n","-------\n","ypred: [Value(data = 0.9608942492854258), Value(data = -0.9546138691436884)]\n","step: 136, loss: 0.003589160613056663\n","-------\n","ypred: [Value(data = 0.9610415160535802), Value(data = -0.9547941841809328)]\n","step: 137, loss: 0.0035613292552708767\n","-------\n","ypred: [Value(data = 0.9611871553116328), Value(data = -0.9549724443216002)]\n","step: 138, loss: 0.003533917683174707\n","-------\n","ypred: [Value(data = 0.961331196720019), Value(data = -0.9551486878759822)]\n","step: 139, loss: 0.003506916546351939\n","-------\n","ypred: [Value(data = 0.9614736691885098), Value(data = -0.9553229521671842)]\n","step: 140, loss: 0.003480316768852085\n","-------\n","ypred: [Value(data = 0.96161460090046), Value(data = -0.9554952735634882)]\n","step: 141, loss: 0.0034541095392197187\n","-------\n","ypred: [Value(data = 0.9617540193361062), Value(data = -0.9556656875094299)]\n","step: 142, loss: 0.0034282863009544593\n","-------\n","ypred: [Value(data = 0.9618919512949576), Value(data = -0.9558342285556531)]\n","step: 143, loss: 0.003402838743380165\n","-------\n","ypred: [Value(data = 0.9620284229173225), Value(data = -0.9560009303875939)]\n","step: 144, loss: 0.0033777587929030755\n","-------\n","ypred: [Value(data = 0.9621634597050067), Value(data = -0.956165825853051)]\n","step: 145, loss: 0.0033530386046397033\n","-------\n","ypred: [Value(data = 0.962297086541224), Value(data = -0.9563289469886924)]\n","step: 146, loss: 0.003328670554396387\n","-------\n","ypred: [Value(data = 0.9624293277097535), Value(data = -0.9564903250455457)]\n","step: 147, loss: 0.003304647230983365\n","-------\n","ypred: [Value(data = 0.962560206913375), Value(data = -0.956649990513518)]\n","step: 148, loss: 0.0032809614288473793\n","-------\n","ypred: [Value(data = 0.9626897472916176), Value(data = -0.9568079731449902)]\n","step: 149, loss: 0.003257606141007242\n","-------\n","ypred: [Value(data = 0.9628179714378495), Value(data = -0.9569643019775236)]\n","step: 150, loss: 0.003234574552278354\n","-------\n","ypred: [Value(data = 0.9629449014157383), Value(data = -0.9571190053557206)]\n","step: 151, loss: 0.0032118600327720737\n","-------\n","ypred: [Value(data = 0.9630705587751082), Value(data = -0.9572721109522759)]\n","step: 152, loss: 0.003189456131657359\n","-------\n","ypred: [Value(data = 0.9631949645672221), Value(data = -0.9574236457882518)]\n","step: 153, loss: 0.003167356571172287\n","-------\n","ypred: [Value(data = 0.9633181393595109), Value(data = -0.957573636252614)]\n","step: 154, loss: 0.0031455552408737658\n","-------\n","ypred: [Value(data = 0.9634401032497747), Value(data = -0.9577221081210555)]\n","step: 155, loss: 0.003124046192114855\n","-------\n","ypred: [Value(data = 0.9635608758798774), Value(data = -0.9578690865741439)]\n","step: 156, loss: 0.003102823632738681\n","-------\n","ypred: [Value(data = 0.9636804764489572), Value(data = -0.9580145962148156)]\n","step: 157, loss: 0.0030818819219797363\n","-------\n","ypred: [Value(data = 0.9637989237261712), Value(data = -0.9581586610852484)]\n","step: 158, loss: 0.0030612155655626817\n","-------\n","ypred: [Value(data = 0.963916236062995), Value(data = -0.9583013046831372)]\n","step: 159, loss: 0.003040819210990053\n","-------\n","ypred: [Value(data = 0.9640324314050952), Value(data = -0.9584425499773949)]\n","step: 160, loss: 0.0030206876430105053\n","-------\n","ypred: [Value(data = 0.9641475273037916), Value(data = -0.9585824194233078)]\n","step: 161, loss: 0.0030008157792591594\n","-------\n","ypred: [Value(data = 0.9642615409271256), Value(data = -0.9587209349771617)]\n","step: 162, loss: 0.0029811986660632324\n","-------\n","ypred: [Value(data = 0.964374489070553), Value(data = -0.9588581181103657)]\n","step: 163, loss: 0.002961831474404766\n","-------\n","ypred: [Value(data = 0.9644863881672725), Value(data = -0.9589939898230893)]\n","step: 164, loss: 0.00294270949603455\n","-------\n","ypred: [Value(data = 0.9645972542982075), Value(data = -0.9591285706574358)]\n","step: 165, loss: 0.0029238281397299995\n","-------\n","ypred: [Value(data = 0.9647071032016536), Value(data = -0.9592618807101697)]\n","step: 166, loss: 0.0029051829276911688\n","-------\n","ypred: [Value(data = 0.9648159502826046), Value(data = -0.959393939645014)]\n","step: 167, loss: 0.002886769492068921\n","-------\n","ypred: [Value(data = 0.9649238106217711), Value(data = -0.9595247667045371)]\n","step: 168, loss: 0.0028685835716195226\n","-------\n","ypred: [Value(data = 0.9650306989843016), Value(data = -0.9596543807216439)]\n","step: 169, loss: 0.0028506210084805854\n","-------\n","ypred: [Value(data = 0.9651366298282196), Value(data = -0.9597828001306862)]\n","step: 170, loss: 0.002832877745062925\n","-------\n","ypred: [Value(data = 0.9652416173125851), Value(data = -0.9599100429782089)]\n","step: 171, loss: 0.002815349821053842\n","-------\n","ypred: [Value(data = 0.965345675305395), Value(data = -0.9600361269333435)]\n","step: 172, loss: 0.002798033370526946\n","-------\n","ypred: [Value(data = 0.9654488173912273), Value(data = -0.9601610692978646)]\n","step: 173, loss: 0.0027809246191543005\n","-------\n","ypred: [Value(data = 0.9655510568786431), Value(data = -0.960284887015923)]\n","step: 174, loss: 0.0027640198815164895\n","-------\n","ypred: [Value(data = 0.9656524068073526), Value(data = -0.9604075966834617)]\n","step: 175, loss: 0.0027473155585070316\n","-------\n","ypred: [Value(data = 0.9657528799551559), Value(data = -0.9605292145573373)]\n","step: 176, loss: 0.0027308081348266754\n","-------\n","ypred: [Value(data = 0.9658524888446655), Value(data = -0.9606497565641465)]\n","step: 177, loss: 0.0027144941765646262\n","-------\n","ypred: [Value(data = 0.9659512457498189), Value(data = -0.9607692383087766)]\n","step: 178, loss: 0.0026983703288627854\n","-------\n","ypred: [Value(data = 0.9660491627021907), Value(data = -0.960887675082687)]\n","step: 179, loss: 0.0026824333136597836\n","-------\n","ypred: [Value(data = 0.966146251497107), Value(data = -0.9610050818719325)]\n","step: 180, loss: 0.0026666799275118225\n","-------\n","ypred: [Value(data = 0.9662425236995759), Value(data = -0.9611214733649364)]\n","step: 181, loss: 0.00265110703948705\n","-------\n","ypred: [Value(data = 0.9663379906500346), Value(data = -0.9612368639600242)]\n","step: 182, loss: 0.0026357115891308337\n","-------\n","ypred: [Value(data = 0.9664326634699227), Value(data = -0.9613512677727275)]\n","step: 183, loss: 0.0026204905844988712\n","-------\n","ypred: [Value(data = 0.9665265530670885), Value(data = -0.9614646986428623)]\n","step: 184, loss: 0.0026054411002558618\n","-------\n","ypred: [Value(data = 0.966619670141031), Value(data = -0.961577170141394)]\n","step: 185, loss: 0.0025905602758369626\n","-------\n","ypred: [Value(data = 0.9667120251879878), Value(data = -0.9616886955770948)]\n","step: 186, loss: 0.002575845313669673\n","-------\n","ypred: [Value(data = 0.9668036285058703), Value(data = -0.9617992880030009)]\n","step: 187, loss: 0.0025612934774539406\n","-------\n","ypred: [Value(data = 0.966894490199054), Value(data = -0.961908960222677)]\n","step: 188, loss: 0.00254690209049813\n","-------\n","ypred: [Value(data = 0.9669846201830286), Value(data = -0.9620177247962945)]\n","step: 189, loss: 0.0025326685341089034\n","-------\n","ypred: [Value(data = 0.9670740281889101), Value(data = -0.9621255940465304)]\n","step: 190, loss: 0.0025185902460329\n","-------\n","ypred: [Value(data = 0.9671627237678254), Value(data = -0.9622325800642917)]\n","step: 191, loss: 0.0025046647189482757\n","-------\n","ypred: [Value(data = 0.967250716295167), Value(data = -0.9623386947142737)]\n","step: 192, loss: 0.0024908894990043158\n","-------\n","ypred: [Value(data = 0.9673380149747267), Value(data = -0.962443949640356)]\n","step: 193, loss: 0.002477262184407296\n","-------\n","ypred: [Value(data = 0.9674246288427115), Value(data = -0.9625483562708427)]\n","step: 194, loss: 0.0024637804240508314\n","-------\n","ypred: [Value(data = 0.9675105667716444), Value(data = -0.9626519258235505)]\n","step: 195, loss: 0.0024504419161893508\n","-------\n","ypred: [Value(data = 0.967595837474155), Value(data = -0.9627546693107529)]\n","step: 196, loss: 0.0024372444071527467\n","-------\n","ypred: [Value(data = 0.9676804495066641), Value(data = -0.9628565975439816)]\n","step: 197, loss: 0.0024241856901010455\n","-------\n","ypred: [Value(data = 0.9677644112729642), Value(data = -0.9629577211386933)]\n","step: 198, loss: 0.0024112636038174096\n","-------\n","ypred: [Value(data = 0.9678477310277003), Value(data = -0.9630580505188046)]\n","step: 199, loss: 0.002398476031538304\n","-------\n"]}],"source":["learning_rate = 0.05\n","\n","for k in range(200):\n","  # forward pass\n","  ypred = [n(x) for x in xs]\n","  loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))  # low loss is better, perfect is loss = 0\n","\n","  # backward pass\n","  for p in n.parameters():\n","    p.grad = 0.0  # zero the gradient \n","  loss.backward()\n","\n","  # update weights and bias\n","  for p in n.parameters():\n","      p.data += -learning_rate * p.grad\n","\n","  # print(f'x: {x}')\n","  print(f'ypred: {ypred}')\n","  print(f'step: {k}, loss: {loss.data}')   \n","  print('-------')  "]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ypred: [Value(data = 0.9679304168797546), Value(data = -0.9631575959210988)]\n","step: 0, loss: 0.0023858208998193634\n","-------\n","ypred: [Value(data = 0.9680124767955376), Value(data = -0.9632563673995103)]\n","step: 1, loss: 0.0023732961774357935\n","-------\n","ypred: [Value(data = 0.968093918602189), Value(data = -0.9633543748292893)]\n","step: 2, loss: 0.002360899874315968\n","-------\n","ypred: [Value(data = 0.9681747499906904), Value(data = -0.9634516279110539)]\n","step: 3, loss: 0.0023486300405071154\n","-------\n","ypred: [Value(data = 0.9682549785188951), Value(data = -0.9635481361747257)]\n","step: 4, loss: 0.0023364847651721555\n","-------\n","ypred: [Value(data = 0.9683346116144735), Value(data = -0.9636439089833628)]\n","step: 5, loss: 0.0023244621756162397\n","-------\n","ypred: [Value(data = 0.9684136565777816), Value(data = -0.9637389555368867)]\n","step: 6, loss: 0.002312560436342201\n","-------\n","ypred: [Value(data = 0.9684921205846508), Value(data = -0.9638332848757053)]\n","step: 7, loss: 0.0023007777481340707\n","-------\n","ypred: [Value(data = 0.9685700106891053), Value(data = -0.9639269058842436)]\n","step: 8, loss: 0.002289112347167176\n","-------\n","ypred: [Value(data = 0.9686473338260048), Value(data = -0.9640198272943744)]\n","step: 9, loss: 0.00227756250414463\n","-------\n","ypred: [Value(data = 0.96872409681362), Value(data = -0.9641120576887612)]\n","step: 10, loss: 0.002266126523458618\n","-------\n","ypred: [Value(data = 0.968800306356139), Value(data = -0.9642036055041091)]\n","step: 11, loss: 0.002254802742376228\n","-------\n","ypred: [Value(data = 0.9688759690461082), Value(data = -0.9642944790343327)]\n","step: 12, loss: 0.0022435895302485207\n","-------\n","ypred: [Value(data = 0.968951091366811), Value(data = -0.9643846864336386)]\n","step: 13, loss: 0.0022324852877423627\n","-------\n","ypred: [Value(data = 0.9690256796945821), Value(data = -0.964474235719527)]\n","step: 14, loss: 0.002221488446094359\n","-------\n","ypred: [Value(data = 0.9690997403010656), Value(data = -0.9645631347757162)]\n","step: 15, loss: 0.0022105974663856436\n","-------\n","ypred: [Value(data = 0.9691732793554121), Value(data = -0.9646513913549908)]\n","step: 16, loss: 0.002199810838837483\n","-------\n","ypred: [Value(data = 0.9692463029264226), Value(data = -0.9647390130819757)]\n","step: 17, loss: 0.002189127082126444\n","-------\n","ypred: [Value(data = 0.9693188169846345), Value(data = -0.9648260074558385)]\n","step: 18, loss: 0.002178544742719083\n","-------\n","ypred: [Value(data = 0.9693908274043579), Value(data = -0.9649123818529245)]\n","step: 19, loss: 0.00216806239422479\n","-------\n","ypred: [Value(data = 0.9694623399656588), Value(data = -0.9649981435293226)]\n","step: 20, loss: 0.002157678636766905\n","-------\n","ypred: [Value(data = 0.9695333603562936), Value(data = -0.965083299623367)]\n","step: 21, loss: 0.0021473920963710254\n","-------\n","ypred: [Value(data = 0.9696038941735937), Value(data = -0.9651678571580755)]\n","step: 22, loss: 0.002137201424370321\n","-------\n","ypred: [Value(data = 0.9696739469263062), Value(data = -0.9652518230435267)]\n","step: 23, loss: 0.002127105296826875\n","-------\n","ypred: [Value(data = 0.9697435240363851), Value(data = -0.9653352040791772)]\n","step: 24, loss: 0.002117102413969102\n","-------\n","ypred: [Value(data = 0.9698126308407423), Value(data = -0.9654180069561219)]\n","step: 25, loss: 0.0021071914996441355\n","-------\n","ypred: [Value(data = 0.9698812725929531), Value(data = -0.9655002382592971)]\n","step: 26, loss: 0.0020973713007852667\n","-------\n","ypred: [Value(data = 0.9699494544649208), Value(data = -0.9655819044696305)]\n","step: 27, loss: 0.0020876405868935086\n","-------\n","ypred: [Value(data = 0.9700171815485011), Value(data = -0.9656630119661377)]\n","step: 28, loss: 0.0020779981495331443\n","-------\n","ypred: [Value(data = 0.9700844588570875), Value(data = -0.9657435670279664)]\n","step: 29, loss: 0.0020684428018407234\n","-------\n","ypred: [Value(data = 0.970151291327157), Value(data = -0.9658235758363928)]\n","step: 30, loss: 0.0020589733780470455\n","-------\n","ypred: [Value(data = 0.9702176838197807), Value(data = -0.9659030444767679)]\n","step: 31, loss: 0.0020495887330118216\n","-------\n","ypred: [Value(data = 0.9702836411220968), Value(data = -0.9659819789404176)]\n","step: 32, loss: 0.0020402877417705313\n","-------\n","ypred: [Value(data = 0.9703491679487496), Value(data = -0.9660603851264968)]\n","step: 33, loss: 0.0020310692990931755\n","-------\n","ypred: [Value(data = 0.9704142689432935), Value(data = -0.9661382688437998)]\n","step: 34, loss: 0.0020219323190545434\n","-------\n","ypred: [Value(data = 0.9704789486795653), Value(data = -0.9662156358125253)]\n","step: 35, loss: 0.0020128757346156594\n","-------\n","ypred: [Value(data = 0.970543211663022), Value(data = -0.966292491666003)]\n","step: 36, loss: 0.002003898497216001\n","-------\n","ypred: [Value(data = 0.9706070623320502), Value(data = -0.9663688419523758)]\n","step: 37, loss: 0.0019949995763762596\n","-------\n","ypred: [Value(data = 0.9706705050592427), Value(data = -0.9664446921362458)]\n","step: 38, loss: 0.0019861779593112307\n","-------\n","ypred: [Value(data = 0.9707335441526462), Value(data = -0.9665200476002784)]\n","step: 39, loss: 0.0019774326505527296\n","-------\n","ypred: [Value(data = 0.9707961838569815), Value(data = -0.9665949136467713)]\n","step: 40, loss: 0.001968762671581893\n","-------\n","ypred: [Value(data = 0.9708584283548333), Value(data = -0.9666692954991856)]\n","step: 41, loss: 0.001960167060470997\n","-------\n","ypred: [Value(data = 0.9709202817678143), Value(data = -0.9667431983036436)]\n","step: 42, loss: 0.0019516448715340845\n","-------\n","ypred: [Value(data = 0.9709817481577032), Value(data = -0.9668166271303887)]\n","step: 43, loss: 0.0019431951749866133\n","-------\n","ypred: [Value(data = 0.9710428315275553), Value(data = -0.9668895869752153)]\n","step: 44, loss: 0.0019348170566133747\n","-------\n","ypred: [Value(data = 0.9711035358227892), Value(data = -0.9669620827608627)]\n","step: 45, loss: 0.0019265096174449128\n","-------\n","ypred: [Value(data = 0.9711638649322486), Value(data = -0.9670341193383803)]\n","step: 46, loss: 0.0019182719734417504\n","-------\n","ypred: [Value(data = 0.9712238226892407), Value(data = -0.9671057014884604)]\n","step: 47, loss: 0.0019101032551865345\n","-------\n","ypred: [Value(data = 0.9712834128725504), Value(data = -0.9671768339227397)]\n","step: 48, loss: 0.0019020026075838182\n","-------\n","ypred: [Value(data = 0.9713426392074332), Value(data = -0.967247521285074)]\n","step: 49, loss: 0.0018939691895670254\n","-------\n","ypred: [Value(data = 0.9714015053665856), Value(data = -0.9673177681527827)]\n","step: 50, loss: 0.0018860021738126942\n","-------\n","ypred: [Value(data = 0.9714600149710938), Value(data = -0.9673875790378661)]\n","step: 51, loss: 0.0018781007464616208\n","-------\n","ypred: [Value(data = 0.9715181715913612), Value(data = -0.9674569583881953)]\n","step: 52, loss: 0.0018702641068467922\n","-------\n","ypred: [Value(data = 0.9715759787480177), Value(data = -0.967525910588676)]\n","step: 53, loss: 0.0018624914672278074\n","-------\n","ypred: [Value(data = 0.971633439912806), Value(data = -0.9675944399623867)]\n","step: 54, loss: 0.0018547820525317456\n","-------\n","ypred: [Value(data = 0.9716905585094519), Value(data = -0.9676625507716917)]\n","step: 55, loss: 0.0018471351001001846\n","-------\n","ypred: [Value(data = 0.9717473379145126), Value(data = -0.9677302472193301)]\n","step: 56, loss: 0.001839549859442289\n","-------\n","ypred: [Value(data = 0.9718037814582097), Value(data = -0.9677975334494802)]\n","step: 57, loss: 0.0018320255919937497\n","-------\n","ypred: [Value(data = 0.9718598924252422), Value(data = -0.9678644135488024)]\n","step: 58, loss: 0.0018245615708813393\n","-------\n","ypred: [Value(data = 0.971915674055583), Value(data = -0.9679308915474579)]\n","step: 59, loss: 0.0018171570806931599\n","-------\n","ypred: [Value(data = 0.9719711295452587), Value(data = -0.9679969714201064)]\n","step: 60, loss: 0.0018098114172541565\n","-------\n","ypred: [Value(data = 0.972026262047112), Value(data = -0.9680626570868818)]\n","step: 61, loss: 0.001802523887406952\n","-------\n","ypred: [Value(data = 0.9720810746715485), Value(data = -0.9681279524143476)]\n","step: 62, loss: 0.001795293808797745\n","-------\n","ypred: [Value(data = 0.9721355704872683), Value(data = -0.9681928612164324)]\n","step: 63, loss: 0.0017881205096671215\n","-------\n","ypred: [Value(data = 0.9721897525219808), Value(data = -0.9682573872553442)]\n","step: 64, loss: 0.0017810033286458603\n","-------\n","ypred: [Value(data = 0.9722436237631068), Value(data = -0.9683215342424656)]\n","step: 65, loss: 0.0017739416145552498\n","-------\n","ypred: [Value(data = 0.972297187158463), Value(data = -0.968385305839232)]\n","step: 66, loss: 0.0017669347262121247\n","-------\n","ypred: [Value(data = 0.9723504456169355), Value(data = -0.9684487056579895)]\n","step: 67, loss: 0.001759982032238227\n","-------\n","ypred: [Value(data = 0.9724034020091369), Value(data = -0.9685117372628347)]\n","step: 68, loss: 0.001753082910874064\n","-------\n","ypred: [Value(data = 0.9724560591680514), Value(data = -0.9685744041704389)]\n","step: 69, loss: 0.0017462367497968084\n","-------\n","ypred: [Value(data = 0.9725084198896659), Value(data = -0.9686367098508536)]\n","step: 70, loss: 0.001739442945942464\n","-------\n","ypred: [Value(data = 0.9725604869335882), Value(data = -0.9686986577282992)]\n","step: 71, loss: 0.001732700905331946\n","-------\n","ypred: [Value(data = 0.9726122630236534), Value(data = -0.9687602511819394)]\n","step: 72, loss: 0.0017260100429010575\n","-------\n","ypred: [Value(data = 0.9726637508485173), Value(data = -0.9688214935466377)]\n","step: 73, loss: 0.001719369782334292\n","-------\n","ypred: [Value(data = 0.9727149530622375), Value(data = -0.9688823881136991)]\n","step: 74, loss: 0.0017127795559023563\n","-------\n","ypred: [Value(data = 0.9727658722848439), Value(data = -0.9689429381315967)]\n","step: 75, loss: 0.0017062388043032632\n","-------\n","ypred: [Value(data = 0.9728165111028969), Value(data = -0.9690031468066843)]\n","step: 76, loss: 0.001699746976506892\n","-------\n","ypred: [Value(data = 0.9728668720700345), Value(data = -0.9690630173038934)]\n","step: 77, loss: 0.0016933035296030695\n","-------\n","ypred: [Value(data = 0.9729169577075092), Value(data = -0.9691225527474172)]\n","step: 78, loss: 0.0016869079286528784\n","-------\n","ypred: [Value(data = 0.9729667705047133), Value(data = -0.9691817562213795)]\n","step: 79, loss: 0.001680559646543324\n","-------\n","ypred: [Value(data = 0.9730163129196945), Value(data = -0.9692406307704924)]\n","step: 80, loss: 0.001674258163845027\n","-------\n","ypred: [Value(data = 0.9730655873796608), Value(data = -0.9692991794006984)]\n","step: 81, loss: 0.0016680029686731894\n","-------\n","ypred: [Value(data = 0.9731145962814765), Value(data = -0.9693574050798026)]\n","step: 82, loss: 0.0016617935565513065\n","-------\n","ypred: [Value(data = 0.9731633419921472), Value(data = -0.9694153107380885)]\n","step: 83, loss: 0.001655629430278136\n","-------\n","ypred: [Value(data = 0.9732118268492959), Value(data = -0.9694728992689267)]\n","step: 84, loss: 0.0016495100997972049\n","-------\n","ypred: [Value(data = 0.9732600531616304), Value(data = -0.9695301735293665)]\n","step: 85, loss: 0.0016434350820693452\n","-------\n","ypred: [Value(data = 0.9733080232094012), Value(data = -0.9695871363407202)]\n","step: 86, loss: 0.001637403900947802\n","-------\n","ypred: [Value(data = 0.9733557392448499), Value(data = -0.9696437904891326)]\n","step: 87, loss: 0.0016314160870561085\n","-------\n","ypred: [Value(data = 0.9734032034926501), Value(data = -0.9697001387261426)]\n","step: 88, loss: 0.0016254711776683855\n","-------\n","ypred: [Value(data = 0.9734504181503394), Value(data = -0.9697561837692308)]\n","step: 89, loss: 0.0016195687165923675\n","-------\n","ypred: [Value(data = 0.9734973853887432), Value(data = -0.9698119283023592)]\n","step: 90, loss: 0.001613708254054705\n","-------\n","ypred: [Value(data = 0.9735441073523902), Value(data = -0.9698673749764991)]\n","step: 91, loss: 0.0016078893465887683\n","-------\n","ypred: [Value(data = 0.9735905861599201), Value(data = -0.9699225264101486)]\n","step: 92, loss: 0.001602111556924809\n","-------\n","ypred: [Value(data = 0.9736368239044842), Value(data = -0.969977385189842)]\n","step: 93, loss: 0.0015963744538822916\n","-------\n","ypred: [Value(data = 0.9736828226541379), Value(data = -0.9700319538706469)]\n","step: 94, loss: 0.0015906776122645953\n","-------\n","ypred: [Value(data = 0.973728584452225), Value(data = -0.9700862349766544)]\n","step: 95, loss: 0.0015850206127558117\n","-------\n","ypred: [Value(data = 0.9737741113177573), Value(data = -0.9701402310014582)]\n","step: 96, loss: 0.0015794030418196665\n","-------\n","ypred: [Value(data = 0.9738194052457843), Value(data = -0.9701939444086263)]\n","step: 97, loss: 0.00157382449160053\n","-------\n","ypred: [Value(data = 0.9738644682077578), Value(data = -0.9702473776321617)]\n","step: 98, loss: 0.00156828455982649\n","-------\n","ypred: [Value(data = 0.9739093021518896), Value(data = -0.9703005330769567)]\n","step: 99, loss: 0.001562782849714331\n","-------\n","ypred: [Value(data = 0.9739539090035014), Value(data = -0.970353413119238)]\n","step: 100, loss: 0.0015573189698764563\n","-------\n","ypred: [Value(data = 0.9739982906653699), Value(data = -0.9704060201070017)]\n","step: 101, loss: 0.001551892534229776\n","-------\n","ypred: [Value(data = 0.9740424490180646), Value(data = -0.9704583563604436)]\n","step: 102, loss: 0.001546503161906317\n","-------\n","ypred: [Value(data = 0.9740863859202793), Value(data = -0.9705104241723791)]\n","step: 103, loss: 0.0015411504771657022\n","-------\n","ypred: [Value(data = 0.9741301032091586), Value(data = -0.9705622258086559)]\n","step: 104, loss: 0.0015358341093093496\n","-------\n","ypred: [Value(data = 0.9741736027006173), Value(data = -0.9706137635085598)]\n","step: 105, loss: 0.0015305536925964178\n","-------\n","ypred: [Value(data = 0.9742168861896544), Value(data = -0.9706650394852115)]\n","step: 106, loss: 0.0015253088661614314\n","-------\n","ypred: [Value(data = 0.9742599554506621), Value(data = -0.970716055925959)]\n","step: 107, loss: 0.0015200992739334593\n","-------\n","ypred: [Value(data = 0.9743028122377282), Value(data = -0.9707668149927601)]\n","step: 108, loss: 0.0015149245645569693\n","-------\n","ypred: [Value(data = 0.974345458284934), Value(data = -0.9708173188225582)]\n","step: 109, loss: 0.001509784391314278\n","-------\n","ypred: [Value(data = 0.9743878953066462), Value(data = -0.9708675695276539)]\n","step: 110, loss: 0.0015046784120494004\n","-------\n","ypred: [Value(data = 0.9744301249978039), Value(data = -0.9709175691960672)]\n","step: 111, loss: 0.0014996062890934724\n","-------\n","ypred: [Value(data = 0.9744721490342009), Value(data = -0.9709673198918943)]\n","step: 112, loss: 0.001494567689191646\n","-------\n","ypred: [Value(data = 0.9745139690727619), Value(data = -0.9710168236556576)]\n","step: 113, loss: 0.0014895622834313889\n","-------\n","ypred: [Value(data = 0.9745555867518154), Value(data = -0.9710660825046503)]\n","step: 114, loss: 0.0014845897471720934\n","-------\n","ypred: [Value(data = 0.9745970036913604), Value(data = -0.9711150984332743)]\n","step: 115, loss: 0.0014796497599761935\n","-------\n","ypred: [Value(data = 0.9746382214933289), Value(data = -0.9711638734133715)]\n","step: 116, loss: 0.001474742005541506\n","-------\n","ypred: [Value(data = 0.9746792417418445), Value(data = -0.9712124093945508)]\n","step: 117, loss: 0.001469866171634898\n","-------\n","ypred: [Value(data = 0.9747200660034754), Value(data = -0.9712607083045078)]\n","step: 118, loss: 0.001465021950027226\n","-------\n","ypred: [Value(data = 0.9747606958274836), Value(data = -0.9713087720493405)]\n","step: 119, loss: 0.001460209036429508\n","-------\n","ypred: [Value(data = 0.97480113274607), Value(data = -0.9713566025138574)]\n","step: 120, loss: 0.0014554271304303454\n","-------\n","ypred: [Value(data = 0.9748413782746149), Value(data = -0.9714042015618817)]\n","step: 121, loss: 0.0014506759354345085\n","-------\n","ypred: [Value(data = 0.9748814339119141), Value(data = -0.9714515710365508)]\n","step: 122, loss: 0.0014459551586026474\n","-------\n","ypred: [Value(data = 0.9749213011404116), Value(data = -0.971498712760609)]\n","step: 123, loss: 0.0014412645107921933\n","-------\n","ypred: [Value(data = 0.9749609814264287), Value(data = -0.9715456285366957)]\n","step: 124, loss: 0.001436603706499354\n","-------\n","ypred: [Value(data = 0.9750004762203872), Value(data = -0.9715923201476293)]\n","step: 125, loss: 0.0014319724638022129\n","-------\n","ypred: [Value(data = 0.9750397869570313), Value(data = -0.9716387893566859)]\n","step: 126, loss: 0.0014273705043048172\n","-------\n","ypred: [Value(data = 0.9750789150556441), Value(data = -0.9716850379078721)]\n","step: 127, loss: 0.001422797553082441\n","-------\n","ypred: [Value(data = 0.9751178619202612), Value(data = -0.9717310675261952)]\n","step: 128, loss: 0.0014182533386277243\n","-------\n","ypred: [Value(data = 0.9751566289398803), Value(data = -0.9717768799179277)]\n","step: 129, loss: 0.0014137375927978644\n","-------\n","ypred: [Value(data = 0.9751952174886676), Value(data = -0.9718224767708666)]\n","step: 130, loss: 0.0014092500507628541\n","-------\n","ypred: [Value(data = 0.9752336289261605), Value(data = -0.9718678597545901)]\n","step: 131, loss: 0.0014047904509545245\n","-------\n","ypred: [Value(data = 0.9752718645974673), Value(data = -0.9719130305207082)]\n","step: 132, loss: 0.0014003585350166603\n","-------\n","ypred: [Value(data = 0.9753099258334628), Value(data = -0.9719579907031098)]\n","step: 133, loss: 0.0013959540477559834\n","-------\n","ypred: [Value(data = 0.9753478139509819), Value(data = -0.9720027419182069)]\n","step: 134, loss: 0.0013915767370939309\n","-------\n","ypred: [Value(data = 0.9753855302530087), Value(data = -0.9720472857651722)]\n","step: 135, loss: 0.001387226354019497\n","-------\n","ypred: [Value(data = 0.9754230760288631), Value(data = -0.9720916238261749)]\n","step: 136, loss: 0.0013829026525427723\n","-------\n","ypred: [Value(data = 0.9754604525543852), Value(data = -0.9721357576666115)]\n","step: 137, loss: 0.0013786053896493787\n","-------\n","ypred: [Value(data = 0.9754976610921144), Value(data = -0.9721796888353336)]\n","step: 138, loss: 0.001374334325255746\n","-------\n","ypred: [Value(data = 0.9755347028914682), Value(data = -0.9722234188648702)]\n","step: 139, loss: 0.0013700892221651865\n","-------\n","ypred: [Value(data = 0.975571579188916), Value(data = -0.9722669492716494)]\n","step: 140, loss: 0.001365869846024671\n","-------\n","ypred: [Value(data = 0.9756082912081517), Value(data = -0.9723102815562128)]\n","step: 141, loss: 0.0013616759652825372\n","-------\n","ypred: [Value(data = 0.9756448401602621), Value(data = -0.9723534172034302)]\n","step: 142, loss: 0.0013575073511467735\n","-------\n","ypred: [Value(data = 0.9756812272438937), Value(data = -0.9723963576827065)]\n","step: 143, loss: 0.0013533637775442137\n","-------\n","ypred: [Value(data = 0.9757174536454164), Value(data = -0.9724391044481899)]\n","step: 144, loss: 0.0013492450210802855\n","-------\n","ypred: [Value(data = 0.9757535205390839), Value(data = -0.972481658938973)]\n","step: 145, loss: 0.0013451508609996304\n","-------\n","ypred: [Value(data = 0.9757894290871931), Value(data = -0.9725240225792925)]\n","step: 146, loss: 0.001341081079147279\n","-------\n","ypred: [Value(data = 0.9758251804402396), Value(data = -0.9725661967787254)]\n","step: 147, loss: 0.001337035459930594\n","-------\n","ypred: [Value(data = 0.9758607757370706), Value(data = -0.9726081829323813)]\n","step: 148, loss: 0.0013330137902818862\n","-------\n","ypred: [Value(data = 0.9758962161050375), Value(data = -0.9726499824210935)]\n","step: 149, loss: 0.0013290158596215495\n","-------\n","ypred: [Value(data = 0.9759315026601426), Value(data = -0.9726915966116038)]\n","step: 150, loss: 0.0013250414598220935\n","-------\n","ypred: [Value(data = 0.9759666365071871), Value(data = -0.9727330268567486)]\n","step: 151, loss: 0.0013210903851724686\n","-------\n","ypred: [Value(data = 0.9760016187399139), Value(data = -0.9727742744956384)]\n","step: 152, loss: 0.0013171624323433013\n","-------\n","ypred: [Value(data = 0.9760364504411503), Value(data = -0.9728153408538355)]\n","step: 153, loss: 0.001313257400352593\n","-------\n","ypred: [Value(data = 0.9760711326829469), Value(data = -0.9728562272435306)]\n","step: 154, loss: 0.0013093750905319836\n","-------\n","ypred: [Value(data = 0.9761056665267152), Value(data = -0.9728969349637145)]\n","step: 155, loss: 0.0013055153064936598\n","-------\n","ypred: [Value(data = 0.9761400530233628), Value(data = -0.9729374653003476)]\n","step: 156, loss: 0.0013016778540978259\n","-------\n","ypred: [Value(data = 0.9761742932134269), Value(data = -0.9729778195265274)]\n","step: 157, loss: 0.0012978625414206814\n","-------\n","ypred: [Value(data = 0.9762083881272045), Value(data = -0.973017998902653)]\n","step: 158, loss: 0.0012940691787229836\n","-------\n","ypred: [Value(data = 0.9762423387848826), Value(data = -0.9730580046765871)]\n","step: 159, loss: 0.0012902975784190942\n","-------\n","ypred: [Value(data = 0.9762761461966645), Value(data = -0.9730978380838151)]\n","step: 160, loss: 0.001286547555046666\n","-------\n","ypred: [Value(data = 0.9763098113628952), Value(data = -0.9731375003476024)]\n","step: 161, loss: 0.0012828189252366722\n","-------\n","ypred: [Value(data = 0.9763433352741845), Value(data = -0.9731769926791487)]\n","step: 162, loss: 0.0012791115076840865\n","-------\n","ypred: [Value(data = 0.9763767189115288), Value(data = -0.9732163162777407)]\n","step: 163, loss: 0.0012754251231189375\n","-------\n","ypred: [Value(data = 0.97640996324643), Value(data = -0.973255472330901)]\n","step: 164, loss: 0.0012717595942779818\n","-------\n","ypred: [Value(data = 0.9764430692410137), Value(data = -0.9732944620145365)]\n","step: 165, loss: 0.0012681147458767105\n","-------\n","ypred: [Value(data = 0.9764760378481445), Value(data = -0.9733332864930833)]\n","step: 166, loss: 0.001264490404581905\n","-------\n","ypred: [Value(data = 0.9765088700115413), Value(data = -0.9733719469196496)]\n","step: 167, loss: 0.0012608863989846241\n","-------\n","ypred: [Value(data = 0.9765415666658884), Value(data = -0.9734104444361571)]\n","step: 168, loss: 0.0012573025595736462\n","-------\n","ypred: [Value(data = 0.9765741287369474), Value(data = -0.9734487801734796)]\n","step: 169, loss: 0.001253738718709326\n","-------\n","ypred: [Value(data = 0.9766065571416656), Value(data = -0.9734869552515794)]\n","step: 170, loss: 0.0012501947105979143\n","-------\n","ypred: [Value(data = 0.9766388527882838), Value(data = -0.973524970779642)]\n","step: 171, loss: 0.0012466703712662895\n","-------\n","ypred: [Value(data = 0.9766710165764423), Value(data = -0.9735628278562094)]\n","step: 172, loss: 0.0012431655385370484\n","-------\n","ypred: [Value(data = 0.9767030493972851), Value(data = -0.9736005275693093)]\n","step: 173, loss: 0.0012396800520041368\n","-------\n","ypred: [Value(data = 0.9767349521335627), Value(data = -0.9736380709965852)]\n","step: 174, loss: 0.0012362137530087052\n","-------\n","ypred: [Value(data = 0.9767667256597331), Value(data = -0.9736754592054224)]\n","step: 175, loss: 0.0012327664846154833\n","-------\n","ypred: [Value(data = 0.9767983708420623), Value(data = -0.973712693253073)]\n","step: 176, loss: 0.0012293380915894985\n","-------\n","ypred: [Value(data = 0.9768298885387218), Value(data = -0.9737497741867789)]\n","step: 177, loss: 0.0012259284203731571\n","-------\n","ypred: [Value(data = 0.9768612795998861), Value(data = -0.9737867030438933)]\n","step: 178, loss: 0.0012225373190636818\n","-------\n","ypred: [Value(data = 0.9768925448678278), Value(data = -0.9738234808519992)]\n","step: 179, loss: 0.0012191646373910015\n","-------\n","ypred: [Value(data = 0.9769236851770121), Value(data = -0.9738601086290287)]\n","step: 180, loss: 0.001215810226695829\n","-------\n","ypred: [Value(data = 0.9769547013541888), Value(data = -0.9738965873833773)]\n","step: 181, loss: 0.0012124739399082857\n","-------\n","ypred: [Value(data = 0.9769855942184845), Value(data = -0.9739329181140188)]\n","step: 182, loss: 0.0012091556315267007\n","-------\n","ypred: [Value(data = 0.9770163645814922), Value(data = -0.9739691018106179)]\n","step: 183, loss: 0.0012058551575968614\n","-------\n","ypred: [Value(data = 0.9770470132473601), Value(data = -0.9740051394536418)]\n","step: 184, loss: 0.0012025723756914754\n","-------\n","ypred: [Value(data = 0.9770775410128791), Value(data = -0.9740410320144676)]\n","step: 185, loss: 0.0011993071448901358\n","-------\n","ypred: [Value(data = 0.9771079486675692), Value(data = -0.9740767804554922)]\n","step: 186, loss: 0.001196059325759398\n","-------\n","ypred: [Value(data = 0.9771382369937643), Value(data = -0.9741123857302376)]\n","step: 187, loss: 0.0011928287803332901\n","-------\n","ypred: [Value(data = 0.9771684067666961), Value(data = -0.9741478487834552)]\n","step: 188, loss: 0.0011896153720941467\n","-------\n","ypred: [Value(data = 0.9771984587545766), Value(data = -0.9741831705512297)]\n","step: 189, loss: 0.001186418965953639\n","-------\n","ypred: [Value(data = 0.9772283937186798), Value(data = -0.9742183519610799)]\n","step: 190, loss: 0.001183239428234218\n","-------\n","ypred: [Value(data = 0.9772582124134215), Value(data = -0.9742533939320598)]\n","step: 191, loss: 0.001180076626650753\n","-------\n","ypred: [Value(data = 0.977287915586439), Value(data = -0.9742882973748573)]\n","step: 192, loss: 0.001176930430292488\n","-------\n","ypred: [Value(data = 0.9773175039786689), Value(data = -0.9743230631918908)]\n","step: 193, loss: 0.0011738007096053359\n","-------\n","ypred: [Value(data = 0.9773469783244237), Value(data = -0.9743576922774065)]\n","step: 194, loss: 0.001170687336374304\n","-------\n","ypred: [Value(data = 0.9773763393514685), Value(data = -0.9743921855175717)]\n","step: 195, loss: 0.0011675901837063785\n","-------\n","ypred: [Value(data = 0.9774055877810948), Value(data = -0.9744265437905693)]\n","step: 196, loss: 0.001164509126013486\n","-------\n","ypred: [Value(data = 0.977434724328195), Value(data = -0.9744607679666891)]\n","step: 197, loss: 0.0011614440389958469\n","-------\n","ypred: [Value(data = 0.977463749701335), Value(data = -0.9744948589084187)]\n","step: 198, loss: 0.0011583947996255484\n","-------\n","ypred: [Value(data = 0.9774926646028255), Value(data = -0.9745288174705329)]\n","step: 199, loss: 0.0011553612861303366\n","-------\n","ypred: [Value(data = 0.9775214697287935), Value(data = -0.9745626445001828)]\n","step: 200, loss: 0.0011523433779776263\n","-------\n","ypred: [Value(data = 0.9775501657692514), Value(data = -0.9745963408369814)]\n","step: 201, loss: 0.0011493409558589107\n","-------\n","ypred: [Value(data = 0.9775787534081659), Value(data = -0.97462990731309)]\n","step: 202, loss: 0.001146353901674238\n","-------\n","ypred: [Value(data = 0.9776072333235265), Value(data = -0.9746633447533027)]\n","step: 203, loss: 0.0011433820985169737\n","-------\n","ypred: [Value(data = 0.9776356061874116), Value(data = -0.9746966539751304)]\n","step: 204, loss: 0.0011404254306588255\n","-------\n","ypred: [Value(data = 0.9776638726660549), Value(data = -0.9747298357888823)]\n","step: 205, loss: 0.0011374837835350631\n","-------\n","ypred: [Value(data = 0.9776920334199107), Value(data = -0.9747628909977473)]\n","step: 206, loss: 0.0011345570437299656\n","-------\n","ypred: [Value(data = 0.9777200891037178), Value(data = -0.9747958203978742)]\n","step: 207, loss: 0.001131645098962492\n","-------\n","ypred: [Value(data = 0.9777480403665628), Value(data = -0.9748286247784504)]\n","step: 208, loss: 0.0011287478380721564\n","-------\n","ypred: [Value(data = 0.9777758878519436), Value(data = -0.97486130492178)]\n","step: 209, loss: 0.00112586515100511\n","-------\n","ypred: [Value(data = 0.9778036321978293), Value(data = -0.9748938616033602)]\n","step: 210, loss: 0.0011229969288004708\n","-------\n","ypred: [Value(data = 0.9778312740367229), Value(data = -0.9749262955919575)]\n","step: 211, loss: 0.0011201430635767653\n","-------\n","ypred: [Value(data = 0.9778588139957198), Value(data = -0.9749586076496825)]\n","step: 212, loss: 0.001117303448518674\n","-------\n","ypred: [Value(data = 0.9778862526965684), Value(data = -0.9749907985320626)]\n","step: 213, loss: 0.0011144779778639116\n","-------\n","ypred: [Value(data = 0.9779135907557273), Value(data = -0.9750228689881162)]\n","step: 214, loss: 0.0011116665468903046\n","-------\n","ypred: [Value(data = 0.9779408287844236), Value(data = -0.9750548197604234)]\n","step: 215, loss: 0.0011088690519030784\n","-------\n","ypred: [Value(data = 0.9779679673887097), Value(data = -0.9750866515851974)]\n","step: 216, loss: 0.0011060853902223073\n","-------\n","ypred: [Value(data = 0.9779950071695196), Value(data = -0.9751183651923536)]\n","step: 217, loss: 0.001103315460170574\n","-------\n","ypred: [Value(data = 0.9780219487227237), Value(data = -0.9751499613055792)]\n","step: 218, loss: 0.0011005591610607963\n","-------\n","ypred: [Value(data = 0.9780487926391845), Value(data = -0.9751814406424013)]\n","step: 219, loss: 0.0010978163931841683\n","-------\n","ypred: [Value(data = 0.9780755395048093), Value(data = -0.975212803914253)]\n","step: 220, loss: 0.001095087057798448\n","-------\n","ypred: [Value(data = 0.9781021899006043), Value(data = -0.9752440518265408)]\n","step: 221, loss: 0.0010923710571161937\n","-------\n","ypred: [Value(data = 0.9781287444027269), Value(data = -0.9752751850787089)]\n","step: 222, loss: 0.001089668294293348\n","-------\n","ypred: [Value(data = 0.9781552035825376), Value(data = -0.9753062043643043)]\n","step: 223, loss: 0.001086978673417884\n","-------\n","ypred: [Value(data = 0.9781815680066509), Value(data = -0.9753371103710402)]\n","step: 224, loss: 0.001084302099498652\n","-------\n","ypred: [Value(data = 0.9782078382369863), Value(data = -0.9753679037808588)]\n","step: 225, loss: 0.0010816384784543857\n","-------\n","ypred: [Value(data = 0.9782340148308176), Value(data = -0.9753985852699933)]\n","step: 226, loss: 0.0010789877171028556\n","-------\n","ypred: [Value(data = 0.9782600983408227), Value(data = -0.9754291555090292)]\n","step: 227, loss: 0.001076349723150169\n","-------\n","ypred: [Value(data = 0.9782860893151317), Value(data = -0.9754596151629638)]\n","step: 228, loss: 0.001073724405180275\n","-------\n","ypred: [Value(data = 0.978311988297375), Value(data = -0.9754899648912669)]\n","step: 229, loss: 0.0010711116726445273\n","-------\n","ypred: [Value(data = 0.9783377958267306), Value(data = -0.975520205347939)]\n","step: 230, loss: 0.0010685114358514808\n","-------\n","ypred: [Value(data = 0.978363512437971), Value(data = -0.9755503371815696)]\n","step: 231, loss: 0.0010659236059567727\n","-------\n","ypred: [Value(data = 0.9783891386615094), Value(data = -0.9755803610353937)]\n","step: 232, loss: 0.001063348094953184\n","-------\n","ypred: [Value(data = 0.9784146750234447), Value(data = -0.9756102775473495)]\n","step: 233, loss: 0.0010607848156608246\n","-------\n","ypred: [Value(data = 0.9784401220456069), Value(data = -0.9756400873501336)]\n","step: 234, loss: 0.0010582336817174438\n","-------\n","ypred: [Value(data = 0.9784654802456016), Value(data = -0.9756697910712562)]\n","step: 235, loss: 0.0010556946075688987\n","-------\n","ypred: [Value(data = 0.9784907501368534), Value(data = -0.9756993893330946)]\n","step: 236, loss: 0.0010531675084597875\n","-------\n","ypred: [Value(data = 0.9785159322286495), Value(data = -0.9757288827529492)]\n","step: 237, loss: 0.001050652300424066\n","-------\n","ypred: [Value(data = 0.9785410270261823), Value(data = -0.9757582719430936)]\n","step: 238, loss: 0.0010481489002760413\n","-------\n","ypred: [Value(data = 0.9785660350305917), Value(data = -0.9757875575108292)]\n","step: 239, loss: 0.0010456572256012239\n","-------\n","ypred: [Value(data = 0.9785909567390068), Value(data = -0.9758167400585365)]\n","step: 240, loss: 0.001043177194747475\n","-------\n","ypred: [Value(data = 0.9786157926445863), Value(data = -0.9758458201837243)]\n","step: 241, loss: 0.001040708726816307\n","-------\n","ypred: [Value(data = 0.9786405432365606), Value(data = -0.975874798479083)]\n","step: 242, loss: 0.0010382517416540947\n","-------\n","ypred: [Value(data = 0.9786652090002705), Value(data = -0.9759036755325315)]\n","step: 243, loss: 0.0010358061598436561\n","-------\n","ypred: [Value(data = 0.9786897904172076), Value(data = -0.9759324519272689)]\n","step: 244, loss: 0.0010333719026957616\n","-------\n","ypred: [Value(data = 0.9787142879650531), Value(data = -0.9759611282418208)]\n","step: 245, loss: 0.0010309488922408687\n","-------\n","ypred: [Value(data = 0.9787387021177166), Value(data = -0.9759897050500883)]\n","step: 246, loss: 0.0010285370512209424\n","-------\n","ypred: [Value(data = 0.9787630333453742), Value(data = -0.9760181829213956)]\n","step: 247, loss: 0.0010261363030813289\n","-------\n","ypred: [Value(data = 0.978787282114506), Value(data = -0.976046562420536)]\n","step: 248, loss: 0.0010237465719628329\n","-------\n","ypred: [Value(data = 0.978811448887934), Value(data = -0.976074844107818)]\n","step: 249, loss: 0.0010213677826938442\n","-------\n","ypred: [Value(data = 0.9788355341248581), Value(data = -0.9761030285391115)]\n","step: 250, loss: 0.001018999860782566\n","-------\n","ypred: [Value(data = 0.9788595382808927), Value(data = -0.9761311162658923)]\n","step: 251, loss: 0.0010166427324093921\n","-------\n","ypred: [Value(data = 0.9788834618081026), Value(data = -0.976159107835287)]\n","step: 252, loss: 0.0010142963244193339\n","-------\n","ypred: [Value(data = 0.9789073051550385), Value(data = -0.976187003790116)]\n","step: 253, loss: 0.001011960564314612\n","-------\n","ypred: [Value(data = 0.9789310687667722), Value(data = -0.976214804668938)]\n","step: 254, loss: 0.0010096353802472595\n","-------\n","ypred: [Value(data = 0.9789547530849304), Value(data = -0.9762425110060918)]\n","step: 255, loss: 0.001007320701011914\n","-------\n","ypred: [Value(data = 0.9789783585477299), Value(data = -0.9762701233317395)]\n","step: 256, loss: 0.0010050164560386585\n","-------\n","ypred: [Value(data = 0.9790018855900106), Value(data = -0.9762976421719071)]\n","step: 257, loss: 0.0010027225753859647\n","-------\n","ypred: [Value(data = 0.979025334643269), Value(data = -0.9763250680485276)]\n","step: 258, loss: 0.0010004389897337001\n","-------\n","ypred: [Value(data = 0.9790487061356916), Value(data = -0.9763524014794795)]\n","step: 259, loss: 0.0009981656303763272\n","-------\n","ypred: [Value(data = 0.9790720004921868), Value(data = -0.9763796429786294)]\n","step: 260, loss: 0.0009959024292160391\n","-------\n","ypred: [Value(data = 0.9790952181344175), Value(data = -0.9764067930558699)]\n","step: 261, loss: 0.000993649318756139\n","-------\n","ypred: [Value(data = 0.9791183594808326), Value(data = -0.9764338522171598)]\n","step: 262, loss: 0.0009914062320943967\n","-------\n","ypred: [Value(data = 0.9791414249466985), Value(data = -0.976460820964563)]\n","step: 263, loss: 0.0009891731029165673\n","-------\n","ypred: [Value(data = 0.9791644149441303), Value(data = -0.9764876997962864)]\n","step: 264, loss: 0.000986949865489933\n","-------\n","ypred: [Value(data = 0.9791873298821223), Value(data = -0.9765144892067186)]\n","step: 265, loss: 0.0009847364546569373\n","-------\n","ypred: [Value(data = 0.979210170166578), Value(data = -0.9765411896864656)]\n","step: 266, loss: 0.000982532805829031\n","-------\n","ypred: [Value(data = 0.9792329362003405), Value(data = -0.9765678017223909)]\n","step: 267, loss: 0.0009803388549803173\n","-------\n","ypred: [Value(data = 0.9792556283832219), Value(data = -0.9765943257976488)]\n","step: 268, loss: 0.0009781545386415968\n","-------\n","ypred: [Value(data = 0.9792782471120324), Value(data = -0.9766207623917224)]\n","step: 269, loss: 0.0009759797938942987\n","-------\n","ypred: [Value(data = 0.9793007927806094), Value(data = -0.9766471119804588)]\n","step: 270, loss: 0.0009738145583644993\n","-------\n","ypred: [Value(data = 0.9793232657798461), Value(data = -0.9766733750361045)]\n","step: 271, loss: 0.0009716587702171162\n","-------\n","ypred: [Value(data = 0.979345666497719), Value(data = -0.9766995520273403)]\n","step: 272, loss: 0.0009695123681500689\n","-------\n","ypred: [Value(data = 0.9793679953193171), Value(data = -0.9767256434193153)]\n","step: 273, loss: 0.000967375291388582\n","-------\n","ypred: [Value(data = 0.979390252626868), Value(data = -0.9767516496736817)]\n","step: 274, loss: 0.0009652474796795487\n","-------\n","ypred: [Value(data = 0.9794124387997662), Value(data = -0.9767775712486281)]\n","step: 275, loss: 0.0009631288732859155\n","-------\n","ypred: [Value(data = 0.9794345542145997), Value(data = -0.976803408598912)]\n","step: 276, loss: 0.0009610194129812687\n","-------\n","ypred: [Value(data = 0.9794565992451764), Value(data = -0.9768291621758942)]\n","step: 277, loss: 0.0009589190400442996\n","-------\n","ypred: [Value(data = 0.9794785742625505), Value(data = -0.9768548324275702)]\n","step: 278, loss: 0.0009568276962535115\n","-------\n","ypred: [Value(data = 0.9795004796350487), Value(data = -0.9768804197986024)]\n","step: 279, loss: 0.0009547453238819082\n","-------\n","ypred: [Value(data = 0.9795223157282958), Value(data = -0.9769059247303521)]\n","step: 280, loss: 0.0009526718656917627\n","-------\n","ypred: [Value(data = 0.97954408290524), Value(data = -0.9769313476609106)]\n","step: 281, loss: 0.0009506072649294698\n","-------\n","ypred: [Value(data = 0.979565781526178), Value(data = -0.9769566890251309)]\n","step: 282, loss: 0.0009485514653204111\n","-------\n","ypred: [Value(data = 0.9795874119487802), Value(data = -0.9769819492546572)]\n","step: 283, loss: 0.0009465044110639781\n","-------\n","ypred: [Value(data = 0.9796089745281144), Value(data = -0.9770071287779561)]\n","step: 284, loss: 0.0009444660468285817\n","-------\n","ypred: [Value(data = 0.9796304696166711), Value(data = -0.977032228020346)]\n","step: 285, loss: 0.0009424363177467406\n","-------\n","ypred: [Value(data = 0.9796518975643869), Value(data = -0.977057247404027)]\n","step: 286, loss: 0.0009404151694102312\n","-------\n","ypred: [Value(data = 0.9796732587186682), Value(data = -0.9770821873481107)]\n","step: 287, loss: 0.0009384025478652968\n","-------\n","ypred: [Value(data = 0.9796945534244147), Value(data = -0.9771070482686477)]\n","step: 288, loss: 0.0009363983996079756\n","-------\n","ypred: [Value(data = 0.9797157820240429), Value(data = -0.977131830578657)]\n","step: 289, loss: 0.0009344026715793878\n","-------\n","ypred: [Value(data = 0.9797369448575085), Value(data = -0.9771565346881552)]\n","step: 290, loss: 0.0009324153111611067\n","-------\n","ypred: [Value(data = 0.9797580422623294), Value(data = -0.9771811610041826)]\n","step: 291, loss: 0.0009304362661706775\n","-------\n","ypred: [Value(data = 0.9797790745736082), Value(data = -0.9772057099308322)]\n","step: 292, loss: 0.0009284654848570573\n","-------\n","ypred: [Value(data = 0.979800042124054), Value(data = -0.9772301818692766)]\n","step: 293, loss: 0.0009265029158962131\n","-------\n","ypred: [Value(data = 0.9798209452440044), Value(data = -0.9772545772177946)]\n","step: 294, loss: 0.0009245485083867347\n","-------\n","ypred: [Value(data = 0.9798417842614476), Value(data = -0.9772788963717991)]\n","step: 295, loss: 0.0009226022118454644\n","-------\n","ypred: [Value(data = 0.9798625595020433), Value(data = -0.9773031397238618)]\n","step: 296, loss: 0.0009206639762032861\n","-------\n","ypred: [Value(data = 0.9798832712891438), Value(data = -0.9773273076637411)]\n","step: 297, loss: 0.0009187337518008407\n","-------\n","ypred: [Value(data = 0.9799039199438156), Value(data = -0.9773514005784062)]\n","step: 298, loss: 0.0009168114893843898\n","-------\n","ypred: [Value(data = 0.9799245057848598), Value(data = -0.977375418852064)]\n","step: 299, loss: 0.0009148971401016679\n","-------\n","ypred: [Value(data = 0.9799450291288323), Value(data = -0.9773993628661838)]\n","step: 300, loss: 0.0009129906554978173\n","-------\n","ypred: [Value(data = 0.9799654902900641), Value(data = -0.9774232329995223)]\n","step: 301, loss: 0.0009110919875113768\n","-------\n","ypred: [Value(data = 0.9799858895806821), Value(data = -0.9774470296281481)]\n","step: 302, loss: 0.0009092010884702779\n","-------\n","ypred: [Value(data = 0.9800062273106278), Value(data = -0.977470753125466)]\n","step: 303, loss: 0.000907317911087983\n","-------\n","ypred: [Value(data = 0.9800265037876777), Value(data = -0.9774944038622425)]\n","step: 304, loss: 0.000905442408459496\n","-------\n","ypred: [Value(data = 0.9800467193174626), Value(data = -0.9775179822066273)]\n","step: 305, loss: 0.0009035745340576467\n","-------\n","ypred: [Value(data = 0.9800668742034864), Value(data = -0.9775414885241793)]\n","step: 306, loss: 0.0009017142417292061\n","-------\n","ypred: [Value(data = 0.9800869687471453), Value(data = -0.9775649231778882)]\n","step: 307, loss: 0.0008998614856912249\n","-------\n","ypred: [Value(data = 0.9801070032477466), Value(data = -0.9775882865281984)]\n","step: 308, loss: 0.0008980162205272984\n","-------\n","ypred: [Value(data = 0.9801269780025272), Value(data = -0.9776115789330321)]\n","step: 309, loss: 0.0008961784011838894\n","-------\n","ypred: [Value(data = 0.9801468933066722), Value(data = -0.9776348007478111)]\n","step: 310, loss: 0.0008943479829667717\n","-------\n","ypred: [Value(data = 0.9801667494533324), Value(data = -0.9776579523254798)]\n","step: 311, loss: 0.0008925249215374248\n","-------\n","ypred: [Value(data = 0.980186546733643), Value(data = -0.977681034016527)]\n","step: 312, loss: 0.0008907091729095388\n","-------\n","ypred: [Value(data = 0.980206285436741), Value(data = -0.9777040461690079)]\n","step: 313, loss: 0.000888900693445503\n","-------\n","ypred: [Value(data = 0.9802259658497828), Value(data = -0.9777269891285654)]\n","step: 314, loss: 0.000887099439853\n","-------\n","ypred: [Value(data = 0.9802455882579617), Value(data = -0.9777498632384521)]\n","step: 315, loss: 0.0008853053691815637\n","-------\n","ypred: [Value(data = 0.980265152944525), Value(data = -0.9777726688395512)]\n","step: 316, loss: 0.0008835184388192507\n","-------\n","ypred: [Value(data = 0.980284660190791), Value(data = -0.9777954062703973)]\n","step: 317, loss: 0.0008817386064892943\n","-------\n","ypred: [Value(data = 0.9803041102761659), Value(data = -0.9778180758671967)]\n","step: 318, loss: 0.0008799658302468733\n","-------\n","ypred: [Value(data = 0.9803235034781607), Value(data = -0.9778406779638491)]\n","step: 319, loss: 0.0008782000684757984\n","-------\n","ypred: [Value(data = 0.980342840072407), Value(data = -0.9778632128919664)]\n","step: 320, loss: 0.0008764412798853687\n","-------\n","ypred: [Value(data = 0.9803621203326742), Value(data = -0.9778856809808942)]\n","step: 321, loss: 0.00087468942350715\n","-------\n","ypred: [Value(data = 0.9803813445308848), Value(data = -0.9779080825577307)]\n","step: 322, loss: 0.0008729444586918897\n","-------\n","ypred: [Value(data = 0.9804005129371312), Value(data = -0.9779304179473459)]\n","step: 323, loss: 0.0008712063451063944\n","-------\n","ypred: [Value(data = 0.9804196258196903), Value(data = -0.9779526874724028)]\n","step: 324, loss: 0.0008694750427304808\n","-------\n","ypred: [Value(data = 0.9804386834450408), Value(data = -0.9779748914533748)]\n","step: 325, loss: 0.0008677505118539429\n","-------\n","ypred: [Value(data = 0.9804576860778771), Value(data = -0.9779970302085652)]\n","step: 326, loss: 0.0008660327130735909\n","-------\n","ypred: [Value(data = 0.9804766339811255), Value(data = -0.9780191040541266)]\n","step: 327, loss: 0.0008643216072902563\n","-------\n","ypred: [Value(data = 0.9804955274159589), Value(data = -0.9780411133040791)]\n","step: 328, loss: 0.0008626171557059042\n","-------\n","ypred: [Value(data = 0.9805143666418121), Value(data = -0.9780630582703284)]\n","step: 329, loss: 0.000860919319820733\n","-------\n","ypred: [Value(data = 0.9805331519163968), Value(data = -0.9780849392626848)]\n","step: 330, loss: 0.0008592280614303002\n","-------\n","ypred: [Value(data = 0.9805518834957153), Value(data = -0.9781067565888802)]\n","step: 331, loss: 0.000857543342622769\n","-------\n","ypred: [Value(data = 0.9805705616340763), Value(data = -0.9781285105545872)]\n","step: 332, loss: 0.0008558651257760332\n","-------\n","ypred: [Value(data = 0.9805891865841084), Value(data = -0.9781502014634351)]\n","step: 333, loss: 0.000854193373555029\n","-------\n","ypred: [Value(data = 0.9806077585967748), Value(data = -0.9781718296170293)]\n","step: 334, loss: 0.0008525280489089587\n","-------\n","ypred: [Value(data = 0.9806262779213869), Value(data = -0.978193395314967)]\n","step: 335, loss: 0.0008508691150686455\n","-------\n","ypred: [Value(data = 0.9806447448056188), Value(data = -0.9782148988548551)]\n","step: 336, loss: 0.0008492165355438125\n","-------\n","ypred: [Value(data = 0.9806631594955206), Value(data = -0.9782363405323269)]\n","step: 337, loss: 0.0008475702741205114\n","-------\n","ypred: [Value(data = 0.9806815222355324), Value(data = -0.978257720641059)]\n","step: 338, loss: 0.0008459302948584618\n","-------\n","ypred: [Value(data = 0.9806998332684975), Value(data = -0.9782790394727876)]\n","step: 339, loss: 0.000844296562088514\n","-------\n","ypred: [Value(data = 0.9807180928356761), Value(data = -0.9783002973173254)]\n","step: 340, loss: 0.0008426690404100808\n","-------\n","ypred: [Value(data = 0.9807363011767581), Value(data = -0.9783214944625768)]\n","step: 341, loss: 0.0008410476946886595\n","-------\n","ypred: [Value(data = 0.9807544585298769), Value(data = -0.9783426311945556)]\n","step: 342, loss: 0.0008394324900532677\n","-------\n","ypred: [Value(data = 0.9807725651316214), Value(data = -0.9783637077973995)]\n","step: 343, loss: 0.0008378233918940559\n","-------\n","ypred: [Value(data = 0.9807906212170496), Value(data = -0.9783847245533864)]\n","step: 344, loss: 0.0008362203658598393\n","-------\n","ypred: [Value(data = 0.9808086270197013), Value(data = -0.97840568174295)]\n","step: 345, loss: 0.0008346233778557047\n","-------\n","ypred: [Value(data = 0.9808265827716101), Value(data = -0.9784265796446953)]\n","step: 346, loss: 0.0008330323940405972\n","-------\n","ypred: [Value(data = 0.9808444887033162), Value(data = -0.9784474185354132)]\n","step: 347, loss: 0.0008314473808250324\n","-------\n","ypred: [Value(data = 0.9808623450438788), Value(data = -0.9784681986900966)]\n","step: 348, loss: 0.0008298683048687074\n","-------\n","ypred: [Value(data = 0.9808801520208883), Value(data = -0.9784889203819551)]\n","step: 349, loss: 0.0008282951330782079\n","-------\n","ypred: [Value(data = 0.9808979098604781), Value(data = -0.978509583882429)]\n","step: 350, loss: 0.000826727832604774\n","-------\n","ypred: [Value(data = 0.9809156187873368), Value(data = -0.9785301894612052)]\n","step: 351, loss: 0.0008251663708419974\n","-------\n","ypred: [Value(data = 0.9809332790247199), Value(data = -0.9785507373862304)]\n","step: 352, loss: 0.0008236107154236372\n","-------\n","ypred: [Value(data = 0.980950890794462), Value(data = -0.9785712279237265)]\n","step: 353, loss: 0.0008220608342213917\n","-------\n","ypred: [Value(data = 0.9809684543169872), Value(data = -0.9785916613382046)]\n","step: 354, loss: 0.0008205166953427253\n","-------\n","ypred: [Value(data = 0.9809859698113222), Value(data = -0.978612037892479)]\n","step: 355, loss: 0.0008189782671287045\n","-------\n","ypred: [Value(data = 0.9810034374951062), Value(data = -0.9786323578476804)]\n","step: 356, loss: 0.0008174455181519204\n","-------\n","ypred: [Value(data = 0.9810208575846032), Value(data = -0.9786526214632709)]\n","step: 357, loss: 0.0008159184172143143\n","-------\n","ypred: [Value(data = 0.9810382302947126), Value(data = -0.9786728289970573)]\n","step: 358, loss: 0.0008143969333451141\n","-------\n","ypred: [Value(data = 0.9810555558389804), Value(data = -0.9786929807052042)]\n","step: 359, loss: 0.0008128810357987913\n","-------\n","ypred: [Value(data = 0.9810728344296101), Value(data = -0.9787130768422472)]\n","step: 360, loss: 0.0008113706940530252\n","-------\n","ypred: [Value(data = 0.9810900662774735), Value(data = -0.9787331176611075)]\n","step: 361, loss: 0.0008098658778066422\n","-------\n","ypred: [Value(data = 0.9811072515921215), Value(data = -0.9787531034131032)]\n","step: 362, loss: 0.0008083665569776823\n","-------\n","ypred: [Value(data = 0.9811243905817947), Value(data = -0.978773034347964)]\n","step: 363, loss: 0.0008068727017013561\n","-------\n","ypred: [Value(data = 0.9811414834534338), Value(data = -0.978792910713843)]\n","step: 364, loss: 0.0008053842823281472\n","-------\n","ypred: [Value(data = 0.98115853041269), Value(data = -0.9788127327573293)]\n","step: 365, loss: 0.0008039012694218769\n","-------\n","ypred: [Value(data = 0.9811755316639353), Value(data = -0.9788325007234614)]\n","step: 366, loss: 0.0008024236337577633\n","-------\n","ypred: [Value(data = 0.9811924874102732), Value(data = -0.9788522148557394)]\n","step: 367, loss: 0.0008009513463205426\n","-------\n","ypred: [Value(data = 0.9812093978535479), Value(data = -0.9788718753961372)]\n","step: 368, loss: 0.0007994843783026043\n","-------\n","ypred: [Value(data = 0.9812262631943548), Value(data = -0.9788914825851147)]\n","step: 369, loss: 0.0007980227011021527\n","-------\n","ypred: [Value(data = 0.9812430836320505), Value(data = -0.9789110366616299)]\n","step: 370, loss: 0.0007965662863213695\n","-------\n","ypred: [Value(data = 0.9812598593647627), Value(data = -0.9789305378631518)]\n","step: 371, loss: 0.0007951151057645547\n","-------\n","ypred: [Value(data = 0.9812765905893992), Value(data = -0.9789499864256708)]\n","step: 372, loss: 0.0007936691314364194\n","-------\n","ypred: [Value(data = 0.9812932775016584), Value(data = -0.9789693825837111)]\n","step: 373, loss: 0.0007922283355402723\n","-------\n","ypred: [Value(data = 0.9813099202960384), Value(data = -0.9789887265703434)]\n","step: 374, loss: 0.0007907926904762315\n","-------\n","ypred: [Value(data = 0.9813265191658462), Value(data = -0.9790080186171948)]\n","step: 375, loss: 0.0007893621688395492\n","-------\n","ypred: [Value(data = 0.9813430743032078), Value(data = -0.9790272589544613)]\n","step: 376, loss: 0.0007879367434188498\n","-------\n","ypred: [Value(data = 0.9813595858990767), Value(data = -0.9790464478109183)]\n","step: 377, loss: 0.0007865163871944706\n","-------\n","ypred: [Value(data = 0.9813760541432432), Value(data = -0.9790655854139327)]\n","step: 378, loss: 0.0007851010733367528\n","-------\n","ypred: [Value(data = 0.9813924792243441), Value(data = -0.9790846719894742)]\n","step: 379, loss: 0.0007836907752043478\n","-------\n","ypred: [Value(data = 0.981408861329871), Value(data = -0.9791037077621245)]\n","step: 380, loss: 0.0007822854663426593\n","-------\n","ypred: [Value(data = 0.9814252006461793), Value(data = -0.9791226929550901)]\n","step: 381, loss: 0.0007808851204821399\n","-------\n","ypred: [Value(data = 0.9814414973584974), Value(data = -0.9791416277902129)]\n","step: 382, loss: 0.0007794897115366798\n","-------\n","ypred: [Value(data = 0.9814577516509351), Value(data = -0.9791605124879791)]\n","step: 383, loss: 0.0007780992136020768\n","-------\n","ypred: [Value(data = 0.9814739637064924), Value(data = -0.9791793472675323)]\n","step: 384, loss: 0.0007767136009543743\n","-------\n","ypred: [Value(data = 0.9814901337070682), Value(data = -0.9791981323466823)]\n","step: 385, loss: 0.0007753328480483595\n","-------\n","ypred: [Value(data = 0.9815062618334683), Value(data = -0.9792168679419159)]\n","step: 386, loss: 0.000773956929515994\n","-------\n","ypred: [Value(data = 0.9815223482654145), Value(data = -0.9792355542684072)]\n","step: 387, loss: 0.0007725858201648905\n","-------\n","ypred: [Value(data = 0.9815383931815526), Value(data = -0.9792541915400284)]\n","step: 388, loss: 0.0007712194949767762\n","-------\n","ypred: [Value(data = 0.9815543967594604), Value(data = -0.9792727799693584)]\n","step: 389, loss: 0.000769857929106036\n","-------\n","ypred: [Value(data = 0.9815703591756564), Value(data = -0.9792913197676943)]\n","step: 390, loss: 0.0007685010978781999\n","-------\n","ypred: [Value(data = 0.9815862806056075), Value(data = -0.9793098111450612)]\n","step: 391, loss: 0.0007671489767884601\n","-------\n","ypred: [Value(data = 0.9816021612237372), Value(data = -0.9793282543102205)]\n","step: 392, loss: 0.0007658015415002745\n","-------\n","ypred: [Value(data = 0.9816180012034338), Value(data = -0.9793466494706816)]\n","step: 393, loss: 0.0007644587678438576\n","-------\n","ypred: [Value(data = 0.9816338007170574), Value(data = -0.9793649968327099)]\n","step: 394, loss: 0.0007631206318148314\n","-------\n","ypred: [Value(data = 0.9816495599359492), Value(data = -0.9793832966013373)]\n","step: 395, loss: 0.0007617871095727536\n","-------\n","ypred: [Value(data = 0.9816652790304374), Value(data = -0.9794015489803718)]\n","step: 396, loss: 0.0007604581774397396\n","-------\n","ypred: [Value(data = 0.9816809581698466), Value(data = -0.9794197541724057)]\n","step: 397, loss: 0.0007591338118991245\n","-------\n","ypred: [Value(data = 0.9816965975225044), Value(data = -0.9794379123788259)]\n","step: 398, loss: 0.0007578139895940326\n","-------\n","ypred: [Value(data = 0.9817121972557488), Value(data = -0.9794560237998234)]\n","step: 399, loss: 0.0007564986873260641\n","-------\n","ypred: [Value(data = 0.9817277575359366), Value(data = -0.9794740886344009)]\n","step: 400, loss: 0.0007551878820539543\n","-------\n","ypred: [Value(data = 0.9817432785284496), Value(data = -0.9794921070803835)]\n","step: 401, loss: 0.0007538815508922284\n","-------\n","ypred: [Value(data = 0.9817587603977029), Value(data = -0.9795100793344259)]\n","step: 402, loss: 0.000752579671109931\n","-------\n","ypred: [Value(data = 0.9817742033071517), Value(data = -0.9795280055920232)]\n","step: 403, loss: 0.0007512822201292714\n","-------\n","ypred: [Value(data = 0.9817896074192983), Value(data = -0.9795458860475186)]\n","step: 404, loss: 0.0007499891755243697\n","-------\n","ypred: [Value(data = 0.9818049728956997), Value(data = -0.9795637208941113)]\n","step: 405, loss: 0.0007487005150200081\n","-------\n","ypred: [Value(data = 0.9818202998969744), Value(data = -0.9795815103238668)]\n","step: 406, loss: 0.0007474162164903093\n","-------\n","ypred: [Value(data = 0.9818355885828092), Value(data = -0.9795992545277242)]\n","step: 407, loss: 0.000746136257957553\n","-------\n","ypred: [Value(data = 0.9818508391119665), Value(data = -0.9796169536955057)]\n","step: 408, loss: 0.000744860617590884\n","-------\n","ypred: [Value(data = 0.981866051642291), Value(data = -0.9796346080159234)]\n","step: 409, loss: 0.0007435892737051482\n","-------\n","ypred: [Value(data = 0.9818812263307165), Value(data = -0.9796522176765892)]\n","step: 410, loss: 0.0007423222047596312\n","-------\n","ypred: [Value(data = 0.9818963633332725), Value(data = -0.979669782864022)]\n","step: 411, loss: 0.0007410593893568973\n","-------\n","ypred: [Value(data = 0.9819114628050911), Value(data = -0.9796873037636566)]\n","step: 412, loss: 0.0007398008062415595\n","-------\n","ypred: [Value(data = 0.9819265249004137), Value(data = -0.9797047805598512)]\n","step: 413, loss: 0.0007385464342991607\n","-------\n","ypred: [Value(data = 0.9819415497725971), Value(data = -0.9797222134358954)]\n","step: 414, loss: 0.0007372962525549708\n","-------\n","ypred: [Value(data = 0.9819565375741204), Value(data = -0.9797396025740185)]\n","step: 415, loss: 0.000736050240172848\n","-------\n","ypred: [Value(data = 0.9819714884565913), Value(data = -0.979756948155397)]\n","step: 416, loss: 0.0007348083764541029\n","-------\n","ypred: [Value(data = 0.9819864025707529), Value(data = -0.9797742503601632)]\n","step: 417, loss: 0.0007335706408363376\n","-------\n","ypred: [Value(data = 0.982001280066489), Value(data = -0.9797915093674114)]\n","step: 418, loss: 0.0007323370128923853\n","-------\n","ypred: [Value(data = 0.9820161210928315), Value(data = -0.9798087253552069)]\n","step: 419, loss: 0.0007311074723291629\n","-------\n","ypred: [Value(data = 0.982030925797966), Value(data = -0.9798258985005931)]\n","step: 420, loss: 0.0007298819989865748\n","-------\n","ypred: [Value(data = 0.9820456943292382), Value(data = -0.9798430289795986)]\n","step: 421, loss: 0.0007286605728364513\n","-------\n","ypred: [Value(data = 0.9820604268331595), Value(data = -0.9798601169672456)]\n","step: 422, loss: 0.0007274431739814505\n","-------\n","ypred: [Value(data = 0.9820751234554139), Value(data = -0.9798771626375564)]\n","step: 423, loss: 0.0007262297826540074\n","-------\n","ypred: [Value(data = 0.9820897843408636), Value(data = -0.9798941661635613)]\n","step: 424, loss: 0.0007250203792152593\n","-------\n","ypred: [Value(data = 0.9821044096335544), Value(data = -0.9799111277173052)]\n","step: 425, loss: 0.0007238149441540463\n","-------\n","ypred: [Value(data = 0.9821189994767224), Value(data = -0.9799280474698556)]\n","step: 426, loss: 0.0007226134580858219\n","-------\n","ypred: [Value(data = 0.9821335540127998), Value(data = -0.9799449255913089)]\n","step: 427, loss: 0.0007214159017516812\n","-------\n","ypred: [Value(data = 0.9821480733834198), Value(data = -0.9799617622507979)]\n","step: 428, loss: 0.0007202222560173126\n","-------\n","ypred: [Value(data = 0.9821625577294236), Value(data = -0.9799785576164988)]\n","step: 429, loss: 0.0007190325018720043\n","-------\n","ypred: [Value(data = 0.9821770071908649), Value(data = -0.9799953118556385)]\n","step: 430, loss: 0.0007178466204276408\n","-------\n","ypred: [Value(data = 0.9821914219070165), Value(data = -0.9800120251344999)]\n","step: 431, loss: 0.0007166645929177558\n","-------\n","ypred: [Value(data = 0.9822058020163751), Value(data = -0.9800286976184313)]\n","step: 432, loss: 0.0007154864006964944\n","-------\n","ypred: [Value(data = 0.9822201476566675), Value(data = -0.98004532947185)]\n","step: 433, loss: 0.0007143120252377242\n","-------\n","ypred: [Value(data = 0.9822344589648558), Value(data = -0.9800619208582523)]\n","step: 434, loss: 0.0007131414481339867\n","-------\n","ypred: [Value(data = 0.9822487360771427), Value(data = -0.9800784719402176)]\n","step: 435, loss: 0.0007119746510956339\n","-------\n","ypred: [Value(data = 0.9822629791289771), Value(data = -0.9800949828794159)]\n","step: 436, loss: 0.0007108116159498495\n","-------\n","ypred: [Value(data = 0.9822771882550594), Value(data = -0.9801114538366142)]\n","step: 437, loss: 0.0007096523246397312\n","-------\n","ypred: [Value(data = 0.9822913635893468), Value(data = -0.9801278849716838)]\n","step: 438, loss: 0.0007084967592233442\n","-------\n","ypred: [Value(data = 0.9823055052650587), Value(data = -0.9801442764436049)]\n","step: 439, loss: 0.0007073449018728495\n","-------\n","ypred: [Value(data = 0.9823196134146813), Value(data = -0.9801606284104748)]\n","step: 440, loss: 0.0007061967348735762\n","-------\n","ypred: [Value(data = 0.982333688169974), Value(data = -0.9801769410295131)]\n","step: 441, loss: 0.0007050522406231157\n","-------\n","ypred: [Value(data = 0.9823477296619731), Value(data = -0.9801932144570681)]\n","step: 442, loss: 0.0007039114016304794\n","-------\n","ypred: [Value(data = 0.982361738020998), Value(data = -0.9802094488486229)]\n","step: 443, loss: 0.0007027742005151789\n","-------\n","ypred: [Value(data = 0.9823757133766553), Value(data = -0.9802256443588026)]\n","step: 444, loss: 0.0007016406200063643\n","-------\n","ypred: [Value(data = 0.9823896558578445), Value(data = -0.9802418011413784)]\n","step: 445, loss: 0.0007005106429419858\n","-------\n","ypred: [Value(data = 0.9824035655927632), Value(data = -0.9802579193492755)]\n","step: 446, loss: 0.0006993842522678964\n","-------\n","ypred: [Value(data = 0.9824174427089106), Value(data = -0.9802739991345779)]\n","step: 447, loss: 0.0006982614310370732\n","-------\n","ypred: [Value(data = 0.982431287333094), Value(data = -0.980290040648535)]\n","step: 448, loss: 0.0006971421624087054\n","-------\n","ypred: [Value(data = 0.9824450995914327), Value(data = -0.980306044041567)]\n","step: 449, loss: 0.0006960264296474177\n","-------\n","ypred: [Value(data = 0.982458879609363), Value(data = -0.9803220094632707)]\n","step: 450, loss: 0.0006949142161224286\n","-------\n","ypred: [Value(data = 0.9824726275116429), Value(data = -0.9803379370624262)]\n","step: 451, loss: 0.0006938055053067303\n","-------\n","ypred: [Value(data = 0.982486343422357), Value(data = -0.9803538269870012)]\n","step: 452, loss: 0.0006927002807762999\n","-------\n","ypred: [Value(data = 0.9825000274649207), Value(data = -0.9803696793841574)]\n","step: 453, loss: 0.0006915985262093035\n","-------\n","ypred: [Value(data = 0.9825136797620856), Value(data = -0.9803854944002566)]\n","step: 454, loss: 0.0006905002253852613\n","-------\n","ypred: [Value(data = 0.9825273004359432), Value(data = -0.9804012721808653)]\n","step: 455, loss: 0.000689405362184318\n","-------\n","ypred: [Value(data = 0.9825408896079301), Value(data = -0.9804170128707606)]\n","step: 456, loss: 0.0006883139205864422\n","-------\n","ypred: [Value(data = 0.9825544473988321), Value(data = -0.9804327166139363)]\n","step: 457, loss: 0.0006872258846706405\n","-------\n","ypred: [Value(data = 0.9825679739287893), Value(data = -0.9804483835536077)]\n","step: 458, loss: 0.0006861412386142071\n","-------\n","ypred: [Value(data = 0.9825814693172993), Value(data = -0.9804640138322165)]\n","step: 459, loss: 0.0006850599666920151\n","-------\n","ypred: [Value(data = 0.982594933683223), Value(data = -0.9804796075914373)]\n","step: 460, loss: 0.0006839820532756778\n","-------\n","ypred: [Value(data = 0.9826083671447882), Value(data = -0.9804951649721824)]\n","step: 461, loss: 0.0006829074828328656\n","-------\n","ypred: [Value(data = 0.9826217698195939), Value(data = -0.9805106861146067)]\n","step: 462, loss: 0.0006818362399265614\n","-------\n","ypred: [Value(data = 0.9826351418246149), Value(data = -0.9805261711581131)]\n","step: 463, loss: 0.0006807683092143447\n","-------\n","ypred: [Value(data = 0.9826484832762057), Value(data = -0.9805416202413583)]\n","step: 464, loss: 0.000679703675447632\n","-------\n","ypred: [Value(data = 0.9826617942901051), Value(data = -0.980557033502257)]\n","step: 465, loss: 0.0006786423234709882\n","-------\n","ypred: [Value(data = 0.9826750749814402), Value(data = -0.9805724110779871)]\n","step: 466, loss: 0.0006775842382214363\n","-------\n","ypred: [Value(data = 0.9826883254647304), Value(data = -0.9805877531049957)]\n","step: 467, loss: 0.0006765294047277068\n","-------\n","ypred: [Value(data = 0.9827015458538917), Value(data = -0.9806030597190031)]\n","step: 468, loss: 0.0006754778081095728\n","-------\n","ypred: [Value(data = 0.9827147362622407), Value(data = -0.9806183310550076)]\n","step: 469, loss: 0.0006744294335771784\n","-------\n","ypred: [Value(data = 0.9827278968024987), Value(data = -0.9806335672472917)]\n","step: 470, loss: 0.0006733842664303077\n","-------\n","ypred: [Value(data = 0.9827410275867957), Value(data = -0.9806487684294255)]\n","step: 471, loss: 0.0006723422920577459\n","-------\n","ypred: [Value(data = 0.9827541287266742), Value(data = -0.9806639347342726)]\n","step: 472, loss: 0.0006713034959365927\n","-------\n","ypred: [Value(data = 0.9827672003330937), Value(data = -0.9806790662939942)]\n","step: 473, loss: 0.0006702678636315979\n","-------\n","ypred: [Value(data = 0.9827802425164337), Value(data = -0.9806941632400541)]\n","step: 474, loss: 0.0006692353807945162\n","-------\n","ypred: [Value(data = 0.9827932553864985), Value(data = -0.9807092257032237)]\n","step: 475, loss: 0.0006682060331634262\n","-------\n","ypred: [Value(data = 0.9828062390525204), Value(data = -0.9807242538135863)]\n","step: 476, loss: 0.0006671798065621167\n","-------\n","ypred: [Value(data = 0.9828191936231638), Value(data = -0.9807392477005414)]\n","step: 477, loss: 0.0006661566868994325\n","-------\n","ypred: [Value(data = 0.9828321192065291), Value(data = -0.9807542074928106)]\n","step: 478, loss: 0.0006651366601686131\n","-------\n","ypred: [Value(data = 0.9828450159101562), Value(data = -0.9807691333184406)]\n","step: 479, loss: 0.0006641197124467059\n","-------\n","ypred: [Value(data = 0.9828578838410283), Value(data = -0.9807840253048086)]\n","step: 480, loss: 0.0006631058298939144\n","-------\n","ypred: [Value(data = 0.9828707231055757), Value(data = -0.9807988835786267)]\n","step: 481, loss: 0.0006620949987529926\n","-------\n","ypred: [Value(data = 0.9828835338096793), Value(data = -0.9808137082659464)]\n","step: 482, loss: 0.0006610872053486058\n","-------\n","ypred: [Value(data = 0.9828963160586746), Value(data = -0.9808284994921624)]\n","step: 483, loss: 0.0006600824360867695\n","-------\n","ypred: [Value(data = 0.9829090699573545), Value(data = -0.9808432573820179)]\n","step: 484, loss: 0.0006590806774542128\n","-------\n","ypred: [Value(data = 0.9829217956099738), Value(data = -0.9808579820596087)]\n","step: 485, loss: 0.0006580819160177703\n","-------\n","ypred: [Value(data = 0.9829344931202526), Value(data = -0.9808726736483864)]\n","step: 486, loss: 0.0006570861384238387\n","-------\n","ypred: [Value(data = 0.9829471625913789), Value(data = -0.980887332271164)]\n","step: 487, loss: 0.0006560933313977559\n","-------\n","ypred: [Value(data = 0.9829598041260134), Value(data = -0.9809019580501205)]\n","step: 488, loss: 0.0006551034817431893\n","-------\n","ypred: [Value(data = 0.982972417826292), Value(data = -0.9809165511068031)]\n","step: 489, loss: 0.000654116576341638\n","-------\n","ypred: [Value(data = 0.9829850037938295), Value(data = -0.9809311115621331)]\n","step: 490, loss: 0.000653132602151812\n","-------\n","ypred: [Value(data = 0.9829975621297234), Value(data = -0.9809456395364097)]\n","step: 491, loss: 0.0006521515462090485\n","-------\n","ypred: [Value(data = 0.9830100929345569), Value(data = -0.9809601351493137)]\n","step: 492, loss: 0.0006511733956247943\n","-------\n","ypred: [Value(data = 0.983022596308402), Value(data = -0.9809745985199114)]\n","step: 493, loss: 0.0006501981375860403\n","-------\n","ypred: [Value(data = 0.9830350723508237), Value(data = -0.98098902976666)]\n","step: 494, loss: 0.0006492257593547265\n","-------\n","ypred: [Value(data = 0.9830475211608819), Value(data = -0.9810034290074098)]\n","step: 495, loss: 0.0006482562482672673\n","-------\n","ypred: [Value(data = 0.9830599428371364), Value(data = -0.9810177963594091)]\n","step: 496, loss: 0.0006472895917339491\n","-------\n","ypred: [Value(data = 0.9830723374776488), Value(data = -0.9810321319393084)]\n","step: 497, loss: 0.0006463257772384195\n","-------\n","ypred: [Value(data = 0.9830847051799863), Value(data = -0.9810464358631635)]\n","step: 498, loss: 0.0006453647923371574\n","-------\n","ypred: [Value(data = 0.9830970460412247), Value(data = -0.9810607082464402)]\n","step: 499, loss: 0.000644406624658935\n","-------\n","ypred: [Value(data = 0.9831093601579519), Value(data = -0.9810749492040174)]\n","step: 500, loss: 0.0006434512619043042\n","-------\n","ypred: [Value(data = 0.9831216476262706), Value(data = -0.9810891588501918)]\n","step: 501, loss: 0.0006424986918450561\n","-------\n","ypred: [Value(data = 0.9831339085418017), Value(data = -0.9811033372986803)]\n","step: 502, loss: 0.0006415489023237575\n","-------\n","ypred: [Value(data = 0.9831461429996873), Value(data = -0.9811174846626256)]\n","step: 503, loss: 0.0006406018812531694\n","-------\n","ypred: [Value(data = 0.9831583510945939), Value(data = -0.9811316010545985)]\n","step: 504, loss: 0.0006396576166157934\n","-------\n","ypred: [Value(data = 0.9831705329207152), Value(data = -0.9811456865866018)]\n","step: 505, loss: 0.0006387160964633762\n","-------\n","ypred: [Value(data = 0.9831826885717756), Value(data = -0.981159741370075)]\n","step: 506, loss: 0.0006377773089163505\n","-------\n","ypred: [Value(data = 0.9831948181410324), Value(data = -0.9811737655158961)]\n","step: 507, loss: 0.0006368412421634381\n","-------\n","ypred: [Value(data = 0.9832069217212798), Value(data = -0.9811877591343872)]\n","step: 508, loss: 0.0006359078844610589\n","-------\n","ypred: [Value(data = 0.9832189994048508), Value(data = -0.9812017223353163)]\n","step: 509, loss: 0.0006349772241329427\n","-------\n","ypred: [Value(data = 0.9832310512836211), Value(data = -0.9812156552279028)]\n","step: 510, loss: 0.0006340492495695622\n","-------\n","ypred: [Value(data = 0.9832430774490114), Value(data = -0.9812295579208185)]\n","step: 511, loss: 0.0006331239492277396\n","-------\n","ypred: [Value(data = 0.9832550779919904), Value(data = -0.981243430522194)]\n","step: 512, loss: 0.0006322013116300883\n","-------\n","ypred: [Value(data = 0.9832670530030777), Value(data = -0.9812572731396196)]\n","step: 513, loss: 0.0006312813253646344\n","-------\n","ypred: [Value(data = 0.9832790025723469), Value(data = -0.9812710858801503)]\n","step: 514, loss: 0.0006303639790842858\n","-------\n","ypred: [Value(data = 0.9832909267894279), Value(data = -0.9812848688503089)]\n","step: 515, loss: 0.0006294492615063991\n","-------\n","ypred: [Value(data = 0.98330282574351), Value(data = -0.9812986221560891)]\n","step: 516, loss: 0.0006285371614123134\n","-------\n","ypred: [Value(data = 0.9833146995233449), Value(data = -0.9813123459029586)]\n","step: 517, loss: 0.000627627667646935\n","-------\n","ypred: [Value(data = 0.9833265482172491), Value(data = -0.9813260401958631)]\n","step: 518, loss: 0.0006267207691182401\n","-------\n","ypred: [Value(data = 0.9833383719131066), Value(data = -0.9813397051392302)]\n","step: 519, loss: 0.000625816454796828\n","-------\n","ypred: [Value(data = 0.9833501706983719), Value(data = -0.9813533408369705)]\n","step: 520, loss: 0.0006249147137155459\n","-------\n","ypred: [Value(data = 0.9833619446600728), Value(data = -0.9813669473924832)]\n","step: 521, loss: 0.0006240155349689698\n","-------\n","ypred: [Value(data = 0.9833736938848123), Value(data = -0.9813805249086578)]\n","step: 522, loss: 0.0006231189077130399\n","-------\n","ypred: [Value(data = 0.9833854184587723), Value(data = -0.981394073487878)]\n","step: 523, loss: 0.0006222248211645903\n","-------\n","ypred: [Value(data = 0.9833971184677153), Value(data = -0.9814075932320249)]\n","step: 524, loss: 0.0006213332646009289\n","-------\n","ypred: [Value(data = 0.9834087939969878), Value(data = -0.98142108424248)]\n","step: 525, loss: 0.0006204442273594147\n","-------\n","ypred: [Value(data = 0.9834204451315223), Value(data = -0.9814345466201283)]\n","step: 526, loss: 0.0006195576988370531\n","-------\n","ypred: [Value(data = 0.9834320719558403), Value(data = -0.981447980465361)]\n","step: 527, loss: 0.0006186736684900831\n","-------\n","ypred: [Value(data = 0.9834436745540541), Value(data = -0.9814613858780797)]\n","step: 528, loss: 0.0006177921258335361\n","-------\n","ypred: [Value(data = 0.9834552530098709), Value(data = -0.9814747629576988)]\n","step: 529, loss: 0.0006169130604408358\n","-------\n","ypred: [Value(data = 0.9834668074065932), Value(data = -0.9814881118031481)]\n","step: 530, loss: 0.0006160364619434261\n","-------\n","ypred: [Value(data = 0.9834783378271231), Value(data = -0.9815014325128768)]\n","step: 531, loss: 0.000615162320030322\n","-------\n","ypred: [Value(data = 0.9834898443539639), Value(data = -0.9815147251848552)]\n","step: 532, loss: 0.0006142906244477652\n","-------\n","ypred: [Value(data = 0.9835013270692227), Value(data = -0.9815279899165794)]\n","step: 533, loss: 0.0006134213649987566\n","-------\n","ypred: [Value(data = 0.9835127860546127), Value(data = -0.9815412268050729)]\n","step: 534, loss: 0.0006125545315427319\n","-------\n","ypred: [Value(data = 0.9835242213914561), Value(data = -0.9815544359468898)]\n","step: 535, loss: 0.0006116901139951415\n","-------\n","ypred: [Value(data = 0.983535633160686), Value(data = -0.9815676174381177)]\n","step: 536, loss: 0.0006108281023270834\n","-------\n","ypred: [Value(data = 0.9835470214428492), Value(data = -0.9815807713743813)]\n","step: 537, loss: 0.0006099684865648759\n","-------\n","ypred: [Value(data = 0.983558386318108), Value(data = -0.9815938978508444)]\n","step: 538, loss: 0.0006091112567897293\n","-------\n","ypred: [Value(data = 0.9835697278662432), Value(data = -0.9816069969622128)]\n","step: 539, loss: 0.0006082564031373559\n","-------\n","ypred: [Value(data = 0.983581046166656), Value(data = -0.9816200688027373)]\n","step: 540, loss: 0.0006074039157975917\n","-------\n","ypred: [Value(data = 0.9835923412983704), Value(data = -0.9816331134662175)]\n","step: 541, loss: 0.0006065537850140033\n","-------\n","ypred: [Value(data = 0.9836036133400355), Value(data = -0.9816461310460023)]\n","step: 542, loss: 0.0006057060010835815\n","-------\n","ypred: [Value(data = 0.9836148623699283), Value(data = -0.981659121634995)]\n","step: 543, loss: 0.0006048605543562978\n","-------\n","ypred: [Value(data = 0.9836260884659548), Value(data = -0.9816720853256546)]\n","step: 544, loss: 0.0006040174352348229\n","-------\n","ypred: [Value(data = 0.9836372917056534), Value(data = -0.9816850222099989)]\n","step: 545, loss: 0.0006031766341741139\n","-------\n","ypred: [Value(data = 0.9836484721661964), Value(data = -0.9816979323796076)]\n","step: 546, loss: 0.0006023381416810698\n","-------\n","ypred: [Value(data = 0.9836596299243929), Value(data = -0.981710815925624)]\n","step: 547, loss: 0.0006015019483142023\n","-------\n","ypred: [Value(data = 0.9836707650566899), Value(data = -0.9817236729387587)]\n","step: 548, loss: 0.0006006680446832785\n","-------\n","ypred: [Value(data = 0.9836818776391757), Value(data = -0.9817365035092921)]\n","step: 549, loss: 0.0005998364214489343\n","-------\n","ypred: [Value(data = 0.9836929677475814), Value(data = -0.981749307727076)]\n","step: 550, loss: 0.0005990070693223868\n","-------\n","ypred: [Value(data = 0.9837040354572831), Value(data = -0.9817620856815374)]\n","step: 551, loss: 0.0005981799790650669\n","-------\n","ypred: [Value(data = 0.9837150808433042), Value(data = -0.9817748374616806)]\n","step: 552, loss: 0.00059735514148828\n","-------\n","ypred: [Value(data = 0.9837261039803171), Value(data = -0.9817875631560896)]\n","step: 553, loss: 0.0005965325474528746\n","-------\n","ypred: [Value(data = 0.9837371049426462), Value(data = -0.9818002628529308)]\n","step: 554, loss: 0.0005957121878689142\n","-------\n","ypred: [Value(data = 0.9837480838042689), Value(data = -0.9818129366399557)]\n","step: 555, loss: 0.0005948940536953311\n","-------\n","ypred: [Value(data = 0.9837590406388185), Value(data = -0.9818255846045031)]\n","step: 556, loss: 0.0005940781359396251\n","-------\n","ypred: [Value(data = 0.9837699755195858), Value(data = -0.9818382068335018)]\n","step: 557, loss: 0.0005932644256575071\n","-------\n","ypred: [Value(data = 0.9837808885195212), Value(data = -0.9818508034134725)]\n","step: 558, loss: 0.0005924529139526207\n","-------\n","ypred: [Value(data = 0.9837917797112371), Value(data = -0.9818633744305317)]\n","step: 559, loss: 0.0005916435919761554\n","-------\n","ypred: [Value(data = 0.9838026491670092), Value(data = -0.9818759199703924)]\n","step: 560, loss: 0.0005908364509266096\n","-------\n","ypred: [Value(data = 0.9838134969587794), Value(data = -0.9818884401183675)]\n","step: 561, loss: 0.0005900314820494032\n","-------\n","ypred: [Value(data = 0.983824323158157), Value(data = -0.9819009349593717)]\n","step: 562, loss: 0.0005892286766366281\n","-------\n","ypred: [Value(data = 0.9838351278364209), Value(data = -0.9819134045779248)]\n","step: 563, loss: 0.0005884280260266874\n","-------\n","ypred: [Value(data = 0.9838459110645219), Value(data = -0.9819258490581526)]\n","step: 564, loss: 0.0005876295216040188\n","-------\n","ypred: [Value(data = 0.9838566729130842), Value(data = -0.9819382684837908)]\n","step: 565, loss: 0.0005868331547987723\n","-------\n","ypred: [Value(data = 0.9838674134524075), Value(data = -0.9819506629381861)]\n","step: 566, loss: 0.0005860389170865318\n","-------\n","ypred: [Value(data = 0.9838781327524688), Value(data = -0.981963032504299)]\n","step: 567, loss: 0.0005852467999879947\n","-------\n","ypred: [Value(data = 0.9838888308829247), Value(data = -0.9819753772647063)]\n","step: 568, loss: 0.0005844567950686686\n","-------\n","ypred: [Value(data = 0.9838995079131128), Value(data = -0.9819876973016031)]\n","step: 569, loss: 0.0005836688939385961\n","-------\n","ypred: [Value(data = 0.9839101639120537), Value(data = -0.9819999926968046)]\n","step: 570, loss: 0.0005828830882520681\n","-------\n","ypred: [Value(data = 0.9839207989484529), Value(data = -0.98201226353175)]\n","step: 571, loss: 0.0005820993697072867\n","-------\n","ypred: [Value(data = 0.9839314130907029), Value(data = -0.9820245098875025)]\n","step: 572, loss: 0.0005813177300461323\n","-------\n","ypred: [Value(data = 0.9839420064068847), Value(data = -0.9820367318447529)]\n","step: 573, loss: 0.0005805381610538464\n","-------\n","ypred: [Value(data = 0.9839525789647694), Value(data = -0.982048929483822)]\n","step: 574, loss: 0.0005797606545587548\n","-------\n","ypred: [Value(data = 0.9839631308318209), Value(data = -0.9820611028846614)]\n","step: 575, loss: 0.0005789852024319978\n","-------\n","ypred: [Value(data = 0.9839736620751965), Value(data = -0.9820732521268573)]\n","step: 576, loss: 0.0005782117965872216\n","-------\n","ypred: [Value(data = 0.9839841727617499), Value(data = -0.9820853772896312)]\n","step: 577, loss: 0.0005774404289803365\n","-------\n","ypred: [Value(data = 0.9839946629580317), Value(data = -0.9820974784518435)]\n","step: 578, loss: 0.0005766710916092103\n","-------\n","ypred: [Value(data = 0.9840051327302924), Value(data = -0.9821095556919943)]\n","step: 579, loss: 0.000575903776513415\n","-------\n","ypred: [Value(data = 0.9840155821444834), Value(data = -0.9821216090882259)]\n","step: 580, loss: 0.0005751384757739664\n","-------\n","ypred: [Value(data = 0.9840260112662584), Value(data = -0.9821336387183256)]\n","step: 581, loss: 0.0005743751815130167\n","-------\n","ypred: [Value(data = 0.9840364201609765), Value(data = -0.9821456446597269)]\n","step: 582, loss: 0.000573613885893618\n","-------\n","ypred: [Value(data = 0.9840468088937021), Value(data = -0.9821576269895116)]\n","step: 583, loss: 0.0005728545811194675\n","-------\n","ypred: [Value(data = 0.9840571775292082), Value(data = -0.9821695857844123)]\n","step: 584, loss: 0.0005720972594346176\n","-------\n","ypred: [Value(data = 0.9840675261319769), Value(data = -0.9821815211208144)]\n","step: 585, loss: 0.0005713419131232237\n","-------\n","ypred: [Value(data = 0.9840778547662019), Value(data = -0.9821934330747576)]\n","step: 586, loss: 0.0005705885345092961\n","-------\n","ypred: [Value(data = 0.9840881634957898), Value(data = -0.9822053217219386)]\n","step: 587, loss: 0.0005698371159564264\n","-------\n","ypred: [Value(data = 0.9840984523843614), Value(data = -0.9822171871377128)]\n","step: 588, loss: 0.0005690876498675481\n","-------\n","ypred: [Value(data = 0.9841087214952541), Value(data = -0.9822290293970957)]\n","step: 589, loss: 0.0005683401286846897\n","-------\n","ypred: [Value(data = 0.9841189708915229), Value(data = -0.9822408485747655)]\n","step: 590, loss: 0.0005675945448887073\n","-------\n","ypred: [Value(data = 0.9841292006359423), Value(data = -0.9822526447450655)]\n","step: 591, loss: 0.0005668508909990257\n","-------\n","ypred: [Value(data = 0.984139410791008), Value(data = -0.9822644179820044)]\n","step: 592, loss: 0.0005661091595734443\n","-------\n","ypred: [Value(data = 0.9841496014189378), Value(data = -0.9822761683592601)]\n","step: 593, loss: 0.00056536934320783\n","-------\n","ypred: [Value(data = 0.9841597725816744), Value(data = -0.9822878959501805)]\n","step: 594, loss: 0.0005646314345359054\n","-------\n","ypred: [Value(data = 0.9841699243408859), Value(data = -0.9822996008277856)]\n","step: 595, loss: 0.0005638954262290063\n","-------\n","ypred: [Value(data = 0.9841800567579676), Value(data = -0.9823112830647692)]\n","step: 596, loss: 0.0005631613109958464\n","-------\n","ypred: [Value(data = 0.984190169894044), Value(data = -0.9823229427335017)]\n","step: 597, loss: 0.0005624290815822532\n","-------\n","ypred: [Value(data = 0.9842002638099697), Value(data = -0.9823345799060306)]\n","step: 598, loss: 0.0005616987307709714\n","-------\n","ypred: [Value(data = 0.9842103385663316), Value(data = -0.9823461946540831)]\n","step: 599, loss: 0.0005609702513813998\n","-------\n","ypred: [Value(data = 0.9842203942234496), Value(data = -0.982357787049068)]\n","step: 600, loss: 0.0005602436362693757\n","-------\n","ypred: [Value(data = 0.9842304308413791), Value(data = -0.9823693571620766)]\n","step: 601, loss: 0.0005595188783269471\n","-------\n","ypred: [Value(data = 0.9842404484799113), Value(data = -0.9823809050638868)]\n","step: 602, loss: 0.0005587959704821007\n","-------\n","ypred: [Value(data = 0.9842504471985759), Value(data = -0.9823924308249614)]\n","step: 603, loss: 0.0005580749056986144\n","-------\n","ypred: [Value(data = 0.9842604270566419), Value(data = -0.9824039345154533)]\n","step: 604, loss: 0.0005573556769757487\n","-------\n","ypred: [Value(data = 0.9842703881131188), Value(data = -0.9824154162052047)]\n","step: 605, loss: 0.0005566382773480915\n","-------\n","ypred: [Value(data = 0.9842803304267588), Value(data = -0.9824268759637508)]\n","step: 606, loss: 0.000555922699885286\n","-------\n","ypred: [Value(data = 0.9842902540560579), Value(data = -0.9824383138603197)]\n","step: 607, loss: 0.0005552089376918473\n","-------\n","ypred: [Value(data = 0.9843001590592568), Value(data = -0.9824497299638358)]\n","step: 608, loss: 0.000554496983906917\n","-------\n","ypred: [Value(data = 0.9843100454943435), Value(data = -0.9824611243429203)]\n","step: 609, loss: 0.0005537868317040718\n","-------\n","ypred: [Value(data = 0.9843199134190536), Value(data = -0.9824724970658938)]\n","step: 610, loss: 0.0005530784742910785\n","-------\n","ypred: [Value(data = 0.9843297628908723), Value(data = -0.9824838482007775)]\n","step: 611, loss: 0.0005523719049096898\n","-------\n","ypred: [Value(data = 0.9843395939670354), Value(data = -0.9824951778152943)]\n","step: 612, loss: 0.0005516671168354795\n","-------\n","ypred: [Value(data = 0.9843494067045313), Value(data = -0.9825064859768722)]\n","step: 613, loss: 0.0005509641033775394\n","-------\n","ypred: [Value(data = 0.9843592011601018), Value(data = -0.9825177727526438)]\n","step: 614, loss: 0.0005502628578783633\n","-------\n","ypred: [Value(data = 0.9843689773902436), Value(data = -0.9825290382094503)]\n","step: 615, loss: 0.0005495633737135633\n","-------\n","ypred: [Value(data = 0.98437873545121), Value(data = -0.9825402824138402)]\n","step: 616, loss: 0.0005488656442917414\n","-------\n","ypred: [Value(data = 0.9843884753990115), Value(data = -0.982551505432074)]\n","step: 617, loss: 0.0005481696630542101\n","-------\n","ypred: [Value(data = 0.9843981972894178), Value(data = -0.9825627073301237)]\n","step: 618, loss: 0.0005474754234748504\n","-------\n","ypred: [Value(data = 0.9844079011779595), Value(data = -0.9825738881736756)]\n","step: 619, loss: 0.0005467829190598383\n","-------\n","ypred: [Value(data = 0.9844175871199278), Value(data = -0.9825850480281306)]\n","step: 620, loss: 0.0005460921433475579\n","-------\n","ypred: [Value(data = 0.9844272551703779), Value(data = -0.9825961869586075)]\n","step: 621, loss: 0.0005454030899082658\n","-------\n","ypred: [Value(data = 0.9844369053841285), Value(data = -0.9826073050299431)]\n","step: 622, loss: 0.0005447157523440103\n","-------\n","ypred: [Value(data = 0.9844465378157645), Value(data = -0.9826184023066941)]\n","step: 623, loss: 0.0005440301242883814\n","-------\n","ypred: [Value(data = 0.9844561525196369), Value(data = -0.9826294788531392)]\n","step: 624, loss: 0.0005433461994063271\n","-------\n","ypred: [Value(data = 0.9844657495498659), Value(data = -0.9826405347332804)]\n","step: 625, loss: 0.0005426639713939367\n","-------\n","ypred: [Value(data = 0.9844753289603402), Value(data = -0.982651570010844)]\n","step: 626, loss: 0.0005419834339782988\n","-------\n","ypred: [Value(data = 0.9844848908047192), Value(data = -0.982662584749283)]\n","step: 627, loss: 0.0005413045809172791\n","-------\n","ypred: [Value(data = 0.9844944351364346), Value(data = -0.9826735790117777)]\n","step: 628, loss: 0.0005406274059993444\n","-------\n","ypred: [Value(data = 0.9845039620086914), Value(data = -0.9826845528612378)]\n","step: 629, loss: 0.0005399519030433481\n","-------\n","ypred: [Value(data = 0.9845134714744684), Value(data = -0.9826955063603038)]\n","step: 630, loss: 0.0005392780658983896\n","-------\n","ypred: [Value(data = 0.9845229635865206), Value(data = -0.9827064395713483)]\n","step: 631, loss: 0.0005386058884435962\n","-------\n","ypred: [Value(data = 0.9845324383973794), Value(data = -0.9827173525564779)]\n","step: 632, loss: 0.000537935364587947\n","-------\n","ypred: [Value(data = 0.9845418959593543), Value(data = -0.9827282453775332)]\n","step: 633, loss: 0.0005372664882701304\n","-------\n","ypred: [Value(data = 0.9845513363245345), Value(data = -0.982739118096093)]\n","step: 634, loss: 0.0005365992534582696\n","-------\n","ypred: [Value(data = 0.984560759544789), Value(data = -0.982749970773473)]\n","step: 635, loss: 0.0005359336541498567\n","-------\n","ypred: [Value(data = 0.9845701656717691), Value(data = -0.9827608034707285)]\n","step: 636, loss: 0.000535269684371499\n","-------\n","ypred: [Value(data = 0.9845795547569085), Value(data = -0.9827716162486557)]\n","step: 637, loss: 0.0005346073381787668\n","-------\n","ypred: [Value(data = 0.9845889268514249), Value(data = -0.9827824091677934)]\n","step: 638, loss: 0.0005339466096560202\n","-------\n","ypred: [Value(data = 0.984598282006321), Value(data = -0.9827931822884236)]\n","step: 639, loss: 0.0005332874929162331\n","-------\n","ypred: [Value(data = 0.9846076202723865), Value(data = -0.9828039356705737)]\n","step: 640, loss: 0.0005326299821008169\n","-------\n","ypred: [Value(data = 0.9846169417001976), Value(data = -0.9828146693740171)]\n","step: 641, loss: 0.000531974071379465\n","-------\n","ypred: [Value(data = 0.9846262463401201), Value(data = -0.9828253834582755)]\n","step: 642, loss: 0.0005313197549499471\n","-------\n","ypred: [Value(data = 0.9846355342423085), Value(data = -0.9828360779826196)]\n","step: 643, loss: 0.0005306670270379881\n","-------\n","ypred: [Value(data = 0.984644805456709), Value(data = -0.9828467530060703)]\n","step: 644, loss: 0.0005300158818970741\n","-------\n","ypred: [Value(data = 0.9846540600330592), Value(data = -0.9828574085874009)]\n","step: 645, loss: 0.000529366313808267\n","-------\n","ypred: [Value(data = 0.9846632980208903), Value(data = -0.9828680447851376)]\n","step: 646, loss: 0.000528718317080081\n","-------\n","ypred: [Value(data = 0.9846725194695272), Value(data = -0.9828786616575609)]\n","step: 647, loss: 0.0005280718860482998\n","-------\n","ypred: [Value(data = 0.9846817244280903), Value(data = -0.9828892592627079)]\n","step: 648, loss: 0.0005274270150757932\n","-------\n","ypred: [Value(data = 0.9846909129454965), Value(data = -0.9828998376583719)]\n","step: 649, loss: 0.0005267836985524044\n","-------\n","ypred: [Value(data = 0.98470008507046), Value(data = -0.9829103969021056)]\n","step: 650, loss: 0.0005261419308947228\n","-------\n","ypred: [Value(data = 0.9847092408514936), Value(data = -0.9829209370512206)]\n","step: 651, loss: 0.0005255017065460008\n","-------\n","ypred: [Value(data = 0.9847183803369095), Value(data = -0.9829314581627906)]\n","step: 652, loss: 0.0005248630199759219\n","-------\n","ypred: [Value(data = 0.984727503574821), Value(data = -0.9829419602936502)]\n","step: 653, loss: 0.0005242258656805119\n","-------\n","ypred: [Value(data = 0.9847366106131427), Value(data = -0.9829524435003989)]\n","step: 654, loss: 0.000523590238181921\n","-------\n","ypred: [Value(data = 0.9847457014995921), Value(data = -0.9829629078394002)]\n","step: 655, loss: 0.0005229561320283186\n","-------\n","ypred: [Value(data = 0.9847547762816906), Value(data = -0.9829733533667844)]\n","step: 656, loss: 0.0005223235417936961\n","-------\n","ypred: [Value(data = 0.9847638350067646), Value(data = -0.9829837801384483)]\n","step: 657, loss: 0.0005216924620777583\n","-------\n","ypred: [Value(data = 0.9847728777219459), Value(data = -0.9829941882100581)]\n","step: 658, loss: 0.000521062887505738\n","-------\n","ypred: [Value(data = 0.9847819044741735), Value(data = -0.9830045776370493)]\n","step: 659, loss: 0.0005204348127282666\n","-------\n","ypred: [Value(data = 0.9847909153101942), Value(data = -0.9830149484746288)]\n","step: 660, loss: 0.0005198082324211989\n","-------\n","ypred: [Value(data = 0.9847999102765641), Value(data = -0.9830253007777753)]\n","step: 661, loss: 0.0005191831412854979\n","-------\n","ypred: [Value(data = 0.9848088894196486), Value(data = -0.9830356346012409)]\n","step: 662, loss: 0.0005185595340470794\n","-------\n","ypred: [Value(data = 0.9848178527856244), Value(data = -0.9830459499995531)]\n","step: 663, loss: 0.0005179374054566271\n","-------\n","ypred: [Value(data = 0.9848268004204801), Value(data = -0.9830562470270146)]\n","step: 664, loss: 0.0005173167502894962\n","-------\n","ypred: [Value(data = 0.9848357323700171), Value(data = -0.983066525737705)]\n","step: 665, loss: 0.0005166975633455536\n","-------\n","ypred: [Value(data = 0.9848446486798507), Value(data = -0.9830767861854823)]\n","step: 666, loss: 0.0005160798394490338\n","-------\n","ypred: [Value(data = 0.9848535493954109), Value(data = -0.9830870284239843)]\n","step: 667, loss: 0.0005154635734483711\n","-------\n","ypred: [Value(data = 0.9848624345619438), Value(data = -0.9830972525066284)]\n","step: 668, loss: 0.0005148487602161147\n","-------\n","ypred: [Value(data = 0.9848713042245119), Value(data = -0.9831074584866145)]\n","step: 669, loss: 0.0005142353946487248\n","-------\n","ypred: [Value(data = 0.9848801584279957), Value(data = -0.9831176464169248)]\n","step: 670, loss: 0.0005136234716664821\n","-------\n","ypred: [Value(data = 0.9848889972170942), Value(data = -0.9831278163503253)]\n","step: 671, loss: 0.0005130129862133361\n","-------\n","ypred: [Value(data = 0.984897820636326), Value(data = -0.9831379683393676)]\n","step: 672, loss: 0.0005124039332567488\n","-------\n","ypred: [Value(data = 0.9849066287300303), Value(data = -0.9831481024363894)]\n","step: 673, loss: 0.0005117963077875713\n","-------\n","ypred: [Value(data = 0.9849154215423679), Value(data = -0.983158218693515)]\n","step: 674, loss: 0.0005111901048199247\n","-------\n","ypred: [Value(data = 0.9849241991173214), Value(data = -0.9831683171626581)]\n","step: 675, loss: 0.0005105853193910429\n","-------\n","ypred: [Value(data = 0.9849329614986975), Value(data = -0.9831783978955213)]\n","step: 676, loss: 0.0005099819465611349\n","-------\n","ypred: [Value(data = 0.9849417087301264), Value(data = -0.9831884609435978)]\n","step: 677, loss: 0.0005093799814132871\n","-------\n","ypred: [Value(data = 0.9849504408550639), Value(data = -0.9831985063581727)]\n","step: 678, loss: 0.0005087794190532919\n","-------\n","ypred: [Value(data = 0.9849591579167917), Value(data = -0.9832085341903241)]\n","step: 679, loss: 0.0005081802546095268\n","-------\n","ypred: [Value(data = 0.9849678599584181), Value(data = -0.9832185444909235)]\n","step: 680, loss: 0.0005075824832328449\n","-------\n","ypred: [Value(data = 0.9849765470228795), Value(data = -0.9832285373106371)]\n","step: 681, loss: 0.0005069861000964428\n","-------\n","ypred: [Value(data = 0.984985219152941), Value(data = -0.9832385126999279)]\n","step: 682, loss: 0.0005063911003956876\n","-------\n","ypred: [Value(data = 0.9849938763911972), Value(data = -0.9832484707090552)]\n","step: 683, loss: 0.0005057974793480515\n","-------\n","ypred: [Value(data = 0.9850025187800728), Value(data = -0.9832584113880768)]\n","step: 684, loss: 0.0005052052321929449\n","-------\n","ypred: [Value(data = 0.9850111463618244), Value(data = -0.9832683347868492)]\n","step: 685, loss: 0.0005046143541916115\n","-------\n","ypred: [Value(data = 0.9850197591785403), Value(data = -0.9832782409550295)]\n","step: 686, loss: 0.00050402484062698\n","-------\n","ypred: [Value(data = 0.9850283572721419), Value(data = -0.9832881299420758)]\n","step: 687, loss: 0.0005034366868035695\n","-------\n","ypred: [Value(data = 0.9850369406843844), Value(data = -0.9832980017972479)]\n","step: 688, loss: 0.0005028498880473645\n","-------\n","ypred: [Value(data = 0.985045509456858), Value(data = -0.9833078565696097)]\n","step: 689, loss: 0.0005022644397056453\n","-------\n","ypred: [Value(data = 0.9850540636309879), Value(data = -0.9833176943080287)]\n","step: 690, loss: 0.0005016803371469353\n","-------\n","ypred: [Value(data = 0.9850626032480364), Value(data = -0.9833275150611777)]\n","step: 691, loss: 0.0005010975757608303\n","-------\n","ypred: [Value(data = 0.9850711283491023), Value(data = -0.983337318877536)]\n","step: 692, loss: 0.000500516150957898\n","-------\n","ypred: [Value(data = 0.9850796389751229), Value(data = -0.9833471058053892)]\n","step: 693, loss: 0.0004999360581695753\n","-------\n","ypred: [Value(data = 0.985088135166874), Value(data = -0.9833568758928326)]\n","step: 694, loss: 0.0004993572928479967\n","-------\n","ypred: [Value(data = 0.9850966169649714), Value(data = -0.9833666291877692)]\n","step: 695, loss: 0.0004987798504659499\n","-------\n","ypred: [Value(data = 0.9851050844098712), Value(data = -0.9833763657379129)]\n","step: 696, loss: 0.0004982037265166986\n","-------\n","ypred: [Value(data = 0.9851135375418707), Value(data = -0.9833860855907883)]\n","step: 697, loss: 0.0004976289165139043\n","-------\n","ypred: [Value(data = 0.9851219764011093), Value(data = -0.9833957887937325)]\n","step: 698, loss: 0.0004970554159914884\n","-------\n","ypred: [Value(data = 0.9851304010275695), Value(data = -0.9834054753938952)]\n","step: 699, loss: 0.0004964832205035217\n","-------\n","ypred: [Value(data = 0.9851388114610772), Value(data = -0.9834151454382405)]\n","step: 700, loss: 0.0004959123256241262\n","-------\n","ypred: [Value(data = 0.9851472077413028), Value(data = -0.9834247989735465)]\n","step: 701, loss: 0.0004953427269473597\n","-------\n","ypred: [Value(data = 0.9851555899077619), Value(data = -0.9834344360464083)]\n","step: 702, loss: 0.0004947744200870766\n","-------\n","ypred: [Value(data = 0.985163957999816), Value(data = -0.9834440567032368)]\n","step: 703, loss: 0.0004942074006768621\n","-------\n","ypred: [Value(data = 0.9851723120566739), Value(data = -0.983453660990261)]\n","step: 704, loss: 0.0004936416643698696\n","-------\n","ypred: [Value(data = 0.9851806521173911), Value(data = -0.9834632489535283)]\n","step: 705, loss: 0.0004930772068387657\n","-------\n","ypred: [Value(data = 0.985188978220872), Value(data = -0.983472820638906)]\n","step: 706, loss: 0.0004925140237755759\n","-------\n","ypred: [Value(data = 0.9851972904058699), Value(data = -0.9834823760920814)]\n","step: 707, loss: 0.000491952110891594\n","-------\n","ypred: [Value(data = 0.9852055887109876), Value(data = -0.9834919153585632)]\n","step: 708, loss: 0.0004913914639172993\n","-------\n","ypred: [Value(data = 0.985213873174679), Value(data = -0.9835014384836824)]\n","step: 709, loss: 0.000490832078602192\n","-------\n","ypred: [Value(data = 0.9852221438352489), Value(data = -0.9835109455125931)]\n","step: 710, loss: 0.0004902739507147466\n","-------\n","ypred: [Value(data = 0.9852304007308541), Value(data = -0.983520436490273)]\n","step: 711, loss: 0.0004897170760422811\n","-------\n","ypred: [Value(data = 0.9852386438995043), Value(data = -0.9835299114615257)]\n","step: 712, loss: 0.0004891614503908237\n","-------\n","ypred: [Value(data = 0.9852468733790628), Value(data = -0.983539370470979)]\n","step: 713, loss: 0.0004886070695850856\n","-------\n","ypred: [Value(data = 0.9852550892072467), Value(data = -0.9835488135630888)]\n","step: 714, loss: 0.00048805392946826517\n","-------\n","ypred: [Value(data = 0.9852632914216285), Value(data = -0.9835582407821375)]\n","step: 715, loss: 0.00048750202590201497\n","-------\n","ypred: [Value(data = 0.985271480059636), Value(data = -0.9835676521722361)]\n","step: 716, loss: 0.00048695135476631627\n","-------\n","ypred: [Value(data = 0.9852796551585538), Value(data = -0.9835770477773251)]\n","step: 717, loss: 0.0004864019119593544\n","-------\n","ypred: [Value(data = 0.9852878167555228), Value(data = -0.9835864276411742)]\n","step: 718, loss: 0.00048585369339748587\n","-------\n","ypred: [Value(data = 0.9852959648875425), Value(data = -0.9835957918073852)]\n","step: 719, loss: 0.0004853066950150346\n","-------\n","ypred: [Value(data = 0.9853040995914703), Value(data = -0.9836051403193904)]\n","step: 720, loss: 0.00048476091276430347\n","-------\n","ypred: [Value(data = 0.985312220904023), Value(data = -0.9836144732204556)]\n","step: 721, loss: 0.00048421634261538483\n","-------\n","ypred: [Value(data = 0.9853203288617773), Value(data = -0.9836237905536789)]\n","step: 722, loss: 0.0004836729805561445\n","-------\n","ypred: [Value(data = 0.9853284235011704), Value(data = -0.9836330923619937)]\n","step: 723, loss: 0.0004831308225920366\n","-------\n","ypred: [Value(data = 0.9853365048585006), Value(data = -0.9836423786881678)]\n","step: 724, loss: 0.0004825898647460836\n","-------\n","ypred: [Value(data = 0.985344572969928), Value(data = -0.983651649574805)]\n","step: 725, loss: 0.0004820501030587402\n","-------\n","ypred: [Value(data = 0.9853526278714757), Value(data = -0.9836609050643453)]\n","step: 726, loss: 0.0004815115335878062\n","-------\n","ypred: [Value(data = 0.9853606695990297), Value(data = -0.9836701451990669)]\n","step: 727, loss: 0.00048097415240833075\n","-------\n","ypred: [Value(data = 0.9853686981883399), Value(data = -0.9836793700210859)]\n","step: 728, loss: 0.0004804379556125181\n","-------\n","ypred: [Value(data = 0.9853767136750211), Value(data = -0.9836885795723569)]\n","step: 729, loss: 0.0004799029393096475\n","-------\n","ypred: [Value(data = 0.9853847160945529), Value(data = -0.9836977738946752)]\n","step: 730, loss: 0.00047936909962595516\n","-------\n","ypred: [Value(data = 0.9853927054822812), Value(data = -0.9837069530296758)]\n","step: 731, loss: 0.00047883643270456804\n","-------\n","ypred: [Value(data = 0.985400681873418), Value(data = -0.9837161170188359)]\n","step: 732, loss: 0.0004783049347053921\n","-------\n","ypred: [Value(data = 0.9854086453030427), Value(data = -0.9837252659034744)]\n","step: 733, loss: 0.00047777460180502924\n","-------\n","ypred: [Value(data = 0.9854165958061027), Value(data = -0.983734399724753)]\n","step: 734, loss: 0.0004772454301966966\n","-------\n","ypred: [Value(data = 0.9854245334174135), Value(data = -0.9837435185236773)]\n","step: 735, loss: 0.00047671741609011927\n","-------\n","ypred: [Value(data = 0.9854324581716601), Value(data = -0.9837526223410973)]\n","step: 736, loss: 0.0004761905557114425\n","-------\n","ypred: [Value(data = 0.9854403701033969), Value(data = -0.9837617112177084)]\n","step: 737, loss: 0.00047566484530315597\n","-------\n","ypred: [Value(data = 0.9854482692470488), Value(data = -0.9837707851940517)]\n","step: 738, loss: 0.0004751402811239984\n","-------\n","ypred: [Value(data = 0.9854561556369115), Value(data = -0.9837798443105149)]\n","step: 739, loss: 0.00047461685944887776\n","-------\n","ypred: [Value(data = 0.9854640293071526), Value(data = -0.9837888886073334)]\n","step: 740, loss: 0.0004740945765687641\n","-------\n","ypred: [Value(data = 0.9854718902918117), Value(data = -0.9837979181245907)]\n","step: 741, loss: 0.00047357342879062093\n","-------\n","ypred: [Value(data = 0.9854797386248014), Value(data = -0.9838069329022191)]\n","step: 742, loss: 0.0004730534124373179\n","-------\n","ypred: [Value(data = 0.9854875743399076), Value(data = -0.9838159329800008)]\n","step: 743, loss: 0.0004725345238475329\n","-------\n","ypred: [Value(data = 0.9854953974707904), Value(data = -0.983824918397568)]\n","step: 744, loss: 0.00047201675937568675\n","-------\n","ypred: [Value(data = 0.9855032080509841), Value(data = -0.9838338891944044)]\n","step: 745, loss: 0.00047150011539184633\n","-------\n","ypred: [Value(data = 0.985511006113899), Value(data = -0.9838428454098451)]\n","step: 746, loss: 0.0004709845882816359\n","-------\n","ypred: [Value(data = 0.9855187916928205), Value(data = -0.9838517870830782)]\n","step: 747, loss: 0.0004704701744461642\n","-------\n","ypred: [Value(data = 0.985526564820911), Value(data = -0.9838607142531444)]\n","step: 748, loss: 0.00046995687030194693\n","-------\n","ypred: [Value(data = 0.9855343255312096), Value(data = -0.9838696269589389)]\n","step: 749, loss: 0.0004694446722808071\n","-------\n","ypred: [Value(data = 0.985542073856633), Value(data = -0.9838785252392112)]\n","step: 750, loss: 0.00046893357682980814\n","-------\n","ypred: [Value(data = 0.9855498098299763), Value(data = -0.9838874091325666)]\n","step: 751, loss: 0.0004684235804111488\n","-------\n","ypred: [Value(data = 0.9855575334839133), Value(data = -0.9838962786774657)]\n","step: 752, loss: 0.0004679146795021333\n","-------\n","ypred: [Value(data = 0.9855652448509971), Value(data = -0.983905133912226)]\n","step: 753, loss: 0.00046740687059504437\n","-------\n","ypred: [Value(data = 0.9855729439636605), Value(data = -0.9839139748750231)]\n","step: 754, loss: 0.0004669001501970698\n","-------\n","ypred: [Value(data = 0.9855806308542172), Value(data = -0.9839228016038898)]\n","step: 755, loss: 0.00046639451483024156\n","-------\n","ypred: [Value(data = 0.9855883055548618), Value(data = -0.9839316141367183)]\n","step: 756, loss: 0.0004658899610313408\n","-------\n","ypred: [Value(data = 0.9855959680976702), Value(data = -0.9839404125112596)]\n","step: 757, loss: 0.00046538648535183937\n","-------\n","ypred: [Value(data = 0.985603618514601), Value(data = -0.9839491967651254)]\n","step: 758, loss: 0.00046488408435780106\n","-------\n","ypred: [Value(data = 0.9856112568374952), Value(data = -0.9839579669357876)]\n","step: 759, loss: 0.00046438275462981225\n","-------\n","ypred: [Value(data = 0.985618883098077), Value(data = -0.98396672306058)]\n","step: 760, loss: 0.00046388249276291363\n","-------\n","ypred: [Value(data = 0.9856264973279547), Value(data = -0.9839754651766982)]\n","step: 761, loss: 0.000463383295366505\n","-------\n","ypred: [Value(data = 0.9856340995586207), Value(data = -0.9839841933212006)]\n","step: 762, loss: 0.0004628851590642986\n","-------\n","ypred: [Value(data = 0.9856416898214526), Value(data = -0.9839929075310089)]\n","step: 763, loss: 0.0004623880804942098\n","-------\n","ypred: [Value(data = 0.9856492681477131), Value(data = -0.9840016078429089)]\n","step: 764, loss: 0.0004618920563083143\n","-------\n","ypred: [Value(data = 0.9856568345685512), Value(data = -0.9840102942935511)]\n","step: 765, loss: 0.00046139708317275005\n","-------\n","ypred: [Value(data = 0.9856643891150024), Value(data = -0.9840189669194515)]\n","step: 766, loss: 0.0004609031577676478\n","-------\n","ypred: [Value(data = 0.9856719318179891), Value(data = -0.9840276257569912)]\n","step: 767, loss: 0.00046041027678708475\n","-------\n","ypred: [Value(data = 0.9856794627083211), Value(data = -0.9840362708424191)]\n","step: 768, loss: 0.0004599184369389663\n","-------\n","ypred: [Value(data = 0.9856869818166969), Value(data = -0.9840449022118501)]\n","step: 769, loss: 0.00045942763494498964\n","-------\n","ypred: [Value(data = 0.9856944891737031), Value(data = -0.9840535199012678)]\n","step: 770, loss: 0.00045893786754056204\n","-------\n","ypred: [Value(data = 0.9857019848098155), Value(data = -0.9840621239465238)]\n","step: 771, loss: 0.00045844913147471565\n","-------\n","ypred: [Value(data = 0.9857094687554001), Value(data = -0.984070714383339)]\n","step: 772, loss: 0.00045796142351004745\n","-------\n","ypred: [Value(data = 0.9857169410407123), Value(data = -0.9840792912473038)]\n","step: 773, loss: 0.000457474740422668\n","-------\n","ypred: [Value(data = 0.9857244016958986), Value(data = -0.9840878545738785)]\n","step: 774, loss: 0.00045698907900210297\n","-------\n","ypred: [Value(data = 0.9857318507509967), Value(data = -0.9840964043983954)]\n","step: 775, loss: 0.00045650443605121114\n","-------\n","ypred: [Value(data = 0.9857392882359358), Value(data = -0.9841049407560569)]\n","step: 776, loss: 0.00045602080838617887\n","-------\n","ypred: [Value(data = 0.9857467141805376), Value(data = -0.9841134636819386)]\n","step: 777, loss: 0.00045553819283637037\n","-------\n","ypred: [Value(data = 0.9857541286145163), Value(data = -0.9841219732109882)]\n","step: 778, loss: 0.00045505658624432166\n","-------\n","ypred: [Value(data = 0.985761531567479), Value(data = -0.9841304693780266)]\n","step: 779, loss: 0.00045457598546564694\n","-------\n","ypred: [Value(data = 0.9857689230689273), Value(data = -0.9841389522177489)]\n","step: 780, loss: 0.0004540963873689616\n","-------\n","ypred: [Value(data = 0.9857763031482559), Value(data = -0.9841474217647248)]\n","step: 781, loss: 0.000453617788835835\n","-------\n","ypred: [Value(data = 0.9857836718347551), Value(data = -0.9841558780533984)]\n","step: 782, loss: 0.00045314018676071604\n","-------\n","ypred: [Value(data = 0.9857910291576099), Value(data = -0.98416432111809)]\n","step: 783, loss: 0.00045266357805086224\n","-------\n","ypred: [Value(data = 0.9857983751459007), Value(data = -0.9841727509929955)]\n","step: 784, loss: 0.0004521879596262946\n","-------\n","ypred: [Value(data = 0.9858057098286046), Value(data = -0.9841811677121882)]\n","step: 785, loss: 0.00045171332841968843\n","-------\n","ypred: [Value(data = 0.9858130332345948), Value(data = -0.9841895713096183)]\n","step: 786, loss: 0.0004512396813763579\n","-------\n","ypred: [Value(data = 0.9858203453926417), Value(data = -0.9841979618191141)]\n","step: 787, loss: 0.00045076701545415144\n","-------\n","ypred: [Value(data = 0.9858276463314134), Value(data = -0.9842063392743822)]\n","step: 788, loss: 0.0004502953276234232\n","-------\n","ypred: [Value(data = 0.9858349360794757), Value(data = -0.9842147037090081)]\n","step: 789, loss: 0.000449824614866942\n","-------\n","ypred: [Value(data = 0.985842214665293), Value(data = -0.9842230551564572)]\n","step: 790, loss: 0.0004493548741798353\n","-------\n","ypred: [Value(data = 0.9858494821172284), Value(data = -0.9842313936500752)]\n","step: 791, loss: 0.00044888610256952716\n","-------\n","ypred: [Value(data = 0.985856738463545), Value(data = -0.9842397192230877)]\n","step: 792, loss: 0.0004484182970556766\n","-------\n","ypred: [Value(data = 0.9858639837324051), Value(data = -0.9842480319086022)]\n","step: 793, loss: 0.0004479514546701206\n","-------\n","ypred: [Value(data = 0.9858712179518716), Value(data = -0.9842563317396075)]\n","step: 794, loss: 0.0004474855724568064\n","-------\n","ypred: [Value(data = 0.9858784411499079), Value(data = -0.9842646187489752)]\n","step: 795, loss: 0.00044702064747171867\n","-------\n","ypred: [Value(data = 0.9858856533543788), Value(data = -0.9842728929694594)]\n","step: 796, loss: 0.00044655667678283667\n","-------\n","ypred: [Value(data = 0.985892854593051), Value(data = -0.9842811544336977)]\n","step: 797, loss: 0.0004460936574700649\n","-------\n","ypred: [Value(data = 0.9859000448935926), Value(data = -0.9842894031742113)]\n","step: 798, loss: 0.0004456315866251849\n","-------\n","ypred: [Value(data = 0.9859072242835749), Value(data = -0.9842976392234066)]\n","step: 799, loss: 0.0004451704613517586\n","-------\n"]}],"source":["learning_rate = 0.05\n","\n","# Create a list of losses\n","losses = []\n","for k in range(800):\n","  # forward pass\n","  ypred = [n(x) for x in xs]\n","  loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))  # low loss is better, perfect is loss = 0\n","  losses.append(loss.data)\n","\n","  # backward pass\n","  for p in n.parameters():\n","    p.grad = 0.0  # zero the gradient \n","  loss.backward()\n","\n","  # update weights and bias\n","  for p in n.parameters():\n","      p.data += -learning_rate * p.grad\n","\n","  # print(f'x: {x}')\n","  print(f'ypred: {ypred}')\n","  print(f'step: {k}, loss: {loss.data}')   \n","  print('-------')  "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["Text(0, 0.5, 'Loss')"]},"execution_count":15,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","# Create a list of iterations\n","iterations = range(len(losses))\n","\n","# Plot the loss as a function of iteration\n","plt.plot(iterations, losses)\n","\n","# Add a title to the plot\n","plt.title('Loss vs. Iteration')\n","\n","# Add labels to the x-axis and y-axis\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# TODO add derivative, add draw_dot, backward"]},{"cell_type":"markdown","metadata":{},"source":["#### Tanh activation function"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["_num = np.arange(-5, 5, 0.2)\n","plt.plot(_num, np.tanh(_num))\n","plt.grid()"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
