{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### [chatGPT-4, released on 2023-03-14, has 1 trillion paramaters and cost $100 million to train](https://en.wikipedia.org/wiki/GPT-4)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import math, random, torch\n","import numpy as np\n","# import random\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def plot_losses(losses):\n","  # import matplotlib.pyplot as plt\n","  \n","  # Create a list of iterations\n","  iterations = range(len(losses))\n","\n","  # Plot the loss as a function of iteration\n","  plt.plot(iterations, losses)\n","\n","  # Add a title to the plot\n","  plt.title('Loss vs. Iteration')\n","\n","  # Add labels to the x-axis and y-axis\n","  plt.xlabel('Iteration')\n","  plt.ylabel('Loss')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Micrograd Classes and Functions"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from graphviz import Digraph\n","\n","def trace(root):\n","  \"\"\"Builds a set of all nodes and edges in a graph.\"\"\"\n","  nodes, edges = set(), set()\n","\n","  def build(v):\n","    if v not in nodes:\n","      nodes.add(v)\n","      for child in v._prev:\n","        edges.add((child, v))\n","        build(child)\n","\n","  build(root)\n","  return nodes, edges\n","\n","def draw_dot(root):\n","  \"\"\"Creates a Digraph representation of the graph.\"\"\"\n","  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'})  # LR = left to right\n","\n","  nodes, edges = trace(root)\n","  for n in nodes:\n","    uid = str(id(n))\n","    # For any value in the graph, create a rectangular ('record') node for it.\n","    dot.node(name=uid, label=\"{ %s | data %.4f | grad % .4f }\" % (n.label, n.data, n.grad), shape=\"record\")\n","\n","    if n._op:\n","      # If this value is a result of some operation, create an op node.\n","      dot.node(name=uid + n._op, label=n._op)\n","      # And connect this node to it\n","      dot.edge(uid + n._op, uid)\n","\n","  for n1, n2 in edges:\n","    # Connect nl to the op node of n2.\n","    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n","\n","  return dot"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class Value:\n","\n","    def __init__(self, data, _children=(), _op='', label=''):\n","        self.data = data\n","        self.grad = 0.0\n","        self._backward = lambda : None\n","        self._prev = set(_children)\n","        self._op = _op\n","        self.label = label\n","\n","    def __repr__(self) -> str:\n","        return f\"Value(data = {self.data})\"\n","    \n","    def __add__(self, other):\n","        other = other if isinstance(other, Value) else Value(other)\n","        out = Value(self.data + other.data, (self, other), '+')\n","\n","        def _backward():\n","            self.grad += 1.0 * out.grad\n","            other.grad += 1.0 * out.grad\n","        out._backward = _backward    \n","\n","        return out\n","\n","    def __radd__(self, other): # other + self\n","        return self + other\n","\n","    def __mul__(self, other):\n","        other = other if isinstance(other, Value) else Value(other)        \n","        out = Value(self.data * other.data, (self, other), '*')\n","\n","        def _backward():\n","            self.grad += other.data * out.grad\n","            other.grad += self.data * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def __rmul__(self, other):  # other * self\n","        return self * other\n","\n","    def __pow__(self, other):\n","        assert isinstance(other, (int, float)), \"only support int/float power for now\"\n","        out = Value(self.data**other, (self,), f'**{other}')\n","\n","        def _backward():\n","            self.grad += other * (self.data ** (other - 1)) * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def __truediv__(self, other):  # self / other\n","        return self * other**-1\n","\n","    def __neg__(self):  # -self\n","        return self * -1\n","    \n","    def __sub__(self, other):  # self - other\n","        return self + (-other)\n","\n","    def __rsub__(self, other): # other - self\n","        return other + (-self)\n","\n","    def tanh(self):\n","        x = self.data\n","        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n","        out = Value(t, (self, ), 'tanh')\n","\n","        def _backward():\n","            self.grad += (1 - t**2) * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    # https://en.wikipedia.org/wiki/Hyperbolic_functions\n","    def exp(self):\n","        x = self.data\n","        out = Value(math.exp(x), (self, ), 'exp')\n","\n","        def _backward():\n","            self.grad += out.data * out.grad\n","        out._backward = _backward\n","\n","        return out\n","\n","    def backward(self):\n","        topo = []\n","        visited = set()\n","\n","        # topological sort\n","        def build_topo(v):\n","            if v not in visited:\n","                visited.add(v)\n","                for child in v._prev:\n","                    build_topo(child)\n","                topo.append(v)\n","        build_topo(self)\n","\n","        self.grad = 1  # initialize\n","        for node in reversed(topo):\n","            node._backward()    "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class Neuron:\n","    \n","    def __init__(self, nin):\n","        # random numbers evenly distributed between -1 and 1    \n","        self.w = [Value(random.uniform(-1, 1)) for _ in range(nin)]  \n","        self.b = Value(random.uniform(-1,1))\n","\n","#### my add ##########################################\n","    def __repr__(self) -> str:\n","        return f\"Neuron(w = {self.w}, b = {self.b})\"\n","######################################################\n","\n","    def __call__(self, x):\n","        # w * x + b\n","        # print(list(zip(self.w, x)), self.b)\n","        act = sum((wi*xi for wi,xi in zip(self.w, x)), self.b) \n","        out = act.tanh()\n","        return out\n","\n","    def parameters(self):\n","        # print(f'w: {self.w}, b: {[self.b]}')\n","        return self.w + [self.b]\n","\n","\n","class Layer:\n","    def __init__(self, nin, nout):\n","        self.neurons = [Neuron(nin) for _ in range(nout)]\n","\n","#### my add ##########################################\n","    def __repr__(self) -> str:\n","        return f\"Layer(neurons = {self.neurons})\"\n","######################################################\n","\n","    def __call__(self, x):\n","        outs = [n(x) for n in self.neurons]\n","        return outs[0] if len(outs) == 1 else outs\n","\n","    def parameters(self):\n","        # params = []\n","        # for neuron in self.neurons:\n","        #     ps = neuron.parameters()\n","        #     params.extend(ps)\n","        # return params\n","        return [p for neuron in self.neurons for p in neuron.parameters()]\n","\n","class MLP:\n","    def __init__(self, nin, nouts):\n","        sz = [nin] + nouts\n","        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n","\n","    def __call__(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","    def parameters(self):\n","        params = []\n","        # for layer in self.layers:\n","        #     ps = layer.parameters()\n","        #     params.extend(ps)\n","        # return params\n","        return [p for layer in self.layers for p in layer.parameters()]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Neural Network Neuron\n","<!-- ### Simple Neural Network: Single Neuron with 3 Inputs -->\n","<img src=\"..\\karpathy\\img\\neural_network_single_neuron.png\">"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Activation Function: Tanh"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 400x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["_num = np.arange(-5, 5, 0.2)\n","plt.figure(figsize=(4, 2))\n","plt.plot(_num, np.tanh(_num))\n","plt.title(\"Tanh Activation\")\n","plt.grid()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Calculate Output with Forward Pass: tanh(x0\\*w0 + x1\\*w1 + x2\\*w2 + b)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["neuron output: -0.7071067801767762\n"]}],"source":["# inputs\n","x0 = Value(-3.0, label='x0')\n","x1 = Value(0.0, label='x1')\n","x2 = Value(0.5, label='x2')\n","\n","# weights\n","w0 = Value(2.0, label='w0')\n","w1 = Value(1.0, label='w1')\n","w2 = Value(1.0, label='w2')\n","\n","# bias\n","b = Value(4.618626415, label='b')\n","\n","# forward pass: x0*w0 + x1*w1 + x2*w2 + b\n","x0w0 = x0*w0; x0w0.label = 'x0*w0'\n","x1w1 = x1*w1; x1w1.label = 'x1*w1'\n","x2w2 = x2*w2; x2w2.label = 'x2*w2'\n","n_sum = x0w0 + x1w1 + x2w2; n_sum.label = 'x0w0 + x1w1 + x2w2'\n","n = n_sum + b; n.label = 'n'\n","out_0 = n.tanh(); out_0.label = 'out_0'\n","print(f'neuron output: {out_0.data}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Calculate Gradient with Backward Pass"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["w0.grad, d(output)/d(w0): -1.500000004284097\n"]},{"data":{"image/svg+xml":["<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n","<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n"," \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n","<!-- Generated by graphviz version 2.46.0 (20210118.1747)\n"," -->\n","<!-- Pages: 1 -->\n","<svg width=\"1995pt\" height=\"265pt\"\n"," viewBox=\"0.00 0.00 1995.00 265.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n","<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 261)\">\n","<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-261 1991,-261 1991,4 -4,4\"/>\n","<!-- 2087572055040 -->\n","<g id=\"node1\" class=\"node\">\n","<title>2087572055040</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1018,-82.5 1018,-118.5 1325,-118.5 1325,-82.5 1018,-82.5\"/>\n","<text text-anchor=\"middle\" x=\"1087\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0w0 + x1w1 + x2w2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1156,-82.5 1156,-118.5 \"/>\n","<text text-anchor=\"middle\" x=\"1199\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;5.5000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1242,-82.5 1242,-118.5 \"/>\n","<text text-anchor=\"middle\" x=\"1283.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2087572055184+ -->\n","<g id=\"node11\" class=\"node\">\n","<title>2087572055184+</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"1388\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"1388\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n","</g>\n","<!-- 2087572055040&#45;&gt;2087572055184+ -->\n","<g id=\"edge16\" class=\"edge\">\n","<title>2087572055040&#45;&gt;2087572055184+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1315.57,-118.51C1328.6,-120.15 1340.83,-121.69 1351.36,-123.01\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1350.94,-126.49 1361.3,-124.26 1351.81,-119.54 1350.94,-126.49\"/>\n","</g>\n","<!-- 2087572055040+ -->\n","<g id=\"node2\" class=\"node\">\n","<title>2087572055040+</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"955\" cy=\"-100.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"955\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n","</g>\n","<!-- 2087572055040+&#45;&gt;2087572055040 -->\n","<g id=\"edge1\" class=\"edge\">\n","<title>2087572055040+&#45;&gt;2087572055040</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M982.3,-100.5C989.69,-100.5 998.31,-100.5 1007.71,-100.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1007.77,-104 1017.77,-100.5 1007.77,-97 1007.77,-104\"/>\n","</g>\n","<!-- 2087572033056 -->\n","<g id=\"node3\" class=\"node\">\n","<title>2087572033056</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"0,-220.5 0,-256.5 201,-256.5 201,-220.5 0,-220.5\"/>\n","<text text-anchor=\"middle\" x=\"16.5\" y=\"-234.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w0</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"33,-220.5 33,-256.5 \"/>\n","<text text-anchor=\"middle\" x=\"73.5\" y=\"-234.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 2.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"114,-220.5 114,-256.5 \"/>\n","<text text-anchor=\"middle\" x=\"157.5\" y=\"-234.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad &#45;1.5000</text>\n","</g>\n","<!-- 2087572054080* -->\n","<g id=\"node5\" class=\"node\">\n","<title>2087572054080*</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"264\" cy=\"-183.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"264\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n","</g>\n","<!-- 2087572033056&#45;&gt;2087572054080* -->\n","<g id=\"edge13\" class=\"edge\">\n","<title>2087572033056&#45;&gt;2087572054080*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M173.4,-220.46C182.75,-217.68 192.16,-214.67 201,-211.5 211.53,-207.72 222.76,-202.9 232.72,-198.34\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"234.25,-201.48 241.83,-194.07 231.29,-195.14 234.25,-201.48\"/>\n","</g>\n","<!-- 2087572054080 -->\n","<g id=\"node4\" class=\"node\">\n","<title>2087572054080</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"327,-165.5 327,-201.5 549,-201.5 549,-165.5 327,-165.5\"/>\n","<text text-anchor=\"middle\" x=\"353.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0*w0</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"380,-165.5 380,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"423\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"466,-165.5 466,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"507.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2087572054704+ -->\n","<g id=\"node13\" class=\"node\">\n","<title>2087572054704+</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"612\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"612\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n","</g>\n","<!-- 2087572054080&#45;&gt;2087572054704+ -->\n","<g id=\"edge20\" class=\"edge\">\n","<title>2087572054080&#45;&gt;2087572054704+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M520,-165.42C529.85,-162.69 539.71,-159.71 549,-156.5 559.58,-152.85 570.81,-148.07 580.78,-143.49\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"582.32,-146.63 589.87,-139.21 579.33,-140.3 582.32,-146.63\"/>\n","</g>\n","<!-- 2087572054080*&#45;&gt;2087572054080 -->\n","<g id=\"edge2\" class=\"edge\">\n","<title>2087572054080*&#45;&gt;2087572054080</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M291.12,-183.5C298.66,-183.5 307.41,-183.5 316.81,-183.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"316.82,-187 326.81,-183.5 316.81,-180 316.82,-187\"/>\n","</g>\n","<!-- 2087572033104 -->\n","<g id=\"node6\" class=\"node\">\n","<title>2087572033104</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1,-165.5 1,-201.5 200,-201.5 200,-165.5 1,-165.5\"/>\n","<text text-anchor=\"middle\" x=\"16\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"31,-165.5 31,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"74\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;3.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"117,-165.5 117,-201.5 \"/>\n","<text text-anchor=\"middle\" x=\"158.5\" y=\"-179.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n","</g>\n","<!-- 2087572033104&#45;&gt;2087572054080* -->\n","<g id=\"edge9\" class=\"edge\">\n","<title>2087572033104&#45;&gt;2087572054080*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M200.1,-183.5C209.5,-183.5 218.57,-183.5 226.75,-183.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"226.95,-187 236.95,-183.5 226.95,-180 226.95,-187\"/>\n","</g>\n","<!-- 2087572054128 -->\n","<g id=\"node7\" class=\"node\">\n","<title>2087572054128</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"329.5,-110.5 329.5,-146.5 546.5,-146.5 546.5,-110.5 329.5,-110.5\"/>\n","<text text-anchor=\"middle\" x=\"356\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1*w1</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"382.5,-110.5 382.5,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"423\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"463.5,-110.5 463.5,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"505\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2087572054128&#45;&gt;2087572054704+ -->\n","<g id=\"edge19\" class=\"edge\">\n","<title>2087572054128&#45;&gt;2087572054704+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M546.95,-128.5C556.82,-128.5 566.28,-128.5 574.76,-128.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"574.92,-132 584.92,-128.5 574.92,-125 574.92,-132\"/>\n","</g>\n","<!-- 2087572054128* -->\n","<g id=\"node8\" class=\"node\">\n","<title>2087572054128*</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"264\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"264\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n","</g>\n","<!-- 2087572054128*&#45;&gt;2087572054128 -->\n","<g id=\"edge3\" class=\"edge\">\n","<title>2087572054128*&#45;&gt;2087572054128</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M291.12,-128.5C299.31,-128.5 308.94,-128.5 319.28,-128.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"319.39,-132 329.39,-128.5 319.39,-125 319.39,-132\"/>\n","</g>\n","<!-- 2087572033152 -->\n","<g id=\"node9\" class=\"node\">\n","<title>2087572033152</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"341,-55.5 341,-91.5 535,-91.5 535,-55.5 341,-55.5\"/>\n","<text text-anchor=\"middle\" x=\"356\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"371,-55.5 371,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"411.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.5000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"452,-55.5 452,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"493.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2087572054320* -->\n","<g id=\"node20\" class=\"node\">\n","<title>2087572054320*</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"612\" cy=\"-73.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"612\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n","</g>\n","<!-- 2087572033152&#45;&gt;2087572054320* -->\n","<g id=\"edge12\" class=\"edge\">\n","<title>2087572033152&#45;&gt;2087572054320*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M535.06,-73.5C549.08,-73.5 562.74,-73.5 574.52,-73.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"574.77,-77 584.77,-73.5 574.77,-70 574.77,-77\"/>\n","</g>\n","<!-- 2087572055184 -->\n","<g id=\"node10\" class=\"node\">\n","<title>2087572055184</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1451,-109.5 1451,-145.5 1643,-145.5 1643,-109.5 1451,-109.5\"/>\n","<text text-anchor=\"middle\" x=\"1462.5\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">n</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1474,-109.5 1474,-145.5 \"/>\n","<text text-anchor=\"middle\" x=\"1517\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;0.8814</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1560,-109.5 1560,-145.5 \"/>\n","<text text-anchor=\"middle\" x=\"1601.5\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2087572055328tanh -->\n","<g id=\"node18\" class=\"node\">\n","<title>2087572055328tanh</title>\n","<ellipse fill=\"none\" stroke=\"black\" cx=\"1706\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n","<text text-anchor=\"middle\" x=\"1706\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">tanh</text>\n","</g>\n","<!-- 2087572055184&#45;&gt;2087572055328tanh -->\n","<g id=\"edge15\" class=\"edge\">\n","<title>2087572055184&#45;&gt;2087572055328tanh</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1643.4,-127.5C1652.32,-127.5 1660.93,-127.5 1668.75,-127.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1668.86,-131 1678.86,-127.5 1668.86,-124 1668.86,-131\"/>\n","</g>\n","<!-- 2087572055184+&#45;&gt;2087572055184 -->\n","<g id=\"edge4\" class=\"edge\">\n","<title>2087572055184+&#45;&gt;2087572055184</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1415.28,-127.5C1422.78,-127.5 1431.44,-127.5 1440.67,-127.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1440.87,-131 1450.87,-127.5 1440.87,-124 1440.87,-131\"/>\n","</g>\n","<!-- 2087572054704 -->\n","<g id=\"node12\" class=\"node\">\n","<title>2087572054704</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"689,-110.5 689,-146.5 878,-146.5 878,-110.5 689,-110.5\"/>\n","<text text-anchor=\"middle\" x=\"699\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\"> </text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"709,-110.5 709,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"752\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"795,-110.5 795,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"836.5\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2087572054704&#45;&gt;2087572055040+ -->\n","<g id=\"edge8\" class=\"edge\">\n","<title>2087572054704&#45;&gt;2087572055040+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M878.17,-113.03C892.5,-110.66 906.49,-108.35 918.47,-106.37\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"919.14,-109.81 928.44,-104.72 918,-102.9 919.14,-109.81\"/>\n","</g>\n","<!-- 2087572054704+&#45;&gt;2087572054704 -->\n","<g id=\"edge5\" class=\"edge\">\n","<title>2087572054704+&#45;&gt;2087572054704</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M639.11,-128.5C650.28,-128.5 664.11,-128.5 678.74,-128.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"678.97,-132 688.97,-128.5 678.97,-125 678.97,-132\"/>\n","</g>\n","<!-- 2087572033200 -->\n","<g id=\"node14\" class=\"node\">\n","<title>2087572033200</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"2,-110.5 2,-146.5 199,-146.5 199,-110.5 2,-110.5\"/>\n","<text text-anchor=\"middle\" x=\"18.5\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w1</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"35,-110.5 35,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"75.5\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 1.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"116,-110.5 116,-146.5 \"/>\n","<text text-anchor=\"middle\" x=\"157.5\" y=\"-124.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n","</g>\n","<!-- 2087572033200&#45;&gt;2087572054128* -->\n","<g id=\"edge11\" class=\"edge\">\n","<title>2087572033200&#45;&gt;2087572054128*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M199.17,-128.5C208.89,-128.5 218.26,-128.5 226.69,-128.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"226.83,-132 236.83,-128.5 226.83,-125 226.83,-132\"/>\n","</g>\n","<!-- 2087572033248 -->\n","<g id=\"node15\" class=\"node\">\n","<title>2087572033248</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"339.5,-0.5 339.5,-36.5 536.5,-36.5 536.5,-0.5 339.5,-0.5\"/>\n","<text text-anchor=\"middle\" x=\"356\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">w2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"372.5,-0.5 372.5,-36.5 \"/>\n","<text text-anchor=\"middle\" x=\"413\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 1.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"453.5,-0.5 453.5,-36.5 \"/>\n","<text text-anchor=\"middle\" x=\"495\" y=\"-14.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.2500</text>\n","</g>\n","<!-- 2087572033248&#45;&gt;2087572054320* -->\n","<g id=\"edge18\" class=\"edge\">\n","<title>2087572033248&#45;&gt;2087572054320*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M520,-36.58C529.85,-39.31 539.71,-42.29 549,-45.5 559.58,-49.15 570.81,-53.93 580.78,-58.51\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"579.33,-61.7 589.87,-62.79 582.32,-55.37 579.33,-61.7\"/>\n","</g>\n","<!-- 2087572033296 -->\n","<g id=\"node16\" class=\"node\">\n","<title>2087572033296</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1077.5,-137.5 1077.5,-173.5 1265.5,-173.5 1265.5,-137.5 1077.5,-137.5\"/>\n","<text text-anchor=\"middle\" x=\"1089.5\" y=\"-151.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1101.5,-137.5 1101.5,-173.5 \"/>\n","<text text-anchor=\"middle\" x=\"1142\" y=\"-151.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 4.6186</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1182.5,-137.5 1182.5,-173.5 \"/>\n","<text text-anchor=\"middle\" x=\"1224\" y=\"-151.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2087572033296&#45;&gt;2087572055184+ -->\n","<g id=\"edge17\" class=\"edge\">\n","<title>2087572033296&#45;&gt;2087572055184+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1265.65,-143.34C1295.85,-139.4 1327.56,-135.26 1350.99,-132.2\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1351.68,-135.64 1361.14,-130.88 1350.77,-128.7 1351.68,-135.64\"/>\n","</g>\n","<!-- 2087572055328 -->\n","<g id=\"node17\" class=\"node\">\n","<title>2087572055328</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"1769,-109.5 1769,-145.5 1987,-145.5 1987,-109.5 1769,-109.5\"/>\n","<text text-anchor=\"middle\" x=\"1793.5\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">out_0</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1818,-109.5 1818,-145.5 \"/>\n","<text text-anchor=\"middle\" x=\"1861\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;0.7071</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"1904,-109.5 1904,-145.5 \"/>\n","<text text-anchor=\"middle\" x=\"1945.5\" y=\"-123.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 1.0000</text>\n","</g>\n","<!-- 2087572055328tanh&#45;&gt;2087572055328 -->\n","<g id=\"edge6\" class=\"edge\">\n","<title>2087572055328tanh&#45;&gt;2087572055328</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M1733.19,-127.5C1740.65,-127.5 1749.28,-127.5 1758.56,-127.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"1758.84,-131 1768.84,-127.5 1758.84,-124 1758.84,-131\"/>\n","</g>\n","<!-- 2087572054320 -->\n","<g id=\"node19\" class=\"node\">\n","<title>2087572054320</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"675,-55.5 675,-91.5 892,-91.5 892,-55.5 675,-55.5\"/>\n","<text text-anchor=\"middle\" x=\"701.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2*w2</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"728,-55.5 728,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"768.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.5000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"809,-55.5 809,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"850.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2087572054320&#45;&gt;2087572055040+ -->\n","<g id=\"edge14\" class=\"edge\">\n","<title>2087572054320&#45;&gt;2087572055040+</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M892.33,-90.68C901.68,-92.17 910.63,-93.59 918.66,-94.87\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"918.23,-98.35 928.66,-96.46 919.33,-91.43 918.23,-98.35\"/>\n","</g>\n","<!-- 2087572054320*&#45;&gt;2087572054320 -->\n","<g id=\"edge7\" class=\"edge\">\n","<title>2087572054320*&#45;&gt;2087572054320</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M639.11,-73.5C646.55,-73.5 655.16,-73.5 664.4,-73.5\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"664.66,-77 674.66,-73.5 664.66,-70 664.66,-77\"/>\n","</g>\n","<!-- 2087572033008 -->\n","<g id=\"node21\" class=\"node\">\n","<title>2087572033008</title>\n","<polygon fill=\"none\" stroke=\"black\" points=\"3.5,-55.5 3.5,-91.5 197.5,-91.5 197.5,-55.5 3.5,-55.5\"/>\n","<text text-anchor=\"middle\" x=\"18.5\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"33.5,-55.5 33.5,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"74\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 0.0000</text>\n","<polyline fill=\"none\" stroke=\"black\" points=\"114.5,-55.5 114.5,-91.5 \"/>\n","<text text-anchor=\"middle\" x=\"156\" y=\"-69.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.5000</text>\n","</g>\n","<!-- 2087572033008&#45;&gt;2087572054128* -->\n","<g id=\"edge10\" class=\"edge\">\n","<title>2087572033008&#45;&gt;2087572054128*</title>\n","<path fill=\"none\" stroke=\"black\" d=\"M173.4,-91.54C182.75,-94.32 192.16,-97.33 201,-100.5 211.53,-104.28 222.76,-109.1 232.72,-113.66\"/>\n","<polygon fill=\"black\" stroke=\"black\" points=\"231.29,-116.86 241.83,-117.93 234.25,-110.52 231.29,-116.86\"/>\n","</g>\n","</g>\n","</svg>\n"],"text/plain":["<graphviz.graphs.Digraph at 0x1e60cfc4f40>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# backward pass to calculate gradient\n","out_0.backward()\n","  \n","out_0_grad = w0.grad  # store w0.grad, further calculation with w0 will reset w0.grad to zero\n","# print(f'w0.grad(i.e. d(output)/d(w0)): {w0.grad}')\n","print(f'w0.grad, d(output)/d(w0): {w0.grad}')\n","draw_dot(out_0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Check Backward Pass Gradient Calculation: d(output) / d(x0)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["---- w0.grad from backward pass is same as d(out)/d(w0) calculation ----\n","out_1: -0.7071082802, out_0: -0.7071067802, d(out): -0.0000015000, d(w0): 0.0000010000, d(out)/d(w0): -1.4999968224\n","d(out) / d(w0):             -1.4999968224\n","w0.grad from backward pass: -1.5000000043\n"]}],"source":["h = 0.000001\n","w0 += h  # increment w0 by h\n","\n","# x0*w0 + x1*w1 + x2*w2 + b\n","x0w0 = x0*w0; x0w0.label = 'x0*w0'\n","x1w1 = x1*w1; x1w1.label = 'x1*w1'\n","x2w2 = x2*w2; x2w2.label = 'x2*w2'\n","n_sum = x0w0 + x1w1 + x2w2; n_sum.label = 'x0w0 + x1w1 + x2w2'\n","n = n_sum + b; n.label = 'n'\n","out_1 = n.tanh(); out_1.label = 'out_1'\n","out_grad = (out_1 - out_0) / h \n","\n","print(f'---- w0.grad from backward pass is same as d(out)/d(w0) calculation ----')\n","print(f'out_1: {out_1.data:<12.10f}, out_0: {out_0.data:<12.10f}, d(out): {out_1.data-out_0.data:<12.10f}, d(w0): {h:<12.10f}, d(out)/d(w0): {(out_1.data-out_0.data)/h:<12.10f}')\n","print(f'd(out) / d(w0):             {out_grad.data:<12.10f}')\n","print(f'w0.grad from backward pass: {out_0_grad:<12.10f}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Check Output and Gradient Calculation with PyTorch"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["---- torch results matched backward pass results ----\n","x0.data.item()  = -3.000000\n","x0.grad.item()  =  1.000000\n","w0.data.item()  =  2.000000\n","w0.grad.item()  = -1.500000 <-- result matched micrograd\n","---\n","x1.data.item()  =  0.000000\n","x1.grad.item()  =  0.500000\n","w1.data.item()  =  1.000000\n","w1.grad.item()  =  0.000000\n","---\n","x2.data.item()  =  0.500000\n","x2.grad.item()  =  0.500000\n","w2.data.item()  =  1.000000\n","w2.grad.item()  =  0.250000\n","---\n","out.data.item() = -0.707107 <-- result matched micrograd\n"]}],"source":["x0 = torch.Tensor([-3.0]).double();      x0.requires_grad = True\n","x1 = torch.Tensor([0.0]).double();       x1.requires_grad = True\n","x2 = torch.Tensor([0.5]).double();       x2.requires_grad = True\n","w0 = torch.Tensor([2.0]).double();       w0.requires_grad = True\n","w1 = torch.Tensor([1.0]).double();       w1.requires_grad = True\n","w2 = torch.Tensor([1.0]).double();       w2.requires_grad = True\n","b = torch.Tensor([4.61862664]).double(); b.requires_grad  = True\n","n = x0*w0 + x1*w1 + x2*w2 + b\n","o3 = torch.tanh(n)\n","o3.backward()\n","\n","print('---- torch results matched backward pass results ----')\n","print(f'x0.data.item()  = {x0.data.item():>9.6f}')\n","print(f'x0.grad.item()  = {x0.grad.item():>9.6f}')\n","print(f'w0.data.item()  = {w0.data.item():>9.6f}')\n","print(f'w0.grad.item()  = {w0.grad.item():>9.6f} <-- result matched micrograd')\n","print('---')\n","print(f'x1.data.item()  = {x1.data.item():>9.6f}')\n","print(f'x1.grad.item()  = {x1.grad.item():>9.6f}')\n","print(f'w1.data.item()  = {w1.data.item():>9.6f}')\n","print(f'w1.grad.item()  = {w1.grad.item():>9.6f}')\n","print('---')\n","print(f'x2.data.item()  = {x2.data.item():>9.6f}')\n","print(f'x2.grad.item()  = {x2.grad.item():>9.6f}')\n","print(f'w2.data.item()  = {w2.data.item():>9.6f}')\n","print(f'w2.grad.item()  = {w2.grad.item():>9.6f}')\n","print('---')\n","print(f'out.data.item() = {o3.data.item():>9.6f} <-- result matched micrograd')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Neural Network MLP(3, [4, 4, 1])\n","    input layer:     3 nodes\n","    hidden layer 1:  4 nodes\n","    hidden layer 2:  4 nodes\n","    output layer:    1 node\n","\n","<!-- ![Getting Started](..\\karpathy\\img\\Nertual_Network_Neuron.PNG) -->\n","<img src=\"..\\karpathy\\img\\neural_network_neuron.PNG\">"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Create neural work, initialize weights and biases, define inputs and desired outputs "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# create neural network and initialize weights and biases\n","n = MLP(3, [4, 4, 1])\n","\n","# inputs\n","xs = [\n","  [2.0, 3.0, -1.0],\n","  [3.0, -1.0, 0.5]\n","]\n","\n","# desired targets\n","ys = [1.0, -1.0]\n","\n","# learning rate (i.e. step size)\n","learning_rate = 0.05"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["parameters in MLP: 41\n","\n","i:  0,  -0.7911880687\n","i:  1,   0.1681384946\n","i:  2,   0.3434205348\n","i:  3,   0.5372491251\n","i:  4,  -0.7962553228\n","---\n","i: 36,   0.0438858644\n","i: 37,   0.1389885760\n","i: 38,  -0.4538985278\n","i: 39,   0.8435442055\n","i: 40,   0.4810401013\n"]}],"source":["# number of parameters (e.g sum (weights + bias to each neuron and output))\n","# MLP(3, [4, 4, 1]) --> 4_neurons(3_inputs + 1_bias) + 4_neurons(4_neurons + 1_bias) + 1_output(4_neurons + 1_bias) = 41_parameters \n","print(f'parameters in MLP: {len(n.parameters())}\\n')\n","\n","# print first 5 parameters\n","for i, v in enumerate(n.parameters()):\n","  if i < 5:\n","    print(f'i: {i:>2}, {v.data:>14.10f}')\n"," \n","print('---')\n","\n","# print last 5 parameters   \n","for i, v in enumerate(n.parameters()):\n","  if i >= len(n.parameters()) - 5:\n","    print(f'i: {i:>2}, {v.data:>14.10f}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### ---- Start: Calculate Neural Network Output and Loss with Matrix Multiplication ----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Transpose inputs xs"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["xs_mats[0].shape: (2, 3)\n","xs_mats:\n","[array([[ 2. ,  3. , -1. ],\n","       [ 3. , -1. ,  0.5]])]\n","\n","xs_mats_T[0].shape: (3, 2)\n","xs_mats_T:\n","[array([[ 2. ,  3. ],\n","       [ 3. , -1. ],\n","       [-1. ,  0.5]])]\n"]}],"source":["xs_mats = [np.array(xs)]  # convert xs to list of np.arrays\n","xs_mats_T = []\n","for mat in xs_mats:\n","  mat_transpose = np.transpose(mat)\n","  xs_mats_T.append(mat_transpose)\n","\n","print(f'xs_mats[0].shape: {xs_mats[0].shape}')\n","print(f'xs_mats:\\n{xs_mats}\\n')\n","print(f'xs_mats_T[0].shape: {xs_mats_T[0].shape}')\n","print(f'xs_mats_T:\\n{xs_mats_T}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Get Neural Network's Weights and Biases Matrices"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["layer_cnt: 3\n","\n","layer: 0, neuron_cnt: 4\n","----\n","layer: 0, neuron 0\n","w0: -0.7911881,   w0.grad:  0.0000000\n","w1:  0.1681385,   w1.grad:  0.0000000\n","w2:  0.3434205,   w2.grad:  0.0000000\n","b:   0.5372491\n","\n","layer: 0, neuron 1\n","w0: -0.7962553,   w0.grad:  0.0000000\n","w1: -0.1620012,   w1.grad:  0.0000000\n","w2:  0.0643322,   w2.grad:  0.0000000\n","b:  -0.0554613\n","\n","layer: 0, neuron 2\n","w0: -0.3192068,   w0.grad:  0.0000000\n","w1:  0.3057773,   w1.grad:  0.0000000\n","w2:  0.8234954,   w2.grad:  0.0000000\n","b:  -0.9533239\n","\n","layer: 0, neuron 3\n","w0:  0.5169531,   w0.grad:  0.0000000\n","w1:  0.8584325,   w1.grad:  0.0000000\n","w2:  0.3468074,   w2.grad:  0.0000000\n","b:  -0.6029976\n","\n","------\n","layer: 1, neuron_cnt: 4\n","----\n","layer: 1, neuron 0\n","w0:  0.7455540,   w0.grad:  0.0000000\n","w1: -0.5965593,   w1.grad:  0.0000000\n","w2: -0.9452535,   w2.grad:  0.0000000\n","w3:  0.0896001,   w3.grad:  0.0000000\n","b:  -0.3548910\n","\n","layer: 1, neuron 1\n","w0:  0.4024509,   w0.grad:  0.0000000\n","w1:  0.2851980,   w1.grad:  0.0000000\n","w2:  0.6652325,   w2.grad:  0.0000000\n","w3:  0.5693226,   w3.grad:  0.0000000\n","b:  -0.8488536\n","\n","layer: 1, neuron 2\n","w0:  0.1793506,   w0.grad:  0.0000000\n","w1:  0.9909725,   w1.grad:  0.0000000\n","w2:  0.7591568,   w2.grad:  0.0000000\n","w3:  0.8218845,   w3.grad:  0.0000000\n","b:   0.6513783\n","\n","layer: 1, neuron 3\n","w0:  0.5763845,   w0.grad:  0.0000000\n","w1:  0.7709540,   w1.grad:  0.0000000\n","w2:  0.8442386,   w2.grad:  0.0000000\n","w3: -0.9306916,   w3.grad:  0.0000000\n","b:   0.2378641\n","\n","------\n","layer: 2, neuron_cnt: 1\n","----\n","layer: 2, neuron 0\n","w0:  0.0438859,   w0.grad:  0.0000000\n","w1:  0.1389886,   w1.grad:  0.0000000\n","w2: -0.4538985,   w2.grad:  0.0000000\n","w3:  0.8435442,   w3.grad:  0.0000000\n","b:   0.4810401\n","\n","------\n"]}],"source":["layer_cnt = len(n.layers)\n","w_mats = []  # list of weights matrix for each layer \n","b_mats = []  # list of bias matrix for each layer\n","print(f'layer_cnt: {layer_cnt}\\n')\n","for i, layer in enumerate(n.layers):\n","    neuron_cnt = len(layer.neurons)\n","    print(f'layer: {i}, neuron_cnt: {neuron_cnt}')\n","\n","    print('----')\n","    b_mat = []  # accumulate neuon's bias for each row     \n","    for j, neuron in enumerate(layer.neurons):\n","        print(f'layer: {i}, neuron {j}')\n","        b = neuron.b.data  # bias of neuron \n","        w_row = []  # accumulate neuon's weights for each row\n","        # b_row = []  # accumulate neuon's bias for each row\n","        for k, w in enumerate(neuron.w):\n","            w_row.append(w.data)\n","            print(f'w{k}: {w.data:10.7f},   w{k}.grad: {w.grad:10.7f}')\n","        if j == 0:            \n","            w_mat = np.array([w_row])\n","        else:\n","            w_mat = np.vstack((w_mat, w_row))\n","        \n","        b_mat.append(b)\n","        print(f'b:  {b:10.7f}\\n')\n","        # print(f'b:  {b:10.7f}')        \n","        # print(f'b_mat:  {b_mat}\\n')\n","    w_mats.append(w_mat)  \n","    b_mats.append(np.array([b_mat]))        \n","    print('------')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Print Neural Network's Weights and Biases Matrices"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["i: 0\n","w_mat(4, 3):\n","[[-0.79118807  0.16813849  0.34342053]\n"," [-0.79625532 -0.16200117  0.06433224]\n"," [-0.3192068   0.30577729  0.82349538]\n"," [ 0.51695312  0.85843247  0.3468074 ]]\n","b_mat(1, 4):\n","[[ 0.53724913 -0.05546134 -0.95332389 -0.60299758]]\n","\n","i: 1\n","w_mat(4, 4):\n","[[ 0.74555399 -0.59655929 -0.94525347  0.08960008]\n"," [ 0.40245086  0.28519803  0.66523253  0.56932261]\n"," [ 0.17935063  0.99097251  0.75915685  0.8218845 ]\n"," [ 0.57638455  0.77095397  0.84423862 -0.93069165]]\n","b_mat(1, 4):\n","[[-0.35489097 -0.84885365  0.65137833  0.23786407]]\n","\n","i: 2\n","w_mat(1, 4):\n","[[ 0.04388586  0.13898858 -0.45389853  0.84354421]]\n","b_mat(1, 1):\n","[[0.4810401]]\n","\n"]}],"source":["zipped_w_n_b = zip(w_mats, b_mats)\n","for i, w_n_b in enumerate(zipped_w_n_b):\n","  print(f'i: {i}')    \n","  print(f'w_mat{w_n_b[0].shape}:\\n{w_n_b[0]}')\n","  print(f'b_mat{w_n_b[1].shape}:\\n{w_n_b[1]}\\n')  \n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Calculate Neural Network Output and Loss with Matrix Multiplication"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<img src=\"..\\karpathy\\img\\neural_mat.PNG\">"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------\n","layer: 0\n","weights (4, 3):\n","[[-0.79118807  0.16813849  0.34342053]\n"," [-0.79625532 -0.16200117  0.06433224]\n"," [-0.3192068   0.30577729  0.82349538]\n"," [ 0.51695312  0.85843247  0.3468074 ]]\n","\n","input (3, 2):\n","[[ 2.   3. ]\n"," [ 3.  -1. ]\n"," [-1.   0.5]]\n","\n","weights_x_inputs (4, 2):\n","[[-1.42138119 -2.36999243]\n"," [-2.14284641 -2.19459867]\n"," [-0.5445771  -0.85165001]\n"," [ 3.26239625  0.86583058]]\n","\n","bias (4, 1):\n","[[ 0.53724913]\n"," [-0.05546134]\n"," [-0.95332389]\n"," [-0.60299758]]\n","\n","weights_x_inputs_plus_bias (4, 2):\n","[[-0.88413206 -1.83274331]\n"," [-2.19830774 -2.25006001]\n"," [-1.49790099 -1.80497391]\n"," [ 2.65939867  0.262833  ]]\n","\n","output (4, 2):\n","[[-0.70848333 -0.95009376]\n"," [-0.97566189 -0.97802872]\n"," [-0.90476823 -0.94731868]\n"," [ 0.99025048  0.25694342]]\n","\n","--------------------------------------------------\n","layer: 1\n","weights (4, 4):\n","[[ 0.74555399 -0.59655929 -0.94525347  0.08960008]\n"," [ 0.40245086  0.28519803  0.66523253  0.56932261]\n"," [ 0.17935063  0.99097251  0.75915685  0.8218845 ]\n"," [ 0.57638455  0.77095397  0.84423862 -0.93069165]]\n","\n","input (4, 2):\n","[[-0.70848333 -0.95009376]\n"," [-0.97566189 -0.97802872]\n"," [-0.90476823 -0.94731868]\n"," [ 0.99025048  0.25694342]]\n","\n","weights_x_inputs (4, 2):\n","[[ 0.99778942  0.79358435]\n"," [-0.60149585 -1.14520142]\n"," [-0.96691052 -1.64758514]\n"," [-2.84600738 -2.3405326 ]]\n","\n","bias (4, 1):\n","[[-0.35489097]\n"," [-0.84885365]\n"," [ 0.65137833]\n"," [ 0.23786407]]\n","\n","weights_x_inputs_plus_bias (4, 2):\n","[[ 0.64289844  0.43869338]\n"," [-1.45034949 -1.99405507]\n"," [-0.31553219 -0.99620681]\n"," [-2.60814331 -2.10266853]]\n","\n","output (4, 2):\n","[[ 0.56686984  0.4125608 ]\n"," [-0.89576196 -0.96360515]\n"," [-0.30546153 -0.75999651]\n"," [-0.9892037  -0.9706069 ]]\n","\n","--------------------------------------------------\n","layer: 2\n","weights (1, 4):\n","[[ 0.04388586  0.13898858 -0.45389853  0.84354421]]\n","\n","input (4, 2):\n","[[ 0.56686984  0.4125608 ]\n"," [-0.89576196 -0.96360515]\n"," [-0.30546153 -0.75999651]\n"," [-0.9892037  -0.9706069 ]]\n","\n","weights_x_inputs (1, 2):\n","[[-0.79541162 -0.58961306]]\n","\n","bias (1, 1):\n","[[0.4810401]]\n","\n","weights_x_inputs_plus_bias (1, 2):\n","[[-0.31437152 -0.10857295]]\n","\n","output (1, 2):\n","[[-0.30440879 -0.10814833]]\n","\n","-- manual forward pass calculation --\n","manual calculation: [-0.30440879 -0.10814833]\n","desired output:     [1.0, -1.0]\n","loss:               2.496881682872085\n"]}],"source":["verbose = True   # print calculation output and weights and bias matrices \n","# verbose = False  # print calculation output only\n","\n","for layer in range(len(n.layers)):\n","  if layer == 0:  # first layer, use given inputs xs as inputs\n","    input = xs_mats_T[layer]\n","  else:  # after first layer, use outputs from preceding layers as inputs\n","    input = output\n","\n","  weights = w_mats[layer]\n","  bias = np.transpose(b_mats[layer])\n","\n","  weights_x_input = np.matmul(weights, input)\n","  weights_x_input_plus_bias = weights_x_input + bias\n","\n","  # output = np.tanh(np.matmul(weights, input) + bias)\n","  output = np.tanh(weights_x_input_plus_bias)\n","\n","  if verbose:\n","    print(f'{\"-\"*50}')\n","    print(f'layer: {layer}')\n","    print(f'weights {weights.shape}:\\n{weights}\\n')\n","    print(f'input {input.shape}:\\n{input}\\n')\n","\n","    print(f'weights_x_inputs {weights_x_input.shape}:\\n{weights_x_input}\\n')\n","    print(f'bias {bias.shape}:\\n{bias}\\n')\n","    print(f'weights_x_inputs_plus_bias {weights_x_input_plus_bias.shape}:\\n{weights_x_input_plus_bias}\\n')\n","\n","    print(f'output {output.shape}:\\n{output}\\n')    \n","\n","yout = output[0]\n","loss = sum((yout - ys)**2)\n","\n","print(f'-- manual forward pass calculation --')\n","print(f'manual calculation: {yout}')   \n","print(f'desired output:     {ys}')   \n","print(f'loss:               {loss}')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### ### ---- End: Calculate Neural Network Output and Loss with Matrix Multiplication ---- ----"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Prediction with Micrograd Neural Network"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Micrograd Forward Pass Results, Same as Matrix Multiplication"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-- micrograd forward pass calculation --\n","ypred_data:         [-0.3044087888790053, -0.10814833387648382]\n","ys:                 [1.0, -1.0]\n","loss_data:          2.4968816828720852\n"]}],"source":["ypred = [n(x) for x in xs]\n","loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))  # low loss is better, perfect is loss = 0\n","ypred_data = [v.data for v in ypred] \n","loss_data = loss.data\n","\n","print(f'-- micrograd forward pass calculation --')\n","print(f'ypred_data:         {ypred_data}')\n","print(f'ys:                 {ys}')\n","print(f'loss_data:          {loss_data}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Micrograd backward pass and update parameters"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["=== update parameters ===\n","  i  parameter before         gradient     learning rate      parameter after\n","  0     -0.7911880687     0.0838238837           0.05000        -0.7953792629\n","  1      0.1681384946     0.1022184690           0.05000         0.1630275711\n","  2      0.3434205348    -0.0333601758           0.05000         0.3450885436\n","  3      0.5372491251     0.0397740003           0.05000         0.5352604250\n","  4     -0.7962553228     0.0525661103           0.05000        -0.7988836284\n","  5     -0.1620011718     0.1509966343           0.05000        -0.1695510035\n","  6      0.0643322442    -0.0525184984           0.05000         0.0669581691\n","  7     -0.0554613369     0.0328419160           0.05000        -0.0571034327\n","  8     -0.3192068022     0.1919708248           0.05000        -0.3288053434\n","  9      0.3057772942     0.4193670923           0.05000         0.2848089395\n"," 10      0.8234953754    -0.1437711779           0.05000         0.8306839343\n"," 11     -0.9533238944     0.1079318538           0.05000        -0.9587204870\n"," 12      0.5169531169    -0.9279663097           0.05000         0.5633514324\n"," 13      0.8584324702     0.3660432131           0.05000         0.8401303096\n"," 14      0.3468073970    -0.1752869097           0.05000         0.3555717425\n"," 15     -0.6029975758    -0.3041656387           0.05000        -0.5877892939\n"," 16      0.7455539939    -0.0110443153           0.05000         0.7461062097\n"," 17     -0.5965592876     0.0059983913           0.05000        -0.5968592072\n"," 18     -0.9452534749     0.0029718675           0.05000        -0.9454020682\n"," 19      0.0896000787    -0.0533176652           0.05000         0.0922659620\n"," 20     -0.3548909742    -0.0063037537           0.05000        -0.3545757865\n"," 21      0.4024508557     0.0294245255           0.05000         0.4009796294\n"," 22      0.2851980340     0.0463054822           0.05000         0.2828827599\n"," 23      0.6652325296     0.0422342005           0.05000         0.6631208196\n"," 24      0.5693226086    -0.0598801405           0.05000         0.5723166156\n"," 25     -0.8488536456    -0.0475030599           0.05000        -0.8464784926\n"," 26      0.1793506326    -0.3690564252           0.05000         0.1978034538\n"," 27      0.9909725091    -0.6198896373           0.05000         1.0219669910\n"," 28      0.7591568488    -0.5612074279           0.05000         0.7872172202\n"," 29      0.8218845048     0.8778194491           0.05000         0.7779935324\n"," 30      0.6513783342     0.6361728391           0.05000         0.6195696922\n"," 31      0.5763845457    -0.0514527450           0.05000         0.5789571830\n"," 32      0.7709539673    -0.0424017418           0.05000         0.7730740544\n"," 33      0.8442386221    -0.0427966645           0.05000         0.8463784553\n"," 34     -0.9306916489    -0.0203326179           0.05000        -0.9296750180\n"," 35      0.2378640699     0.0432505169           0.05000         0.2357015440\n"," 36      0.0438858644    -0.6145427610           0.05000         0.0746130025\n"," 37      0.1389885760     0.4216505862           0.05000         0.1179060467\n"," 38     -0.4538985278    -0.6167034985           0.05000        -0.4230633529\n"," 39      0.8435442055     0.6304909668           0.05000         0.8120196572\n"," 40      0.4810401013    -0.6042312243           0.05000         0.5112516625\n"]}],"source":["# backward pass to calculate gradients\n","for p in n.parameters():\n","  p.grad = 0.0  # zero the gradient \n","loss.backward()\n","\n","# update weights and bias\n","if verbose:\n","  print('=== update parameters ===')\n","  print(f'  i  parameter before         gradient     learning rate      parameter after')\n","for i, p in enumerate(n.parameters()):\n","  p_before = p.data\n","  p.data += -learning_rate * p.grad\n","  if verbose:    \n","    print(f'{i:>3}  {p_before:>16.10f}   {p.grad:>14.10f}    {learning_rate:>14.5f}       {p.data:>14.10f}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Improve Prediction with Parameter Iteration "]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ypred: [Value(data = -0.16668316001096575), Value(data = -0.04322428991207708)]\n","step: 0, loss: 2.276569355267422\n","-------\n","ypred: [Value(data = -0.08456214326266621), Value(data = -0.004965079549568608)]\n","step: 1, loss: 2.1663695355143044\n","-------\n","ypred: [Value(data = -0.045077182845671554), Value(data = 0.007161534593857602)]\n","step: 2, loss: 2.1065606748700993\n","-------\n","ypred: [Value(data = -0.02580399712339421), Value(data = 0.007747849266354653)]\n","step: 3, loss: 2.0678295682152967\n","-------\n","ypred: [Value(data = -0.01461904692592382), Value(data = 0.004699728420703134)]\n","step: 4, loss: 2.0388733546735045\n","-------\n","ypred: [Value(data = -0.006501874515561262), Value(data = 0.0006906849225983299)]\n","step: 5, loss: 2.014427870294197\n","-------\n","ypred: [Value(data = 0.0006301683831138774), Value(data = -0.0037202974369529938)]\n","step: 6, loss: 1.9913133060850767\n","-------\n","ypred: [Value(data = 0.007858884436183553), Value(data = -0.008704769671464656)]\n","step: 7, loss: 1.9670102268643181\n","-------\n","ypred: [Value(data = 0.01603783051131154), Value(data = -0.014751818944240717)]\n","step: 8, loss: 1.9388955292585686\n","-------\n","ypred: [Value(data = 0.026148845021779964), Value(data = -0.022647774904275195)]\n","step: 9, loss: 1.9036034439519776\n","-------\n","ypred: [Value(data = 0.03953879049773721), Value(data = -0.033646353159681286)]\n","step: 10, loss: 1.8563251057201327\n","-------\n","ypred: [Value(data = 0.05806964093702977), Value(data = -0.049793195127909716)]\n","step: 11, loss: 1.7901257733497227\n","-------\n","ypred: [Value(data = 0.08397676143118135), Value(data = -0.0743504466874042)]\n","step: 12, loss: 1.695925669145915\n","-------\n","ypred: [Value(data = 0.11915552557432442), Value(data = -0.1119168799252981)]\n","step: 13, loss: 1.564578616287862\n","-------\n","ypred: [Value(data = 0.16440136617888665), Value(data = -0.16700370671040157)]\n","step: 14, loss: 1.3921079014779218\n","-------\n","ypred: [Value(data = 0.21975648654237095), Value(data = -0.23988681457317412)]\n","step: 15, loss: 1.1865519949524217\n","-------\n","ypred: [Value(data = 0.28417964804227125), Value(data = -0.3228594572573424)]\n","step: 16, loss: 0.9709180909027075\n","-------\n","ypred: [Value(data = 0.35315308619442826), Value(data = -0.4037854174296309)]\n","step: 17, loss: 0.7738827583693522\n","-------\n","ypred: [Value(data = 0.41960894648872665), Value(data = -0.4743774933539974)]\n","step: 18, loss: 0.6131327944887526\n","-------\n","ypred: [Value(data = 0.47851172079871945), Value(data = -0.5326185004498869)]\n","step: 19, loss: 0.490395491466025\n","-------\n","ypred: [Value(data = 0.5284475400323707), Value(data = -0.5798554779557991)]\n","step: 20, loss: 0.39888314190527263\n","-------\n","ypred: [Value(data = 0.5701282751393066), Value(data = -0.6182665805505495)]\n","step: 21, loss: 0.3305101033592778\n","-------\n","ypred: [Value(data = 0.6049200594648392), Value(data = -0.6498366405422072)]\n","step: 22, loss: 0.2787025377200336\n","-------\n","ypred: [Value(data = 0.6341677289014277), Value(data = -0.6761267120799708)]\n","step: 23, loss: 0.23872715720526944\n","-------\n","ypred: [Value(data = 0.6589942594650816), Value(data = -0.6983086131769695)]\n","step: 24, loss: 0.20730260796097152\n","-------\n","ypred: [Value(data = 0.6802849018559852), Value(data = -0.7172535477348628)]\n","step: 25, loss: 0.1821633002497585\n","-------\n","ypred: [Value(data = 0.6987246547566056), Value(data = -0.733612769648893)]\n","step: 26, loss: 0.16172899014566022\n","-------\n","ypred: [Value(data = 0.7148425491610881), Value(data = -0.7478787306142061)]\n","step: 27, loss: 0.1448799062456505\n","-------\n","ypred: [Value(data = 0.7290494465471652), Value(data = -0.7604288466904159)]\n","step: 28, loss: 0.13080853991448177\n","-------\n","ypred: [Value(data = 0.741667277408791), Value(data = -0.771556338970076)]\n","step: 29, loss: 0.11892230182614133\n","-------\n","ypred: [Value(data = 0.7529508577137882), Value(data = -0.7814920025486031)]\n","step: 30, loss: 0.10877902365457259\n","-------\n","ypred: [Value(data = 0.7631039839456256), Value(data = -0.7904197153933836)]\n","step: 31, loss: 0.10004361811822472\n","-------\n","ypred: [Value(data = 0.7722913073174558), Value(data = -0.7984876253328919)]\n","step: 32, loss: 0.09245848586717034\n","-------\n","ypred: [Value(data = 0.7806471425622581), Value(data = -0.805816328191452)]\n","step: 33, loss: 0.08582297446315221\n","-------\n","ypred: [Value(data = 0.7882820564034694), Value(data = -0.812504926148284)]\n","step: 34, loss: 0.07997889035940417\n","-------\n","ypred: [Value(data = 0.795287841776079), Value(data = -0.81863557291559)]\n","step: 35, loss: 0.07480012313635194\n","-------\n","ypred: [Value(data = 0.8017413101603614), Value(data = -0.8242769243256136)]\n","step: 36, loss: 0.07018510742139612\n","-------\n","ypred: [Value(data = 0.8077072110910323), Value(data = -0.8294867869302346)]\n","step: 37, loss: 0.06605127249776405\n","-------\n","ypred: [Value(data = 0.8132405010579085), Value(data = -0.8343141718718947)]\n","step: 38, loss: 0.06233090408759714\n","-------\n","ypred: [Value(data = 0.8183881228232642), Value(data = -0.8388009027384695)]\n","step: 39, loss: 0.05896802288959012\n","-------\n","ypred: [Value(data = 0.8231904128669184), Value(data = -0.8429828854215992)]\n","step: 40, loss: 0.05591600437269743\n","-------\n","ypred: [Value(data = 0.8276822237961308), Value(data = -0.8468911193448501)]\n","step: 41, loss: 0.053135745331319706\n","-------\n","ypred: [Value(data = 0.8318938263702995), Value(data = -0.8505525090004851)]\n","step: 42, loss: 0.0505942381784691\n","-------\n","ypred: [Value(data = 0.8358516397063998), Value(data = -0.8539905199989312)]\n","step: 43, loss: 0.048263452437260115\n","-------\n","ypred: [Value(data = 0.8395788264671834), Value(data = -0.8572257130901371)]\n","step: 44, loss: 0.04611944992026591\n","-------\n","ypred: [Value(data = 0.8430957811537361), Value(data = -0.860276181700775)]\n","step: 45, loss: 0.04414167929187113\n","-------\n","ypred: [Value(data = 0.8464205331633579), Value(data = -0.8631579126453776)]\n","step: 46, loss: 0.042312409505397386\n","-------\n","ypred: [Value(data = 0.8495690814249579), Value(data = -0.865885085254283)]\n","step: 47, loss: 0.04061627162058189\n","-------\n","ypred: [Value(data = 0.8525556737557874), Value(data = -0.8684703208220818)]\n","step: 48, loss: 0.03903988584625589\n","-------\n","ypred: [Value(data = 0.8553930412865954), Value(data = -0.8709248917355332)]\n","step: 49, loss: 0.03757155608182411\n","-------\n","ypred: [Value(data = 0.8580925961543601), Value(data = -0.8732588976866266)]\n","step: 50, loss: 0.036201018281818535\n","-------\n","ypred: [Value(data = 0.8606645990004835), Value(data = -0.8754814148669058)]\n","step: 51, loss: 0.03491923201524369\n","-------\n","ypred: [Value(data = 0.8631183015188622), Value(data = -0.8776006228650135)]\n","step: 52, loss: 0.03371820690211379\n","-------\n","ypred: [Value(data = 0.8654620682846409), Value(data = -0.8796239130704536)]\n","step: 53, loss: 0.032590857374716335\n","-------\n","ypred: [Value(data = 0.8677034812953488), Value(data = -0.8815579816631195)]\n","step: 54, loss: 0.03153088056908406\n","-------\n","ypred: [Value(data = 0.8698494300223785), Value(data = -0.8834089096953383)]\n","step: 55, loss: 0.03053265320392955\n","-------\n","ypred: [Value(data = 0.8719061892654104), Value(data = -0.8851822323172087)]\n","step: 56, loss: 0.029591144124168287\n","-------\n","ypred: [Value(data = 0.8738794866972115), Value(data = -0.886882998831105)]\n","step: 57, loss: 0.028701839829202647\n","-------\n","ypred: [Value(data = 0.8757745616597352), Value(data = -0.8885158249677096)]\n","step: 58, loss: 0.02786068081346128\n","-------\n","ypred: [Value(data = 0.8775962165080547), Value(data = -0.8900849385387013)]\n","step: 59, loss: 0.02706400694918408\n","-------\n","ypred: [Value(data = 0.8793488615835401), Value(data = -0.8915942194285548)]\n","step: 60, loss: 0.0263085104624921\n","-------\n","ypred: [Value(data = 0.8810365547218723), Value(data = -0.8930472347307008)]\n","step: 61, loss: 0.025591195311191906\n","-------\n","ypred: [Value(data = 0.8826630360571724), Value(data = -0.8944472697044791)]\n","step: 62, loss: 0.024909341980159393\n","-------\n","ypred: [Value(data = 0.8842317587645662), Value(data = -0.8957973551232769)]\n","step: 63, loss: 0.02426047687805008\n","-------\n","ypred: [Value(data = 0.8857459162850517), Value(data = -0.8971002914966226)]\n","step: 64, loss: 0.02364234565562244\n","-------\n","ypred: [Value(data = 0.8872084664947582), Value(data = -0.8983586705762822)]\n","step: 65, loss: 0.023052889877484824\n","-------\n","ypred: [Value(data = 0.8886221532124718), Value(data = -0.8995748944958315)]\n","step: 66, loss: 0.02249022657054947\n","-------\n","ypred: [Value(data = 0.8899895253822389), Value(data = -0.90075119284253)]\n","step: 67, loss: 0.021952630247805735\n","-------\n","ypred: [Value(data = 0.8913129542199159), Value(data = -0.9018896379178191)]\n","step: 68, loss: 0.021438517068298753\n","-------\n","ypred: [Value(data = 0.8925946485721636), Value(data = -0.9029921584069658)]\n","step: 69, loss: 0.02094643084587625\n","-------\n","ypred: [Value(data = 0.8938366687022389), Value(data = -0.9040605516481394)]\n","step: 70, loss: 0.02047503066229752\n","-------\n","ypred: [Value(data = 0.8950409386879978), Value(data = -0.9050964946655639)]\n","step: 71, loss: 0.02002307987625998\n","-------\n","ypred: [Value(data = 0.8962092575929128), Value(data = -0.906101554109592)]\n","step: 72, loss: 0.0195894363500482\n","-------\n","ypred: [Value(data = 0.8973433095499107), Value(data = -0.9070771952279456)]\n","step: 73, loss: 0.01917304374087079\n","-------\n","ypred: [Value(data = 0.8984446728798848), Value(data = -0.9080247899764724)]\n","step: 74, loss: 0.01877292372534561\n","-------\n","ypred: [Value(data = 0.8995148283513381), Value(data = -0.9089456243641114)]\n","step: 75, loss: 0.018388169043702544\n","-------\n","ypred: [Value(data = 0.9005551666743727), Value(data = -0.9098409051150367)]\n","step: 76, loss: 0.018017937265637603\n","-------\n","ypred: [Value(data = 0.9015669953108327), Value(data = -0.9107117657208195)]\n","step: 77, loss: 0.017661445192831457\n","-------\n","ypred: [Value(data = 0.9025515446725416), Value(data = -0.9115592719467039)]\n","step: 78, loss: 0.01731796382430472\n","-------\n","ypred: [Value(data = 0.9035099737710358), Value(data = -0.9123844268485101)]\n","step: 79, loss: 0.01698681382033028\n","-------\n","ypred: [Value(data = 0.9044433753747826), Value(data = -0.9131881753500889)]\n","step: 80, loss: 0.016667361408811622\n","-------\n","ypred: [Value(data = 0.9053527807234139), Value(data = -0.9139714084255228)]\n","step: 81, loss: 0.016359014685078384\n","-------\n","ypred: [Value(data = 0.9062391638428866), Value(data = -0.9147349669252599)]\n","step: 82, loss: 0.016061220262117586\n","-------\n","ypred: [Value(data = 0.9071034455005593), Value(data = -0.9154796450809998)]\n","step: 83, loss: 0.01577346023350132\n","-------\n","ypred: [Value(data = 0.9079464968348758), Value(data = -0.9162061937203113)]\n","step: 84, loss: 0.015495249415809521\n","-------\n","ypred: [Value(data = 0.908769142690567), Value(data = -0.9169153232186044)]\n","step: 85, loss: 0.015226132841283114\n","-------\n","ypred: [Value(data = 0.9095721646869627), Value(data = -0.9176077062131147)]\n","step: 86, loss: 0.014965683474866216\n","-------\n","ypred: [Value(data = 0.9103563040440878), Value(data = -0.9182839801009554)]\n","step: 87, loss: 0.014713500132777082\n","-------\n","ypred: [Value(data = 0.9111222641886334), Value(data = -0.9189447493409905)]\n","step: 88, loss: 0.014469205582349941\n","-------\n","ypred: [Value(data = 0.9118707131596128), Value(data = -0.9195905875772443)]\n","step: 89, loss: 0.014232444805168065\n","-------\n","ypred: [Value(data = 0.9126022858315083), Value(data = -0.9202220395997671)]\n","step: 90, loss: 0.014002883407498508\n","-------\n","ypred: [Value(data = 0.9133175859709077), Value(data = -0.9208396231572709)]\n","step: 91, loss: 0.01378020616379386\n","-------\n","ypred: [Value(data = 0.9140171881410571), Value(data = -0.9214438306344324)]\n","step: 92, loss: 0.013564115680562112\n","-------\n","ypred: [Value(data = 0.914701639467332), Value(data = -0.9220351306054998)]\n","step: 93, loss: 0.013354331169262495\n","-------\n","ypred: [Value(data = 0.9153714612753785), Value(data = -0.9226139692747037)]\n","step: 94, loss: 0.013150587318081258\n","-------\n","ypred: [Value(data = 0.916027150612547), Value(data = -0.9231807718129748)]\n","step: 95, loss: 0.012952633253498116\n","-------\n","ypred: [Value(data = 0.9166691816622402), Value(data = -0.9237359435995726)]\n","step: 96, loss: 0.0127602315834883\n","-------\n","ypred: [Value(data = 0.9172980070598985), Value(data = -0.9242798713764176)]\n","step: 97, loss: 0.012573157515036452\n","-------\n","ypred: [Value(data = 0.9179140591185415), Value(data = -0.9248129243222092)]\n","step: 98, loss: 0.01239119803937214\n","-------\n","ypred: [Value(data = 0.9185177509710626), Value(data = -0.9253354550527509)]\n","step: 99, loss: 0.012214151178993547\n","-------\n","ypred: [Value(data = 0.9191094776358224), Value(data = -0.92584780055334)]\n","step: 100, loss: 0.012041825291126754\n","-------\n","ypred: [Value(data = 0.919689617011509), Value(data = -0.9263502830485407)]\n","step: 101, loss: 0.011874038422788176\n","-------\n","ypred: [Value(data = 0.9202585308067006), Value(data = -0.9268432108141964)]\n","step: 102, loss: 0.011710617713082025\n","-------\n","ypred: [Value(data = 0.9208165654090984), Value(data = -0.927326878936112)]\n","step: 103, loss: 0.011551398838778116\n","-------\n","ypred: [Value(data = 0.921364052698964), Value(data = -0.9278015700194518)]\n","step: 104, loss: 0.011396225499587418\n","-------\n","ypred: [Value(data = 0.921901310810915), Value(data = -0.9282675548525512)]\n","step: 105, loss: 0.011244948939885058\n","-------\n","ypred: [Value(data = 0.9224286448478753), Value(data = -0.9287250930285282)]\n","step: 106, loss: 0.01109742750392901\n","-------\n","ypred: [Value(data = 0.9229463475506686), Value(data = -0.9291744335277996)]\n","step: 107, loss: 0.010953526221890428\n","-------\n","ypred: [Value(data = 0.923454699926445), Value(data = -0.9296158152643409)]\n","step: 108, loss: 0.010813116424253963\n","-------\n","ypred: [Value(data = 0.9239539718388791), Value(data = -0.9300494675983038)]\n","step: 109, loss: 0.010676075382362754\n","-------\n","ypred: [Value(data = 0.9244444225628368), Value(data = -0.9304756108173888)]\n","step: 110, loss: 0.01054228597307835\n","-------\n","ypred: [Value(data = 0.9249263013059905), Value(data = -0.9308944565891757)]\n","step: 111, loss: 0.010411636365704245\n","-------\n","ypred: [Value(data = 0.9253998476996689), Value(data = -0.9313062083864432)]\n","step: 112, loss: 0.010284019729479368\n","-------\n","ypred: [Value(data = 0.9258652922610461), Value(data = -0.931711061887343)]\n","step: 113, loss: 0.010159333960094413\n","-------\n","ypred: [Value(data = 0.926322856828613), Value(data = -0.9321092053521541)]\n","step: 114, loss: 0.010037481423813029\n","-------\n","ypred: [Value(data = 0.9267727549727236), Value(data = -0.9325008199782023)]\n","step: 115, loss: 0.009918368717899827\n","-------\n","ypred: [Value(data = 0.9272151923828704), Value(data = -0.9328860802344157)]\n","step: 116, loss: 0.009801906446163855\n","-------\n","ypred: [Value(data = 0.9276503672332245), Value(data = -0.9332651541768655)]\n","step: 117, loss: 0.00968800900852481\n","-------\n","ypred: [Value(data = 0.928078470527851), Value(data = -0.9336382037465529)]\n","step: 118, loss: 0.009576594403597222\n","-------\n","ypred: [Value(data = 0.9284996864269194), Value(data = -0.9340053850505937)]\n","step: 119, loss: 0.009467584043369257\n","-------\n","ypred: [Value(data = 0.9289141925551162), Value(data = -0.9343668486278801)]\n","step: 120, loss: 0.009360902579126699\n","-------\n","ypred: [Value(data = 0.9293221602933951), Value(data = -0.9347227397002115)]\n","step: 121, loss: 0.009256477737838886\n","-------\n","ypred: [Value(data = 0.9297237550551051), Value(data = -0.9350731984098183)]\n","step: 122, loss: 0.009154240168285692\n","-------\n","ypred: [Value(data = 0.9301191365474728), Value(data = -0.9354183600441351)]\n","step: 123, loss: 0.009054123296259712\n","-------\n","ypred: [Value(data = 0.9305084590193375), Value(data = -0.9357583552486171)]\n","step: 124, loss: 0.008956063188229977\n","-------\n","ypred: [Value(data = 0.9308918714959831), Value(data = -0.9360933102283401)]\n","step: 125, loss: 0.0088599984228989\n","-------\n","ypred: [Value(data = 0.931269518001845), Value(data = -0.9364233469390717)]\n","step: 126, loss: 0.008765869970128355\n","-------\n","ypred: [Value(data = 0.9316415377718219), Value(data = -0.9367485832684499)]\n","step: 127, loss: 0.008673621076749467\n","-------\n","ypred: [Value(data = 0.9320080654518687), Value(data = -0.9370691332078684)]\n","step: 128, loss: 0.008583197158806384\n","-------\n","ypred: [Value(data = 0.9323692312895036), Value(data = -0.9373851070156206)]\n","step: 129, loss: 0.00849454569981795\n","-------\n","ypred: [Value(data = 0.9327251613148202), Value(data = -0.9376966113718198)]\n","step: 130, loss: 0.008407616154671019\n","-------\n","ypred: [Value(data = 0.9330759775125531), Value(data = -0.9380037495255801)]\n","step: 131, loss: 0.008322359858787308\n","-------\n","ypred: [Value(data = 0.9334217979857123), Value(data = -0.9383066214349027)]\n","step: 132, loss: 0.0082387299422317\n","-------\n","ypred: [Value(data = 0.9337627371112668), Value(data = -0.9386053238996956)]\n","step: 133, loss: 0.008156681248452438\n","-------\n","ypred: [Value(data = 0.9340989056883283), Value(data = -0.9388999506883131)]\n","step: 134, loss: 0.008076170257366415\n","-------\n","ypred: [Value(data = 0.9344304110792528), Value(data = -0.9391905926579862)]\n","step: 135, loss: 0.007997155012522728\n","-------\n","ypred: [Value(data = 0.9347573573440562), Value(data = -0.939477337869485)]\n","step: 136, loss: 0.00791959505209566\n","-------\n","ypred: [Value(data = 0.9350798453685117), Value(data = -0.9397602716963382)]\n","step: 137, loss: 0.007843451343475333\n","-------\n","ypred: [Value(data = 0.9353979729862754), Value(data = -0.9400394769289067)]\n","step: 138, loss: 0.007768686221241125\n","-------\n","ypred: [Value(data = 0.9357118350953624), Value(data = -0.9403150338735978)]\n","step: 139, loss: 0.007695263328315655\n","-------\n","ypred: [Value(data = 0.936021523769281), Value(data = -0.9405870204474817)]\n","step: 140, loss: 0.007623147560112632\n","-------\n","ypred: [Value(data = 0.9363271283631067), Value(data = -0.9408555122685591)]\n","step: 141, loss: 0.0075523050115028495\n","-------\n","ypred: [Value(data = 0.9366287356147658), Value(data = -0.9411205827419156)]\n","step: 142, loss: 0.007482702926434865\n","-------\n","ypred: [Value(data = 0.9369264297417824), Value(data = -0.9413823031419769)]\n","step: 143, loss: 0.007414309650057399\n","-------\n","ypred: [Value(data = 0.937220292533722), Value(data = -0.9416407426910752)]\n","step: 144, loss: 0.007347094583200735\n","-------\n","ypred: [Value(data = 0.9375104034405568), Value(data = -0.941895968634517)]\n","step: 145, loss: 0.007281028139083011\n","-------\n","ypred: [Value(data = 0.9377968396571631), Value(data = -0.942148046312335)]\n","step: 146, loss: 0.00721608170211642\n","-------\n","ypred: [Value(data = 0.9380796762041449), Value(data = -0.9423970392278949)]\n","step: 147, loss: 0.0071522275886962226\n","-------\n","ypred: [Value(data = 0.938358986005174), Value(data = -0.9426430091135185)]\n","step: 148, loss: 0.007089439009862259\n","-------\n","ypred: [Value(data = 0.9386348399610178), Value(data = -0.9428860159932734)]\n","step: 149, loss: 0.007027690035730521\n","-------\n","ypred: [Value(data = 0.9389073070204227), Value(data = -0.9431261182430745)]\n","step: 150, loss: 0.006966955561597642\n","-------\n","ypred: [Value(data = 0.9391764542480067), Value(data = -0.9433633726482277)]\n","step: 151, loss: 0.006907211275628352\n","-------\n","ypred: [Value(data = 0.9394423468893108), Value(data = -0.9435978344585477)]\n","step: 152, loss: 0.006848433628039948\n","-------\n","ypred: [Value(data = 0.9397050484331463), Value(data = -0.9438295574411663)]\n","step: 153, loss: 0.006790599801704477\n","-------\n","ypred: [Value(data = 0.9399646206713671), Value(data = -0.9440585939311443)]\n","step: 154, loss: 0.006733687684093444\n","-------\n","ypred: [Value(data = 0.9402211237561957), Value(data = -0.9442849948799954)]\n","step: 155, loss: 0.006677675840494208\n","-------\n","ypred: [Value(data = 0.9404746162552163), Value(data = -0.9445088099022212)]\n","step: 156, loss: 0.00662254348843158\n","-------\n","ypred: [Value(data = 0.940725155204145), Value(data = -0.9447300873199542)]\n","step: 157, loss: 0.006568270473232582\n","-------\n","ypred: [Value(data = 0.9409727961574855), Value(data = -0.9449488742057967)]\n","step: 158, loss: 0.006514837244674956\n","-------\n","ypred: [Value(data = 0.9412175932371651), Value(data = -0.9451652164239419)]\n","step: 159, loss: 0.006462224834664503\n","-------\n","ypred: [Value(data = 0.9414595991792486), Value(data = -0.9453791586696593)]\n","step: 160, loss: 0.00641041483588849\n","-------\n","ypred: [Value(data = 0.941698865378815), Value(data = -0.9455907445072163)]\n","step: 161, loss: 0.006359389381396558\n","-------\n","ypred: [Value(data = 0.9419354419330849), Value(data = -0.945800016406314)]\n","step: 162, loss: 0.006309131125061996\n","-------\n","ypred: [Value(data = 0.9421693776828752), Value(data = -0.9460070157770998)]\n","step: 163, loss: 0.006259623222880281\n","-------\n","ypred: [Value(data = 0.9424007202524594), Value(data = -0.9462117830038265)]\n","step: 164, loss: 0.006210849315062897\n","-------\n","ypred: [Value(data = 0.942629516087902), Value(data = -0.946414357477215)]\n","step: 165, loss: 0.006162793508887994\n","-------\n","ypred: [Value(data = 0.9428558104939391), Value(data = -0.9466147776255833)]\n","step: 166, loss: 0.006115440362270522\n","-------\n","ypred: [Value(data = 0.9430796476694653), Value(data = -0.9468130809447921)]\n","step: 167, loss: 0.006068774868017445\n","-------\n","ypred: [Value(data = 0.9433010707416913), Value(data = -0.9470093040270646)]\n","step: 168, loss: 0.006022782438734759\n","-------\n","ypred: [Value(data = 0.9435201217990304), Value(data = -0.9472034825887256)]\n","step: 169, loss: 0.005977448892355361\n","-------\n","ypred: [Value(data = 0.9437368419227663), Value(data = -0.9473956514969106)]\n","step: 170, loss: 0.005932760438258269\n","-------\n","ypred: [Value(data = 0.943951271217558), Value(data = -0.9475858447952876)]\n","step: 171, loss: 0.005888703663951425\n","-------\n","ypred: [Value(data = 0.9441634488408308), Value(data = -0.9477740957288358)]\n","step: 172, loss: 0.0058452655222913305\n","-------\n","ypred: [Value(data = 0.9443734130310993), Value(data = -0.9479604367677207)]\n","step: 173, loss: 0.005802433319215067\n","-------\n","ypred: [Value(data = 0.9445812011352704), Value(data = -0.9481448996303039)]\n","step: 174, loss: 0.005760194701960606\n","-------\n","ypred: [Value(data = 0.9447868496349664), Value(data = -0.9483275153053263)]\n","step: 175, loss: 0.005718537647753095\n","-------\n","ypred: [Value(data = 0.9449903941719117), Value(data = -0.9485083140732975)]\n","step: 176, loss: 0.005677450452935823\n","-------\n","ypred: [Value(data = 0.9451918695724207), Value(data = -0.9486873255271242)]\n","step: 177, loss: 0.005636921722525859\n","-------\n","ypred: [Value(data = 0.9453913098710242), Value(data = -0.9488645785920121)]\n","step: 178, loss: 0.0055969403601750095\n","-------\n","ypred: [Value(data = 0.9455887483332692), Value(data = -0.9490401015446694)]\n","step: 179, loss: 0.005557495558517914\n","-------\n","ypred: [Value(data = 0.9457842174777287), Value(data = -0.9492139220318394)]\n","step: 180, loss: 0.0055185767898903075\n","-------\n","ypred: [Value(data = 0.9459777490972475), Value(data = -0.9493860670881931)]\n","step: 181, loss: 0.005480173797400834\n","-------\n","ypred: [Value(data = 0.9461693742794638), Value(data = -0.9495565631536032)]\n","step: 182, loss: 0.0054422765863408815\n","-------\n","ypred: [Value(data = 0.9463591234266252), Value(data = -0.94972543608983)]\n","step: 183, loss: 0.005404875415917802\n","-------\n","ypred: [Value(data = 0.9465470262747365), Value(data = -0.9498927111966375)]\n","step: 184, loss: 0.005367960791297281\n","-------\n","ypred: [Value(data = 0.9467331119120601), Value(data = -0.9500584132273655)]\n","step: 185, loss: 0.005331523455941694\n","-------\n","ypred: [Value(data = 0.946917408796997), Value(data = -0.9502225664039788)]\n","step: 186, loss: 0.005295554384231424\n","-------\n","ypred: [Value(data = 0.9470999447753705), Value(data = -0.950385194431613)]\n","step: 187, loss: 0.005260044774357699\n","-------\n","ypred: [Value(data = 0.9472807470971396), Value(data = -0.9505463205126374)]\n","step: 188, loss: 0.005224986041474539\n","-------\n","ypred: [Value(data = 0.9474598424325598), Value(data = -0.9507059673602557)]\n","step: 189, loss: 0.005190369811099624\n","-------\n","ypred: [Value(data = 0.947637256887816), Value(data = -0.9508641572116572)]\n","step: 190, loss: 0.005156187912753317\n","-------\n","ypred: [Value(data = 0.9478130160201452), Value(data = -0.9510209118407418)]\n","step: 191, loss: 0.005122432373826008\n","-------\n","ypred: [Value(data = 0.9479871448524709), Value(data = -0.9511762525704308)]\n","step: 192, loss: 0.005089095413664205\n","-------\n","ypred: [Value(data = 0.9481596678875656), Value(data = -0.9513302002845826)]\n","step: 193, loss: 0.005056169437866346\n","-------\n","ypred: [Value(data = 0.9483306091217596), Value(data = -0.951482775439523)]\n","step: 194, loss: 0.0050236470327801475\n","-------\n","ypred: [Value(data = 0.9484999920582137), Value(data = -0.951633998075213)]\n","step: 195, loss: 0.004991520960192557\n","-------\n","ypred: [Value(data = 0.9486678397197732), Value(data = -0.9517838878260575)]\n","step: 196, loss: 0.004959784152205101\n","-------\n","ypred: [Value(data = 0.9488341746614144), Value(data = -0.9519324639313781)]\n","step: 197, loss: 0.004928429706286916\n","-------\n","ypred: [Value(data = 0.9489990189823035), Value(data = -0.9520797452455544)]\n","step: 198, loss: 0.004897450880498402\n","-------\n","ypred: [Value(data = 0.9491623943374803), Value(data = -0.9522257502478507)]\n","step: 199, loss: 0.004866841088878592\n","-------\n"]}],"source":["# Create a list of losses\n","losses = []\n","for k in range(200):\n","  # forward pass\n","  ypred = [n(x) for x in xs]\n","  loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))  # low loss is better, perfect is loss = 0\n","  losses.append(loss.data)\n","\n","  # backward pass to calculate gradients\n","  for p in n.parameters():\n","    p.grad = 0.0  # zero the gradient \n","  loss.backward()\n","\n","  # update weights and bias\n","  for p in n.parameters():\n","      p.data += -learning_rate * p.grad\n","\n","  # print(f'x: {x}')\n","  print(f'ypred: {ypred}')\n","  print(f'step: {k}, loss: {loss.data}')   \n","  print('-------')  "]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plot_losses(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Build same model with pyTorch "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 loss: 1.1970751285552979\n","Epoch 10 loss: 0.18996579945087433\n","Epoch 20 loss: 0.004989537410438061\n","Epoch 30 loss: 7.578667282359675e-05\n","\n","Prediction:\n","tensor([[ 0.9993],\n","        [-0.9987]])\n","Loss: 1.6576777852606028e-06\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(3, 4)\n","        self.fc2 = nn.Linear(4, 4)\n","        # self.fc3 = nn.Linear(4, 4)\n","        self.fc4 = nn.Linear(4, 1)        \n","\n","    def forward(self, x):\n","        x = torch.tanh(self.fc1(x))\n","        x = torch.tanh(self.fc2(x))\n","        # x = torch.tanh(self.fc3(x))        \n","        x = self.fc4(x)  \n","        return x\n","\n","\n","\n","model = MLP()\n","\n","# inputs\n","xs = [\n","  [2.0, 3.0, -1.0],\n","  [3.0, -1.0, 0.5]\n","]\n","\n","# desired targets\n","ys = [1.0, -1.0]\n","\n","# convert to tensor\n","t_xs = torch.tensor(xs)\n","\n","# add a dimension to the index=1 position to target tensor,\n","#  e.g. change size from [2] to [2, 1]\n","t_ys = torch.unsqueeze(torch.tensor(ys), 1)\n","\n","# learning rate (i.e. step size)\n","learning_rate = 0.05\n","\n","losses = []\n","for epoch in range(40):\n","    # forward pass\n","    outputs = model(t_xs)\n","\n","    # calculate loss\n","    loss = torch.nn.functional.mse_loss(outputs, t_ys)\n","\n","    # remove loss gradient \n","    losses.append(loss.detach())\n","\n","    # backpropagate\n","    loss.backward()\n","\n","    # update weights\n","    for p in model.parameters():\n","        p.data -= learning_rate * p.grad.data\n","\n","    # zero gradients\n","    for p in model.parameters():\n","        p.grad.data.zero_()\n","\n","    if epoch % 10 == 0:\n","        print(f\"Epoch {epoch} loss: {loss}\")\n","\n","prediction = model(t_xs)\n","print('')\n","print(f\"Prediction:\\n{prediction.detach()}\")\n","print(f\"Loss: {loss}\")\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plot_losses(losses)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["input xs:\n","[[2.0, 3.0, -1.0], [3.0, -1.0, 0.5]]\n","\n","target ys:\n","[1.0, -1.0]\n","---------\n","\n","layer: 0.0,  i: 0\n","\n","w,  torch.Size([4, 3]):\n","tensor([[ 0.4952, -0.5699,  0.3840],\n","        [-0.0370,  0.3407, -0.3267],\n","        [-0.3087,  0.0199,  0.1469],\n","        [-0.4513,  0.3781, -0.4316]])\n","\n","input,  torch.Size([3, 2]):\n","tensor([[ 2.0000,  3.0000],\n","        [ 3.0000, -1.0000],\n","        [-1.0000,  0.5000]])\n","\n","w * input,  torch.Size([4, 2]):\n","tensor([[-1.1033,  2.2475],\n","        [ 1.2748, -0.6151],\n","        [-0.7046, -0.8724],\n","        [ 0.6635, -1.9478]])\n","\n","bT,  torch.Size([4, 1]):\n","tensor([[ 0.2710],\n","        [ 0.2610],\n","        [-0.4757],\n","        [ 0.6070]])\n","\n","w * input + bT,  torch.Size([4, 2]):\n","tensor([[-0.8323,  2.5186],\n","        [ 1.5358, -0.3541],\n","        [-1.1803, -1.3482],\n","        [ 1.2706, -1.3407]])\n","\n","output,  torch.Size([4, 2]):\n","tensor([[-0.6817,  0.9871],\n","        [ 0.9114, -0.3400],\n","        [-0.8275, -0.8736],\n","        [ 0.8540, -0.8718]])\n","\n","\n","layer: 1.0,  i: 2\n","\n","w,  torch.Size([4, 4]):\n","tensor([[-0.1655, -0.1606, -0.2585, -0.6142],\n","        [ 0.1981, -0.4256, -0.0472, -0.4966],\n","        [ 0.0494, -0.2767, -0.3210,  0.2561],\n","        [ 0.3980, -0.0769,  0.0601, -0.2729]])\n","\n","input,  torch.Size([4, 2]):\n","tensor([[-0.6817,  0.9871],\n","        [ 0.9114, -0.3400],\n","        [-0.8275, -0.8736],\n","        [ 0.8540, -0.8718]])\n","\n","w * input,  torch.Size([4, 2]):\n","tensor([[-0.3441,  0.6526],\n","        [-0.9080,  0.8145],\n","        [ 0.1985,  0.2000],\n","        [-0.6242,  0.6044]])\n","\n","bT,  torch.Size([4, 1]):\n","tensor([[ 0.0538],\n","        [ 0.3214],\n","        [ 0.4658],\n","        [-0.0810]])\n","\n","w * input + bT,  torch.Size([4, 2]):\n","tensor([[-0.2902,  0.7064],\n","        [-0.5865,  1.1359],\n","        [ 0.6642,  0.6658],\n","        [-0.7052,  0.5234]])\n","\n","output,  torch.Size([4, 2]):\n","tensor([[-0.2824,  0.6084],\n","        [-0.5274,  0.8130],\n","        [ 0.5812,  0.5822],\n","        [-0.6077,  0.4803]])\n","\n","\n","layer: 2.0,  i: 4\n","\n","w,  torch.Size([1, 4]):\n","tensor([[-0.3635, -0.8000,  0.2315, -0.5534]])\n","\n","input,  torch.Size([4, 2]):\n","tensor([[-0.2824,  0.6084],\n","        [-0.5274,  0.8130],\n","        [ 0.5812,  0.5822],\n","        [-0.6077,  0.4803]])\n","\n","w * input,  torch.Size([1, 2]):\n","tensor([[ 0.9954, -1.0026]])\n","\n","bT,  torch.Size([1, 1]):\n","tensor([[0.0039]])\n","\n","w * input + bT,  torch.Size([1, 2]):\n","tensor([[ 0.9993, -0.9987]])\n","\n","output,  torch.Size([1, 2]):\n","tensor([[ 0.9993, -0.9987]])\n","\n","\n"]}],"source":["print(f'input xs:\\n{xs}\\n')\n","print(f'target ys:\\n{ys}')\n","print('---------\\n')\n","l_items = list(model.parameters())\n","if len(l_items) % 2 == 0:\n","  for i in range(0, len(l_items), 2):\n","    if i == 0:\n","      x0 = torch.clone(t_xs).detach() \n","      input = torch.transpose(x0, 0, 1)\n","    else:\n","      input = output\n","\n","    w = l_items[i].detach()  # remove gradient\n","    b_ = l_items[i + 1].detach()  # remove gradient\n","    b = torch.clone(b_).detach()  # remove gradient\n","    bT = torch.unsqueeze(b, 1)  # add a dimension to index 1 position\n","    w_input = torch.matmul(w, input)\n","    w_input_bT = torch.add(w_input, bT)\n","\n","    if i == len(l_items) - 2:  # skip tanh activation on output node\n","      output = w_input_bT\n","    else:  \n","      output = torch.tanh(w_input_bT)      \n","\n","    print(f'layer: {i / 2},  i: {i}\\n')\n","    print(f'w,  {w.shape}:\\n{w}\\n')\n","    print(f'input,  {input.shape}:\\n{input}\\n')\n","    print(f'w * input,  {w_input.shape}:\\n{w_input}\\n')        \n","    print(f'bT,  {bT.shape}:\\n{bT}\\n')\n","    print(f'w * input + bT,  {w_input_bT.shape}:\\n{w_input_bT}\\n')\n","    print(f'output,  {output.shape}:\\n{output}\\n')            \n","    print('')\n","else:\n","  raise ValueError(f\"len(l_items) {len(l_items)} is not divisible by 2.\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 2])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["t_ys = torch.tensor(ys)\n","t_ys_ = torch.unsqueeze(t_ys, 0)\n","t_ys_.shape"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.9993, -0.9987]]) torch.Size([1, 2])\n","tensor([[ 1., -1.]]) torch.Size([1, 2])\n"]},{"data":{"text/plain":["tensor(2.1670e-06)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["t_ys = torch.tensor(ys)\n","t_ys_ = torch.unsqueeze(t_ys, 0)\n","t_ys_.shape\n","\n","print(output, output.shape)\n","print(t_ys_, t_ys_.shape)\n","\n","difference = output - t_ys_\n","squared_difference = torch.pow(difference, 2)\n","# loss = torch.sum(squared_difference) / len(squared_difference)\n","loss = torch.sum(squared_difference)\n","loss"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.9993, -0.9987]]) torch.Size([1, 2])\n","tensor([ 1., -1.]) torch.Size([2])\n","difference: tensor([[-0.0007,  0.0013]])\n","squared_difference: tensor([[4.8991e-07, 1.6771e-06]])\n"]},{"data":{"text/plain":["tensor(1.0835e-06)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["print(output, output.shape)\n","print(torch.tensor(ys), torch.tensor(ys).shape)\n","\n","difference = output - torch.tensor(ys)\n","print(f'difference: {difference}')\n","squared_difference = torch.pow(difference, 2)\n","print(f'squared_difference: {squared_difference}')\n","# loss = torch.sum(squared_difference) / len(squared_difference)\n","loss = torch.sum(squared_difference) / 2\n","loss"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["1"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["difference\n","len(squared_difference)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(1.0835e-06)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["t_ys = torch.tensor(ys)\n","t_ys_ = torch.unsqueeze(t_ys, 0)\n","t_ys_.shape\n","\n","torch.nn.functional.mse_loss(output, t_ys_)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(2.1670e-06)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["torch.sum((output - torch.tensor(ys))**2)"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
