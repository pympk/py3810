{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code finds the recent dates in df_picks that are missing in df_model_top_picks. For those missing dates, it finds stock picks in df_picks that meet the 'criteria_model_top_picks' and append them to df_model_top_picks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "pd.set_option('display.width', 900)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "fp_df_picks  = f'df_picks'  # stock picks by criteria: CAGR/UI, CAGR/rtn_std, rtd/UI\n",
    "fp_df_model_top_picks = f'df_model_top_picks'  # top stock picks from model developed by back test\n",
    "\n",
    "verbose = True\n",
    "# verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicts the best performing symbols are from df_filtered_picks  columns:\n",
      "performance   days_lookbacks      sym_freq      days_eval           \n",
      "1st           [30, 60, 120]       sym_freq_9    days_eval = 4       \n",
      "2nd           [15, 30, 60, 120]   sym_freq_12   days_eval = 5       \n",
      "3rd           [30, 60, 120]       sym_freq_8    days_eval = 4       \n",
      "\n",
      "model criteria for top picks:\n",
      "[([30, 60, 120], 'sym_freq_9'), ([15, 30, 60, 120], 'sym_freq_12'), ([30, 60, 120], 'sym_freq_8')]\n"
     ]
    }
   ],
   "source": [
    "print(f'Model predicts the best performing symbols are from df_filtered_picks  columns:')\n",
    "print(f'performance   {\"days_lookbacks\":<20}{\"sym_freq\":<14}{\"days_eval\":<20}')\n",
    "print(f'1st           {\"[30, 60, 120]\":<20}{\"sym_freq_9\":<14}{\"days_eval = 4\":<20}')\n",
    "print(f'2nd           {\"[15, 30, 60, 120]\":<20}{\"sym_freq_12\":<14}{\"days_eval = 5\":<20}')\n",
    "print(f'3rd           {\"[30, 60, 120]\":<20}{\"sym_freq_8\":<14}{\"days_eval = 4\":<20}')\n",
    "\n",
    "criteria_model_top_picks = [([30, 60, 120], 'sym_freq_9'), ([15, 30, 60, 120], 'sym_freq_12'), ([30, 60, 120], 'sym_freq_8')]\n",
    "print(f'\\nmodel criteria for top picks:\\n{criteria_model_top_picks}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criteria of the best stocks from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists for lookback periods and column names:\n",
    "\n",
    "# 1. Lookback periods (in days) for two potential scenarios:\n",
    "my_days_lookbacks = [\n",
    "    [30, 60, 120],  # Scenario 1: Lookbacks of 30, 60, and 120 days\n",
    "    [15, 30, 60, 120]  # Scenario 2: Lookbacks of 15, 30, 60, and 120 days\n",
    "]\n",
    "\n",
    "# 2. Columns to be used in the analysis:\n",
    "my_cols = ['sym_freq_12', 'sym_freq_9', 'sym_freq_8']  # Columns representing frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df_model_top_picks: 1509\n",
      "         date  days_lookback   syms_freq         symbols\n",
      "0  2024-01-26  [30, 60, 120]  sym_freq_9         ['SHV']\n",
      "1  2024-01-26  [30, 60, 120]  sym_freq_8        ['FTSM']\n",
      "2  2024-01-25  [30, 60, 120]  sym_freq_9         ['SHV']\n",
      "3  2024-01-24  [30, 60, 120]  sym_freq_8         ['SHV']\n",
      "4  2024-01-23  [30, 60, 120]  sym_freq_8  ['ANF', 'SHV'] \n",
      "\n",
      "            date  days_lookback   syms_freq   symbols\n",
      "1504  2018-07-12  [30, 60, 120]  sym_freq_8  ['TNDM']\n",
      "1505  2018-07-11  [30, 60, 120]  sym_freq_8  ['TNDM']\n",
      "1506  2018-07-10  [30, 60, 120]  sym_freq_8  ['TNDM']\n",
      "1507  2018-07-09  [30, 60, 120]  sym_freq_8  ['TNDM']\n",
      "1508  2018-07-06  [30, 60, 120]  sym_freq_8  ['TNDM']\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame from a pickle file\n",
    "df_model_top_picks = pickle_load(path_data_dump, fp_df_model_top_picks)\n",
    "\n",
    "# Print the length of the DataFrame\n",
    "print(f'Length of df_model_top_picks: {len(df_model_top_picks)}')\n",
    "\n",
    "# Print the first 5 rows of the DataFrame\n",
    "print(df_model_top_picks.head(), '\\n')\n",
    "\n",
    "# Print the last 5 rows of the DataFrame\n",
    "print(df_model_top_picks.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest date in model: 2024-01-26\n"
     ]
    }
   ],
   "source": [
    "# 1. Extract dates from DataFrame:\n",
    "dates_in_model = df_model_top_picks.date.tolist()  # Convert date column to a list\n",
    "\n",
    "# 2. Find the latest date:\n",
    "latest_date_in_model = max(dates_in_model, key=lambda x: datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "\n",
    "# 3. Print the latest date:\n",
    "print(f\"Latest date in model: {latest_date_in_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean df_picks_pick data:<br>- drop duplicates<br>- sort on date<br>- re-index<br>- save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the DataFrame from a pickle file df_picks\n",
      "Dropping duplicates, keeping last occurrence...\n",
      "Sorting by date, max lookback, then lookback (descending)...\n",
      "Resetting index...\n",
      "Save the modified DataFrame back to a pickle file df_picks\n",
      "Number of rows: 2806\n",
      "     date_end_df_train  max_days_lookbacks     days_lookbacks sym_freq_15 sym_freq_14 sym_freq_13 sym_freq_12 sym_freq_11 sym_freq_10        sym_freq_9                     sym_freq_8                sym_freq_7                     sym_freq_6                     sym_freq_5                     sym_freq_4                     sym_freq_3 sym_freq_2\n",
      "0           2024-01-29                 120      [30, 60, 120]          []          []          []          []          []          []           ['SHV']                ['ANF', 'FTSM']                        []                ['CYTK', 'PGR']   ['AGO', 'FATE', 'NTNX', 'X']                             []  ['BK', 'GDDY', 'HA', 'HY',...         []\n",
      "1           2024-01-29                 120  [15, 30, 60, 120]          []          []          []          []     ['SHV']          []                []                ['ANF', 'FTSM']   ['FATE', 'NTNX', 'PGR']               ['CYTK', 'JNPR']   ['AGO', 'NVDA', 'SMCI', 'X']         ['AMD', 'NOW', 'SPLK']  ['ASML', 'BK', 'BSIG', 'CB...         []\n",
      "2           2024-01-26                 120      [30, 60, 120]          []          []          []          []          []          []           ['SHV']                       ['FTSM']           ['ANF', 'CYTK']                 ['HY', 'SRPT']                   ['AGO', 'X']                       ['FATE']  ['AMD', 'BK', 'GDDY', 'HA'...         []\n",
      "3           2024-01-26                 120  [15, 30, 60, 120]          []          []          []          []     ['SHV']          []                []                       ['FTSM']           ['ANF', 'CYTK']         ['HY', 'JNPR', 'SRPT']  ['AGO', 'AMD', 'NVDA', 'PG...               ['FATE', 'NTNX']  ['ASML', 'BK', 'BMA', 'BSI...         []\n",
      "4           2024-01-25                 120      [30, 60, 120]          []          []          []          []          []          []           ['SHV']                             []          ['CYTK', 'FTSM']                  ['ANF', 'HY']                  ['FFWM', 'X']       ['FATE', 'NTNX', 'WING']  ['AGO', 'AMD', 'BK', 'BLFS...         []\n",
      "...                ...                 ...                ...         ...         ...         ...         ...         ...         ...               ...                            ...                       ...                            ...                            ...                            ...                            ...        ...\n",
      "2801        2018-07-05                 120  [15, 30, 60, 120]          []          []          []          []          []          []          ['RAMP']  ['ARWR', 'BLFS', 'NTRA', '...   ['RGNX', 'SHV', 'SRPT']               ['CATO', 'ETSY']        ['CYRX', 'FTSM', 'RUN']   ['DRI', 'MSGS', 'STAA', 'W']                ['AEE', 'AXGN']         []\n",
      "2802        2018-07-03                 120      [30, 60, 120]          []          []          []          []          []          []                []                             []  ['CATO', 'RGNX', 'TNDM']  ['ARWR', 'BLFS', 'ETSY', '...  ['CYRX', 'FTSM', 'RUN', 'S...          ['CARA', 'MSGS', 'W']       ['AXGN', 'AXON', 'EVTC']         []\n",
      "2803        2018-07-03                 120  [15, 30, 60, 120]          []          []          []          []          []          []  ['RAMP', 'RGNX']  ['ARWR', 'BLFS', 'ETSY', '...   ['CATO', 'SHV', 'SRPT']                       ['XENE']  ['CARA', 'CYRX', 'FTSM', '...                  ['MSGS', 'W']        ['AEE', 'AXGN', 'AXON']         []\n",
      "2804        2018-07-02                 120      [30, 60, 120]          []          []          []          []          []          []                []                             []          ['TNDM', 'XENE']  ['ARWR', 'BLFS', 'CATO', '...                ['RUN', 'SRPT']  ['CARA', 'CYRX', 'FTSM', '...        ['AXON', 'LULU', 'NSP']         []\n",
      "2805        2018-07-02                 120  [15, 30, 60, 120]          []          []          []          []          []          []                []  ['ARWR', 'BLFS', 'ETSY', '...           ['SHV', 'SRPT']                       ['CATO']                ['CARA', 'RUN']  ['CYRX', 'ENPH', 'FTSM', '...                ['AEE', 'AXON']         []\n",
      "\n",
      "[2806 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Load data from pickle file fpdf_model_top_picks_picks\n",
    "print(f\"Load the DataFrame from a pickle file {fp_df_picks }\")\n",
    "df_picks  = pickle_load(path_data_dump, fp_df_picks)\n",
    "\n",
    "# 2. Drop duplicates, keeping the last occurrence\n",
    "print(\"Dropping duplicates, keeping last occurrence...\")\n",
    "df_picks = df_picks.drop_duplicates(subset=['date_end_df_train', 'max_days_lookbacks', 'days_lookbacks'], keep='last')\n",
    "\n",
    "# 3. Sort by date, max lookback, then lookback (descending)\n",
    "print(\"Sorting by date, max lookback, then lookback (descending)...\")\n",
    "df_picks = df_picks.sort_values(by=['date_end_df_train', 'max_days_lookbacks', 'days_lookbacks'], ascending=False)\n",
    "\n",
    "# 4. Reset index (optional)\n",
    "print(\"Resetting index...\")\n",
    "df_picks = df_picks.reset_index(drop=True)\n",
    "\n",
    "# 5. Save data to pickle (replace with actual saving)\n",
    "# Comment: Save the modified DataFrame back to a pickle file\n",
    "print(f\"Save the modified DataFrame back to a pickle file {fp_df_picks}\")\n",
    "pickle_dump(df_picks, path_data_dump, fp_df_picks)\n",
    "\n",
    "# 6. Print information about the DataFrame\n",
    "print(f\"Number of rows: {len(df_picks)}\")\n",
    "print(df_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  date_end_df_train  max_days_lookbacks     days_lookbacks sym_freq_15 sym_freq_14 sym_freq_13 sym_freq_12 sym_freq_11 sym_freq_10 sym_freq_9       sym_freq_8               sym_freq_7        sym_freq_6                    sym_freq_5              sym_freq_4                     sym_freq_3 sym_freq_2\n",
      "0        2024-01-29                 120      [30, 60, 120]          []          []          []          []          []          []    ['SHV']  ['ANF', 'FTSM']                       []   ['CYTK', 'PGR']  ['AGO', 'FATE', 'NTNX', 'X']                      []  ['BK', 'GDDY', 'HA', 'HY',...         []\n",
      "1        2024-01-29                 120  [15, 30, 60, 120]          []          []          []          []     ['SHV']          []         []  ['ANF', 'FTSM']  ['FATE', 'NTNX', 'PGR']  ['CYTK', 'JNPR']  ['AGO', 'NVDA', 'SMCI', 'X']  ['AMD', 'NOW', 'SPLK']  ['ASML', 'BK', 'BSIG', 'CB...         []\n"
     ]
    }
   ],
   "source": [
    "# Convert the date column to datetime format for accurate filtering\n",
    "df_picks['date_end_df_train'] = pd.to_datetime(df_picks['date_end_df_train'])\n",
    "\n",
    "# Filter rows after '2013-12-31' (exclusive)\n",
    "df_filtered_picks = df_picks[df_picks['date_end_df_train'] > latest_date_in_model]\n",
    "\n",
    "# SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Convert the date column back to '%Y-%m-%d' format\n",
    "df_filtered_picks['date_end_df_train'] = df_filtered_picks['date_end_df_train'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# # Print the filtered DataFrame\n",
    "print(df_filtered_picks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get dates in df_filtered_picks where values in column \"days_lookbacks\" matched items in my_days_lookbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates_in_days_lookbacks, len(1):\n",
      "['2024-01-29']\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the dates\n",
    "dates_in_days_lookbacks = []\n",
    "\n",
    "# Iterate through each days lookback configuration\n",
    "for my_days_lookback in my_days_lookbacks:\n",
    "    # Create a mask to filter rows based on the current days lookback\n",
    "    mask_days_lookback = df_filtered_picks ['days_lookbacks'] == str(my_days_lookback)\n",
    "\n",
    "    # Extract the ending dates for the training datasets that match the lookback\n",
    "    l_dates = df_filtered_picks.loc[mask_days_lookback, 'date_end_df_train'].tolist()\n",
    "\n",
    "    # Extend the dates list with the extracted dates (avoiding nested lists)\n",
    "    dates_in_days_lookbacks.extend(l_dates)\n",
    "\n",
    "# Remove duplicates and sort the dates from newest to oldest\n",
    "dates_in_days_lookbacks = sorted(set(dates_in_days_lookbacks), reverse=True)\n",
    "\n",
    "# Print the list of dates along with its length\n",
    "print(f'dates_in_days_lookbacks, len({len(dates_in_days_lookbacks)}):\\n{dates_in_days_lookbacks}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of tuples of all combination of dates_in_days_lookbacks and criteria_model_top_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_lookback_symfreq, len(3):\n",
      "[('2024-01-29', ([30, 60, 120], 'sym_freq_9')), ('2024-01-29', ([15, 30, 60, 120], 'sym_freq_12')), ('2024-01-29', ([30, 60, 120], 'sym_freq_8'))]\n"
     ]
    }
   ],
   "source": [
    "# Generate all possible combinations of dates, lookbacks, and top features\n",
    "date_lookback_symfreq = list(product(\n",
    "    dates_in_days_lookbacks,  # List of dates\n",
    "    criteria_model_top_picks  # List of (lookback, top feature) tuples\n",
    "))\n",
    "\n",
    "# Print the resulting list of tuples, along with its length\n",
    "print(f'date_lookback_symfreq, len({len(date_lookback_symfreq)}):\\n{date_lookback_symfreq}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get symbols in my_cols where values of \"date_end_df_picks_train\" equals to dates_in_days_lookbacks, and \"days_lookbacks\" equals to my_days_lookbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Results:\n",
      "0     2024-01-29    [30, 60, 120]        sym_freq_9 : ['SHV']\n",
      "1                   [15, 30, 60, 120]    sym_freq_12: []\n",
      "2                   [30, 60, 120]        sym_freq_8 : ['ANF', 'FTSM']\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the picked symbols\n",
    "picks = []\n",
    "\n",
    "# Track the previous date for formatting output\n",
    "prev_date = ''\n",
    "\n",
    "# Iterate through each combination of date, lookback, and top feature,\n",
    "# now handling the nested tuple structure\n",
    "for i, (_date, (my_days_lookback, my_col)) in enumerate(date_lookback_symfreq):\n",
    "    # Create a mask to filter rows in the DataFrame based on the date and lookback criteria\n",
    "    mask = (df_filtered_picks['date_end_df_train'] == _date) & (df_filtered_picks['days_lookbacks'] == str(my_days_lookback))\n",
    "\n",
    "    # Extract the list of symbols picked by the model for the current criteria\n",
    "    list_in_df_filtered_picks = df_filtered_picks.loc[mask, my_col]\n",
    "    my_str = list_in_df_filtered_picks.tolist()[0]  # Convert the Pandas Series to a string\n",
    "    my_list = literal_eval(my_str)  # Convert the string representation of the list to an actual list\n",
    "\n",
    "    # Print the model's picks in a formatted way, grouping by date\n",
    "    if _date != prev_date:\n",
    "        if prev_date == '':\n",
    "            print(\"\\nModel Results:\")  # Print a header for the results\n",
    "        else:\n",
    "            print(\"\\n\")  # Separate results for different dates\n",
    "        print(f\"{i:<6}{_date:<14}{str(my_days_lookback):<21}{my_col:<11}: {my_list}\")\n",
    "    else:\n",
    "        print(f\"{i:<6}{' ':<14}{str(my_days_lookback):<21}{my_col:<11}: {my_list}\")\n",
    "\n",
    "    # Add the picked symbols to the list of picks\n",
    "    picks.append((i, my_list))\n",
    "\n",
    "    # Update the previous date for the next iteration\n",
    "    prev_date = _date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create iterable z_items of date_lookback_symfreq and picks<br>Add picks to df_model_top_picks if dlb_sym_freq match criteria_model_top_picks and _syms has symbol(s)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before add len(df_model_top_picks): 1509\n",
      "0, 2024-01-29, [30, 60, 120], sym_freq_9, ['SHV']\n",
      "\n",
      "Added row 1509 to df_model_top_picks:\n",
      "['2024-01-29', [30, 60, 120], 'sym_freq_9', ['SHV']]\n",
      "\n",
      "1, 2024-01-29, [15, 30, 60, 120], sym_freq_12, []\n",
      "2, 2024-01-29, [30, 60, 120], sym_freq_8, ['ANF', 'FTSM']\n",
      "\n",
      "Added row 1510 to df_model_top_picks:\n",
      "['2024-01-29', [30, 60, 120], 'sym_freq_8', ['ANF', 'FTSM']]\n",
      "\n",
      "after add len(df_model_top_picks): 1511\n"
     ]
    }
   ],
   "source": [
    "print(f'before add len(df_model_top_picks): {len(df_model_top_picks)}')\n",
    "\n",
    "# Combine date_lookback_symfreq and picks into a single iterable\n",
    "z_items = zip(date_lookback_symfreq, picks)\n",
    "\n",
    "# Iterate through each combined item\n",
    "for i, item in enumerate(z_items):\n",
    "    # Unpack the date, lookback, feature, counter, and symbols\n",
    "    _date, _days_lookback, _sym_freq, _counter, _syms = (\n",
    "        item[0][0],\n",
    "        item[0][1][0],  # Accessing nested tuple elements\n",
    "        item[0][1][1],\n",
    "        item[1][0],\n",
    "        item[1][1],\n",
    "    )\n",
    "\n",
    "    len_df_model_top_picks = len(df_model_top_picks)\n",
    "\n",
    "    # Print the current item's details for inspection\n",
    "    print(f\"{i}, {_date}, {_days_lookback}, {_sym_freq}, {_syms}\")\n",
    "\n",
    "    # Create a tuple for model criteria matching\n",
    "    dlb_sym_freq = (_days_lookback, _sym_freq)\n",
    "\n",
    "    # Add data to the DataFrame if the criteria are met and symbols exist\n",
    "    if dlb_sym_freq in criteria_model_top_picks and _syms:\n",
    "        row_add = [_date, _days_lookback, _sym_freq, _syms]\n",
    "        df_model_top_picks.loc[len_df_model_top_picks] = row_add  # Append row using index\n",
    "        print(f\"\\nAdded row {len_df_model_top_picks} to df_model_top_picks:\\n{row_add}\\n\")\n",
    "\n",
    "print(f'after add len(df_model_top_picks): {len(df_model_top_picks)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_model_top_picks:\n",
      "            date  days_lookback   syms_freq          symbols\n",
      "0     2024-01-29  [30, 60, 120]  sym_freq_9          ['SHV']\n",
      "1     2024-01-29  [30, 60, 120]  sym_freq_8  ['ANF', 'FTSM']\n",
      "2     2024-01-26  [30, 60, 120]  sym_freq_9          ['SHV']\n",
      "3     2024-01-26  [30, 60, 120]  sym_freq_8         ['FTSM']\n",
      "4     2024-01-25  [30, 60, 120]  sym_freq_9          ['SHV']\n",
      "...          ...            ...         ...              ...\n",
      "1506  2018-07-12  [30, 60, 120]  sym_freq_8         ['TNDM']\n",
      "1507  2018-07-11  [30, 60, 120]  sym_freq_8         ['TNDM']\n",
      "1508  2018-07-10  [30, 60, 120]  sym_freq_8         ['TNDM']\n",
      "1509  2018-07-09  [30, 60, 120]  sym_freq_8         ['TNDM']\n",
      "1510  2018-07-06  [30, 60, 120]  sym_freq_8         ['TNDM']\n",
      "\n",
      "[1511 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert all data types in the DataFrame to strings\n",
    "df_model_top_picks = df_model_top_picks.astype(str)\n",
    "\n",
    "# Remove any duplicate rows, keeping the last occurrence of each\n",
    "df_model_top_picks = df_model_top_picks.drop_duplicates(keep='last')\n",
    "\n",
    "# Sort the DataFrame by 'date' (descending), 'days_lookback' (descending), and 'syms_freq' (descending)\n",
    "df_model_top_picks = df_model_top_picks.sort_values(\n",
    "    by=['date', 'days_lookback', 'syms_freq'], ascending=False\n",
    ")\n",
    "\n",
    "# Reset the index of the DataFrame, dropping the old index\n",
    "df_model_top_picks = df_model_top_picks.reset_index(drop=True)\n",
    "\n",
    "print(f'df_model_top_picks:\\n{df_model_top_picks}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup df_model_top_picks<br>- convert data to str<br>- drop duplicates, keep last value<br>- sort date, newest first<br>- re-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df_model_top_picks: 1511\n",
      "File path: df_model_top_picks\n",
      "DataFrame contents:\n",
      "            date  days_lookback   syms_freq          symbols\n",
      "0     2024-01-29  [30, 60, 120]  sym_freq_9          ['SHV']\n",
      "1     2024-01-29  [30, 60, 120]  sym_freq_8  ['ANF', 'FTSM']\n",
      "2     2024-01-26  [30, 60, 120]  sym_freq_9          ['SHV']\n",
      "3     2024-01-26  [30, 60, 120]  sym_freq_8         ['FTSM']\n",
      "4     2024-01-25  [30, 60, 120]  sym_freq_9          ['SHV']\n",
      "...          ...            ...         ...              ...\n",
      "1506  2018-07-12  [30, 60, 120]  sym_freq_8         ['TNDM']\n",
      "1507  2018-07-11  [30, 60, 120]  sym_freq_8         ['TNDM']\n",
      "1508  2018-07-10  [30, 60, 120]  sym_freq_8         ['TNDM']\n",
      "1509  2018-07-09  [30, 60, 120]  sym_freq_8         ['TNDM']\n",
      "1510  2018-07-06  [30, 60, 120]  sym_freq_8         ['TNDM']\n",
      "\n",
      "[1511 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert all data types in the DataFrame to strings\n",
    "df_model_top_picks = df_model_top_picks.astype(str)\n",
    "\n",
    "# Remove any duplicate rows, keeping the last occurrence of each\n",
    "df_model_top_picks = df_model_top_picks.drop_duplicates(keep='last')\n",
    "\n",
    "# Sort the DataFrame by 'date' (descending), 'days_lookback' (descending), and 'syms_freq' (descending)\n",
    "df_model_top_picks = df_model_top_picks.sort_values(\n",
    "    by=['date', 'days_lookback', 'syms_freq'], ascending=False\n",
    ")\n",
    "\n",
    "# Reset the index of the DataFrame, dropping the old index\n",
    "df_model_top_picks = df_model_top_picks.reset_index(drop=True)\n",
    "\n",
    "# Save the DataFrame to a pickle file\n",
    "pickle_dump(df_model_top_picks, path_data_dump, fp_df_model_top_picks)\n",
    "\n",
    "# Print the length of the DataFrame\n",
    "print(f'Length of df_model_top_picks: {len(df_model_top_picks)}')\n",
    "\n",
    "# Print the file path and contents of the DataFrame\n",
    "print(f'File path: {fp_df_model_top_picks}\\nDataFrame contents:\\n{df_model_top_picks}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_model_top_picks.head(20):\n",
      "          date      days_lookback    syms_freq           symbols\n",
      "0   2024-01-29      [30, 60, 120]   sym_freq_9           ['SHV']\n",
      "1   2024-01-29      [30, 60, 120]   sym_freq_8   ['ANF', 'FTSM']\n",
      "2   2024-01-26      [30, 60, 120]   sym_freq_9           ['SHV']\n",
      "3   2024-01-26      [30, 60, 120]   sym_freq_8          ['FTSM']\n",
      "4   2024-01-25      [30, 60, 120]   sym_freq_9           ['SHV']\n",
      "5   2024-01-24      [30, 60, 120]   sym_freq_8           ['SHV']\n",
      "6   2024-01-23      [30, 60, 120]   sym_freq_8    ['ANF', 'SHV']\n",
      "7   2024-01-22      [30, 60, 120]   sym_freq_8           ['SHV']\n",
      "8   2024-01-19      [30, 60, 120]   sym_freq_8   ['CYTK', 'SHV']\n",
      "9   2024-01-18      [30, 60, 120]   sym_freq_9           ['SHV']\n",
      "10  2024-01-18      [30, 60, 120]   sym_freq_8          ['CYTK']\n",
      "11  2024-01-17      [30, 60, 120]   sym_freq_9           ['SHV']\n",
      "12  2024-01-17      [30, 60, 120]   sym_freq_8  ['CYTK', 'FTSM']\n",
      "13  2024-01-16      [30, 60, 120]   sym_freq_9   ['CYTK', 'SHV']\n",
      "14  2024-01-16      [30, 60, 120]   sym_freq_8          ['FTSM']\n",
      "15  2024-01-12      [30, 60, 120]   sym_freq_9          ['CYTK']\n",
      "16  2024-01-12      [30, 60, 120]   sym_freq_8   ['FTSM', 'SHV']\n",
      "17  2024-01-11      [30, 60, 120]   sym_freq_9          ['CYTK']\n",
      "18  2024-01-11      [30, 60, 120]   sym_freq_8   ['FTSM', 'SHV']\n",
      "19  2024-01-11  [15, 30, 60, 120]  sym_freq_12          ['CYTK']\n"
     ]
    }
   ],
   "source": [
    "print(f'{fp_df_model_top_picks}.head(20):\\n{df_model_top_picks.head(20)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
