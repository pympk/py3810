{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "pd.set_option('display.width', 900)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "fp_df_picks  = f'df_picks'  # stock picks by criteria: CAGR/UI, CAGR/rtn_std, rtd/UI\n",
    "fp_df_model_top_picks = f'df_model_top_picks'  # top stock picks from model developed by back test\n",
    "\n",
    "verbose = True\n",
    "# verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean df_picks_pick data:<br>- drop duplicates<br>- sort on date<br>- re-index<br>- save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicts the best performing symbols are from df_filtered_picks  columns:\n",
      "performance   days_lookbacks      sym_freq      days_eval           \n",
      "1st           [30, 60, 120]       sym_freq_9    days_eval = 4       \n",
      "2nd           [15, 30, 60, 120]   sym_freq_12   days_eval = 5       \n",
      "3rd           [30, 60, 120]       sym_freq_8    days_eval = 4       \n"
     ]
    }
   ],
   "source": [
    "print(f'Model predicts the best performing symbols are from df_filtered_picks  columns:')\n",
    "print(f'performance   {\"days_lookbacks\":<20}{\"sym_freq\":<14}{\"days_eval\":<20}')\n",
    "print(f'1st           {\"[30, 60, 120]\":<20}{\"sym_freq_9\":<14}{\"days_eval = 4\":<20}')\n",
    "print(f'2nd           {\"[15, 30, 60, 120]\":<20}{\"sym_freq_12\":<14}{\"days_eval = 5\":<20}')\n",
    "print(f'3rd           {\"[30, 60, 120]\":<20}{\"sym_freq_8\":<14}{\"days_eval = 4\":<20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criteria of the best stocks from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_days_lookbacks = [[30, 60, 120], [15, 30, 60, 120]]\n",
    "my_cols = ['sym_freq_12', 'sym_freq_9', 'sym_freq_8']\n",
    "criteria_model_top_picks = [([30, 60, 120], 'sym_freq_9'), ([15, 30, 60, 120], 'sym_freq_12'), ([30, 60, 120], 'sym_freq_8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df_model_top_picks: 1479\n",
      "         date      days_lookback    syms_freq                  symbols\n",
      "0  2024-01-04      [30, 60, 120]   sym_freq_9                 ['CYTK']\n",
      "1  2024-01-04      [30, 60, 120]   sym_freq_8          ['FTSM', 'SHV']\n",
      "2  2024-01-04  [15, 30, 60, 120]  sym_freq_12                 ['CYTK']\n",
      "3  2024-01-03      [30, 60, 120]   sym_freq_8  ['CYTK', 'FTSM', 'SHV']\n",
      "4  2024-01-02      [30, 60, 120]   sym_freq_8          ['CYTK', 'SHV'] \n",
      "\n",
      "            date  days_lookback   syms_freq   symbols\n",
      "1474  2018-07-12  [30, 60, 120]  sym_freq_8  ['TNDM']\n",
      "1475  2018-07-11  [30, 60, 120]  sym_freq_8  ['TNDM']\n",
      "1476  2018-07-10  [30, 60, 120]  sym_freq_8  ['TNDM']\n",
      "1477  2018-07-09  [30, 60, 120]  sym_freq_8  ['TNDM']\n",
      "1478  2018-07-06  [30, 60, 120]  sym_freq_8  ['TNDM']\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame from a pickle file\n",
    "df_model_top_picks = pickle_load(path_data_dump, fp_df_model_top_picks)\n",
    "\n",
    "# Print the length of the DataFrame\n",
    "print(f'Length of df_model_top_picks: {len(df_model_top_picks)}')\n",
    "\n",
    "# Print the first 5 rows of the DataFrame\n",
    "print(df_model_top_picks.head(), '\\n')\n",
    "\n",
    "# Print the last 5 rows of the DataFrame\n",
    "print(df_model_top_picks.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO remove this cell\n",
    "# df_model_top_picks = df_model_top_picks[3::]\n",
    "# # Reset the index of the DataFrame, dropping the old index\n",
    "# df_model_top_picks = df_model_top_picks.reset_index(drop=True)\n",
    "# print(df_model_top_picks.head(), '\\n')\n",
    "# print(df_model_top_picks.tail())\n",
    "# print(f'len(df_model_top_picks.date.tolist()): {len(df_model_top_picks.date.tolist())}')\n",
    "# print(f'len(set(df_model_top_picks.date.tolist())): {len(set(df_model_top_picks.date.tolist()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest_date_in_model : 2024-01-04\n"
     ]
    }
   ],
   "source": [
    "dates_in_model = df_model_top_picks.date.tolist()\n",
    "latest_date_in_model = max(dates_in_model, key=lambda x: datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "\n",
    "print(f\"latest_date_in_model : {latest_date_in_model }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the DataFrame from a pickle file df_picks\n",
      "Dropping duplicates, keeping last occurrence...\n",
      "Sorting by date, max lookback, then lookback (descending)...\n",
      "Resetting index...\n",
      "Save the modified DataFrame back to a pickle file df_picks\n",
      "Number of rows: 2774\n",
      "     date_end_df_train  max_days_lookbacks     days_lookbacks sym_freq_15 sym_freq_14 sym_freq_13 sym_freq_12 sym_freq_11           sym_freq_10        sym_freq_9                     sym_freq_8                sym_freq_7                     sym_freq_6                     sym_freq_5                     sym_freq_4                     sym_freq_3 sym_freq_2\n",
      "0           2024-01-04                 120      [30, 60, 120]          []          []          []          []          []                    []          ['CYTK']                ['FTSM', 'SHV']                     ['X']          ['GBTC', 'GPS', 'HA']                 ['ANF', 'MBI']          ['HY', 'LRN', 'MARA']  ['BPMC', 'BTC-USD', 'FATE'...         []\n",
      "1           2024-01-04                 120  [15, 30, 60, 120]          []          []          []    ['CYTK']          []  ['FTSM', 'SHV', 'X']                []                             []                    ['HY']  ['GBTC', 'GPS', 'HA', 'MARA']  ['ANF', 'FATE', 'HPP', 'LA...                ['COMM', 'LRN']  ['ARLP', 'BPMC', 'BTC-USD'...         []\n",
      "2           2024-01-03                 120      [30, 60, 120]          []          []          []          []          []                    []                []        ['CYTK', 'FTSM', 'SHV']                     ['X']                  ['GPS', 'HA']  ['ANF', 'COLL', 'GBTC', 'M...  ['BPMC', 'BURL', 'LRN', 'M...  ['BBWI', 'HIBB', 'HOLI', '...         []\n",
      "3           2024-01-03                 120  [15, 30, 60, 120]          []          []          []          []    ['CYTK']  ['FTSM', 'SHV', 'X']                []                       ['COLL']                        []  ['GPS', 'HA', 'HPP', 'HY',...  ['ANF', 'GBTC', 'LAZ', 'LC...  ['BPMC', 'BURL', 'FATE', '...                             []         []\n",
      "4           2024-01-02                 120      [30, 60, 120]          []          []          []          []          []                    []                []                ['CYTK', 'SHV']                  ['FTSM']                  ['GPS', 'HA']    ['ANF', 'BPMC', 'MBI', 'X']                ['LRN', 'MARA']  ['BIG', 'BKE', 'BURL', 'FF...         []\n",
      "...                ...                 ...                ...         ...         ...         ...         ...         ...                   ...               ...                            ...                       ...                            ...                            ...                            ...                            ...        ...\n",
      "2769        2018-07-05                 120  [15, 30, 60, 120]          []          []          []          []          []                    []          ['RAMP']  ['ARWR', 'BLFS', 'NTRA', '...   ['RGNX', 'SHV', 'SRPT']               ['CATO', 'ETSY']        ['CYRX', 'FTSM', 'RUN']   ['DRI', 'MSGS', 'STAA', 'W']                ['AEE', 'AXGN']         []\n",
      "2770        2018-07-03                 120      [30, 60, 120]          []          []          []          []          []                    []                []                             []  ['CATO', 'RGNX', 'TNDM']  ['ARWR', 'BLFS', 'ETSY', '...  ['CYRX', 'FTSM', 'RUN', 'S...          ['CARA', 'MSGS', 'W']       ['AXGN', 'AXON', 'EVTC']         []\n",
      "2771        2018-07-03                 120  [15, 30, 60, 120]          []          []          []          []          []                    []  ['RAMP', 'RGNX']  ['ARWR', 'BLFS', 'ETSY', '...   ['CATO', 'SHV', 'SRPT']                       ['XENE']  ['CARA', 'CYRX', 'FTSM', '...                  ['MSGS', 'W']        ['AEE', 'AXGN', 'AXON']         []\n",
      "2772        2018-07-02                 120      [30, 60, 120]          []          []          []          []          []                    []                []                             []          ['TNDM', 'XENE']  ['ARWR', 'BLFS', 'CATO', '...                ['RUN', 'SRPT']  ['CARA', 'CYRX', 'FTSM', '...        ['AXON', 'LULU', 'NSP']         []\n",
      "2773        2018-07-02                 120  [15, 30, 60, 120]          []          []          []          []          []                    []                []  ['ARWR', 'BLFS', 'ETSY', '...           ['SHV', 'SRPT']                       ['CATO']                ['CARA', 'RUN']  ['CYRX', 'ENPH', 'FTSM', '...                ['AEE', 'AXON']         []\n",
      "\n",
      "[2774 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Load data from pickle file fpdf_model_top_picks_picks\n",
    "print(f\"Load the DataFrame from a pickle file {fp_df_picks }\")\n",
    "df_picks  = pickle_load(path_data_dump, fp_df_picks)\n",
    "\n",
    "# 2. Drop duplicates, keeping the last occurrence\n",
    "print(\"Dropping duplicates, keeping last occurrence...\")\n",
    "df_picks = df_picks.drop_duplicates(subset=['date_end_df_train', 'max_days_lookbacks', 'days_lookbacks'], keep='last')\n",
    "\n",
    "# 3. Sort by date, max lookback, then lookback (descending)\n",
    "print(\"Sorting by date, max lookback, then lookback (descending)...\")\n",
    "df_picks = df_picks.sort_values(by=['date_end_df_train', 'max_days_lookbacks', 'days_lookbacks'], ascending=False)\n",
    "\n",
    "# 4. Reset index (optional)\n",
    "print(\"Resetting index...\")\n",
    "df_picks = df_picks.reset_index(drop=True)\n",
    "\n",
    "# 5. Save data to pickle (replace with actual saving)\n",
    "# Comment: Save the modified DataFrame back to a pickle file\n",
    "print(f\"Save the modified DataFrame back to a pickle file {fp_df_picks}\")\n",
    "pickle_dump(df_picks, path_data_dump, fp_df_picks)\n",
    "\n",
    "# 6. Print information about the DataFrame\n",
    "print(f\"Number of rows: {len(df_picks)}\")\n",
    "# print(df_picks.head())\n",
    "print(df_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [date_end_df_train, max_days_lookbacks, days_lookbacks, sym_freq_15, sym_freq_14, sym_freq_13, sym_freq_12, sym_freq_11, sym_freq_10, sym_freq_9, sym_freq_8, sym_freq_7, sym_freq_6, sym_freq_5, sym_freq_4, sym_freq_3, sym_freq_2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Convert the date column to datetime format for accurate filtering\n",
    "df_picks['date_end_df_train'] = pd.to_datetime(df_picks['date_end_df_train'])\n",
    "\n",
    "# Filter rows after '2013-12-31' (exclusive)\n",
    "df_filtered_picks = df_picks[df_picks['date_end_df_train'] > latest_date_in_model]\n",
    "\n",
    "# SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Convert the date column back to '%Y-%m-%d' format\n",
    "df_filtered_picks['date_end_df_train'] = df_filtered_picks['date_end_df_train'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# # Print the filtered DataFrame\n",
    "print(df_filtered_picks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get dates in df_filtered_picks where values in column \"days_lookbacks\" matched items in my_days_lookbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates_in_days_lookbacks, len(0):\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the dates\n",
    "dates_in_days_lookbacks = []\n",
    "\n",
    "# Iterate through each days lookback configuration\n",
    "for my_days_lookback in my_days_lookbacks:\n",
    "    # Create a mask to filter rows based on the current days lookback\n",
    "    mask_days_lookback = df_filtered_picks ['days_lookbacks'] == str(my_days_lookback)\n",
    "\n",
    "    # Extract the ending dates for the training datasets that match the lookback\n",
    "    l_dates = df_filtered_picks.loc[mask_days_lookback, 'date_end_df_train'].tolist()\n",
    "\n",
    "    # Extend the dates list with the extracted dates (avoiding nested lists)\n",
    "    dates_in_days_lookbacks.extend(l_dates)\n",
    "\n",
    "# Remove duplicates and sort the dates from newest to oldest\n",
    "dates_in_days_lookbacks = sorted(set(dates_in_days_lookbacks), reverse=True)\n",
    "\n",
    "# Print the list of dates along with its length\n",
    "print(f'dates_in_days_lookbacks, len({len(dates_in_days_lookbacks)}):\\n{dates_in_days_lookbacks}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of tuples of all combination of dates_in_days_lookbacks and criteria_model_top_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_lookback_symfreq, len(0):\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Generate all possible combinations of dates, lookbacks, and top features\n",
    "date_lookback_symfreq = list(product(\n",
    "    dates_in_days_lookbacks,  # List of dates\n",
    "    criteria_model_top_picks  # List of (lookback, top feature) tuples\n",
    "))\n",
    "\n",
    "# Print the resulting list of tuples, along with its length\n",
    "print(f'date_lookback_symfreq, len({len(date_lookback_symfreq)}):\\n{date_lookback_symfreq}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get symbols in my_cols where values of \"date_end_df_picks_train\" equals to dates_in_days_lookbacks, and \"days_lookbacks\" equals to my_days_lookbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the picked symbols\n",
    "picks = []\n",
    "\n",
    "# Track the previous date for formatting output\n",
    "prev_date = ''\n",
    "\n",
    "# Iterate through each combination of date, lookback, and top feature,\n",
    "# now handling the nested tuple structure\n",
    "for i, (_date, (my_days_lookback, my_col)) in enumerate(date_lookback_symfreq):\n",
    "    # Create a mask to filter rows in the DataFrame based on the date and lookback criteria\n",
    "    mask = (df_filtered_picks['date_end_df_train'] == _date) & (df_filtered_picks['days_lookbacks'] == str(my_days_lookback))\n",
    "\n",
    "    # Extract the list of symbols picked by the model for the current criteria\n",
    "    list_in_df_filtered_picks = df_filtered_picks.loc[mask, my_col]\n",
    "    my_str = list_in_df_filtered_picks.tolist()[0]  # Convert the Pandas Series to a string\n",
    "    my_list = literal_eval(my_str)  # Convert the string representation of the list to an actual list\n",
    "\n",
    "    # Print the model's picks in a formatted way, grouping by date\n",
    "    if _date != prev_date:\n",
    "        if prev_date == '':\n",
    "            print(\"\\nModel Results:\")  # Print a header for the results\n",
    "        else:\n",
    "            print(\"\\n\")  # Separate results for different dates\n",
    "        print(f\"{i:<6}{_date:<14}{str(my_days_lookback):<21}{my_col:<11}: {my_list}\")\n",
    "    else:\n",
    "        print(f\"{i:<6}{' ':<14}{str(my_days_lookback):<21}{my_col:<11}: {my_list}\")\n",
    "\n",
    "    # Add the picked symbols to the list of picks\n",
    "    picks.append((i, my_list))\n",
    "\n",
    "    # Update the previous date for the next iteration\n",
    "    prev_date = _date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create iterable z_items of date_lookback_symfreq and picks<br>Add picks to df_model_top_picks if dlb_sym_freq match criteria_model_top_picks and _syms has symbol(s)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before add len(df_model_top_picks): 1479\n",
      "after add len(df_model_top_picks): 1479\n"
     ]
    }
   ],
   "source": [
    "print(f'before add len(df_model_top_picks): {len(df_model_top_picks)}')\n",
    "# Combine date_lookback_symfreq and picks into a single iterable\n",
    "z_items = zip(date_lookback_symfreq, picks)\n",
    "\n",
    "# Iterate through each combined item\n",
    "for i, item in enumerate(z_items):\n",
    "    # Unpack the date, lookback, feature, counter, and symbols\n",
    "    _date, _days_lookback, _sym_freq, _counter, _syms = (\n",
    "        item[0][0],\n",
    "        item[0][1][0],  # Accessing nested tuple elements\n",
    "        item[0][1][1],\n",
    "        item[1][0],\n",
    "        item[1][1],\n",
    "    )\n",
    "\n",
    "    len_df_model_top_picks = len(df_model_top_picks)\n",
    "\n",
    "    # Print the current item's details for inspection\n",
    "    print(f\"{i}, {_date}, {_days_lookback}, {_sym_freq}, {_syms}\")\n",
    "\n",
    "    # Create a tuple for model criteria matching\n",
    "    dlb_sym_freq = (_days_lookback, _sym_freq)\n",
    "\n",
    "    # Add data to the DataFrame if the criteria are met and symbols exist\n",
    "    if dlb_sym_freq in criteria_model_top_picks and _syms:\n",
    "        row_add = [_date, _days_lookback, _sym_freq, _syms]\n",
    "        df_model_top_picks.loc[len_df_model_top_picks] = row_add  # Append row using index\n",
    "        print(f\"\\nAdded row {len_df_model_top_picks} to df_model_top_picks:\\n{row_add}\\n\")\n",
    "\n",
    "print(f'after add len(df_model_top_picks): {len(df_model_top_picks)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_model_top_picks:\n",
      "            date      days_lookback    syms_freq                  symbols\n",
      "0     2024-01-04      [30, 60, 120]   sym_freq_9                 ['CYTK']\n",
      "1     2024-01-04      [30, 60, 120]   sym_freq_8          ['FTSM', 'SHV']\n",
      "2     2024-01-04  [15, 30, 60, 120]  sym_freq_12                 ['CYTK']\n",
      "3     2024-01-03      [30, 60, 120]   sym_freq_8  ['CYTK', 'FTSM', 'SHV']\n",
      "4     2024-01-02      [30, 60, 120]   sym_freq_8          ['CYTK', 'SHV']\n",
      "...          ...                ...          ...                      ...\n",
      "1474  2018-07-12      [30, 60, 120]   sym_freq_8                 ['TNDM']\n",
      "1475  2018-07-11      [30, 60, 120]   sym_freq_8                 ['TNDM']\n",
      "1476  2018-07-10      [30, 60, 120]   sym_freq_8                 ['TNDM']\n",
      "1477  2018-07-09      [30, 60, 120]   sym_freq_8                 ['TNDM']\n",
      "1478  2018-07-06      [30, 60, 120]   sym_freq_8                 ['TNDM']\n",
      "\n",
      "[1479 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert all data types in the DataFrame to strings\n",
    "df_model_top_picks = df_model_top_picks.astype(str)\n",
    "\n",
    "# Remove any duplicate rows, keeping the last occurrence of each\n",
    "df_model_top_picks = df_model_top_picks.drop_duplicates(keep='last')\n",
    "\n",
    "# Sort the DataFrame by 'date' (descending), 'days_lookback' (descending), and 'syms_freq' (descending)\n",
    "df_model_top_picks = df_model_top_picks.sort_values(\n",
    "    by=['date', 'days_lookback', 'syms_freq'], ascending=False\n",
    ")\n",
    "\n",
    "# Reset the index of the DataFrame, dropping the old index\n",
    "df_model_top_picks = df_model_top_picks.reset_index(drop=True)\n",
    "\n",
    "print(f'df_model_top_picks:\\n{df_model_top_picks}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup df_model_top_picks<br>- convert data to str<br>- drop duplicates, keep last value<br>- sort date, newest first<br>- re-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df_model_top_picks: 1479\n",
      "File path: df_model_top_picks\n",
      "DataFrame contents:\n",
      "            date      days_lookback    syms_freq                  symbols\n",
      "0     2024-01-04      [30, 60, 120]   sym_freq_9                 ['CYTK']\n",
      "1     2024-01-04      [30, 60, 120]   sym_freq_8          ['FTSM', 'SHV']\n",
      "2     2024-01-04  [15, 30, 60, 120]  sym_freq_12                 ['CYTK']\n",
      "3     2024-01-03      [30, 60, 120]   sym_freq_8  ['CYTK', 'FTSM', 'SHV']\n",
      "4     2024-01-02      [30, 60, 120]   sym_freq_8          ['CYTK', 'SHV']\n",
      "...          ...                ...          ...                      ...\n",
      "1474  2018-07-12      [30, 60, 120]   sym_freq_8                 ['TNDM']\n",
      "1475  2018-07-11      [30, 60, 120]   sym_freq_8                 ['TNDM']\n",
      "1476  2018-07-10      [30, 60, 120]   sym_freq_8                 ['TNDM']\n",
      "1477  2018-07-09      [30, 60, 120]   sym_freq_8                 ['TNDM']\n",
      "1478  2018-07-06      [30, 60, 120]   sym_freq_8                 ['TNDM']\n",
      "\n",
      "[1479 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert all data types in the DataFrame to strings\n",
    "df_model_top_picks = df_model_top_picks.astype(str)\n",
    "\n",
    "# Remove any duplicate rows, keeping the last occurrence of each\n",
    "df_model_top_picks = df_model_top_picks.drop_duplicates(keep='last')\n",
    "\n",
    "# Sort the DataFrame by 'date' (descending), 'days_lookback' (descending), and 'syms_freq' (descending)\n",
    "df_model_top_picks = df_model_top_picks.sort_values(\n",
    "    by=['date', 'days_lookback', 'syms_freq'], ascending=False\n",
    ")\n",
    "\n",
    "# Reset the index of the DataFrame, dropping the old index\n",
    "df_model_top_picks = df_model_top_picks.reset_index(drop=True)\n",
    "\n",
    "# Save the DataFrame to a pickle file\n",
    "pickle_dump(df_model_top_picks, path_data_dump, fp_df_model_top_picks)\n",
    "\n",
    "# Print the length of the DataFrame\n",
    "print(f'Length of df_model_top_picks: {len(df_model_top_picks)}')\n",
    "\n",
    "# Print the file path and contents of the DataFrame\n",
    "print(f'File path: {fp_df_model_top_picks}\\nDataFrame contents:\\n{df_model_top_picks}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_model_top_picks.head(20):\n",
      "          date      days_lookback    syms_freq                  symbols\n",
      "0   2024-01-04      [30, 60, 120]   sym_freq_9                 ['CYTK']\n",
      "1   2024-01-04      [30, 60, 120]   sym_freq_8          ['FTSM', 'SHV']\n",
      "2   2024-01-04  [15, 30, 60, 120]  sym_freq_12                 ['CYTK']\n",
      "3   2024-01-03      [30, 60, 120]   sym_freq_8  ['CYTK', 'FTSM', 'SHV']\n",
      "4   2024-01-02      [30, 60, 120]   sym_freq_8          ['CYTK', 'SHV']\n",
      "5   2023-12-29      [30, 60, 120]   sym_freq_8          ['CYTK', 'SHV']\n",
      "6   2023-12-28      [30, 60, 120]   sym_freq_8          ['CYTK', 'SHV']\n",
      "7   2023-12-27      [30, 60, 120]   sym_freq_8          ['CYTK', 'SHV']\n",
      "8   2023-12-26      [30, 60, 120]   sym_freq_8                  ['SHV']\n",
      "9   2023-12-22      [30, 60, 120]   sym_freq_8                  ['SHV']\n",
      "10  2023-12-21      [30, 60, 120]   sym_freq_8                  ['SHV']\n",
      "11  2023-12-20      [30, 60, 120]   sym_freq_8           ['GPS', 'SHV']\n",
      "12  2023-12-19      [30, 60, 120]   sym_freq_8           ['GPS', 'SHV']\n",
      "13  2023-12-18      [30, 60, 120]   sym_freq_8                  ['SHV']\n",
      "14  2023-12-15      [30, 60, 120]   sym_freq_8                  ['SHV']\n",
      "15  2023-12-13      [30, 60, 120]   sym_freq_8           ['GPS', 'SHV']\n",
      "16  2023-12-12      [30, 60, 120]   sym_freq_8           ['GPS', 'SHV']\n",
      "17  2023-12-11      [30, 60, 120]   sym_freq_8           ['GPS', 'SHV']\n",
      "18  2023-12-08      [30, 60, 120]   sym_freq_8           ['GPS', 'SHV']\n",
      "19  2023-12-07      [30, 60, 120]   sym_freq_8           ['GPS', 'SHV']\n"
     ]
    }
   ],
   "source": [
    "print(f'{fp_df_model_top_picks}.head(20):\\n{df_model_top_picks.head(20)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
