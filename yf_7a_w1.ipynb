{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_picks_v_SPY (df_eval, df_SPY):\n",
    "  import numpy as np\n",
    "  from myUtils import symb_perf_stats_vectorized_v8 as sps\n",
    "\n",
    "  _d_cols_values = {}\n",
    "\n",
    "  if np.all(df_eval.index == df_SPY.index):\n",
    "    (\n",
    "      _symbols,\n",
    "      _period_yr,\n",
    "      _retn,\n",
    "      _DD,\n",
    "      _UI,\n",
    "      _MDD,\n",
    "      _retnMean,\n",
    "      _retnStd,\n",
    "      _retnStd_div_UI,\n",
    "      _CAGR,\n",
    "      _CAGR_div_retnStd,\n",
    "      _CAGR_div_UI,\n",
    "      SPY_retnStd_d_UI,     \n",
    "      SPY_CAGR,\n",
    "      SPY_CAGR_d_retnStd,\n",
    "      SPY_CAGR_d_UI,\n",
    "    ) = sps(df_SPY)\n",
    "\n",
    "    (\n",
    "      _symbols,\n",
    "      _period_yr,\n",
    "      _retn,\n",
    "      _DD,\n",
    "      _UI,\n",
    "      _MDD,\n",
    "      _retnMean,\n",
    "      _retnStd,\n",
    "      _retnStd_div_UI,\n",
    "      _CAGR,\n",
    "      _CAGR_div_retnStd,\n",
    "      _CAGR_div_UI,\n",
    "      grp_retnStd_d_UI,     \n",
    "      grp_CAGR,\n",
    "      grp_CAGR_d_retnStd,\n",
    "      grp_CAGR_d_UI,\n",
    "    ) = sps(df_eval)  \n",
    "\n",
    "    ### column names for rows ###\n",
    "    col_add1 = ['grp(CAGR)_mean',         'grp(CAGR)_std',         'grp(CAGR)_mean/std']\n",
    "    col_add2 = ['grp(CAGR/UI)_mean',      'grp(CAGR/UI)_std',      'grp(CAGR/UI)_mean/std']\n",
    "    col_add3 = ['grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std']\n",
    "    col_add4 = ['grp(retnStd/UI)_mean',   'grp(retnStd/UI)_std',   'grp(retnStd/UI)_mean/std']\n",
    "    col_add5 = ['SPY_CAGR', 'SPY_CAGR/UI', 'SPY_CAGR/retnStd', 'SPY_retnStd/UI']\n",
    "    cols = col_add1 + col_add2 + col_add3 + col_add4 + col_add5\n",
    "\n",
    "    row_add1      = [grp_CAGR[0],           grp_CAGR[1],           grp_CAGR[2]]\n",
    "    row_add2      = [grp_CAGR_d_UI[0],      grp_CAGR_d_UI[1],      grp_CAGR_d_UI[2]]\n",
    "    row_add3      = [grp_CAGR_d_retnStd[0], grp_CAGR_d_retnStd[1], grp_CAGR_d_retnStd[2]]\n",
    "    row_add4      = [grp_retnStd_d_UI[0],   grp_retnStd_d_UI[1],   grp_retnStd_d_UI[2]]\n",
    "    row_add5      = [SPY_CAGR[0], SPY_CAGR_d_UI[0], SPY_CAGR_d_retnStd[0], SPY_retnStd_d_UI[0]]\n",
    "    rows = row_add1 + row_add2 + row_add3 + row_add4 + row_add5\n",
    "\n",
    "    _d_cols_values = dict(zip(cols, rows))\n",
    "\n",
    "  return _d_cols_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grp_top_syms_n_freq(df, sets_lookback_slices, verbose=False):\n",
    "    # grp_top_set_syms_n_freq is a list of lists of top_set_syms_n_freq, e.g.\n",
    "    #   [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)],\n",
    "    #    [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "    #   where each list is the best performing symbols from a lb_slices, e.g.\n",
    "    #     [(483, 513, 523), (453, 513, 523), (393, 513, 523)]  \n",
    "    grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "    grp_top_set_syms = []  # grp_top_set_syms_n_freq without the frequency count\n",
    "\n",
    "    # lb_slices, e.g  [(483, 513, 523), (453, 513, 523), (393, 513, 523)],\n",
    "    #  is one max_lookback_slice, e.g. (393, 513, 523), along with\n",
    "    #  the remaining slices of the days_lookbacks, e.g. (483, 513, 523), (453, 513, 523)  \n",
    "    for i, lb_slices in enumerate(sets_lookback_slices):\n",
    "        # print(f'\\n########## {i + 1} of {len(sets_lookback_slices)} lb_slices in sets_lookcak_slices ##########')\n",
    "        print(f'\\n########## {i + 1} of {len(sets_lookback_slices)} lb_slices: {lb_slices} in sets_lookcak_slices ##########')        \n",
    "        # unsorted list of the most frequent symbols in performance metrics of the lb_slices  \n",
    "        grp_most_freq_syms = []\n",
    "        for j, lb_slice in enumerate(lb_slices):  # lb_slice, e.g. (246, 276, 286)\n",
    "            iloc_start_train = lb_slice[0]     # iloc of start of training period\n",
    "            iloc_end_train   = lb_slice[1]     # iloc of end of training period\n",
    "            iloc_start_eval  = iloc_end_train  # iloc of start of evaluation period\n",
    "            iloc_end_eval    = lb_slice[2]     # iloc of end of evaluation period\n",
    "            lookback         = iloc_end_train - iloc_start_train\n",
    "            d_eval           = iloc_end_eval - iloc_start_eval\n",
    "\n",
    "            _df = df.iloc[iloc_start_train:iloc_end_train]\n",
    "            date_start_df_train = _df.index[0].strftime('%Y-%m-%d')\n",
    "            date_end_df_train = _df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "            if verbose:\n",
    "                print(f'days lookback:       {lookback},  {j + 1} of {len(days_lookbacks)} days_lookbacks: {days_lookbacks}')\n",
    "                print(f'lb_slices:           {lb_slices}')\n",
    "                print(f'lb_slice:            {lb_slice}')\n",
    "                print(f'days eval:           {d_eval}')    \n",
    "                print(f'iloc_start_train:    {iloc_start_train}')\n",
    "                print(f'iloc_end_train:      {iloc_end_train}')\n",
    "                print(f'date_start_df_train: {date_start_df_train}')\n",
    "                print(f'date_end_df_train:   {date_end_df_train}')\n",
    "\n",
    "            # perf_ranks, performance rank of one day in days_loolbacks (30 of [15, 30, 60]) e.g.:\n",
    "            # {'period-30': {'r_CAGR/UI': array(['BMA', 'ACIW', 'SHV', 'GBTC', 'BVH', ..., 'BGNE', 'HLF', 'WB', 'HZNP']\n",
    "            #                'r_CAGR/retnStd': array(['BMA', 'GBTC', 'EDU', 'PAR', ..., 'BGNE', 'ACIW', 'HLF', 'EXAS']\n",
    "            #                'r_retnStd/UI': array(['HZNP', 'SHV', 'BVH', 'ACIW', ..., 'FTSM', 'COLL', 'ALGN', 'JOE']\n",
    "            # most_freq_syms, most frequency symbols of one day in days_loolbacks (30 of [15, 30, 60]) e.g.:\n",
    "            # [('BMA', 3), ('ACIW', 3), ('BVH', 3), ('BGNE', 3), ('SHV', 2), ..., ('GBTC', 2), ('AJRD', 1), ('TGH', 1)]\n",
    "            perf_ranks, most_freq_syms = _5_perf_ranks(_df, n_top_syms=n_top_syms)\n",
    "            # unsorted accumulation of most_freq_syms for all the days in days_lookbacks  \n",
    "            grp_most_freq_syms.append(most_freq_syms)  \n",
    "            if verbose:    \n",
    "                # one lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI, e.g. 30 of days_lookbacks [15, 30, 60]\n",
    "                print(f'perf_ranks: {perf_ranks}')  \n",
    "                # most common symbols of perf_ranks \n",
    "                print(f'most_freq_syms: {most_freq_syms}')     \n",
    "                # grp_perf_ranks[lookback] = perf_ranks\n",
    "                print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "        if verbose:\n",
    "            print(f'grp_most_freq_syms: {grp_most_freq_syms}')\n",
    "            # grp_most_freq_syms a is list of lists of tuples of \n",
    "            #  the most-common-symbols symbol:frequency cumulated from\n",
    "            #  each days_lookback  \n",
    "            print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "        # flatten list of lists of (symbol:frequency_count) pairs of all the days in days_lookbacks\n",
    "        flat_grp_most_freq_syms = [val for sublist in grp_most_freq_syms for val in sublist]\n",
    "        # sum symbol's frequency_count, return sorted tuples of \"symbol:frequency_count\"\n",
    "        #  in descending order for all the days in days_lookbacks\n",
    "        #  e.g. [('TA', 6), ('OEC', 4), ('SHV', 4), ('HY', 3), ('ELF', 2), ... , ('TNP', 1)]  \n",
    "        set_most_freq_syms = _6_grp_tuples_sort_sum(flat_grp_most_freq_syms, reverse=True)\n",
    "        # get the top n_top_syms of the most frequent \"symbol, frequency\" pairs\n",
    "        top_set_syms_n_freq = set_most_freq_syms[0:n_top_syms]\n",
    "        # get symbols from top_set_syms_n_freq, i[0] = symbol, i[1]=symbol's frequency count\n",
    "        top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]  \n",
    "\n",
    "        # grp_top_set_syms_n_freq is a list of lists of top_set_syms_n_freq, e.g.\n",
    "        #   [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)],\n",
    "        #    [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "        #   where each list is the best performing symbols from a lb_slices, e.g.\n",
    "        #     [(483, 513, 523), (453, 513, 523), (393, 513, 523)]    \n",
    "        grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "        grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "        if verbose:  \n",
    "            print(f'top {n_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "            print(f'top {n_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "            print(f'===== finish top {n_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return grp_top_set_syms_n_freq, grp_top_set_syms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_grp_top_syms_n_freq(df, max_lookback_slices, grp_top_set_syms_n_freq, verbose):\n",
    "    \n",
    "    from myUtils import symb_perf_stats_vectorized_v8\n",
    "\n",
    "    print('z_grp_top_set_syms_n_freq:')\n",
    "    # zip max_lookback_slices with top performing symbols:freq pairs\n",
    "    z_grp_top_set_syms_n_freq = zip(max_lookback_slices, grp_top_set_syms_n_freq)\n",
    "\n",
    "    idx_train = pd.Index([])\n",
    "    idx_eval = pd.Index([])\n",
    "\n",
    "    t_row_add_total = (),  # tuple to accumulate row_add_total\n",
    "    print(f'type(t_row_add_total): {type(t_row_add_total)}')\n",
    "    print(f't_row_add_total: {t_row_add_total}')\n",
    "\n",
    "    for i, (_lookback_slice, _top_set_syms_n_freq) in enumerate(z_grp_top_set_syms_n_freq):\n",
    "        iloc_start_train = _lookback_slice[0]\n",
    "        iloc_end_train = _lookback_slice[1]\n",
    "        iloc_start_eval = iloc_end_train\n",
    "        iloc_end_eval = _lookback_slice[2]\n",
    "\n",
    "        print(f'{i + 1 } of {n_samples} max_lookback_slice: {_lookback_slice}\\n')\n",
    "        # print(f'max_lookback_slice: {_lookback_slice}\\n')\n",
    "        # dates correspond to max_lookback_slice\n",
    "        idx_train = df.index[iloc_start_train:iloc_end_train]\n",
    "        date_start_df_train = idx_train[0].strftime('%Y-%m-%d')\n",
    "        date_end_df_train = idx_train[-1].strftime('%Y-%m-%d')\n",
    "        print(f'len(idx_train): {len(idx_train)}')\n",
    "        print(f'idx_train: {idx_train}')\n",
    "        print(f'df_train_dates (inclusive): {date_start_df_train} - {date_end_df_train}\\n')     \n",
    "\n",
    "        if run_type != 'current':\n",
    "            idx_eval = df.index[iloc_start_eval:iloc_end_eval]\n",
    "            date_start_df_eval = idx_eval[0].strftime('%Y-%m-%d')\n",
    "            date_end_df_eval = idx_eval[-1].strftime('%Y-%m-%d')\n",
    "            print(f'len(idx_eval): {len(idx_eval)}')\n",
    "            print(f'idx_eval: {idx_eval}')\n",
    "            print(f'df_eval dates (inclusive): {date_start_df_eval} - {date_end_df_eval}\\n')\n",
    "        else: # run_type == \"current'\n",
    "            print(f'run_type: {run_type}, idx_eval is empty: {idx_eval.empty}')\n",
    "\n",
    "        print(f'top_set_syms_n_freq: {_top_set_syms_n_freq}\\n')   \n",
    "\n",
    "        l_sym_freq_cnt = top_set_sym_freq_cnt(_top_set_syms_n_freq)\n",
    "        if verbose:\n",
    "            print(f'set_lookback_slices: {sets_lookback_slices[i]}')    \n",
    "            print(f'max_lookback_slice:  {_lookback_slice}')\n",
    "            print(f'days_lookbacks:      {days_lookbacks}')\n",
    "            print(f'date_end_df_train:   {date_end_df_train}')\n",
    "            print(f'sym_freq_15:         {l_sym_freq_cnt[0]}')\n",
    "            print(f'sym_freq_14:         {l_sym_freq_cnt[1]}')\n",
    "            print(f'sym_freq_13:         {l_sym_freq_cnt[2]}')\n",
    "            print(f'sym_freq_12:         {l_sym_freq_cnt[4]}')\n",
    "            print(f'sym_freq_10:         {l_sym_freq_cnt[5]}')\n",
    "            print(f'sym_freq_9:          {l_sym_freq_cnt[6]}')\n",
    "            print(f'sym_freq_8:          {l_sym_freq_cnt[7]}')\n",
    "            print(f'sym_freq_7:          {l_sym_freq_cnt[8]}')\n",
    "            print(f'sym_freq_6:          {l_sym_freq_cnt[9]}')\n",
    "            print(f'sym_freq_5:          {l_sym_freq_cnt[10]}')\n",
    "            print(f'sym_freq_4:          {l_sym_freq_cnt[11]}')\n",
    "            print(f'sym_freq_3:          {l_sym_freq_cnt[12]}')\n",
    "            print(f'sym_freq_2:          {l_sym_freq_cnt[13]}\\n') \n",
    "\n",
    "        if idx_eval.empty:\n",
    "            if run_type == 'current':\n",
    "              msg_stop = f'\\n\\n**** Normal termination for run_type \"{run_type}\". Wrote current picks to df_picks ****'\n",
    "              print(f'df_picks:\\n{df_picks}')\n",
    "              raise SystemExit(msg_stop)\n",
    "            else:\n",
    "              msg_stop = f'\\n\\n**** STOPPED df_eval is empty but run_type != \"current\", the run_type is \"{run_type}\" ****'\n",
    "              raise SystemExit(msg_stop)    \n",
    "\n",
    "        _sym_idx = ['SPY']\n",
    "        df_SPY = df[iloc_start_eval:iloc_end_eval][_sym_idx]\n",
    "\n",
    "        # drop list with frequency count 2 or less, in l_sym_freq_cnt from zip\n",
    "        zip_cnt_n_syms = zip([15,14,13,12,11,10,9,8,7,6,5,4,3], l_sym_freq_cnt[:-1])\n",
    "        for item in zip_cnt_n_syms:\n",
    "            sym_freq_cnt = item[0]\n",
    "            syms = item[1]\n",
    "            if syms:  # iterate ONLY if there are symbols in syms\n",
    "                df_eval = df[iloc_start_eval:iloc_end_eval][syms]      \n",
    "\n",
    "                if verbose:\n",
    "                    print(f'iloc_start_eval: {iloc_start_eval:>6},  df_eval first date: {date_start_df_eval:>10}') \n",
    "                    print(f'iloc_end_eval:   {iloc_end_eval:>6},  df_eval last date:  {date_end_df_eval:>10}')        \n",
    "                    print(f'frequency count of symbol(s): {sym_freq_cnt}')      \n",
    "\n",
    "                    syms_n_SPY = syms + ['SPY']\n",
    "                    df_eval_n_SPY = df[iloc_start_eval:iloc_end_eval][syms_n_SPY]   \n",
    "                    print(f'\\ndf_eval_n_SPY:\\n{df_eval_n_SPY}\\n')\n",
    "\n",
    "                d_cols_values  = compare_picks_v_SPY(df_eval, df_SPY)\n",
    "                val_rows = []\n",
    "\n",
    "                print(f'Function compare_picks_v_SPY returned column_name:value pairs')\n",
    "                print(f'{\"column_name\":<45}{\"value\":<14}')\n",
    "                for key_col in d_cols_values:\n",
    "                    print(f'{key_col:<30}{d_cols_values[key_col]:>20,.4f}')\n",
    "                    val_rows.append(d_cols_values[key_col])\n",
    "                print('')\n",
    "\n",
    "                # if store_results:  # record results to df\n",
    "                #     row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, sym_freq_cnt]\n",
    "                #     row_add_total = row_add0 + val_rows\n",
    "                #     print(f'row_add_total: {row_add_total}')\n",
    "                #     df_eval_results.loc[len(df_eval_results)] = row_add_total\n",
    "                #     print(f'appended row_add to df_eval_results:\\n{row_add_total}\\n')\n",
    "\n",
    "                row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, sym_freq_cnt]\n",
    "                row_add_total = row_add0 + val_rows\n",
    "\n",
    "                print(f'type(t_row_add_total): {type(t_row_add_total)}')\n",
    "                print(f't_row_add_total: {t_row_add_total}')\n",
    "                print(f'type(row_add_total): {type(row_add_total)}')\n",
    "                print(f'row_add_total: {row_add_total}')\n",
    "\n",
    "                # t_row_add_total.append(row_add_total)\n",
    "                t_row_add_total = t_row_add_total + tuple(row_add_total)\n",
    "\n",
    "        print('='*80, '\\n\\n\\n')\n",
    "\n",
    "    # return t_row_add_total  \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import datetime\n",
    "# from IPython.display import display, HTML\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum, top_set_sym_freq_cnt\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 16)\n",
    "pd.set_option('display.width', 790)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "fp_df_close_clean = 'df_close_clean'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select run parameters. Parameters can also be passed using papermill by running yf_7_freq_cnt_pm_.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose : False\n",
      "store_results: False\n",
      "run_type: test\n",
      "n_samples: 2\n",
      "days_lookbacks: [15, 30]\n",
      "days_eval: 4\n",
      "n_top_syms: 20\n",
      "syms_start: 0\n",
      "syms_end: 10\n",
      "fp_df_eval_results: df_eval_results_test\n",
      "fp_df_picks: df_picks\n"
     ]
    }
   ],
   "source": [
    "# SELECT RUN PARAMETERS.async Parameters can also be passed using papermill by running yf_7_freq_cnt_pm_.ipynb\n",
    "# verbose = True  # True prints more output\n",
    "verbose = False  # True prints more output\n",
    "\n",
    "# write run results to df_eval_results\n",
    "store_results = False\n",
    "# store_results = True\n",
    "\n",
    "# select run type\n",
    "# run_type = 'train'\n",
    "# run_type = 'validate'\n",
    "run_type = 'test'\n",
    "# run_type = 'current'\n",
    "\n",
    "# number of max lookback tuples to create for iloc iloc_start_train:iloc_end_train:iloc_end_eval\n",
    "# i.e. number of grp_top_set_syms_n_freq and grp_top_set_syms \n",
    "# n_samples = 400  \n",
    "# n_samples = 20\n",
    "n_samples = 2\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback iloc_end_train\n",
    "days_lookbacks = [15, 30]\n",
    "# days_lookbacks = [30, 60, 120]\n",
    "# days_lookbacks = [15, 30, 60, 120]\n",
    "days_lookbacks.sort()\n",
    "\n",
    "# number of days in dataframe to evaluate effectiveness of the training, days_eval = len(df_eval)\n",
    "#  days_eval = 4 means buy at close on 1st day after the signal, hold for 2nd and 3rd day, sell at close on 4th day\n",
    "days_eval = 4\n",
    "# days_eval = 5\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "# n_top_syms = 5  \n",
    "\n",
    "# slice starts and ends for selecting the best performing symbols\n",
    "syms_start = 0\n",
    "syms_end = 10\n",
    "\n",
    "# get picks of previous days by dropping the last n rows from df_current\n",
    "#  drop_last_n_rows = 1 drops the last row from df_current\n",
    "drop_last_n_rows = 0\n",
    "\n",
    "# over-ride parameters for run_type 'current'\n",
    "if run_type == 'current':\n",
    "  days_eval = 0  # no need to eval, df_eval will be empty\n",
    "  n_samples = 1  # no need to repeat sample the current result, repeat sample will yield the same tuple\n",
    "\n",
    "\n",
    "fp_df_eval_results = f'df_eval_results_{run_type}'\n",
    "fp_df_picks = f'df_picks'\n",
    "\n",
    "print(f'verbose : {verbose }')\n",
    "print(f'store_results: {store_results}')\n",
    "print(f'run_type: {run_type}')\n",
    "print(f'n_samples: {n_samples}')\n",
    "print(f'days_lookbacks: {days_lookbacks}')\n",
    "print(f'days_eval: {days_eval}')\n",
    "print(f'n_top_syms: {n_top_syms}')\n",
    "print(f'syms_start: {syms_start}')\n",
    "print(f'syms_end: {syms_end}')\n",
    "print(f'fp_df_eval_results: {fp_df_eval_results}')\n",
    "print(f'fp_df_picks: {fp_df_picks}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load previous run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_type != 'current':\n",
    "  df_eval_results = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "\n",
    "df_picks = pickle_load(path_data_dump, fp_df_picks)\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the last n row in df_close_clean to get previous picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop the last n row(s)\n",
    "# n = 1\n",
    "# df_close_clean = df_close_clean[:-n]\n",
    "# df_close_clean.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataframe into Train, Validate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df_close_clean into training (df_train), validation (df_val) and test (df_test) set.\n",
    "# The default split is 0.7, 0.2, 0.1 respectively.\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_close_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create df_current, a df with the latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_days_lookbacks: 30\n"
     ]
    }
   ],
   "source": [
    "max_days_lookbacks = max(days_lookbacks)\n",
    "print(f'max_days_lookbacks: {max_days_lookbacks}')\n",
    "\n",
    "\n",
    "# df_current = df_test.tail(max_days_lookbacks)  \n",
    "df_current = df_test.copy()\n",
    "\n",
    "# df_current.tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load df according to run_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_type == 'train':\n",
    "  df = df_train.copy()    \n",
    "elif run_type == 'validate':\n",
    "  df = df_val.copy()\n",
    "elif run_type == 'test':\n",
    "  df = df_test.copy()\n",
    "elif run_type == 'current':  # get the current picks\n",
    "  print(f'run_type: current')\n",
    "  slice_start = -(max_days_lookbacks + drop_last_n_rows)  \n",
    "  slice_end = -drop_last_n_rows\n",
    "  if drop_last_n_rows == 0:  # return df with all rows\n",
    "    df = df_current[slice_start:].copy()\n",
    "  else:  # return df with dropped drop_last_n_rows rows  \n",
    "    df = df_current[slice_start:slice_end].copy()            \n",
    "  print(f'dropped last {drop_last_n_rows} row(s) from df')          \n",
    "  print(f'df.tail():\\n{df.tail()}\\n')\n",
    "else:\n",
    "  msg_stop = f\"ERROR run_type must be 'train', 'validate', 'test' or 'current', run_type is: {run_type}\"\n",
    "  raise SystemExit(msg_stop )  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print dataframe for the run, and lengths of other dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_type: test, df.tail(3):\n",
      "                     A         AA    AAL         AAP        AAPL         AB        ABB        ABBV         ABC        ABM    ABR        ABT       ACGL       ACHC   ACIW  ...       XRAY    XRX        XYL       YELP   YUMC         YY         ZBH        ZBRA         ZD         ZG       ZION        ZTO         ZTS       ZUMZ        ZWS\n",
      "Date                                                                                                                                                                      ...                                                                                                                                                                \n",
      "2023-03-24  131.960007  40.080002  13.72  110.830002  160.250000  33.490002  31.830999  158.020004  156.410004  43.430000  11.11  98.050003  66.050003  70.160004  25.27  ...  37.250000  14.63  98.589996  30.040001  61.68  29.959999  126.040001  288.730011  75.209999  42.560001  28.250000  28.510000  164.179993  17.620001  19.850000\n",
      "2023-03-27  133.070007  40.119999  13.94  114.739998  158.279999  34.860001  32.139999  157.539993  156.690002  44.009998  11.18  98.459999  66.379997  70.959999  26.26  ...  37.529999  15.01  99.410004  30.240000  61.59  30.049999  126.000000  288.859985  75.820000  41.900002  29.330000  28.150000  165.710007  17.209999  20.360001\n",
      "2023-03-28  132.630005  40.529999  13.98  115.739998  157.649994  35.430000  32.340000  158.250000  158.000000  44.040001  10.94  97.110001  66.809998  70.790001  25.93  ...  37.750000  14.65  99.970001  29.730000  62.16  30.250000  126.139999  290.149994  75.349998  41.630001  29.950001  28.790001  165.039993  17.389999  20.379999\n",
      "\n",
      "[3 rows x 1319 columns]\n",
      "\n",
      "run_type: test, len(df): 150\n",
      "len_df_train: 1050, len_df_val: 300, len_df_test: 150, len_df_current: 150 \n"
     ]
    }
   ],
   "source": [
    "print(f'run_type: {run_type}, df.tail(3):\\n{df.tail(3)}\\n')\n",
    "len_df = len(df)\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)\n",
    "len_df_current = len(df_current)\n",
    "print(f'run_type: {run_type}, len(df): {len(df)}')\n",
    "print(f'len_df_train: {len_df_train}, len_df_val: {len_df_val}, len_df_test: {len_df_test}, len_df_current: {len_df_current} ')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a sets of iloc lookback slices (iloc_start_train:iloc_end_train:iloc_end_eval), where:  \n",
    "* iloc_end_train - iloc_start_train = days_lookback\n",
    "* iloc_end_eval - iloc_end_train = days_eval  \n",
    "#### for example, if given:  \n",
    "* n_samples = 2  \n",
    "* days_lookbacks = [10, 20, 30]  \n",
    "* days_eval = 5  \n",
    "#### a possible result is:  \n",
    "  - max_lookback_slices: [(417, 447, 452), (265, 295, 300)], where:\n",
    "    - len(max_lookback_slices) = n_samples = 2\n",
    "    - middle number in the tuples, 447 and 295, is the iloc of the \"pivot day\" for the days in \"days_lookbacks\" to lookback\n",
    "    - 447 - 417 = middle number - first number = max(days_lookbacks) = 30\n",
    "    - 295 - 265 = middle number - first number = max(days_lookbacks) = 30      \n",
    "    - 452 - 447 = last number - middle number = days_eval = 5\n",
    "    - 300 - 295 = last number - middle number = days_eval = 5    \n",
    "  - sets_lookback_slices: [[(437, 447, 452), (427, 447, 452), (417, 447, 452)], [(285, 295, 300), (275, 295, 300), (265, 295, 300)]], where:\n",
    "    - len(sets_lookback_slices) = n_samples = 2\n",
    "    - last tuple in each list, i.e. (417, 447, 452) and (265, 295, 300), is a tuple from max_lookback_slices\n",
    "    - where a set, e.g. [(437, 447, 452), (427, 447, 452), (417, 447, 452)]:\n",
    "      - middle number, 447, iloc of the \"pivot day\" is constant for that set\n",
    "      - middle number - first number, is the training period specified in days_lookbacks\n",
    "        - 447 - 437 = middle number - first number = days_lookbacks[0] = 10\n",
    "        - 447 - 427 = middle number - first number = days_lookbacks[1] = 20\n",
    "        - 447 - 417 = middle number - first number = days_lookbacks[2] = 30\n",
    "      - last number, 452, iloc of the end of the evaluation period is constant\n",
    "        - 452 - 447 = last number - middle number = days_eval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return n_samples slices\n",
    "max_lookback_slices = _3_random_slices(len_df, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval, verbose=False)\n",
    "# return n_samples * len(days_lookbacks) slices\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'number of max_lookback_slices is equal to n_samples = {n_samples}')\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}\\n')\n",
    "  print(f'days_lookbacks: {days_lookbacks}')  \n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}\\n')\n",
    "  print(f'number of sets in sets_lookback_slices is equal to n_samples = {n_samples}')\n",
    "  print(f'number of tuples in each \"set of lookback slices\" is equal to len(days_lookbacks): {len(days_lookbacks)}')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate grp_top_set_syms_n_freq. It is a list of sub-lists, e.g.:\n",
    " - [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)], ..., [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "#### grp_top_set_syms_n_freq has n_samples sub-lists. Each sub-list corresponds to a tuple in the max_lookback_slices. Each sub-list has n_top_syms tuples of (symbol, frequency) pairs, and is sorted in descending order of frequency. The frequency is the number of times the symbol appears in the top n_top_syms performance rankings of CAGR/UI, CAGR/retnStd and retnStd/UI.\n",
    "#### Therefore, symbols in the sub-list are the best performing symbols for the periods in days_lookbacks. Each sub-list corresponds to a tuple in max_lookback_slices. There are as many sub-lists as there are tuples in max_lookback_slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## 1 of 2 lb_slices: [(88, 103, 107), (73, 103, 107)] in sets_lookcak_slices ##########\n",
      "\n",
      "########## 2 of 2 lb_slices: [(128, 143, 147), (113, 143, 147)] in sets_lookcak_slices ##########\n"
     ]
    }
   ],
   "source": [
    "grp_top_set_syms_n_freq, grp_top_set_syms = get_grp_top_syms_n_freq(df, sets_lookback_slices, verbose) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the best performing symbols for each set in sets_lookback_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, top_set_syms_n_freq in enumerate(grp_top_set_syms_n_freq):\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(top_set_syms_n_freq)\n",
    "  if verbose:\n",
    "    print(f'max_lookback_slices:          {max_lookback_slices}')\n",
    "    # print(f'set_lookback_slices: {sets_lookback_slices[i]}\\n')\n",
    "    print(f'set_lookback_slices {i + 1} of {len(sets_lookback_slices):>3}: {sets_lookback_slices[i]}\\n')    \n",
    "\n",
    "    if run_type == 'current':\n",
    "      print(f'data below will be added to   {fp_df_picks}')\n",
    " \n",
    "    print(f'date_end_df_train:            {date_end_df_train}')    \n",
    "    print(f'max_days_lookbacks:           {max_days_lookbacks}')   \n",
    "    print(f'days_lookbacks:               {days_lookbacks}')\n",
    "    print(f'sym_freq_15:                  {l_sym_freq_cnt[0]}')\n",
    "    print(f'sym_freq_14:                  {l_sym_freq_cnt[1]}')\n",
    "    print(f'sym_freq_13:                  {l_sym_freq_cnt[2]}')\n",
    "    print(f'sym_freq_12:                  {l_sym_freq_cnt[3]}')\n",
    "    print(f'sym_freq_11:                  {l_sym_freq_cnt[4]}')\n",
    "    print(f'sym_freq_10:                  {l_sym_freq_cnt[5]}')\n",
    "    print(f'sym_freq_9:                   {l_sym_freq_cnt[6]}')\n",
    "    print(f'sym_freq_8:                   {l_sym_freq_cnt[7]}')\n",
    "    print(f'sym_freq_7:                   {l_sym_freq_cnt[8]}')\n",
    "    print(f'sym_freq_6:                   {l_sym_freq_cnt[9]}')\n",
    "    print(f'sym_freq_5:                   {l_sym_freq_cnt[10]}')\n",
    "    print(f'sym_freq_4:                   {l_sym_freq_cnt[11]}')\n",
    "    print(f'sym_freq_3:                   {l_sym_freq_cnt[12]}')\n",
    "    print(f'sym_freq_2:                   {l_sym_freq_cnt[13]}\\n')\n",
    "\n",
    "if run_type == 'current':  # record results to df\n",
    "  row_picks0      = [date_end_df_train, max_days_lookbacks, str(days_lookbacks)]\n",
    "  row_picks1      = [str(l_sym_freq_cnt[0]),  str(l_sym_freq_cnt[1]), str(l_sym_freq_cnt[2]),  str(l_sym_freq_cnt[3])]\n",
    "  row_picks2      = [str(l_sym_freq_cnt[4]),  str(l_sym_freq_cnt[5]), str(l_sym_freq_cnt[6]),  str(l_sym_freq_cnt[7])]\n",
    "  row_picks3      = [str(l_sym_freq_cnt[8]),  str(l_sym_freq_cnt[9]), str(l_sym_freq_cnt[10]), str(l_sym_freq_cnt[11])]\n",
    "  row_picks4      = [str(l_sym_freq_cnt[12]), str(l_sym_freq_cnt[13])]\n",
    "  row_picks_total = row_picks0 + row_picks1 + row_picks2 + row_picks3 + row_picks4\n",
    "  print(f'row_picks_total: {row_picks_total}')\n",
    "\n",
    "  df_picks.loc[len(df_picks)] = row_picks_total\n",
    "  pickle_dump(df_picks, path_data_dump, fp_df_picks)\n",
    "  print(f'appended row_picks_total to df_picks:\\n{row_picks_total}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate performance of symbols in set_lookback_slices versus SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms_n_freq:\n",
      "type(t_row_add_total): <class 'tuple'>\n",
      "t_row_add_total: ((),)\n",
      "1 of 2 max_lookback_slice: (73, 103, 107)\n",
      "\n",
      "len(idx_train): 30\n",
      "idx_train: DatetimeIndex(['2022-12-06', '2022-12-07', '2022-12-08', '2022-12-09', '2022-12-12', '2022-12-13', '2022-12-14', '2022-12-15', '2022-12-16', '2022-12-19', '2022-12-20', '2022-12-21', '2022-12-22', '2022-12-23', '2022-12-27', '2022-12-28', '2022-12-29', '2022-12-30', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-09', '2023-01-10', '2023-01-11', '2023-01-12', '2023-01-13', '2023-01-17', '2023-01-18', '2023-01-19'], dtype='datetime64[ns]', name='Date', freq=None)\n",
      "df_train_dates (inclusive): 2022-12-06 - 2023-01-19\n",
      "\n",
      "len(idx_eval): 4\n",
      "idx_eval: DatetimeIndex(['2023-01-20', '2023-01-23', '2023-01-24', '2023-01-25'], dtype='datetime64[ns]', name='Date', freq=None)\n",
      "df_eval dates (inclusive): 2023-01-20 - 2023-01-25\n",
      "\n",
      "top_set_syms_n_freq: [('FTSM', 4), ('NATI', 4), ('NEOG', 4), ('SHV', 4), ('ACIW', 3), ('ALGN', 3), ('BGNE', 3), ('BVH', 3), ('CROX', 3), ('DENN', 3), ('HLF', 3), ('HSBC', 3), ('JBLU', 3), ('JOE', 3), ('MYGN', 3), ('NSTG', 3), ('NTES', 3), ('TRIP', 3), ('BLFS', 2), ('BMA', 2)]\n",
      "\n",
      "Function compare_picks_v_SPY returned column_name:value pairs\n",
      "column_name                                  value         \n",
      "grp(CAGR)_mean                              0.8200\n",
      "grp(CAGR)_std                               1.2944\n",
      "grp(CAGR)_mean/std                          0.6335\n",
      "grp(CAGR/UI)_mean                      19,643.9520\n",
      "grp(CAGR/UI)_std                       33,523.7880\n",
      "grp(CAGR/UI)_mean/std                       0.5860\n",
      "grp(CAGR/retnStd)_mean                    153.3314\n",
      "grp(CAGR/retnStd)_std                     115.3543\n",
      "grp(CAGR/retnStd)_mean/std                  1.3292\n",
      "grp(retnStd/UI)_mean                       78.5391\n",
      "grp(retnStd/UI)_std                       132.7512\n",
      "grp(retnStd/UI)_mean/std                    0.5916\n",
      "SPY_CAGR                                    1.5681\n",
      "SPY_CAGR/UI                             2,448.5448\n",
      "SPY_CAGR/retnStd                          268.0110\n",
      "SPY_retnStd/UI                              9.1360\n",
      "\n",
      "type(t_row_add_total): <class 'tuple'>\n",
      "t_row_add_total: ((),)\n",
      "type(row_add_total): <class 'list'>\n",
      "row_add_total: [2, '[15, 30]', 4, 20, 0, 10, 4, 0.8199945837689074, 1.2943640197336392, 0.633511571140281, 19643.952012216232, 33523.788028239345, 0.5859705351814302, 153.33138968208604, 115.354315316358, 1.329221098158108, 78.53907600774457, 132.75123896988939, 0.5916259359775827, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776]\n",
      "Function compare_picks_v_SPY returned column_name:value pairs\n",
      "column_name                                  value         \n",
      "grp(CAGR)_mean                              4.8831\n",
      "grp(CAGR)_std                              10.2996\n",
      "grp(CAGR)_mean/std                          0.4741\n",
      "grp(CAGR/UI)_mean                       4,420.8839\n",
      "grp(CAGR/UI)_std                        8,487.4937\n",
      "grp(CAGR/UI)_mean/std                       0.5209\n",
      "grp(CAGR/retnStd)_mean                    412.5450\n",
      "grp(CAGR/retnStd)_std                     807.0167\n",
      "grp(CAGR/retnStd)_mean/std                  0.5112\n",
      "grp(retnStd/UI)_mean                        3.8277\n",
      "grp(retnStd/UI)_std                         4.5244\n",
      "grp(retnStd/UI)_mean/std                    0.8460\n",
      "SPY_CAGR                                    1.5681\n",
      "SPY_CAGR/UI                             2,448.5448\n",
      "SPY_CAGR/retnStd                          268.0110\n",
      "SPY_retnStd/UI                              9.1360\n",
      "\n",
      "type(t_row_add_total): <class 'tuple'>\n",
      "t_row_add_total: ((), 2, '[15, 30]', 4, 20, 0, 10, 4, 0.8199945837689074, 1.2943640197336392, 0.633511571140281, 19643.952012216232, 33523.788028239345, 0.5859705351814302, 153.33138968208604, 115.354315316358, 1.329221098158108, 78.53907600774457, 132.75123896988939, 0.5916259359775827, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776)\n",
      "type(row_add_total): <class 'list'>\n",
      "row_add_total: [2, '[15, 30]', 4, 20, 0, 10, 3, 4.883050500959359, 10.299580111921149, 0.4741019000675105, 4420.883894439512, 8487.493689280347, 0.5208703601185661, 412.5449748121386, 807.0166720326737, 0.5111975862568499, 3.827696690833439, 4.524383883330976, 0.8460150132122263, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776]\n",
      "================================================================================ \n",
      "\n",
      "\n",
      "\n",
      "2 of 2 max_lookback_slice: (113, 143, 147)\n",
      "\n",
      "len(idx_train): 30\n",
      "idx_train: DatetimeIndex(['2023-02-03', '2023-02-06', '2023-02-07', '2023-02-08', '2023-02-09', '2023-02-10', '2023-02-13', '2023-02-14', '2023-02-15', '2023-02-16', '2023-02-17', '2023-02-21', '2023-02-22', '2023-02-23', '2023-02-24', '2023-02-27', '2023-02-28', '2023-03-01', '2023-03-02', '2023-03-03', '2023-03-06', '2023-03-07', '2023-03-08', '2023-03-09', '2023-03-10', '2023-03-13', '2023-03-14', '2023-03-15', '2023-03-16', '2023-03-17'], dtype='datetime64[ns]', name='Date', freq=None)\n",
      "df_train_dates (inclusive): 2023-02-03 - 2023-03-17\n",
      "\n",
      "len(idx_eval): 4\n",
      "idx_eval: DatetimeIndex(['2023-03-20', '2023-03-21', '2023-03-22', '2023-03-23'], dtype='datetime64[ns]', name='Date', freq=None)\n",
      "df_eval dates (inclusive): 2023-03-20 - 2023-03-23\n",
      "\n",
      "top_set_syms_n_freq: [('ANET', 6), ('FSLR', 5), ('NTRA', 5), ('SHV', 5), ('FCN', 4), ('GBTC', 4), ('GE', 4), ('HY', 4), ('SGEN', 4), ('AMD', 3), ('AMPH', 3), ('BEP', 3), ('FIZZ', 3), ('FTSM', 3), ('INTC', 3), ('LNTH', 3), ('META', 3), ('MLR', 3), ('NVDA', 3), ('OR', 3)]\n",
      "\n",
      "Function compare_picks_v_SPY returned column_name:value pairs\n",
      "column_name                                  value         \n",
      "grp(CAGR)_mean                             12.6530\n",
      "grp(CAGR)_std                               0.0000\n",
      "grp(CAGR)_mean/std                             inf\n",
      "grp(CAGR/UI)_mean                       2,105.6559\n",
      "grp(CAGR/UI)_std                            0.0000\n",
      "grp(CAGR/UI)_mean/std                          inf\n",
      "grp(CAGR/retnStd)_mean                    789.4230\n",
      "grp(CAGR/retnStd)_std                       0.0000\n",
      "grp(CAGR/retnStd)_mean/std                     inf\n",
      "grp(retnStd/UI)_mean                        2.6673\n",
      "grp(retnStd/UI)_std                         0.0000\n",
      "grp(retnStd/UI)_mean/std                       inf\n",
      "SPY_CAGR                                   -0.1146\n",
      "SPY_CAGR/UI                               -10.2722\n",
      "SPY_CAGR/retnStd                           -9.1555\n",
      "SPY_retnStd/UI                              1.1220\n",
      "\n",
      "type(t_row_add_total): <class 'tuple'>\n",
      "t_row_add_total: ((), 2, '[15, 30]', 4, 20, 0, 10, 4, 0.8199945837689074, 1.2943640197336392, 0.633511571140281, 19643.952012216232, 33523.788028239345, 0.5859705351814302, 153.33138968208604, 115.354315316358, 1.329221098158108, 78.53907600774457, 132.75123896988939, 0.5916259359775827, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776, 2, '[15, 30]', 4, 20, 0, 10, 3, 4.883050500959359, 10.299580111921149, 0.4741019000675105, 4420.883894439512, 8487.493689280347, 0.5208703601185661, 412.5449748121386, 807.0166720326737, 0.5111975862568499, 3.827696690833439, 4.524383883330976, 0.8460150132122263, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776)\n",
      "type(row_add_total): <class 'list'>\n",
      "row_add_total: [2, '[15, 30]', 4, 20, 0, 10, 6, 12.653004280684577, 0.0, inf, 2105.655925247013, 0.0, inf, 789.4229650487424, 0.0, inf, 2.667335533007962, 0.0, inf, -0.1145738645562181, -10.272153944517164, -9.155543336164031, 1.1219600593164762]\n",
      "Function compare_picks_v_SPY returned column_name:value pairs\n",
      "column_name                                  value         \n",
      "grp(CAGR)_mean                              2.6024\n",
      "grp(CAGR)_std                               4.0461\n",
      "grp(CAGR)_mean/std                          0.6432\n",
      "grp(CAGR/UI)_mean                         411.2822\n",
      "grp(CAGR/UI)_std                          356.5278\n",
      "grp(CAGR/UI)_mean/std                       1.1536\n",
      "grp(CAGR/retnStd)_mean                    169.1045\n",
      "grp(CAGR/retnStd)_std                     186.6393\n",
      "grp(CAGR/retnStd)_mean/std                  0.9060\n",
      "grp(retnStd/UI)_mean                        1.8960\n",
      "grp(retnStd/UI)_std                         0.8047\n",
      "grp(retnStd/UI)_mean/std                    2.3563\n",
      "SPY_CAGR                                   -0.1146\n",
      "SPY_CAGR/UI                               -10.2722\n",
      "SPY_CAGR/retnStd                           -9.1555\n",
      "SPY_retnStd/UI                              1.1220\n",
      "\n",
      "type(t_row_add_total): <class 'tuple'>\n",
      "t_row_add_total: ((), 2, '[15, 30]', 4, 20, 0, 10, 4, 0.8199945837689074, 1.2943640197336392, 0.633511571140281, 19643.952012216232, 33523.788028239345, 0.5859705351814302, 153.33138968208604, 115.354315316358, 1.329221098158108, 78.53907600774457, 132.75123896988939, 0.5916259359775827, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776, 2, '[15, 30]', 4, 20, 0, 10, 3, 4.883050500959359, 10.299580111921149, 0.4741019000675105, 4420.883894439512, 8487.493689280347, 0.5208703601185661, 412.5449748121386, 807.0166720326737, 0.5111975862568499, 3.827696690833439, 4.524383883330976, 0.8460150132122263, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776, 2, '[15, 30]', 4, 20, 0, 10, 6, 12.653004280684577, 0.0, inf, 2105.655925247013, 0.0, inf, 789.4229650487424, 0.0, inf, 2.667335533007962, 0.0, inf, -0.1145738645562181, -10.272153944517164, -9.155543336164031, 1.1219600593164762)\n",
      "type(row_add_total): <class 'list'>\n",
      "row_add_total: [2, '[15, 30]', 4, 20, 0, 10, 5, 2.6023759425065123, 4.046083662361912, 0.6431839179982176, 411.28217504758004, 356.5277732185812, 1.1535768204947945, 169.10454627660468, 186.63932866836095, 0.9060499064325623, 1.896017645057314, 0.8046564482136146, 2.3563070292502926, -0.1145738645562181, -10.272153944517164, -9.155543336164031, 1.1219600593164762]\n",
      "Function compare_picks_v_SPY returned column_name:value pairs\n",
      "column_name                                  value         \n",
      "grp(CAGR)_mean                              9.6045\n",
      "grp(CAGR)_std                              17.7267\n",
      "grp(CAGR)_mean/std                          0.5418\n",
      "grp(CAGR/UI)_mean                       3,464.6591\n",
      "grp(CAGR/UI)_std                        6,860.8060\n",
      "grp(CAGR/UI)_mean/std                       0.5050\n",
      "grp(CAGR/retnStd)_mean                    523.1362\n",
      "grp(CAGR/retnStd)_std                   1,148.6020\n",
      "grp(CAGR/retnStd)_mean/std                  0.4555\n",
      "grp(retnStd/UI)_mean                        2.0854\n",
      "grp(retnStd/UI)_std                         2.1049\n",
      "grp(retnStd/UI)_mean/std                    0.9907\n",
      "SPY_CAGR                                   -0.1146\n",
      "SPY_CAGR/UI                               -10.2722\n",
      "SPY_CAGR/retnStd                           -9.1555\n",
      "SPY_retnStd/UI                              1.1220\n",
      "\n",
      "type(t_row_add_total): <class 'tuple'>\n",
      "t_row_add_total: ((), 2, '[15, 30]', 4, 20, 0, 10, 4, 0.8199945837689074, 1.2943640197336392, 0.633511571140281, 19643.952012216232, 33523.788028239345, 0.5859705351814302, 153.33138968208604, 115.354315316358, 1.329221098158108, 78.53907600774457, 132.75123896988939, 0.5916259359775827, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776, 2, '[15, 30]', 4, 20, 0, 10, 3, 4.883050500959359, 10.299580111921149, 0.4741019000675105, 4420.883894439512, 8487.493689280347, 0.5208703601185661, 412.5449748121386, 807.0166720326737, 0.5111975862568499, 3.827696690833439, 4.524383883330976, 0.8460150132122263, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776, 2, '[15, 30]', 4, 20, 0, 10, 6, 12.653004280684577, 0.0, inf, 2105.655925247013, 0.0, inf, 789.4229650487424, 0.0, inf, 2.667335533007962, 0.0, inf, -0.1145738645562181, -10.272153944517164, -9.155543336164031, 1.1219600593164762, 2, '[15, 30]', 4, 20, 0, 10, 5, 2.6023759425065123, 4.046083662361912, 0.6431839179982176, 411.28217504758004, 356.5277732185812, 1.1535768204947945, 169.10454627660468, 186.63932866836095, 0.9060499064325623, 1.896017645057314, 0.8046564482136146, 2.3563070292502926, -0.1145738645562181, -10.272153944517164, -9.155543336164031, 1.1219600593164762)\n",
      "type(row_add_total): <class 'list'>\n",
      "row_add_total: [2, '[15, 30]', 4, 20, 0, 10, 4, 9.60449092724823, 17.726658437175715, 0.5418105708578462, 3464.6591231612174, 6860.806002466511, 0.5049930171346699, 523.1362006294098, 1148.6020461089702, 0.4554547002607192, 2.0853637902473166, 2.1048556206299707, 0.9907395879358127, -0.1145738645562181, -10.272153944517164, -9.155543336164031, 1.1219600593164762]\n",
      "Function compare_picks_v_SPY returned column_name:value pairs\n",
      "column_name                                  value         \n",
      "grp(CAGR)_mean                              8.3256\n",
      "grp(CAGR)_std                              17.0322\n",
      "grp(CAGR)_mean/std                          0.4888\n",
      "grp(CAGR/UI)_mean                  10,637,405.9164\n",
      "grp(CAGR/UI)_std                   33,636,404.4401\n",
      "grp(CAGR/UI)_mean/std                       0.3162\n",
      "grp(CAGR/retnStd)_mean                    858.0235\n",
      "grp(CAGR/retnStd)_std                   2,154.1752\n",
      "grp(CAGR/retnStd)_mean/std                  0.3983\n",
      "grp(retnStd/UI)_mean                    1,411.2257\n",
      "grp(retnStd/UI)_std                     4,457.3647\n",
      "grp(retnStd/UI)_mean/std                    0.3166\n",
      "SPY_CAGR                                   -0.1146\n",
      "SPY_CAGR/UI                               -10.2722\n",
      "SPY_CAGR/retnStd                           -9.1555\n",
      "SPY_retnStd/UI                              1.1220\n",
      "\n",
      "type(t_row_add_total): <class 'tuple'>\n",
      "t_row_add_total: ((), 2, '[15, 30]', 4, 20, 0, 10, 4, 0.8199945837689074, 1.2943640197336392, 0.633511571140281, 19643.952012216232, 33523.788028239345, 0.5859705351814302, 153.33138968208604, 115.354315316358, 1.329221098158108, 78.53907600774457, 132.75123896988939, 0.5916259359775827, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776, 2, '[15, 30]', 4, 20, 0, 10, 3, 4.883050500959359, 10.299580111921149, 0.4741019000675105, 4420.883894439512, 8487.493689280347, 0.5208703601185661, 412.5449748121386, 807.0166720326737, 0.5111975862568499, 3.827696690833439, 4.524383883330976, 0.8460150132122263, 1.5680683356683063, 2448.544751762231, 268.0109868651934, 9.1359864772776, 2, '[15, 30]', 4, 20, 0, 10, 6, 12.653004280684577, 0.0, inf, 2105.655925247013, 0.0, inf, 789.4229650487424, 0.0, inf, 2.667335533007962, 0.0, inf, -0.1145738645562181, -10.272153944517164, -9.155543336164031, 1.1219600593164762, 2, '[15, 30]', 4, 20, 0, 10, 5, 2.6023759425065123, 4.046083662361912, 0.6431839179982176, 411.28217504758004, 356.5277732185812, 1.1535768204947945, 169.10454627660468, 186.63932866836095, 0.9060499064325623, 1.896017645057314, 0.8046564482136146, 2.3563070292502926, -0.1145738645562181, -10.272153944517164, -9.155543336164031, 1.1219600593164762, 2, '[15, 30]', 4, 20, 0, 10, 4, 9.60449092724823, 17.726658437175715, 0.5418105708578462, 3464.6591231612174, 6860.806002466511, 0.5049930171346699, 523.1362006294098, 1148.6020461089702, 0.4554547002607192, 2.0853637902473166, 2.1048556206299707, 0.9907395879358127, -0.1145738645562181, -10.272153944517164, -9.155543336164031, 1.1219600593164762)\n",
      "type(row_add_total): <class 'list'>\n",
      "row_add_total: [2, '[15, 30]', 4, 20, 0, 10, 3, 8.325559871891066, 17.032246629688405, 0.48881160852726435, 10637405.916418903, 33636404.44008997, 0.31624681928668263, 858.0234758164235, 2154.175167754294, 0.39830719834678274, 1411.2256939987317, 4457.364729327419, 0.3166053889899368, -0.1145738645562181, -10.272153944517164, -9.155543336164031, 1.1219600593164762]\n",
      "================================================================================ \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_row_add_total_ = eval_grp_top_syms_n_freq(df, max_lookback_slices, grp_top_set_syms_n_freq, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "if store_results:  # record results to df\n",
    "  # row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, sym_freq_cnt]\n",
    "  # row_add_total = row_add0 + val_rows\n",
    "  print(f'row_add_total: {row_add_total}')\n",
    "  df_eval_results.loc[len(df_eval_results)] = row_add_total\n",
    "  print(f'appended row_add to df_eval_results:\\n{row_add_total}\\n')\n",
    "  pickle_dump(df_eval_results, path_data_dump, fp_df_eval_results)\n",
    "  print(f'Save results to: {fp_df_eval_results}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>days_lookbacks</th>\n",
       "      <th>days_eval</th>\n",
       "      <th>n_top_syms</th>\n",
       "      <th>syms_start</th>\n",
       "      <th>syms_end</th>\n",
       "      <th>sym_freq_cnt</th>\n",
       "      <th>grp(CAGR)_mean</th>\n",
       "      <th>grp(CAGR)_std</th>\n",
       "      <th>grp(CAGR)_mean/std</th>\n",
       "      <th>grp(CAGR/UI)_mean</th>\n",
       "      <th>grp(CAGR/UI)_std</th>\n",
       "      <th>grp(CAGR/UI)_mean/std</th>\n",
       "      <th>grp(CAGR/retnStd)_mean</th>\n",
       "      <th>grp(CAGR/retnStd)_std</th>\n",
       "      <th>grp(CAGR/retnStd)_mean/std</th>\n",
       "      <th>grp(retnStd/UI)_mean</th>\n",
       "      <th>grp(retnStd/UI)_std</th>\n",
       "      <th>grp(retnStd/UI)_mean/std</th>\n",
       "      <th>SPY_CAGR</th>\n",
       "      <th>SPY_CAGR/UI</th>\n",
       "      <th>SPY_CAGR/retnStd</th>\n",
       "      <th>SPY_retnStd/UI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10768</th>\n",
       "      <td>57</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.072861</td>\n",
       "      <td>0.124991</td>\n",
       "      <td>-0.582933</td>\n",
       "      <td>141.029300</td>\n",
       "      <td>198.636117</td>\n",
       "      <td>0.709988</td>\n",
       "      <td>-18.241589</td>\n",
       "      <td>147.439007</td>\n",
       "      <td>-0.123723</td>\n",
       "      <td>1.488370</td>\n",
       "      <td>1.140672</td>\n",
       "      <td>1.304819</td>\n",
       "      <td>-0.902952</td>\n",
       "      <td>-37.133739</td>\n",
       "      <td>-105.585989</td>\n",
       "      <td>0.351692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10769</th>\n",
       "      <td>57</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.985784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-24.200545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-38.364608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.630804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.902952</td>\n",
       "      <td>-37.133739</td>\n",
       "      <td>-105.585989</td>\n",
       "      <td>0.351692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10770</th>\n",
       "      <td>57</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.876533</td>\n",
       "      <td>0.131484</td>\n",
       "      <td>-6.666446</td>\n",
       "      <td>-25.873236</td>\n",
       "      <td>2.105890</td>\n",
       "      <td>-12.286131</td>\n",
       "      <td>-34.089238</td>\n",
       "      <td>4.579804</td>\n",
       "      <td>-7.443383</td>\n",
       "      <td>0.781530</td>\n",
       "      <td>0.167812</td>\n",
       "      <td>4.657170</td>\n",
       "      <td>-0.902952</td>\n",
       "      <td>-37.133739</td>\n",
       "      <td>-105.585989</td>\n",
       "      <td>0.351692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10771</th>\n",
       "      <td>57</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.853924</td>\n",
       "      <td>0.221902</td>\n",
       "      <td>-3.848211</td>\n",
       "      <td>-26.712490</td>\n",
       "      <td>6.312340</td>\n",
       "      <td>-4.231789</td>\n",
       "      <td>-53.312634</td>\n",
       "      <td>16.469317</td>\n",
       "      <td>-3.237088</td>\n",
       "      <td>0.553516</td>\n",
       "      <td>0.218623</td>\n",
       "      <td>2.531828</td>\n",
       "      <td>-0.902952</td>\n",
       "      <td>-37.133739</td>\n",
       "      <td>-105.585989</td>\n",
       "      <td>0.351692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10772</th>\n",
       "      <td>57</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.962932</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>-24.728181</td>\n",
       "      <td>-23.569370</td>\n",
       "      <td>7.883225</td>\n",
       "      <td>-2.989813</td>\n",
       "      <td>-39.377981</td>\n",
       "      <td>9.622466</td>\n",
       "      <td>-4.092296</td>\n",
       "      <td>0.591808</td>\n",
       "      <td>0.145305</td>\n",
       "      <td>4.072856</td>\n",
       "      <td>-0.902952</td>\n",
       "      <td>-37.133739</td>\n",
       "      <td>-105.585989</td>\n",
       "      <td>0.351692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_samples   days_lookbacks  days_eval  n_top_syms  syms_start  syms_end  sym_freq_cnt  grp(CAGR)_mean  grp(CAGR)_std  grp(CAGR)_mean/std  grp(CAGR/UI)_mean  grp(CAGR/UI)_std  grp(CAGR/UI)_mean/std  grp(CAGR/retnStd)_mean  grp(CAGR/retnStd)_std  grp(CAGR/retnStd)_mean/std  grp(retnStd/UI)_mean  grp(retnStd/UI)_std  grp(retnStd/UI)_mean/std  SPY_CAGR  SPY_CAGR/UI  SPY_CAGR/retnStd  SPY_retnStd/UI\n",
       "10768         57  [15, 30, 60,...          6          20           0        10             8       -0.072861       0.124991        -0.582933          141.029300         198.636117          0.709988             -18.241589              147.439007              -0.123723                    1.488370              1.140672             1.304819          -0.902952   -37.133739      -105.585989         0.351692\n",
       "10769         57  [15, 30, 60,...          6          20           0        10             7       -0.985784       0.000000             -inf          -24.200545           0.000000              -inf             -38.364608                0.000000                   -inf                    0.630804              0.000000                  inf          -0.902952   -37.133739      -105.585989         0.351692\n",
       "10770         57  [15, 30, 60,...          6          20           0        10             6       -0.876533       0.131484        -6.666446          -25.873236           2.105890        -12.286131             -34.089238                4.579804              -7.443383                    0.781530              0.167812             4.657170          -0.902952   -37.133739      -105.585989         0.351692\n",
       "10771         57  [15, 30, 60,...          6          20           0        10             5       -0.853924       0.221902        -3.848211          -26.712490           6.312340         -4.231789             -53.312634               16.469317              -3.237088                    0.553516              0.218623             2.531828          -0.902952   -37.133739      -105.585989         0.351692\n",
       "10772         57  [15, 30, 60,...          6          20           0        10             4       -0.962932       0.038941       -24.728181          -23.569370           7.883225         -2.989813             -39.377981                9.622466              -4.092296                    0.591808              0.145305             4.072856          -0.902952   -37.133739      -105.585989         0.351692"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_results = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "df_eval_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pickle_load(path_data_dump, fp_df_picks)\n",
    "# df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
