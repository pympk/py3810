{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.wrighters.io/parameters-jupyter-notebooks-with-papermill/\n",
    "import papermill as pm\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True  # True prints more output\n",
    "# verbose = False  # True prints more output\n",
    "\n",
    "# write run results to df_eval_results\n",
    "# store_results = False\n",
    "store_results = True\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "\n",
    "# slice starts and ends for selecting the best performing symbols\n",
    "syms_start = 0 \n",
    "syms_end = 10 \n",
    "\n",
    "fp_df_eval_results = 'Not_Applicable'\n",
    "days_eval = 0  # no need to eval when getting the current picks    \n",
    "n_samples = 1\n",
    "run_type = 'current'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_drop_last_n_rows = [0, 1, 2]\n",
    "\n",
    "l_days_lookbacks = [\n",
    "    [30, 60, 120],\n",
    "    [15, 30, 60, 120],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': True,\n",
       " 'store_results': True,\n",
       " 'n_top_syms': 20,\n",
       " 'syms_start': 0,\n",
       " 'syms_end': 10}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_params = dict(\n",
    "                  # fp_df_eval_results=fp_df_eval_results,\n",
    "                  # fp_df_picks=fp_df_picks,\n",
    "                  verbose=verbose,\n",
    "                  store_results=store_results,\n",
    "                  n_top_syms=n_top_syms,\n",
    "                  syms_start=syms_start,\n",
    "                  syms_end=syms_end,\n",
    "                  )\n",
    "\n",
    "run_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(product(l_days_lookbacks, l_drop_last_n_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    of 6    run_type: current       n_samples: 1        days_eval: 0        days_lookbacks: [30, 60, 120]          drop_last_n_rows: 0    fp_df_eval_results: Not_Applicable            \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61eefaf327e1457f9f8e1295fe516f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/29 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PapermillExecutionError",
     "evalue": "\n---------------------------------------------------------------------------\nException encountered at \"In [15]\":\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[15], line 91\n     71 _sym_idx = ['SPY']\n     72 df_SPY = df[iloc_start_eval:iloc_end_eval][_sym_idx]\n     74 (\n     75   _symbols,\n     76   _period_yr,\n     77   _retn,\n     78   _DD,\n     79   _UI,\n     80   _MDD,\n     81   _retnMean,\n     82   _retnStd,\n     83   _retnStd_div_UI,\n     84   _CAGR,\n     85   _CAGR_div_retnStd,\n     86   _CAGR_div_UI,\n     87   SPY_retnStd_d_UI,     \n     88   SPY_CAGR,\n     89   SPY_CAGR_d_retnStd,\n     90   SPY_CAGR_d_UI,\n---> 91 ) = symb_perf_stats_vectorized_v8(df_SPY)  \n     93 print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI, CAGR: {SPY_retnStd_d_UI[0]:>17,.1f}, {SPY_CAGR_d_retnStd[0]:>17,.1f}, {SPY_CAGR_d_UI[0]:>17.1f}, {SPY_CAGR[0]:>17.1f}')\n     95 # drop list with frequency count 2 or less, in l_sym_freq_cnt from zip\n\nFile c:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\myUtils.py:3167, in symb_perf_stats_vectorized_v8(df_symbols_close)\n   3163 arr_returns_std = np.std(\n   3164     arr_returns[1:, :], axis=0\n   3165 )  # drop first row\n   3166 arr_returns_0 = arr_returns\n-> 3167 arr_returns_0[0] = 0  # set first row to 0\n   3168 arr_cum_returns = (1 + arr_returns_0).cumprod(\n   3169     axis=0\n   3170 )  # cumulative product of column elements\n   3171 # accumulative max value of column elements\n\nIndexError: index 0 is out of bounds for axis 0 with size 0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPapermillExecutionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m run_params[\u001b[39m'\u001b[39m\u001b[39mdrop_last_n_rows\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m drop_last_n_rows\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m<4\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(items)\u001b[39m}\u001b[39;00m\u001b[39m    run_type: \u001b[39m\u001b[39m{\u001b[39;00mrun_type\u001b[39m:\u001b[39;00m\u001b[39m<10\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m    n_samples: \u001b[39m\u001b[39m{\u001b[39;00mn_samples\u001b[39m:\u001b[39;00m\u001b[39m<5.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m    days_eval: \u001b[39m\u001b[39m{\u001b[39;00mdays_eval\u001b[39m:\u001b[39;00m\u001b[39m<5.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m    days_lookbacks: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(days_lookbacks)\u001b[39m:\u001b[39;00m\u001b[39m<19\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m    drop_last_n_rows: \u001b[39m\u001b[39m{\u001b[39;00mdrop_last_n_rows\u001b[39m}\u001b[39;00m\u001b[39m    fp_df_eval_results: \u001b[39m\u001b[39m{\u001b[39;00mfp_df_eval_results\u001b[39m:\u001b[39;00m\u001b[39m<26\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m res \u001b[39m=\u001b[39m pm\u001b[39m.\u001b[39;49mexecute_notebook(\n\u001b[0;32m     14\u001b[0m   \u001b[39m'\u001b[39;49m\u001b[39myf_7a.ipynb\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m   \u001b[39m'\u001b[39;49m\u001b[39myf_7aPM_out.ipynb\u001b[39;49m\u001b[39m'\u001b[39;49m,    \n\u001b[0;32m     16\u001b[0m   parameters \u001b[39m=\u001b[39;49m run_params \n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     19\u001b[0m i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\.venv\\lib\\site-packages\\papermill\\execute.py:128\u001b[0m, in \u001b[0;36mexecute_notebook\u001b[1;34m(input_path, output_path, parameters, engine_name, request_save_on_cell_execute, prepare_only, kernel_name, language, progress_bar, log_output, stdout_file, stderr_file, start_timeout, report_mode, cwd, **engine_kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m         nb \u001b[39m=\u001b[39m papermill_engines\u001b[39m.\u001b[39mexecute_notebook_with_engine(\n\u001b[0;32m    114\u001b[0m             engine_name,\n\u001b[0;32m    115\u001b[0m             nb,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs\n\u001b[0;32m    125\u001b[0m         )\n\u001b[0;32m    127\u001b[0m     \u001b[39m# Check for errors first (it saves on error before raising)\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     raise_for_execution_errors(nb, output_path)\n\u001b[0;32m    130\u001b[0m \u001b[39m# Write final output in case the engine didn't write it on cell completion.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m write_ipynb(nb, output_path)\n",
      "File \u001b[1;32mc:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\.venv\\lib\\site-packages\\papermill\\execute.py:232\u001b[0m, in \u001b[0;36mraise_for_execution_errors\u001b[1;34m(nb, output_path)\u001b[0m\n\u001b[0;32m    229\u001b[0m nb\u001b[39m.\u001b[39mcells\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, error_msg_cell)\n\u001b[0;32m    231\u001b[0m write_ipynb(nb, output_path)\n\u001b[1;32m--> 232\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
      "\u001b[1;31mPapermillExecutionError\u001b[0m: \n---------------------------------------------------------------------------\nException encountered at \"In [15]\":\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[15], line 91\n     71 _sym_idx = ['SPY']\n     72 df_SPY = df[iloc_start_eval:iloc_end_eval][_sym_idx]\n     74 (\n     75   _symbols,\n     76   _period_yr,\n     77   _retn,\n     78   _DD,\n     79   _UI,\n     80   _MDD,\n     81   _retnMean,\n     82   _retnStd,\n     83   _retnStd_div_UI,\n     84   _CAGR,\n     85   _CAGR_div_retnStd,\n     86   _CAGR_div_UI,\n     87   SPY_retnStd_d_UI,     \n     88   SPY_CAGR,\n     89   SPY_CAGR_d_retnStd,\n     90   SPY_CAGR_d_UI,\n---> 91 ) = symb_perf_stats_vectorized_v8(df_SPY)  \n     93 print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI, CAGR: {SPY_retnStd_d_UI[0]:>17,.1f}, {SPY_CAGR_d_retnStd[0]:>17,.1f}, {SPY_CAGR_d_UI[0]:>17.1f}, {SPY_CAGR[0]:>17.1f}')\n     95 # drop list with frequency count 2 or less, in l_sym_freq_cnt from zip\n\nFile c:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\myUtils.py:3167, in symb_perf_stats_vectorized_v8(df_symbols_close)\n   3163 arr_returns_std = np.std(\n   3164     arr_returns[1:, :], axis=0\n   3165 )  # drop first row\n   3166 arr_returns_0 = arr_returns\n-> 3167 arr_returns_0[0] = 0  # set first row to 0\n   3168 arr_cum_returns = (1 + arr_returns_0).cumprod(\n   3169     axis=0\n   3170 )  # cumulative product of column elements\n   3171 # accumulative max value of column elements\n\nIndexError: index 0 is out of bounds for axis 0 with size 0\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for days_lookbacks, drop_last_n_rows in items:\n",
    "\n",
    "  run_params['run_type'] = run_type\n",
    "  run_params['fp_df_eval_results'] = fp_df_eval_results  \n",
    "  run_params['n_samples'] = n_samples\n",
    "  run_params['days_eval'] = days_eval\n",
    "  run_params['days_lookbacks'] = days_lookbacks\n",
    "  run_params['drop_last_n_rows'] = drop_last_n_rows\n",
    "\n",
    "  print(f'{i:<4} of {len(items)}    run_type: {run_type:<10}    n_samples: {n_samples:<5.0f}    days_eval: {days_eval:<5.0f}    days_lookbacks: {str(days_lookbacks):<19}    drop_last_n_rows: {drop_last_n_rows}    fp_df_eval_results: {fp_df_eval_results:<26}')\n",
    "\n",
    "  res = pm.execute_notebook(\n",
    "    'yf_7a.ipynb',\n",
    "    'yf_7aPM_out.ipynb',    \n",
    "    parameters = run_params \n",
    "  )\n",
    "\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the run parameters before running. It will take about 1 hour and 20 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = len(list(product(run_types, l_days_eval, l_days_lookbacks)))\n",
    "\n",
    "i = 1\n",
    "for run_type, days_eval, days_lookbacks in list(product(run_types, l_days_eval, l_days_lookbacks)):\n",
    "  # use n_samples_train to scale n_samples of other run_types \n",
    "  if run_type == 'train':\n",
    "    n_samples = n_samples_train  # train\n",
    "    fp_df_eval_results = f'df_eval_results_train'    \n",
    "  elif run_type == 'validate':\n",
    "    n_samples = round(n_samples_train * 0.2/0.7)  # validate, proportion to .7,.2,.1 split of train, validate, test\n",
    "    fp_df_eval_results = f'df_eval_results_validate'    \n",
    "  elif run_type == 'test':\n",
    "    n_samples = round(n_samples_train * 0.1/0.7)  # test, proportion to .7,.2,.1 split of train, validate, test  \n",
    "    fp_df_eval_results = f'df_eval_results_test'\n",
    "  elif run_type == 'current':\n",
    "    fp_df_eval_results = 'Not_Applicable'\n",
    "    days_eval = 0  # no need to eval when getting the current picks    \n",
    "    n_samples = 1\n",
    "    # fp_df_eval_results = f'df_eval_results_test'              \n",
    "  else:\n",
    "    n_samples = 2  # debug\n",
    "    fp_df_eval_results = f'df_eval_results' \n",
    "\n",
    "  run_params['run_type'] = run_type\n",
    "  run_params['fp_df_eval_results'] = fp_df_eval_results  \n",
    "  run_params['n_samples'] = n_samples\n",
    "  run_params['days_eval'] = days_eval\n",
    "  run_params['days_lookbacks'] = days_lookbacks\n",
    "\n",
    "  # print(f'run_type: {run_type:<10}    fp_df_eval_results: {fp_df_eval_results:<26}    n_samples: {n_samples:<5.0f}    days_eval: {days_eval:<5.0f}    days_lookbacks: {days_lookbacks}')\n",
    "  print(f'{i:<4} of {len_list}    run_type: {run_type:<10}    fp_df_eval_results: {fp_df_eval_results:<26}    n_samples: {n_samples:<5.0f}    days_eval: {days_eval:<5.0f}    days_lookbacks: {days_lookbacks}')\n",
    "\n",
    "  # res = pm.execute_notebook(\n",
    "  #   'yf_7a_w.ipynb',\n",
    "  #   'yf_7aPM_out.ipynb',    \n",
    "  #   parameters = run_params \n",
    "  # )\n",
    "\n",
    "  i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myUtils import pickle_load\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "# df = pickle_load(path_data_dump, 'df_eval_results_train')\n",
    "# df = pickle_load(path_data_dump, 'df_eval_results_validate')\n",
    "# df = pickle_load(path_data_dump, 'df_eval_results_test')\n",
    "df = pickle_load(path_data_dump, 'df_picks')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbl_concat.loc[tbl_concat['run_type'] == 'train']\n",
    "df.loc[df['date_end_df_train'] == '2023-03-17', 'sym_freq_9']\n",
    "# df.loc[df['date_end_df_train'] == '2023-03-17', 'sym_freq_8']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
