{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/pandas-groupby-a-simple-but-detailed-tutorial-314b8f37005d\n",
    "# https://towardsdatascience.com/accessing-data-in-a-multiindex-dataframe-in-pandas-569e8767201d\n",
    "# https://towardsdatascience.com/summarizing-data-with-pandas-crosstab-efc8b9abecf\n",
    "# https://towardsdatascience.com/how-to-flatten-multiindex-columns-and-rows-in-pandas-f5406c50e569\n",
    "# https://datascientyst.com/list-aggregation-functions-aggfunc-groupby-pandas/\n",
    "# https://datascientyst.com/sort-multiindex-pandas/\n",
    "# https://datascientyst.com/list-aggregation-functions-aggfunc-groupby-pandas/\n",
    "#### pandas function basics ####\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#function-application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, b]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>[c, d, e]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>[d, e, f]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID  col_1  col_2      col_3\n",
       "0  1      0      1     [a, b]\n",
       "1  2      2      4  [c, d, e]\n",
       "2  3      3      5  [d, e, f]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas apply function to df\n",
    "# https://stackoverflow.com/questions/13331698/how-to-apply-a-function-to-two-columns-of-pandas-dataframe\n",
    "# df['col_3'] = df.apply(lambda x: f(x.col_1, x.col_2), axis=1)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'ID':['1', '2', '3'], 'col_1': [0, 2, 3], 'col_2':[1, 4, 5]})\n",
    "mylist = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "\n",
    "def get_sublist(sta,end):\n",
    "    return mylist[sta:end+1]\n",
    "\n",
    "df['col_3'] = df.apply(lambda x: get_sublist(x.col_1, x.col_2), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_and_code</th>\n",
       "      <th>city_name</th>\n",
       "      <th>city_and_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>ChicagoUS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_and_code city_name city_and_country\n",
       "0   Chicago, IL   Chicago        ChicagoUS"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas pipe \n",
    "import pandas as pd\n",
    "\n",
    "def extract_city_name(df):\n",
    "    \"\"\"\n",
    "    Chicago, IL -> Chicago for city_name column\n",
    "    \"\"\"\n",
    "    df[\"city_name\"] = df[\"city_and_code\"].str.split(\",\").str.get(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_country_name(df, country_name=None):\n",
    "    \"\"\"\n",
    "    Chicago -> Chicago-US for city_name column\n",
    "    \"\"\"\n",
    "    col = \"city_name\"\n",
    "    df[\"city_and_country\"] = df[col] + country_name\n",
    "    return df\n",
    "\n",
    "\n",
    "df_p = pd.DataFrame({\"city_and_code\": [\"Chicago, IL\"]})\n",
    "df_p.pipe(extract_city_name).pipe(add_country_name, country_name=\"US\")\n",
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put dict with variable_name:variable_value pairs into memory\n",
    "# convert dictionary entries into variables\n",
    "# https://stackoverflow.com/questions/18090672/convert-dictionary-entries-into-variables?noredirect=1&lq=1\n",
    "d = {'a': 1, 'b': 2}\n",
    "locals().update(d)\n",
    "globals().update(d)  # works inside a function\n",
    "print(f'a: {a}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd pandas display options\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.max_colwidth\", 20)\n",
    "pd.set_option(\"display.width\", 500)  # code-runner format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/4019639/splitting-a-dictionary-in-python-into-keys-and-values\n",
    "# dic dict create dictionary from list of keys and values, exact dic keys and values to separate lists\n",
    "# store pickle run results in dictionary dic dict for future verification test\n",
    "# use notepad find / replace on _vals to add \"\" around _vals to get _keys\n",
    "_keys = ['df_eval_results', 'df', 'max_lookback_slices']\n",
    "_vals = [df_eval_results, df, max_lookback_slices]\n",
    "_d = dict(zip(_keys, _vals))\n",
    "_l_keys = list(_d.keys())\n",
    "_l_vals = list(_d.values())\n",
    "print(_l_keys)\n",
    "print(_l_vals)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort sorted unchanged old list new list \n",
    "old_list = [[3,2,1], [6,5,4]]\n",
    "new_list = []\n",
    "for i in old_list:\n",
    "    new_list.append(sorted(i))\n",
    "\n",
    "print(f'old_list: {old_list}')\n",
    "print(f'new_list: {new_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello               good bye\n",
      "%%%%%%%%%%\n"
     ]
    }
   ],
   "source": [
    "# format fsting f spacing string\n",
    "print(f'{\"hello\":<14}{\"good bye\":>14}')\n",
    "print(f'{\"%\"*10}')\n",
    "print(f'\\n\\n{\"%\"*40:<42}{i+1} of {len(l_sorted_days_lookbacks)} days_lookbacks{\"%\"*40:>42}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip two lists together into dic When you need to create dictionaries from lists, I assume you have the list of keys in a list and the list of matching values in another one:\n",
    "keys_sample = [\"left\", \"right\", \"up\", \"down\"]\n",
    "values_sample = [\"one\", \"two\", 0, None]\n",
    "# dictionary constructor takes pairs, which are the output of zip:\n",
    "together = dict(zip(keys_sample, values_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fstring keep a consistent spacing format \n",
    "blank = ' '\n",
    "print(f'\\n{my_date:<14}{str(my_days_lookback):<21}{my_col}: {my_list}')\n",
    "print(f'{blank:<14}{str(my_days_lookback):<21}{my_col}: {my_list}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df filter multiple conditions requirement and or \n",
    "# Cannot perform 'rand_' with a dtyped [object] array and scalar of type [bool]\n",
    "# The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
    "my_row = (df['date_end_df_train'] == my_date) & (df['days_lookbacks'] == '[15, 30, 60, 120]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_list:   [20, 60, 120]\n"
     ]
    }
   ],
   "source": [
    "# fsting format and justify list\n",
    "my_list = [20, 60, 120]\n",
    "print(f'my_list: {str(my_list):>15}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b']\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/23111990/pandas-dataframe-stored-list-as-string-how-to-convert-back-to-list\n",
    "# convert list stored in dataframe df back to a list\n",
    "# Pandas DataFrame stored list as string: How to convert back to list\n",
    "from ast import literal_eval\n",
    "my_str = \"['a', 'b']\"\n",
    "my_list = literal_eval(my_str)\n",
    "print(my_list)\n",
    "print(type(my_list))\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index pandas drop index column\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/71757911/select-multiple-separately-columns-by-iloc-in-pandas\n",
    "g_tbl.iloc[:, np.r_[1, 16:42]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/how-to-replace-values-in-column-based-on-condition-in-pandas/\n",
    "gdf.loc[gdf['run_type'] == 'train', 'run_type'] = 100\n",
    "\n",
    "# returns the row labels where column 'run_type' equal 'train'\n",
    "tbl_concat.loc[tbl_concat['run_type'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                col1        col2\n",
      "A 1 2017-04-01  14.0   87.346878\n",
      "    2017-06-01   4.0   87.347504\n",
      "  2 2014-08-01   1.0  123.110001\n",
      "    2015-01-01   4.0  209.612503\n",
      "B 3 2014-07-01   1.0   68.540001\n",
      "    2014-12-01   1.0   64.370003\n",
      "  4 2015-01-01   3.0   75.000000 \n",
      "\n",
      "===============\n",
      "                col1       col2\n",
      "A 1 2017-04-01  14.0  87.346878\n",
      "    2017-06-01   4.0  87.347504 \n",
      "\n",
      "                col1        col2\n",
      "A 2 2014-08-01   1.0  123.110001\n",
      "    2015-01-01   4.0  209.612503 \n",
      "\n",
      "                col1       col2\n",
      "B 3 2014-07-01   1.0  68.540001\n",
      "    2014-12-01   1.0  64.370003 \n",
      "\n",
      "                col1  col2\n",
      "B 4 2015-01-01   3.0  75.0 \n",
      "\n",
      "===============\n",
      "df.groupby(level=[0,1]).indices.values():\n",
      "dict_values([array([0, 1], dtype=int64), array([2, 3], dtype=int64), array([4, 5], dtype=int64), array([6], dtype=int64)])\n",
      "===============\n",
      "df.iloc[[0,2,4,6]]:\n",
      "                col1        col2\n",
      "A 1 2017-04-01  14.0   87.346878\n",
      "  2 2014-08-01   1.0  123.110001\n",
      "B 3 2014-07-01   1.0   68.540001\n",
      "  4 2015-01-01   3.0   75.000000\n",
      "===============\n",
      "df.iloc[[0,2,4,6]]=0:\n",
      "                col1        col2\n",
      "A 1 2017-04-01   0.0    0.000000\n",
      "    2017-06-01   4.0   87.347504\n",
      "  2 2014-08-01   0.0    0.000000\n",
      "    2015-01-01   4.0  209.612503\n",
      "B 3 2014-07-01   0.0    0.000000\n",
      "    2014-12-01   1.0   64.370003\n",
      "  4 2015-01-01   0.0    0.000000\n",
      "===============\n",
      "df.iloc[[a[0] for a in df.groupby(level=[0, 1]).indices.values()]] = 0:\n",
      "                col1        col2\n",
      "A 1 2017-04-01   0.0    0.000000\n",
      "    2017-06-01   4.0   87.347504\n",
      "  2 2014-08-01   0.0    0.000000\n",
      "    2015-01-01   4.0  209.612503\n",
      "B 3 2014-07-01   0.0    0.000000\n",
      "    2014-12-01   1.0   64.370003\n",
      "  4 2015-01-01   0.0    0.000000\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/62697810/replace-specific-values-in-multiindex-dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'col1': [14., 4., 1., 4., 1., 1., 3.],\n",
    "                   'col2': [ 87.346878, 87.347504, 123.110001, 209.612503, 68.540001, 64.370003, 75.]},\n",
    "                   index = pd.MultiIndex.from_tuples(([('A', 1, '2017-04-01'), ('A', 1, '2017-06-01'),\n",
    "                                                       ('A', 2, '2014-08-01'), ('A', 2, '2015-01-01'),\n",
    "                                                       ('B', 3, '2014-07-01'), ('B', 3, '2014-12-01'),\n",
    "                                                       ('B', 4, '2015-01-01')])))\n",
    "_df = df.copy()\n",
    "print(df,'\\n')\n",
    "print('='*15)\n",
    "\n",
    "grouped_df = df.groupby(level=[0,1])\n",
    "for key, item in grouped_df:\n",
    "    print(grouped_df.get_group(key), \"\\n\")\n",
    "print('='*15)\n",
    "\n",
    "print(f'df.groupby(level=[0,1]).indices.values():\\n{df.groupby(level=[0,1]).indices.values()}')\n",
    "print('='*15)\n",
    "\n",
    "print(f'df.iloc[[0,2,4,6]]:\\n{df.iloc[[0,2,4,6]]}')\n",
    "print('='*15)\n",
    "\n",
    "df.iloc[[0,2,4,6]]=0\n",
    "print(f'df.iloc[[0,2,4,6]]=0:\\n{df}')\n",
    "print('='*15)\n",
    "\n",
    "_df.iloc[[a[0] for a in _df.groupby(level=[0, 1]).indices.values()]] = 0\n",
    "print(f'df.iloc[[a[0] for a in df.groupby(level=[0, 1]).indices.values()]] = 0:\\n{_df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print groupby object pandas, level 0,1,2 happens to be the row indices\n",
    "grouped_df = tbl_concat.groupby(level=[0,1,2])\n",
    "\n",
    "for key, item in grouped_df:\n",
    "    print(grouped_df.get_group(key), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list sorted unique symbols\n",
    "my_unique_symbols = sorted(list(set(my_symbols)))\n",
    "my_unique_symbols = sorted(list(set(my_symbols)), reverse=True)  # descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format number\n",
    "print(f'symbol:  {symbol:>4}   Date: {sDate:13}df_Close: {sClose:>10.5f} Yahoo_Close: {yhClose:>10.5f}   %_dif_Close: {abs_pct_diff:>7.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df): 10\n",
      "df:\n",
      "            col\n",
      "2022-01-01    1\n",
      "2022-01-02    2\n",
      "2022-01-03    3\n",
      "2022-01-04    4\n",
      "2022-01-05    5\n",
      "2022-01-06    6\n",
      "2022-01-07    7\n",
      "2022-01-08    8\n",
      "2022-01-09    9\n",
      "2022-01-10   10\n",
      "\n",
      "Return the first row\n",
      "df.head(1):\n",
      "            col\n",
      "2022-01-01    1\n",
      "\n",
      "df.iloc[-len(df)] returns the first row as a series:\n",
      "col    1\n",
      "Name: 2022-01-01 00:00:00, dtype: int32\n",
      "\n",
      "df.iloc[-len(df) : -len(df)+1] returns the first row as a df:\n",
      "            col\n",
      "2022-01-01    1\n",
      "\n",
      "df.iloc[0] returns the first row as a series:\n",
      "col    1\n",
      "Name: 2022-01-01 00:00:00, dtype: int32\n",
      "\n",
      "df.iloc[[0]] returns the first row as a df:\n",
      "            col\n",
      "2022-01-01    1\n",
      "\n",
      "df.iloc[0:1] returns the first row as a df:\n",
      "            col\n",
      "2022-01-01    1\n",
      "\n",
      "Return the last row\n",
      "df.tail(1):\n",
      "            col\n",
      "2022-01-10   10\n",
      "\n",
      "df.iloc[len(df)-1] returns the last row as a series:\n",
      "col    10\n",
      "Name: 2022-01-10 00:00:00, dtype: int32\n",
      "\n",
      "df.iloc[len(df)-1 : len(df)] returns the last row as a df:\n",
      "            col\n",
      "2022-01-10   10\n",
      "\n",
      "df.iloc[-1] returns the last row as a series:\n",
      "col    10\n",
      "Name: 2022-01-10 00:00:00, dtype: int32\n",
      "\n",
      "df.iloc[[-1]] returns the last row as a df:\n",
      "            col\n",
      "2022-01-10   10\n",
      "\n",
      "df.iloc[-1:] returns the last row as a df:\n",
      "            col\n",
      "2022-01-10   10\n",
      "\n",
      "Return a slice\n",
      "df.iloc[1:2] returns the second row as a df:\n",
      "            col\n",
      "2022-01-02    2\n",
      "\n",
      "df.iloc[-2:-1] returns the second to the last row as a df:\n",
      "            col\n",
      "2022-01-09    9\n",
      "\n",
      "df.iloc[:2] returns the first two rows as a df:\n",
      "            col\n",
      "2022-01-01    1\n",
      "2022-01-02    2\n",
      "\n",
      "df.iloc[-2:] returns the last two rows as a df:\n",
      "            col\n",
      "2022-01-09    9\n",
      "2022-01-10   10\n",
      "\n",
      "Return all rows\n",
      "df returns the all rows as a df:\n",
      "            col\n",
      "2022-01-01    1\n",
      "2022-01-02    2\n",
      "2022-01-03    3\n",
      "2022-01-04    4\n",
      "2022-01-05    5\n",
      "2022-01-06    6\n",
      "2022-01-07    7\n",
      "2022-01-08    8\n",
      "2022-01-09    9\n",
      "2022-01-10   10\n",
      "\n",
      "df.iloc[0 : len(df)] returns the all rows as a df:\n",
      "            col\n",
      "2022-01-01    1\n",
      "2022-01-02    2\n",
      "2022-01-03    3\n",
      "2022-01-04    4\n",
      "2022-01-05    5\n",
      "2022-01-06    6\n",
      "2022-01-07    7\n",
      "2022-01-08    8\n",
      "2022-01-09    9\n",
      "2022-01-10   10\n",
      "\n",
      "df.iloc[0 : len(df)+1] returns the all rows as a df without warning out-of-bound:\n",
      "            col\n",
      "2022-01-01    1\n",
      "2022-01-02    2\n",
      "2022-01-03    3\n",
      "2022-01-04    4\n",
      "2022-01-05    5\n",
      "2022-01-06    6\n",
      "2022-01-07    7\n",
      "2022-01-08    8\n",
      "2022-01-09    9\n",
      "2022-01-10   10\n",
      "\n",
      "df.iloc[-len(df):] returns all rows as a df:\n",
      "            col\n",
      "2022-01-01    1\n",
      "2022-01-02    2\n",
      "2022-01-03    3\n",
      "2022-01-04    4\n",
      "2022-01-05    5\n",
      "2022-01-06    6\n",
      "2022-01-07    7\n",
      "2022-01-08    8\n",
      "2022-01-09    9\n",
      "2022-01-10   10\n",
      "\n",
      "ERROR: df.iloc[len(df)] will raise IndexError: single positional indexer is out-of-bounds\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdf.iloc[-len(df):] returns all rows as a df:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdf\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(df):]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mERROR: df.iloc[len(df)] will raise IndexError: single positional indexer is out-of-bounds\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdf\u001b[39m.\u001b[39miloc[\u001b[39mlen\u001b[39m(df)]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1625\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1622\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index by location index with a non-integer key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1624\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1625\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[0;32m   1627\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1557\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1556\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# pandas iloc slice, first and last n rows\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# create a range of dates\n",
    "dates = pd.date_range(start='2022-01-01', end='2022-01-10')\n",
    "# create a DataFrame with dates as the index\n",
    "df = pd.DataFrame(index=dates)\n",
    "# add a column of integers to the DataFrame\n",
    "df['col'] = np.arange(1, 11, 1, dtype=int)\n",
    "\n",
    "print(f'len(df): {len(df)}')\n",
    "print(f'df:\\n{df}\\n')\n",
    "\n",
    "print(f'Return the first row')\n",
    "print(f'df.head(1):\\n{df.head(1)}\\n')\n",
    "print(f'df.iloc[-len(df)] returns the first row as a series:\\n{df.iloc[-len(df)]}\\n')\n",
    "print(f'df.iloc[-len(df) : -len(df)+1] returns the first row as a df:\\n{df.iloc[-len(df) : -len(df)+1]}\\n')\n",
    "print(f'df.iloc[0] returns the first row as a series:\\n{df.iloc[0]}\\n')\n",
    "print(f'df.iloc[[0]] returns the first row as a df:\\n{df.iloc[[0]]}\\n')\n",
    "print(f'df.iloc[0:1] returns the first row as a df:\\n{df.iloc[0:1]}\\n')\n",
    "\n",
    "print(f'Return the last row')\n",
    "print(f'df.tail(1):\\n{df.tail(1)}\\n')\n",
    "print(f'df.iloc[len(df)-1] returns the last row as a series:\\n{df.iloc[len(df)-1]}\\n')\n",
    "print(f'df.iloc[len(df)-1 : len(df)] returns the last row as a df:\\n{df.iloc[len(df)-1 : len(df)]}\\n')\n",
    "print(f'df.iloc[-1] returns the last row as a series:\\n{df.iloc[-1]}\\n')\n",
    "print(f'df.iloc[[-1]] returns the last row as a df:\\n{df.iloc[[-1]]}\\n')\n",
    "print(f'df.iloc[-1:] returns the last row as a df:\\n{df.iloc[-1:]}\\n')\n",
    "\n",
    "print(f'Return a slice')\n",
    "print(f'df.iloc[1:2] returns the second row as a df:\\n{df.iloc[1:2]}\\n')\n",
    "print(f'df.iloc[-2:-1] returns the second to the last row as a df:\\n{df.iloc[-2:-1]}\\n')\n",
    "print(f'df.iloc[:2] returns the first two rows as a df:\\n{df.iloc[:2]}\\n')\n",
    "print(f'df.iloc[-2:] returns the last two rows as a df:\\n{df.iloc[-2:]}\\n')\n",
    "\n",
    "print(f'Return all rows')\n",
    "print(f'df returns the all rows as a df:\\n{df}\\n')\n",
    "print(f'df.iloc[0 : len(df)] returns the all rows as a df:\\n{df.iloc[0 : len(df)]}\\n')\n",
    "print(f'df.iloc[0 : len(df)+1] returns the all rows as a df without warning out-of-bound:\\n{df.iloc[0 : len(df)+1]}\\n')\n",
    "print(f'df.iloc[-len(df):] returns all rows as a df:\\n{df.iloc[-len(df):]}\\n')\n",
    "\n",
    "print(f'ERROR: df.iloc[len(df)] will raise IndexError: single positional indexer is out-of-bounds')\n",
    "print(f'{df.iloc[len(df)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex([], dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index[10:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-01\n",
      "2022-01-10\n"
     ]
    }
   ],
   "source": [
    "# print(df.head(1).index[0].strftime('%Y-%m-%d'))\n",
    "# print(df.tail(1).index[0].strftime('%Y-%m-%d'))\n",
    "print(df.index[0].strftime('%Y-%m-%d'))\n",
    "print(df.index[-1].strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df): 10\n",
      "df:\n",
      "            col\n",
      "2022-01-01    1\n",
      "2022-01-02    2\n",
      "2022-01-03    3\n",
      "2022-01-04    4\n",
      "2022-01-05    5\n",
      "2022-01-06    6\n",
      "2022-01-07    7\n",
      "2022-01-08    8\n",
      "2022-01-09    9\n",
      "2022-01-10   10\n",
      "\n",
      "iloc_pos: 0, date: 2022-01-01\n",
      "iloc_pos: 1, date: 2022-01-02\n",
      "iloc_pos: 2, date: 2022-01-03\n",
      "iloc_pos: 3, date: 2022-01-04\n",
      "iloc_pos: 4, date: 2022-01-05\n",
      "iloc_pos: 5, date: 2022-01-06\n",
      "iloc_pos: 6, date: 2022-01-07\n",
      "iloc_pos: 7, date: 2022-01-08\n",
      "iloc_pos: 8, date: 2022-01-09\n",
      "iloc_pos: 9, date: 2022-01-10\n",
      "iloc_pos: 10, date: 2022-01-10\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "ERROR iloc_pos 11 must be <= len(df) 10",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m ERROR iloc_pos 11 must be <= len(df) 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "print(f'len(df): {len(df)}\\ndf:\\n{df}\\n')\n",
    "# df.index[9].strftime('%Y-%m-%d')\n",
    "len_df = len(df)\n",
    "\n",
    "for iloc_pos in np.arange(0, 13, 1, dtype=int): \n",
    "  if iloc_pos < len_df:\n",
    "    _date = df.index[iloc_pos].strftime('%Y-%m-%d')  \n",
    "    print(f'iloc_pos: {iloc_pos}, date: {_date}')\n",
    "  elif iloc_pos == len_df:\n",
    "    _date = df.index[len_df - 1].strftime('%Y-%m-%d')      \n",
    "    print(f'iloc_pos: {len_df}, date: {_date}')  \n",
    "  else:\n",
    "    msg_stop = f'ERROR iloc_pos {iloc_pos} must be <= len(df) {len(df)}' \n",
    "    raise SystemExit(msg_stop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name with today's date\n",
    "str_today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "fp_results = f'yf_8_results_{str_today}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19798229/how-to-do-group-by-on-a-multiindex-in-pandas\n",
    "import pandas\n",
    "df = pandas.DataFrame.from_dict(\n",
    "    {\n",
    "     'category': {0: 'Love', 1: 'Love', 2: 'Fashion', 3: 'Fashion', 4: 'Hair', 5: 'Movies', 6: 'Movies', 7: 'Health', 8: 'Health', 9: 'Celebs', 10: 'Celebs', 11: 'Travel', 12: 'Weightloss', 13: 'Diet', 14: 'Bags'}, \n",
    "     'impressions': {0: 380, 1: 374242, 2: 197, 3: 13363, 4: 4, 5: 189, 6: 60632, 7: 269, 8: 40189, 9: 138, 10: 66590, 11: 2227, 12: 22668, 13: 21707, 14: 229}, \n",
    "     'date': {0: '2013-11-04', 1: '2013-11-04', 2: '2013-11-04', 3: '2013-11-04', 4: '2013-11-04', 5: '2013-11-04', 6: '2013-11-04', 7: '2013-11-04', 8: '2013-11-04', 9: '2013-11-04', 10: '2013-11-04', 11: '2013-11-04', 12: '2013-11-04', 13: '2013-11-04', 14: '2013-11-04'}, 'cpc_cpm_revenue': {0: 0.36823, 1: 474.81522000000001, 2: 0.19434000000000001, 3: 18.264220000000002, 4: 0.00080000000000000004, 5: 0.23613000000000001, 6: 81.391139999999993, 7: 0.27171000000000001, 8: 51.258200000000002, 9: 0.11536, 10: 83.966859999999997, 11: 3.43248, 12: 31.695889999999999, 13: 28.459320000000002, 14: 0.43524000000000002}, 'clicks': {0: 0, 1: 183, 2: 0, 3: 9, 4: 0, 5: 1, 6: 20, 7: 0, 8: 21, 9: 0, 10: 32, 11: 1, 12: 12, 13: 9, 14: 2}, 'size': {0: '300x250', 1: '300x250', 2: '300x250', 3: '300x250', 4: '300x250', 5: '300x250', 6: '300x250', 7: '300x250', 8: '300x250', 9: '300x250', 10: '300x250', 11: '300x250', 12: '300x250', 13: '300x250', 14: '300x250'}\n",
    "    }\n",
    ")\n",
    "df\n",
    "df.set_index(['date', 'category'], inplace=True)\n",
    "print(df.head())\n",
    "df.groupby(level=[0]).sum()\n",
    "print(df.head())\n",
    "df.groupby(level=[0,1]).sum()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# panadas multi level index sort df\n",
    "_tbt_concat.sort_values(by=[\"days_lookbacks\", \"days_eval\", \"sym_freq_cnt\"])\n",
    "_tbt_concat.sort_values(by=\"Rank_d_CAGR/UI_m/s\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force pip install in .venv\n",
    "c:/Users/ping/MyDrive/py_files/python/py3810/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter version run from notebook\n",
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python version running in notebook\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas drop_duplicates method not working on dataframe containing lists, drop duplicate rows\n",
    "#  error: TypeError: unhashable type: 'list'\n",
    "_df = df.astype(str)\n",
    "_df = _df.drop_duplicates(subset=['date', 'days_lookbacks'])\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_data_test = df.iloc[:, :-1]  # drop last column\n",
    "df_eval_SPY_test = df.iloc[:, -1:]  # keep only last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to loop backwards in python? [duplicate]\n",
    "for x in range(6, 2, -1):\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/49700794/selecting-rows-of-pandas-dataframe-where-column-is-not-empty-list\n",
    "# Selecting rows of pandas DataFrame where column is not empty list\n",
    "df[df.my_list.astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list duplicate in list\n",
    "# https://stackoverflow.com/questions/9835762/how-do-i-find-the-duplicates-in-a-list-and-create-another-list-with-them\n",
    "import collections\n",
    "print([item for item, count in collections.Counter(symbols).items() if count > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/50773107/how-to-replace-infinite-value-with-maximum-value-of-a-pandas-column\n",
    "# replace inf in column grp(CAGR/UI)_mean\n",
    "df['grp(CAGR/UI)_mean'].replace(np.inf, grp_inf_replacement['grp(CAGR/UI)_mean'], inplace=True)\n",
    "# replace NaN in column grp(CAGR/UI)_std\n",
    "df['grp(CAGR/UI)_std'].replace(np.nan, grp_inf_replacement['grp(CAGR/UI)_std'], inplace=True)\n",
    "# replace NaN in column grp(CAGR/UI)_mean/std\n",
    "df['grp(CAGR/UI)_mean/std'].replace(np.nan, grp_inf_replacement['grp(CAGR/UI)_mean/std'], inplace=True)\n",
    "# replace inf in column SPY_CAGR/UI\n",
    "df['SPY_CAGR/UI'].replace(np.inf, SPY_inf_replacement, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get values of _cols, where grp(CAGR/UI)_mean is max after filtering out inf\n",
    "_cols = ['grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'grp(CAGR/UI)_mean/std']\n",
    "_df_no_inf = df.loc[df['grp(CAGR/UI)_mean'] != np.inf]  # df with filter out inf in column grp(CAGR/UI)_mean \n",
    "_idx = _df_no_inf['grp(CAGR/UI)_mean'].idxmax()  # index value of max in grp(CAGR/UI)_mean \n",
    "grp_inf_replacement = _df_no_inf.loc[[_idx], _cols].squeeze()  # convert df (only has 1 row) to series\n",
    "print(f'_idx: {_idx}')\n",
    "grp_inf_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/31674195/plot-normal-distribution-given-mean-and-sigma-python\n",
    "# loc is mean, scale is standard deviation\n",
    "import pylab\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "# x = np.linspace(-10000,100000,1000)\n",
    "x = np.linspace(-40e+10,50e+10,1000)\n",
    "y = norm.pdf(x, loc=2.562777e+10, scale=1.036925e+11)    # loc = mean, scale = standard deviation\n",
    "# z = norm.pdf(x, loc=3.540615e+10, scale=1.194430e+11)    # for example\n",
    "# z1 = norm.pdf(x, loc=298.805901, scale=826.875749)    # for example\n",
    "# z1 = norm.pdf(x, loc=1.021825, scale=1.505096)    # for example\n",
    "pylab.plot(x,y, 'b')\n",
    "# pylab.plot(x,z, 'g')\n",
    "# pylab.plot(x,z1, 'r')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop inf, -inf, NaN from df\n",
    "\n",
    "my_cols = ['grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'SPY_CAGR/UI']\n",
    "_df = df[my_cols]\n",
    "row_inf = _df.index[np.isinf(_df).any(axis=1)]\n",
    "print(f'row iloc with inf:\\n{row_inf}\\n')\n",
    "df_inf = df.iloc[row_inf].copy()  # df with inf in my_cols\n",
    "# display(HTML(df_inf.to_html()))\n",
    "df.drop(axis=0, index=row_inf, inplace=True)\n",
    "# display(HTML(df.to_html()))\n",
    "df.dropna(how='any', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 14)\n",
    "pd.set_option('display.max_colwidth', 6)\n",
    "pd.set_option('display.width', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print df\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty DataFrame df and append row\n",
    "import pandas as pd\n",
    "\n",
    "my_cols = ['date', 'days_lookbacks', 'n_top_syms', 'syms_start', 'syms_end', 'grp_dates', 'top_set_syms_n_freq', 'top_set_syms']\n",
    "# Creating Empty DataFrame and Storing it in variable df\n",
    "df = pd.DataFrame(columns=my_cols)\n",
    "\n",
    "row_add = [grp_dates[-1], days_lookbacks, n_top_syms, syms_start, syms_end, grp_dates, top_set_syms_n_freq, top_set_syms]\n",
    "df.loc[len(df)] = row_add\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten symbols_download_err which is a list-of-lists\n",
    "l_symbols_err = [val for sublist in symbols_download_err for val in sublist]\n",
    "pickle_dump(l_symbols_err, path_data_dump, 'l_symbols_err')\n",
    "l_symbols_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns in multilevel, column names is a list \n",
    "df = df.drop(l_syms_0_vol_0_close, axis=1, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-order multiIndex columns\n",
    "_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "# create multilevel column names\n",
    "_col_names = pd.MultiIndex.from_product([_l_symbols, _cols])\n",
    "_df_adj.columns = _col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of unique symbols in df_OHLCV, list(df) is a list of tuples\n",
    "# e.g.: [('AAPL', 'Open')..('AAPL', 'Volume'),...\n",
    "#        ('ZZZZ', 'Open')..('ZZZZ', 'Volume')]\n",
    "symbols_OHLCV = list(set([i[0] for i in list(df)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined 2 lists to one list and remove duplicates, unique symbols\n",
    "a = ['a', 'b', 'c']\n",
    "b = ['a', 'b', 'c', 'd']\n",
    "print(f'Order not kept: {list(set(a + b))}')\n",
    "\n",
    "from collections import OrderedDict\n",
    "print(f'Order kept:     {list(OrderedDict.fromkeys(a+b))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas series to list, df['symbol'] is the symbol column in df\n",
    "df['symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a Python List into Chunks using For Loops\n",
    "a_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "chunked_list = list()\n",
    "chunk_size = 3\n",
    "for i in range(0, len(a_list), chunk_size):\n",
    "    chunked_list.append(a_list[i:i+chunk_size])\n",
    "print(chunked_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiIndex sort df by symbol\n",
    "df_OHLCV_all_dates = df_OHLCV_all_dates.sort_index(axis=1,level=0,sort_remaining=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column names from ['Open', ..., 'Volume'] to ['open', ..., 'volume']\n",
    "# remove_unused_levels() prevents ValueError\n",
    "# e.g ValueError: On level 1, code max (5) >= length of level (5). NOTE: this index is in an inconsistent state\n",
    "# The error may be caused by removing symbols from the dataframe with all NaN in OHLCV columns\n",
    "df_OHLCV_all_dates.columns = df_OHLCV_all_dates.columns.remove_unused_levels()\n",
    "df_OHLCV_all_dates.columns = df_OHLCV_all_dates.columns.set_levels(['open', 'high', 'low', 'close', 'volume'], level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timestamp to string 'yyyy-mm-dd'\n",
    "first_date = df1.index[0].strftime('%Y-%m-%d')\n",
    "last_date = df1.index[-1].strftime('%Y-%m-%d')\n",
    "print(f'first_date: {first_date}, {type(first_date)}')\n",
    "print(f'last_date: {last_date}, {type(first_date)}')\n",
    "\n",
    "# yesterday as a string yyyy-mm-dd\n",
    "from datetime import date, timedelta\n",
    "yesterday = str(date.today() - timedelta(days = 1))\n",
    "print(f'yesterday: {yesterday}, {type(yesterday)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/34439/finding-what-methods-a-python-object-has\n",
    "# list methods in object\n",
    "obj_methods = [method_name for method_name in dir(obj)]\n",
    "# simpler\n",
    "dir(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Unix timestamp in sec. to yyyy-mm-dd,  'startDate': 1367107200\n",
    "from datetime import datetime\n",
    "UTC_timestamp_sec = 1367107200  # Unix time stamp (i.e. seconds since 1970-01-01)\n",
    "# convert Unix UTC_timestamp_sec in sec. to yyyy-mm-dd,  'startDate': 1367107200\n",
    "startDate = datetime.fromtimestamp(UTC_timestamp_sec).strftime(\"%Y-%m-%d\")\n",
    "startDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f string format , comma float\n",
    "key = \"marketCap\"\n",
    "value = 446764482560\n",
    "print(f'{key:20}{value/1e9:<,.3f}B')  # asset in billions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace character in list\n",
    "myList =  ['BRFS', 'BRK.A', 'BRK.B', 'BRKR']\n",
    "new_list = []\n",
    "for x in myList:\n",
    "    new_list.append(x.replace(\".\", \"-\"))\n",
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete dfw, df2 from RAM\n",
    "import gc\n",
    "del [[dfw,df2]]\n",
    "gc.collect()\n",
    "dfw=pd.DataFrame()\n",
    "df2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Customer Name'] == 'Canyon Coffee']  # return df with 'Customer Name' == 'Canyon Coffee' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10 -r 7\n",
    "(\n",
    "    symbols,\n",
    "    period_yr,\n",
    "    drawdown,\n",
    "    UI,\n",
    "    max_drawdown,\n",
    "    returns_std,\n",
    "    Std_UI,\n",
    "    CAGR,\n",
    "    CAGR_Std,\n",
    "    CAGR_UI,\n",
    ") = symb_perf_stats_vectorized_v1(df_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjOHLCV.columns.unique(level=0)  #multi index columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a3812d65f91e7e7447da6b5cfc60716e82f91e6a92533fb27b46796ad1962a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
