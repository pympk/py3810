{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_set_sym_freq_cnt(top_set_syms_n_freq):\n",
    "    # accommodate upto 5 periods of days_lookbacks(i.e. days_lookbacks = [5, 10, 15, 20, 25])\n",
    "    sym_freq_cnt_15 = []\n",
    "    sym_freq_cnt_14 = []\n",
    "    sym_freq_cnt_13 = []\n",
    "    sym_freq_cnt_12 = []\n",
    "    sym_freq_cnt_11 = []\n",
    "    sym_freq_cnt_10 = []\n",
    "    sym_freq_cnt_9 = []\n",
    "    sym_freq_cnt_8 = []\n",
    "    sym_freq_cnt_7 = []\n",
    "    sym_freq_cnt_6 = []\n",
    "    sym_freq_cnt_5 = []\n",
    "    sym_freq_cnt_4 = []\n",
    "    sym_freq_cnt_3 = []\n",
    "    sym_freq_cnt_2 = []\n",
    "\n",
    "    for sym_n_freq in top_set_syms_n_freq:\n",
    "        _sym = sym_n_freq[0]\n",
    "        _freq = sym_n_freq[1]\n",
    "        if _freq == 15:\n",
    "            sym_freq_cnt_15.append(_sym)\n",
    "        elif _freq == 14:\n",
    "            sym_freq_cnt_14.append(_sym)\n",
    "        elif _freq == 13:\n",
    "            sym_freq_cnt_13.append(_sym)\n",
    "        elif _freq == 12:\n",
    "            sym_freq_cnt_12.append(_sym)                        \n",
    "        elif _freq == 11:\n",
    "            sym_freq_cnt_11.append(_sym)\n",
    "        elif _freq == 10:\n",
    "            sym_freq_cnt_10.append(_sym)            \n",
    "        elif _freq == 9:\n",
    "            sym_freq_cnt_9.append(_sym)\n",
    "        elif _freq == 8:\n",
    "            sym_freq_cnt_8.append(_sym)\n",
    "        elif _freq == 7:\n",
    "            sym_freq_cnt_7.append(_sym)  \n",
    "        elif _freq == 6:\n",
    "            sym_freq_cnt_6.append(_sym)\n",
    "        elif _freq == 5:\n",
    "            sym_freq_cnt_5.append(_sym)\n",
    "        elif _freq == 4:\n",
    "            sym_freq_cnt_4.append(_sym)\n",
    "        elif _freq == 3:\n",
    "            sym_freq_cnt_3.append(_sym)          \n",
    "        else:\n",
    "            sym_freq_cnt_2.append(_sym)\n",
    "\n",
    "    l_sym_freq_cnt = []\n",
    "\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_15)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_14)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_13)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_12)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_11)   \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_10)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_9)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_8)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_7)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_6)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_5)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_4)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_3)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_2)    \n",
    "\n",
    "    return l_sym_freq_cnt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import datetime\n",
    "# from IPython.display import display, HTML\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 16)\n",
    "pd.set_option('display.width', 790)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "fp_df_close_clean = 'df_close_clean'\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "str_today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "# str_today = '2023-03-08'\n",
    "fp_df_eval_sym_freq_results_train    = f'df_eval_sym_freq_results_train_{str_today}'\n",
    "fp_df_eval_sym_freq_results_validate = f'df_eval_sym_freq_results_validate_{str_today}'\n",
    "fp_df_eval_sym_freq_results_test     = f'df_eval_sym_freq_results_test_{str_today}'\n",
    "fp_df_eval_sym_freq_results_current  = f'df_eval_sym_freq_results_current_{str_today}'\n",
    "\n",
    "# fp_df_eval_sym_freq_results_train    = f'df_eval_sym_freq_results_train'\n",
    "# fp_df_eval_sym_freq_results_validate = f'df_eval_sym_freq_results_validate'\n",
    "# fp_df_eval_sym_freq_results_test     = f'df_eval_sym_freq_results_test'\n",
    "# fp_df_eval_sym_freq_results_current  = f'df_eval_sym_freq_results_current'\n",
    "###########################################################################################################\n",
    "\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>days_lookbacks</th>\n",
       "      <th>days_eval</th>\n",
       "      <th>n_top_syms</th>\n",
       "      <th>syms_start</th>\n",
       "      <th>syms_end</th>\n",
       "      <th>sym_freq_cnt</th>\n",
       "      <th>grp(CAGR)_mean</th>\n",
       "      <th>grp(CAGR)_std</th>\n",
       "      <th>grp(CAGR)_mean/std</th>\n",
       "      <th>grp(CAGR/UI)_mean</th>\n",
       "      <th>grp(CAGR/UI)_std</th>\n",
       "      <th>grp(CAGR/UI)_mean/std</th>\n",
       "      <th>grp(CAGR/retnStd)_mean</th>\n",
       "      <th>grp(CAGR/retnStd)_std</th>\n",
       "      <th>grp(CAGR/retnStd)_mean/std</th>\n",
       "      <th>grp(retnStd/UI)_mean</th>\n",
       "      <th>grp(retnStd/UI)_std</th>\n",
       "      <th>grp(retnStd/UI)_mean/std</th>\n",
       "      <th>SPY_CAGR</th>\n",
       "      <th>SPY_CAGR/UI</th>\n",
       "      <th>SPY_CAGR/retnStd</th>\n",
       "      <th>SPY_retnStd/UI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>[15]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>58.904695</td>\n",
       "      <td>105.867654</td>\n",
       "      <td>0.556399</td>\n",
       "      <td>4.594863e+05</td>\n",
       "      <td>1.542343e+06</td>\n",
       "      <td>0.297914</td>\n",
       "      <td>2296.148598</td>\n",
       "      <td>3711.167713</td>\n",
       "      <td>0.618713</td>\n",
       "      <td>522.299559</td>\n",
       "      <td>1798.472148</td>\n",
       "      <td>0.290413</td>\n",
       "      <td>2.946712</td>\n",
       "      <td>872.899734</td>\n",
       "      <td>258.839676</td>\n",
       "      <td>3.372357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>[15]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>111.952107</td>\n",
       "      <td>223.091719</td>\n",
       "      <td>0.501821</td>\n",
       "      <td>1.743056e+04</td>\n",
       "      <td>3.447494e+04</td>\n",
       "      <td>0.505601</td>\n",
       "      <td>2246.195961</td>\n",
       "      <td>4397.155946</td>\n",
       "      <td>0.510829</td>\n",
       "      <td>2.829239</td>\n",
       "      <td>2.629919</td>\n",
       "      <td>1.075789</td>\n",
       "      <td>-0.896209</td>\n",
       "      <td>-51.243347</td>\n",
       "      <td>-95.976489</td>\n",
       "      <td>0.533916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>[15]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1362.972667</td>\n",
       "      <td>3638.537745</td>\n",
       "      <td>0.374594</td>\n",
       "      <td>2.720923e+09</td>\n",
       "      <td>7.278938e+09</td>\n",
       "      <td>0.373808</td>\n",
       "      <td>46206.330270</td>\n",
       "      <td>116886.850913</td>\n",
       "      <td>0.395308</td>\n",
       "      <td>14560.855002</td>\n",
       "      <td>22195.762210</td>\n",
       "      <td>0.656020</td>\n",
       "      <td>14.727019</td>\n",
       "      <td>16245.808902</td>\n",
       "      <td>1332.432058</td>\n",
       "      <td>12.192598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>[15]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3.359500</td>\n",
       "      <td>6.476554</td>\n",
       "      <td>0.518717</td>\n",
       "      <td>2.371375e+02</td>\n",
       "      <td>4.000907e+02</td>\n",
       "      <td>0.592709</td>\n",
       "      <td>74.985976</td>\n",
       "      <td>263.740232</td>\n",
       "      <td>0.284318</td>\n",
       "      <td>1.287712</td>\n",
       "      <td>0.652150</td>\n",
       "      <td>1.974564</td>\n",
       "      <td>0.185377</td>\n",
       "      <td>30.143844</td>\n",
       "      <td>23.308673</td>\n",
       "      <td>1.293246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>[15]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.174417</td>\n",
       "      <td>4.510762</td>\n",
       "      <td>0.260359</td>\n",
       "      <td>5.573937e+01</td>\n",
       "      <td>1.641189e+02</td>\n",
       "      <td>0.339628</td>\n",
       "      <td>-23.607678</td>\n",
       "      <td>149.685775</td>\n",
       "      <td>-0.157715</td>\n",
       "      <td>1.035327</td>\n",
       "      <td>0.643888</td>\n",
       "      <td>1.607929</td>\n",
       "      <td>-0.767101</td>\n",
       "      <td>-33.826681</td>\n",
       "      <td>-38.189231</td>\n",
       "      <td>0.885765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10772</th>\n",
       "      <td>114</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.689529</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>3.258717e+01</td>\n",
       "      <td>4.631497e+01</td>\n",
       "      <td>0.703599</td>\n",
       "      <td>18.465116</td>\n",
       "      <td>35.310611</td>\n",
       "      <td>0.522934</td>\n",
       "      <td>1.141084</td>\n",
       "      <td>0.326160</td>\n",
       "      <td>3.498539</td>\n",
       "      <td>-0.632376</td>\n",
       "      <td>-54.976022</td>\n",
       "      <td>-64.251098</td>\n",
       "      <td>0.855643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10773</th>\n",
       "      <td>114</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.438863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-2.602296e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-23.105688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>1.126258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.632376</td>\n",
       "      <td>-54.976022</td>\n",
       "      <td>-64.251098</td>\n",
       "      <td>0.855643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10774</th>\n",
       "      <td>114</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.965938</td>\n",
       "      <td>1.001052</td>\n",
       "      <td>0.964923</td>\n",
       "      <td>5.186914e+01</td>\n",
       "      <td>5.702023e+01</td>\n",
       "      <td>0.909662</td>\n",
       "      <td>31.632336</td>\n",
       "      <td>31.622410</td>\n",
       "      <td>1.000314</td>\n",
       "      <td>1.441876</td>\n",
       "      <td>0.259731</td>\n",
       "      <td>5.551419</td>\n",
       "      <td>-0.632376</td>\n",
       "      <td>-54.976022</td>\n",
       "      <td>-64.251098</td>\n",
       "      <td>0.855643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10775</th>\n",
       "      <td>114</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.625915</td>\n",
       "      <td>0.786217</td>\n",
       "      <td>-0.796110</td>\n",
       "      <td>3.304429e+01</td>\n",
       "      <td>1.097540e+02</td>\n",
       "      <td>0.301076</td>\n",
       "      <td>-7.611364</td>\n",
       "      <td>65.859023</td>\n",
       "      <td>-0.115571</td>\n",
       "      <td>0.741456</td>\n",
       "      <td>0.624454</td>\n",
       "      <td>1.187367</td>\n",
       "      <td>-0.632376</td>\n",
       "      <td>-54.976022</td>\n",
       "      <td>-64.251098</td>\n",
       "      <td>0.855643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10776</th>\n",
       "      <td>114</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.937072</td>\n",
       "      <td>0.048305</td>\n",
       "      <td>-19.399047</td>\n",
       "      <td>-2.634374e+01</td>\n",
       "      <td>9.634057e+00</td>\n",
       "      <td>-2.734439</td>\n",
       "      <td>-57.542959</td>\n",
       "      <td>27.918376</td>\n",
       "      <td>-2.061114</td>\n",
       "      <td>0.495297</td>\n",
       "      <td>0.156094</td>\n",
       "      <td>3.173074</td>\n",
       "      <td>-0.632376</td>\n",
       "      <td>-54.976022</td>\n",
       "      <td>-64.251098</td>\n",
       "      <td>0.855643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10777 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_samples   days_lookbacks  days_eval  n_top_syms  syms_start  syms_end  sym_freq_cnt  grp(CAGR)_mean  grp(CAGR)_std  grp(CAGR)_mean/std  grp(CAGR/UI)_mean  grp(CAGR/UI)_std  grp(CAGR/UI)_mean/std  grp(CAGR/retnStd)_mean  grp(CAGR/retnStd)_std  grp(CAGR/retnStd)_mean/std  grp(retnStd/UI)_mean  grp(retnStd/UI)_std  grp(retnStd/UI)_mean/std   SPY_CAGR   SPY_CAGR/UI  SPY_CAGR/retnStd  SPY_retnStd/UI\n",
       "0            114             [15]          4          20           0        10             3       58.904695     105.867654         0.556399        4.594863e+05       1.542343e+06          0.297914            2296.148598             3711.167713               0.618713                  522.299559           1798.472148             0.290413            2.946712    872.899734       258.839676         3.372357\n",
       "1            114             [15]          4          20           0        10             3      111.952107     223.091719         0.501821        1.743056e+04       3.447494e+04          0.505601            2246.195961             4397.155946               0.510829                    2.829239              2.629919             1.075789           -0.896209    -51.243347       -95.976489         0.533916\n",
       "2            114             [15]          4          20           0        10             3     1362.972667    3638.537745         0.374594        2.720923e+09       7.278938e+09          0.373808           46206.330270           116886.850913               0.395308                14560.855002          22195.762210             0.656020           14.727019  16245.808902      1332.432058        12.192598\n",
       "3            114             [15]          4          20           0        10             3        3.359500       6.476554         0.518717        2.371375e+02       4.000907e+02          0.592709              74.985976              263.740232               0.284318                    1.287712              0.652150             1.974564            0.185377     30.143844        23.308673         1.293246\n",
       "4            114             [15]          4          20           0        10             3        1.174417       4.510762         0.260359        5.573937e+01       1.641189e+02          0.339628             -23.607678              149.685775              -0.157715                    1.035327              0.643888             1.607929           -0.767101    -33.826681       -38.189231         0.885765\n",
       "...          ...              ...        ...         ...         ...       ...           ...             ...            ...              ...                 ...                ...               ...                    ...                     ...                    ...                         ...                   ...                  ...                 ...           ...              ...              ...\n",
       "10772        114  [15, 30, 60,...          6          20           0        10             8        0.003171       0.689529         0.004599        3.258717e+01       4.631497e+01          0.703599              18.465116               35.310611               0.522934                    1.141084              0.326160             3.498539           -0.632376    -54.976022       -64.251098         0.855643\n",
       "10773        114  [15, 30, 60,...          6          20           0        10             7       -0.438863       0.000000             -inf       -2.602296e+01       0.000000e+00              -inf             -23.105688                0.000000                   -inf                    1.126258              0.000000                  inf           -0.632376    -54.976022       -64.251098         0.855643\n",
       "10774        114  [15, 30, 60,...          6          20           0        10             6        0.965938       1.001052         0.964923        5.186914e+01       5.702023e+01          0.909662              31.632336               31.622410               1.000314                    1.441876              0.259731             5.551419           -0.632376    -54.976022       -64.251098         0.855643\n",
       "10775        114  [15, 30, 60,...          6          20           0        10             5       -0.625915       0.786217        -0.796110        3.304429e+01       1.097540e+02          0.301076              -7.611364               65.859023              -0.115571                    0.741456              0.624454             1.187367           -0.632376    -54.976022       -64.251098         0.855643\n",
       "10776        114  [15, 30, 60,...          6          20           0        10             4       -0.937072       0.048305       -19.399047       -2.634374e+01       9.634057e+00         -2.734439             -57.542959               27.918376              -2.061114                    0.495297              0.156094             3.173074           -0.632376    -54.976022       -64.251098         0.855643\n",
       "\n",
       "[10777 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_train)\n",
    "# df\n",
    "# df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_validate)\n",
    "# df\n",
    "# df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_test)\n",
    "# df\n",
    "# df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_current)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_add0 = ['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'syms_start', 'syms_end', 'sym_freq_cnt']\n",
    "col_add1 = ['grp(CAGR)_mean',         'grp(CAGR)_std',         'grp(CAGR)_mean/std']\n",
    "col_add2 = ['grp(CAGR/UI)_mean',      'grp(CAGR/UI)_std',      'grp(CAGR/UI)_mean/std']\n",
    "col_add3 = ['grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std']\n",
    "col_add4 = ['grp(retnStd/UI)_mean',   'grp(retnStd/UI)_std',   'grp(retnStd/UI)_mean/std']\n",
    "col_add5 = ['SPY_CAGR', 'SPY_CAGR/UI', 'SPY_CAGR/retnStd', 'SPY_retnStd/UI']\n",
    "\n",
    "col_add_total = col_add0 + col_add1 + col_add2 + col_add3 + col_add4 + col_add5\n",
    "print(f'col_add_total:\\n{col_add_total}, total columns: {len(col_add_total)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DANGER: Create a new Dataframe to store run results. Previous data will be destroyed. To create a new dataframe, uncomment one choice from below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_eval_sym_freq_results_train)\n",
    "# df\n",
    "\n",
    "# # # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_eval_sym_freq_results_validate)\n",
    "# df\n",
    "\n",
    "# # # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_eval_sym_freq_results_test)\n",
    "# df\n",
    "\n",
    "# # # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_eval_sym_freq_results_current)\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select run parameters. Parameters can also be passed using papermill by running yf_7_freq_cnt_pm_.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# SELECT RUN PARAMETERS.async Parameters can also be passed using papermill by running yf_7_freq_cnt_pm_.ipynb\n",
    "verbose = True  # True prints more output\n",
    "# verbose = False  # True prints more output\n",
    "\n",
    "# write run results to df_eval_results\n",
    "# store_results = False\n",
    "store_results = True\n",
    "\n",
    "# select run type\n",
    "run_type = 'train'\n",
    "# run_type = 'validate'\n",
    "# run_type = 'test'\n",
    "# run_type = 'current'\n",
    "\n",
    "# number of max lookback tuples to create for iloc iloc_start_train:iloc_end_train:iloc_end_eval\n",
    "# i.e. number of grp_top_set_syms_n_freq and grp_top_set_syms \n",
    "# n_samples = 400  \n",
    "n_samples = 2\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback iloc_end_train\n",
    "# days_lookbacks = [7, 15, 30, 60, 120]\n",
    "# days_lookbacks = [30, 60, 120]\n",
    "days_lookbacks = [2]\n",
    "days_lookbacks.sort()\n",
    "\n",
    "# number of days from iloc_end_train are used to evaluate effectiveness of the training\n",
    "days_eval = 4\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "\n",
    "syms_start = 0  #  start index of n_top_syms for evaluation\n",
    "syms_end = 10  #  end index of n_top_syms for evaluation\n",
    "\n",
    "# over-ride parameters for run_type 'current'\n",
    "if run_type == 'current':\n",
    "  days_eval = 0  # no need to eval, df_eval will be empty\n",
    "  n_samples = 1  # no need to repeat sample the current result, repeat sample will yield the same tuple\n",
    "\n",
    "print(f'verbose : {verbose }')\n",
    "print(f'store_results: {store_results}')\n",
    "print(f'run_type: {run_type}')\n",
    "print(f'n_samples: {n_samples}')\n",
    "print(f'days_lookbacks: {days_lookbacks}')\n",
    "print(f'days_eval: {days_eval}')\n",
    "print(f'n_top_syms: {n_top_syms}')\n",
    "print(f'syms_start: {syms_start}')\n",
    "print(f'syms_end: {syms_end}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataframe into Train, Validate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df_close_clean into training (df_train), validation (df_val) and test (df_test) set.\n",
    "# The default split is 0.7, 0.2, 0.1 respectively.\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_close_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create df_current, a df with the latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_days_lookbacks = max(days_lookbacks)\n",
    "print(f'max_days_lookbacks: {max_days_lookbacks}')\n",
    "df_current = df_test.tail(max_days_lookbacks)  \n",
    "df_current.tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load previous data according to run_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_type == 'train':\n",
    "  df_eval_sym_freq_results_train = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_train)\n",
    "  df = df_train.copy()    \n",
    "elif run_type == 'validate':\n",
    "  df_eval_sym_freq_results_validate = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_validate)\n",
    "  df = df_val.copy()\n",
    "elif run_type == 'test':\n",
    "  df_eval_sym_freq_results_test = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_test)\n",
    "  df = df_test.copy()\n",
    "elif run_type == 'current':  # get the current results\n",
    "  df = df_current.copy()\n",
    "else:\n",
    "  msg_stop = f\"ERROR run_type must be 'train', 'validate', 'test' or 'current', run_type is: {run_type}\"\n",
    "  raise SystemExit(msg_stop )  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print dataframe for the run, and lengths of other dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'run_type: {run_type}, df.tail(3):\\n{df.tail(3)}\\n')\n",
    "len_df = len(df)\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)\n",
    "len_df_current = len(df_current)\n",
    "print(f'run_type: {run_type}, len(df): {len(df)}')\n",
    "print(f'len_df_train: {len_df_train}, len_df_val: {len_df_val}, len_df_test: {len_df_test}, len_df_current: {len_df_current} ')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a sets of iloc lookback slices (iloc_start_train:iloc_end_train:iloc_end_eval), where:  \n",
    "* iloc_end_train - iloc_start_train = days_lookback\n",
    "* iloc_end_eval - iloc_end_train = days_eval  \n",
    "#### for example, if given:  \n",
    "* n_samples = 2  \n",
    "* days_lookbacks = [10, 20, 30]  \n",
    "* days_eval = 5  \n",
    "#### a possible result is:  \n",
    "  - max_lookback_slices: [(417, 447, 452), (265, 295, 300)], where:\n",
    "    - len(max_lookback_slices) = n_samples = 2\n",
    "    - middle number in the tuples, 447 and 295, is the iloc of the \"pivot day\" for the days in \"days_lookbacks\" to lookback\n",
    "    - 447 - 417 = middle number - first number = max(days_lookbacks) = 30\n",
    "    - 295 - 265 = middle number - first number = max(days_lookbacks) = 30      \n",
    "    - 452 - 447 = last number - middle number = days_eval = 5\n",
    "    - 300 - 295 = last number - middle number = days_eval = 5    \n",
    "  - sets_lookback_slices: [[(437, 447, 452), (427, 447, 452), (417, 447, 452)], [(285, 295, 300), (275, 295, 300), (265, 295, 300)]], where:\n",
    "    - len(sets_lookback_slices) = n_samples = 2\n",
    "    - last tuple in each list, i.e. (417, 447, 452) and (265, 295, 300), is a tuple from max_lookback_slices\n",
    "    - where a set, e.g. [(437, 447, 452), (427, 447, 452), (417, 447, 452)]:\n",
    "      - middle number, 447, iloc of the \"pivot day\" is constant for that set\n",
    "      - middle number - first number, is the training period specified in days_lookbacks\n",
    "        - 447 - 437 = middle number - first number = days_lookbacks[0] = 10\n",
    "        - 447 - 427 = middle number - first number = days_lookbacks[1] = 20\n",
    "        - 447 - 417 = middle number - first number = days_lookbacks[2] = 30\n",
    "      - last number, 452, iloc of the end of the evaluation period is constant\n",
    "        - 452 - 447 = last number - middle number = days_eval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return n_samples slices\n",
    "max_lookback_slices = _3_random_slices(len_df, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval, verbose=False)\n",
    "# return n_samples * len(days_lookbacks) slices\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'number of max_lookback_slices is equal to n_samples = {n_samples}')\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}\\n')\n",
    "  print(f'number of sets in sets_lookback_slices is equal to n_samples = {n_samples}')\n",
    "  print(f'days_lookbacks: {days_lookbacks}')  \n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}\\n')\n",
    "  print(f'number of tuples in each \"set of lookback slices\" is equal to len(days_lookbacks): len({days_lookbacks})')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate grp_top_set_syms_n_freq. It is a list of sub-lists, e.g.:\n",
    " - [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)], ..., [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "#### grp_top_set_syms_n_freq has n_samples sub-lists. Each sub-list corresponds to a tuple in the max_lookback_slices. Each sub-list has n_top_syms tuples of (symbol, frequency) pairs, and is sorted in descending order of frequency. The frequency is the number of times the symbol appears in the top n_top_syms performance rankings of CAGR/UI, CAGR/retnStd and retnStd/UI.\n",
    "#### Therefore, symbols in the sub-list are the best performing symbols for the periods in days_lookbacks. Each sub-list corresponds to a tuple in max_lookback_slices. There are as many sub-lists as there are tuples in max_lookback_slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp_top_set_syms_n_freq is a list of lists of top_set_syms_n_freq, e.g.\n",
    "#   [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)],\n",
    "#    [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "#   where each list is the best performing symbols from a lb_slices, e.g.\n",
    "#     [(483, 513, 523), (453, 513, 523), (393, 513, 523)]  \n",
    "grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "grp_top_set_syms = []  # grp_top_set_syms_n_freq without the frequency count\n",
    "\n",
    "# lb_slices, e.g  [(483, 513, 523), (453, 513, 523), (393, 513, 523)],\n",
    "#  is one max_lookback_slice, e.g. (393, 513, 523), along with\n",
    "#  the remaining slices of the days_lookbacks, e.g. (483, 513, 523), (453, 513, 523)  \n",
    "for i, lb_slices in enumerate(sets_lookback_slices):\n",
    "  print(f'\\n########## {i + 1} of {len(sets_lookback_slices)} lb_slices in sets_lookcak_slices ##########')\n",
    "  # unsorted list of the most frequent symbols in performance metrics of the lb_slices  \n",
    "  grp_most_freq_syms = []\n",
    "  for j, lb_slice in enumerate(lb_slices):  # lb_slice, e.g. (246, 276, 286)\n",
    "    iloc_start_train = lb_slice[0]     # iloc of start of training period\n",
    "    iloc_end_train   = lb_slice[1]     # iloc of end of training period\n",
    "    iloc_start_eval  = iloc_end_train  # iloc of start of evaluation period\n",
    "    iloc_end_eval    = lb_slice[2]     # iloc of end of evaluation period\n",
    "    lookback         = iloc_end_train - iloc_start_train\n",
    "    d_eval           = iloc_end_eval - iloc_start_eval\n",
    "\n",
    "    _df = df.iloc[iloc_start_train:iloc_end_train]\n",
    "    date_start_df_train = _df.index[0].strftime('%Y-%m-%d')\n",
    "    date_end_df_train = _df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    if verbose:\n",
    "      print(f'days lookback:       {lookback},  {j + 1} of {len(days_lookbacks)} days_lookbacks: {days_lookbacks}')\n",
    "      print(f'lb_slices:           {lb_slices}')\n",
    "      print(f'lb_slice:            {lb_slice}')\n",
    "      print(f'days eval:           {d_eval}')    \n",
    "      print(f'iloc_start_train:    {iloc_start_train}')\n",
    "      print(f'iloc_end_train:      {iloc_end_train}')\n",
    "      print(f'date_start_df_train: {date_start_df_train}')\n",
    "      print(f'date_end_df_train:   {date_end_df_train}')\n",
    "\n",
    "\n",
    "    perf_ranks, most_freq_syms = _5_perf_ranks(_df, n_top_syms=n_top_syms)\n",
    "    # unsorted list of the most frequent symbols in performance metrics of the lb_slices  \n",
    "    grp_most_freq_syms.append(most_freq_syms)  \n",
    "    if verbose:    \n",
    "      # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "      print(f'perf_ranks: {perf_ranks}')  \n",
    "      # most common symbols of perf_ranks \n",
    "      print(f'most_freq_syms: {most_freq_syms}')     \n",
    "      # grp_perf_ranks[lookback] = perf_ranks\n",
    "      print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "  if verbose:\n",
    "    print(f'grp_most_freq_syms: {grp_most_freq_syms}')\n",
    "    # grp_most_freq_syms a is list of lists of tuples of \n",
    "    #  the most-common-symbols symbol:frequency cumulated from\n",
    "    #  each days_lookback  \n",
    "    print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "  # flatten list of lists of (symbol:frequency)\n",
    "  flat_grp_most_freq_syms = [val for sublist in grp_most_freq_syms for val in sublist]\n",
    "  # return \"symbol, frequency\" pairs of the most frequent symbols, i.e. best performing symbols,\n",
    "  #  in flat_grp_most_freq_syms. The paris are sorted in descending frequency.   \n",
    "  set_most_freq_syms = _6_grp_tuples_sort_sum(flat_grp_most_freq_syms, reverse=True)\n",
    "  # get the top n_top_syms of the most frequent \"symbol, frequency\" pairs\n",
    "  top_set_syms_n_freq = set_most_freq_syms[0:n_top_syms]\n",
    "  # get symbols from top_set_syms_n_freq, i[0] = symbol, i[1]=symbol's frequency count\n",
    "  top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]  \n",
    "\n",
    "  # grp_top_set_syms_n_freq is a list of lists of top_set_syms_n_freq, e.g.\n",
    "  #   [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)],\n",
    "  #    [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "  #   where each list is the best performing symbols from a lb_slices, e.g.\n",
    "  #     [(483, 513, 523), (453, 513, 523), (393, 513, 523)]    \n",
    "  grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "  grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "  if verbose:  \n",
    "    print(f'top {n_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "    print(f'top {n_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "    print(f'===== finish top {n_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output the best performing symbols for each set in sets_lookback_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, top_set_syms_n_freq in enumerate(grp_top_set_syms_n_freq):\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(top_set_syms_n_freq)\n",
    "  if verbose:\n",
    "    print(f'set_lookback_slices: {sets_lookback_slices[i]}')\n",
    "    print(f'days_lookbacks:      {days_lookbacks}')\n",
    "    print(f'sym_freq_15:         {l_sym_freq_cnt[0]}')\n",
    "    print(f'sym_freq_14:         {l_sym_freq_cnt[1]}')\n",
    "    print(f'sym_freq_13:         {l_sym_freq_cnt[2]}')\n",
    "    print(f'sym_freq_12:         {l_sym_freq_cnt[3]}')\n",
    "    print(f'sym_freq_11:         {l_sym_freq_cnt[4]}')\n",
    "    print(f'sym_freq_10:         {l_sym_freq_cnt[5]}')\n",
    "    print(f'sym_freq_9:          {l_sym_freq_cnt[6]}')\n",
    "    print(f'sym_freq_8:          {l_sym_freq_cnt[7]}')\n",
    "    print(f'sym_freq_7:          {l_sym_freq_cnt[8]}')\n",
    "    print(f'sym_freq_6:          {l_sym_freq_cnt[9]}')\n",
    "    print(f'sym_freq_5:          {l_sym_freq_cnt[10]}')\n",
    "    print(f'sym_freq_4:          {l_sym_freq_cnt[11]}')\n",
    "    print(f'sym_freq_3:          {l_sym_freq_cnt[12]}')\n",
    "    print(f'sym_freq_2:          {l_sym_freq_cnt[13]}\\n')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare performance of symbols in set_lookback_slices versus SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myUtils import symb_perf_stats_vectorized_v8\n",
    "\n",
    "print('z_grp_top_set_syms_n_freq:')\n",
    "# zip max_lookback_slices with top performing symbols:freq pairs\n",
    "z_grp_top_set_syms_n_freq = zip(max_lookback_slices, grp_top_set_syms_n_freq)\n",
    "\n",
    "idx_train = pd.Index([])\n",
    "idx_eval = pd.Index([])\n",
    "for i, (_lookback_slice, _top_set_syms_n_freq) in enumerate(z_grp_top_set_syms_n_freq):\n",
    "  iloc_start_train = _lookback_slice[0]\n",
    "  iloc_end_train = _lookback_slice[1]\n",
    "  iloc_start_eval = iloc_end_train\n",
    "  iloc_end_eval = _lookback_slice[2]\n",
    "\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice: {_lookback_slice}\\n')\n",
    "  # print(f'max_lookback_slice: {_lookback_slice}\\n')\n",
    "  # dates correspond to max_lookback_slice\n",
    "  idx_train = df.index[iloc_start_train:iloc_end_train]\n",
    "  date_start_df_train = idx_train[0].strftime('%Y-%m-%d')\n",
    "  date_end_df_train = idx_train[-1].strftime('%Y-%m-%d')\n",
    "  print(f'len(idx_train): {len(idx_train)}')\n",
    "  print(f'idx_train: {idx_train}')\n",
    "  print(f'df_train_dates (inclusive): {date_start_df_train} - {date_end_df_train}\\n')     \n",
    "\n",
    "  if run_type != 'current':\n",
    "    idx_eval = df.index[iloc_start_eval:iloc_end_eval]\n",
    "    date_start_df_eval = idx_eval[0].strftime('%Y-%m-%d')\n",
    "    date_end_df_eval = idx_eval[-1].strftime('%Y-%m-%d')\n",
    "    print(f'len(idx_eval): {len(idx_eval)}')\n",
    "    print(f'idx_eval: {idx_eval}')\n",
    "    print(f'df_eval dates (inclusive): {date_start_df_eval} - {date_end_df_eval}\\n')\n",
    "  else: # run_type == \"current'\n",
    "    print(f'run_type: {run_type}, idx_eval is empty: {idx_eval.empty}')\n",
    "\n",
    "  print(f'top_set_syms_n_freq: {_top_set_syms_n_freq}\\n')   \n",
    "\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(_top_set_syms_n_freq)\n",
    "  if verbose:\n",
    "    print(f'max_lookback_slice:  {_lookback_slice}')\n",
    "    print(f'set_lookback_slices: {sets_lookback_slices[i]}')    \n",
    "    print(f'days_lookbacks:      {days_lookbacks}')\n",
    "    print(f'sym_freq_15:         {l_sym_freq_cnt[0]}')\n",
    "    print(f'sym_freq_14:         {l_sym_freq_cnt[1]}')\n",
    "    print(f'sym_freq_13:         {l_sym_freq_cnt[2]}')\n",
    "    print(f'sym_freq_12:         {l_sym_freq_cnt[4]}')\n",
    "    print(f'sym_freq_10:         {l_sym_freq_cnt[5]}')\n",
    "    print(f'sym_freq_9:          {l_sym_freq_cnt[6]}')\n",
    "    print(f'sym_freq_8:          {l_sym_freq_cnt[7]}')\n",
    "    print(f'sym_freq_7:          {l_sym_freq_cnt[8]}')\n",
    "    print(f'sym_freq_6:          {l_sym_freq_cnt[9]}')\n",
    "    print(f'sym_freq_5:          {l_sym_freq_cnt[10]}')\n",
    "    print(f'sym_freq_4:          {l_sym_freq_cnt[11]}')\n",
    "    print(f'sym_freq_3:          {l_sym_freq_cnt[12]}')\n",
    "    print(f'sym_freq_2:          {l_sym_freq_cnt[13]}\\n') \n",
    "\n",
    "  if idx_eval.empty:\n",
    "    if run_type == 'current':\n",
    "      msg_stop = f'\\n\\n**** STOPPED df_eval is empty and run_type is \"{run_type}\" ****'\n",
    "      raise SystemExit(msg_stop)\n",
    "    else:\n",
    "      msg_stop = f'\\n\\n**** STOPPED df_eval is empty but run_type != \"current\", the run_type is \"{run_type}\" ****'\n",
    "      raise SystemExit(msg_stop)    \n",
    "\n",
    "  _sym_idx = ['SPY']\n",
    "  df_SPY = df[iloc_start_eval:iloc_end_eval][_sym_idx]\n",
    "\n",
    "  (\n",
    "    _symbols,\n",
    "    _period_yr,\n",
    "    _retn,\n",
    "    _DD,\n",
    "    _UI,\n",
    "    _MDD,\n",
    "    _retnMean,\n",
    "    _retnStd,\n",
    "    _retnStd_div_UI,\n",
    "    _CAGR,\n",
    "    _CAGR_div_retnStd,\n",
    "    _CAGR_div_UI,\n",
    "    SPY_retnStd_d_UI,     \n",
    "    SPY_CAGR,\n",
    "    SPY_CAGR_d_retnStd,\n",
    "    SPY_CAGR_d_UI,\n",
    "  ) = symb_perf_stats_vectorized_v8(df_SPY)  \n",
    "\n",
    "  print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI, CAGR: {SPY_retnStd_d_UI[0]:>17,.1f}, {SPY_CAGR_d_retnStd[0]:>17,.1f}, {SPY_CAGR_d_UI[0]:>17.1f}, {SPY_CAGR[0]:>17.1f}')\n",
    "\n",
    "  # drop list with frequency count 2 or less, in l_sym_freq_cnt from zip\n",
    "  zip_cnt_n_syms = zip([15,14,13,12,11,10,9,8,7,6,5,4,3], l_sym_freq_cnt[:-1])\n",
    "  for item in zip_cnt_n_syms:\n",
    "    sym_freq_cnt = item[0]\n",
    "    syms = item[1]\n",
    "    if syms:  # iterate ONLY if there are symbols in syms\n",
    "      df_eval = df[iloc_start_eval:iloc_end_eval][syms]      \n",
    "\n",
    "      if verbose:\n",
    "        print(f'iloc_start_eval: {iloc_start_eval:>6},  df_eval first date: {date_start_df_eval:>10}') \n",
    "        print(f'iloc_end_eval:   {iloc_end_eval:>6},  df_eval last date:  {date_end_df_eval:>10}')        \n",
    "        print(f'frequency count of symbol(s): {sym_freq_cnt}')      \n",
    "\n",
    "        syms_n_SPY = syms + ['SPY']\n",
    "        df_eval_n_SPY = df[iloc_start_eval:iloc_end_eval][syms_n_SPY]   \n",
    "        print(f'\\ndf_eval_n_SPY:\\n{df_eval_n_SPY}\\n')\n",
    "\n",
    "      (\n",
    "        _symbols,\n",
    "        _period_yr,\n",
    "        _retn,\n",
    "        _DD,\n",
    "        _UI,\n",
    "        _MDD,\n",
    "        _retnMean,\n",
    "        _retnStd,\n",
    "        _retnStd_div_UI,\n",
    "        _CAGR,\n",
    "        _CAGR_div_retnStd,\n",
    "        _CAGR_div_UI,\n",
    "        grp_retnStd_d_UI,     \n",
    "        grp_CAGR,\n",
    "        grp_CAGR_d_retnStd,\n",
    "        grp_CAGR_d_UI,\n",
    "      ) = symb_perf_stats_vectorized_v8(df_eval)  \n",
    "      print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]  :>17,.1f}, {grp_retnStd_d_UI[1]  :>17,.1f}, {grp_retnStd_d_UI[2]  :>17,.1f}')\n",
    "      print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>17,.1f}, {grp_CAGR_d_retnStd[1]:>17,.1f}, {grp_CAGR_d_retnStd[2]:>17,.1f}')\n",
    "      print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]     :>17,.1f}, {grp_CAGR_d_UI[1]     :>17,.1f}, {grp_CAGR_d_UI[2]     :>17,.1f}')\n",
    "      print(f'grp(CAGR):         mean, std, mean/std: {grp_CAGR[0]          :>17,.1f}, {grp_CAGR[1]          :>17,.1f}, {grp_CAGR[2]          :>17,.1f}\\n')\n",
    "\n",
    "      if store_results:  # record results to df\n",
    "        row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, sym_freq_cnt]\n",
    "        row_add1      = [grp_CAGR[0],           grp_CAGR[1],           grp_CAGR[2]]\n",
    "        row_add2      = [grp_CAGR_d_UI[0],      grp_CAGR_d_UI[1],      grp_CAGR_d_UI[2]]\n",
    "        row_add3      = [grp_CAGR_d_retnStd[0], grp_CAGR_d_retnStd[1], grp_CAGR_d_retnStd[2]]\n",
    "        row_add4      = [grp_retnStd_d_UI[0],   grp_retnStd_d_UI[1],   grp_retnStd_d_UI[2]]\n",
    "        row_add5      = [SPY_CAGR[0], SPY_CAGR_d_UI[0], SPY_CAGR_d_retnStd[0], SPY_retnStd_d_UI[0]]\n",
    "        row_add_total = row_add0 + row_add1 + row_add2 + row_add3 + row_add4 + row_add5\n",
    "        print(f'row_add_total: {row_add_total}')\n",
    "\n",
    "        if run_type == 'train':\n",
    "          df_eval_sym_freq_results_train.loc[len(df_eval_sym_freq_results_train)] = row_add_total\n",
    "          print(f'appended row_add to df_eval_sym_freq_results_train:\\n{row_add_total}\\n')\n",
    "        elif run_type == 'validate':\n",
    "          df_eval_sym_freq_results_validate.loc[len(df_eval_sym_freq_results_validate)] = row_add_total       \n",
    "          print(f'appended row_add to df_eval_sym_freq_results_validate:\\n{row_add_total}\\n')\n",
    "        elif run_type == 'test':\n",
    "          df_eval_sym_freq_results_test.loc[len(df_eval_sym_freq_results_test)] = row_add_total       \n",
    "          print(f'appended row_add to df_eval_sym_freq_results_test:\\n{row_add_total}\\n')\n",
    "        else:\n",
    "          msg_stop = f\"ERROR run_type must be 'train', 'validate', or 'test', run_type is: {run_type}\"\n",
    "          raise SystemExit(msg_stop )                             \n",
    "  \n",
    "  print('='*50, '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if store_results:  # record results to df\n",
    "  if run_type == 'train':\n",
    "    pickle_dump(df_eval_sym_freq_results_train, path_data_dump, fp_df_eval_sym_freq_results_train)\n",
    "    print(f'Save results to: {fp_df_eval_sym_freq_results_train}')\n",
    "  elif run_type == 'validate':\n",
    "    pickle_dump(df_eval_sym_freq_results_validate, path_data_dump, fp_df_eval_sym_freq_results_validate)   \n",
    "    print(f'Save results to: {fp_df_eval_sym_freq_results_validate}')\n",
    "  elif run_type == 'test':\n",
    "    pickle_dump(df_eval_sym_freq_results_test, path_data_dump, fp_df_eval_sym_freq_results_test)   \n",
    "    print(f'Save results to: {fp_df_eval_sym_freq_results_test}')\n",
    "  else:\n",
    "    msg_stop = f\"ERROR: Result was not saved. run_type must be 'train', 'validate', or 'test', run_type is: {run_type}\"\n",
    "    raise SystemExit(msg_stop )  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
