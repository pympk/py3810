{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_set_sym_freq_cnt(top_set_syms_n_freq):\n",
    "    # accommodate upto 5 periods of days_lookbacks(i.e. days_lookbacks = [5, 10, 15, 20, 25])\n",
    "    sym_freq_cnt_15 = []\n",
    "    sym_freq_cnt_14 = []\n",
    "    sym_freq_cnt_13 = []\n",
    "    sym_freq_cnt_12 = []\n",
    "    sym_freq_cnt_11 = []\n",
    "    sym_freq_cnt_10 = []\n",
    "    sym_freq_cnt_9 = []\n",
    "    sym_freq_cnt_8 = []\n",
    "    sym_freq_cnt_7 = []\n",
    "    sym_freq_cnt_6 = []\n",
    "    sym_freq_cnt_5 = []\n",
    "    sym_freq_cnt_4 = []\n",
    "    sym_freq_cnt_3 = []\n",
    "    sym_freq_cnt_2 = []\n",
    "\n",
    "    for sym_n_freq in top_set_syms_n_freq:\n",
    "        _sym = sym_n_freq[0]\n",
    "        _freq = sym_n_freq[1]\n",
    "        if _freq == 15:\n",
    "            sym_freq_cnt_15.append(_sym)\n",
    "        elif _freq == 14:\n",
    "            sym_freq_cnt_14.append(_sym)\n",
    "        elif _freq == 13:\n",
    "            sym_freq_cnt_13.append(_sym)\n",
    "        elif _freq == 12:\n",
    "            sym_freq_cnt_12.append(_sym)                        \n",
    "        elif _freq == 11:\n",
    "            sym_freq_cnt_11.append(_sym)\n",
    "        elif _freq == 10:\n",
    "            sym_freq_cnt_10.append(_sym)            \n",
    "        elif _freq == 9:\n",
    "            sym_freq_cnt_9.append(_sym)\n",
    "        elif _freq == 8:\n",
    "            sym_freq_cnt_8.append(_sym)\n",
    "        elif _freq == 7:\n",
    "            sym_freq_cnt_7.append(_sym)  \n",
    "        elif _freq == 6:\n",
    "            sym_freq_cnt_6.append(_sym)\n",
    "        elif _freq == 5:\n",
    "            sym_freq_cnt_5.append(_sym)\n",
    "        elif _freq == 4:\n",
    "            sym_freq_cnt_4.append(_sym)\n",
    "        elif _freq == 3:\n",
    "            sym_freq_cnt_3.append(_sym)          \n",
    "        else:\n",
    "            sym_freq_cnt_2.append(_sym)\n",
    "\n",
    "    l_sym_freq_cnt = []\n",
    "\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_15)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_14)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_13)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_12)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_11)   \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_10)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_9)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_8)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_7)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_6)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_5)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_4)\n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_3)    \n",
    "    l_sym_freq_cnt.append(sym_freq_cnt_2)    \n",
    "\n",
    "    return l_sym_freq_cnt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import datetime\n",
    "# from IPython.display import display, HTML\n",
    "from yf_utils import _2_split_train_val_test, _3_random_slices, _4_lookback_slices\n",
    "from yf_utils import _5_perf_ranks, _6_grp_tuples_sort_sum\n",
    "from myUtils import pickle_load, pickle_dump\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_colwidth', 16)\n",
    "pd.set_option('display.width', 790)\n",
    "\n",
    "path_dir = \"C:/Users/ping/MyDrive/stocks/yfinance/\"\n",
    "path_data_dump = path_dir + \"VSCode_dump/\"\n",
    "\n",
    "fp_df_close_clean = 'df_close_clean'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fp_df_eval_results = f'df_eval_results'\n",
    "# fp_df_picks = f'df_picks'\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################################################\n",
    "# str_today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "# # str_today = '2023-03-08'\n",
    "# # plan to run tran, validate and test periodically, so add date to file name\n",
    "# fp_df_eval_sym_freq_results_train    = f'df_eval_sym_freq_results_train_{str_today}'\n",
    "# fp_df_eval_sym_freq_results_validate = f'df_eval_sym_freq_results_validate_{str_today}'\n",
    "# fp_df_eval_sym_freq_results_test     = f'df_eval_sym_freq_results_test_{str_today}'\n",
    "# # plan to accumulate current results, therefore no date added to file name\n",
    "# fp_df_picks  = f'df_picks'\n",
    "\n",
    "# fp_df_eval_sym_freq_results_train    = f'df_eval_sym_freq_results_train'\n",
    "# fp_df_eval_sym_freq_results_validate = f'df_eval_sym_freq_results_validate'\n",
    "# fp_df_eval_sym_freq_results_test     = f'df_eval_sym_freq_results_test'\n",
    "# fp_df_picks  = f'df_picks'\n",
    "###########################################################################################################\n",
    "\n",
    "# df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>days_lookbacks</th>\n",
       "      <th>days_eval</th>\n",
       "      <th>n_top_syms</th>\n",
       "      <th>syms_start</th>\n",
       "      <th>syms_end</th>\n",
       "      <th>sym_freq_cnt</th>\n",
       "      <th>grp(CAGR)_mean</th>\n",
       "      <th>grp(CAGR)_std</th>\n",
       "      <th>grp(CAGR)_mean/std</th>\n",
       "      <th>grp(CAGR/UI)_mean</th>\n",
       "      <th>grp(CAGR/UI)_std</th>\n",
       "      <th>grp(CAGR/UI)_mean/std</th>\n",
       "      <th>grp(CAGR/retnStd)_mean</th>\n",
       "      <th>grp(CAGR/retnStd)_std</th>\n",
       "      <th>grp(CAGR/retnStd)_mean/std</th>\n",
       "      <th>grp(retnStd/UI)_mean</th>\n",
       "      <th>grp(retnStd/UI)_std</th>\n",
       "      <th>grp(retnStd/UI)_mean/std</th>\n",
       "      <th>SPY_CAGR</th>\n",
       "      <th>SPY_CAGR/UI</th>\n",
       "      <th>SPY_CAGR/retnStd</th>\n",
       "      <th>SPY_retnStd/UI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>[15]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>74.950511</td>\n",
       "      <td>147.459151</td>\n",
       "      <td>0.508280</td>\n",
       "      <td>1.479397e+08</td>\n",
       "      <td>2.958779e+08</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>3977.407072</td>\n",
       "      <td>7603.145483</td>\n",
       "      <td>0.523127</td>\n",
       "      <td>7716.775325</td>\n",
       "      <td>15428.915983</td>\n",
       "      <td>0.500150</td>\n",
       "      <td>4.189044</td>\n",
       "      <td>8.378088e+06</td>\n",
       "      <td>1479.623925</td>\n",
       "      <td>5662.308941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>[15]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>278.067785</td>\n",
       "      <td>774.936330</td>\n",
       "      <td>0.358827</td>\n",
       "      <td>1.592167e+04</td>\n",
       "      <td>3.985473e+04</td>\n",
       "      <td>0.399493</td>\n",
       "      <td>5050.467338</td>\n",
       "      <td>12814.470885</td>\n",
       "      <td>0.394122</td>\n",
       "      <td>2.382776</td>\n",
       "      <td>1.484835</td>\n",
       "      <td>1.604741</td>\n",
       "      <td>3.611062</td>\n",
       "      <td>1.235180e+03</td>\n",
       "      <td>425.632526</td>\n",
       "      <td>2.901988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>[15]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.405022</td>\n",
       "      <td>3.247018</td>\n",
       "      <td>0.432712</td>\n",
       "      <td>9.126885e+05</td>\n",
       "      <td>3.025837e+06</td>\n",
       "      <td>0.301632</td>\n",
       "      <td>187.746538</td>\n",
       "      <td>420.619524</td>\n",
       "      <td>0.446357</td>\n",
       "      <td>634.144526</td>\n",
       "      <td>2097.710029</td>\n",
       "      <td>0.302303</td>\n",
       "      <td>-0.807072</td>\n",
       "      <td>-5.674591e+01</td>\n",
       "      <td>-138.004767</td>\n",
       "      <td>0.411188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>[15]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.582610</td>\n",
       "      <td>3.574802</td>\n",
       "      <td>0.442713</td>\n",
       "      <td>2.610400e+02</td>\n",
       "      <td>5.610042e+02</td>\n",
       "      <td>0.465308</td>\n",
       "      <td>97.344412</td>\n",
       "      <td>228.506320</td>\n",
       "      <td>0.426003</td>\n",
       "      <td>1.461892</td>\n",
       "      <td>0.632036</td>\n",
       "      <td>2.312990</td>\n",
       "      <td>0.408491</td>\n",
       "      <td>1.094061e+02</td>\n",
       "      <td>62.561447</td>\n",
       "      <td>1.748779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>[15]</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10.077365</td>\n",
       "      <td>31.995710</td>\n",
       "      <td>0.314960</td>\n",
       "      <td>6.577771e+02</td>\n",
       "      <td>2.007828e+03</td>\n",
       "      <td>0.327606</td>\n",
       "      <td>232.676873</td>\n",
       "      <td>902.573007</td>\n",
       "      <td>0.257793</td>\n",
       "      <td>0.932434</td>\n",
       "      <td>0.709970</td>\n",
       "      <td>1.313343</td>\n",
       "      <td>-0.385821</td>\n",
       "      <td>-1.047276e+02</td>\n",
       "      <td>-210.263039</td>\n",
       "      <td>0.498079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>6</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.933872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-3.565790e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-108.627379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.328259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>-0.864667</td>\n",
       "      <td>-5.091508e+01</td>\n",
       "      <td>-95.027459</td>\n",
       "      <td>0.535793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>6</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.412179</td>\n",
       "      <td>0.404332</td>\n",
       "      <td>-1.019406</td>\n",
       "      <td>-2.139015e+01</td>\n",
       "      <td>6.369611e+01</td>\n",
       "      <td>-0.335816</td>\n",
       "      <td>-123.316093</td>\n",
       "      <td>179.229294</td>\n",
       "      <td>-0.688035</td>\n",
       "      <td>0.978119</td>\n",
       "      <td>0.573216</td>\n",
       "      <td>1.706370</td>\n",
       "      <td>-0.864667</td>\n",
       "      <td>-5.091508e+01</td>\n",
       "      <td>-95.027459</td>\n",
       "      <td>0.535793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>6</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.573099</td>\n",
       "      <td>0.560366</td>\n",
       "      <td>-1.022724</td>\n",
       "      <td>-1.554596e+01</td>\n",
       "      <td>2.307710e+01</td>\n",
       "      <td>-0.673653</td>\n",
       "      <td>-19.211139</td>\n",
       "      <td>19.979990</td>\n",
       "      <td>-0.961519</td>\n",
       "      <td>1.274893</td>\n",
       "      <td>0.451515</td>\n",
       "      <td>2.823591</td>\n",
       "      <td>-0.864667</td>\n",
       "      <td>-5.091508e+01</td>\n",
       "      <td>-95.027459</td>\n",
       "      <td>0.535793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>6</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.733702</td>\n",
       "      <td>0.302423</td>\n",
       "      <td>-2.426079</td>\n",
       "      <td>-3.324763e+01</td>\n",
       "      <td>1.064873e+01</td>\n",
       "      <td>-3.122215</td>\n",
       "      <td>-56.341709</td>\n",
       "      <td>24.956295</td>\n",
       "      <td>-2.257615</td>\n",
       "      <td>0.756306</td>\n",
       "      <td>0.413644</td>\n",
       "      <td>1.828399</td>\n",
       "      <td>-0.864667</td>\n",
       "      <td>-5.091508e+01</td>\n",
       "      <td>-95.027459</td>\n",
       "      <td>0.535793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>6</td>\n",
       "      <td>[15, 30, 60,...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.857364</td>\n",
       "      <td>0.158130</td>\n",
       "      <td>-5.421890</td>\n",
       "      <td>-3.723342e+01</td>\n",
       "      <td>1.280018e+01</td>\n",
       "      <td>-2.908820</td>\n",
       "      <td>-54.547081</td>\n",
       "      <td>21.081003</td>\n",
       "      <td>-2.587499</td>\n",
       "      <td>0.722736</td>\n",
       "      <td>0.270575</td>\n",
       "      <td>2.671113</td>\n",
       "      <td>-0.864667</td>\n",
       "      <td>-5.091508e+01</td>\n",
       "      <td>-95.027459</td>\n",
       "      <td>0.535793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_samples   days_lookbacks  days_eval  n_top_syms  syms_start  syms_end  sym_freq_cnt  grp(CAGR)_mean  grp(CAGR)_std  grp(CAGR)_mean/std  grp(CAGR/UI)_mean  grp(CAGR/UI)_std  grp(CAGR/UI)_mean/std  grp(CAGR/retnStd)_mean  grp(CAGR/retnStd)_std  grp(CAGR/retnStd)_mean/std  grp(retnStd/UI)_mean  grp(retnStd/UI)_std  grp(retnStd/UI)_mean/std  SPY_CAGR   SPY_CAGR/UI  SPY_CAGR/retnStd  SPY_retnStd/UI\n",
       "0           40             [15]          4          20           0        10             3       74.950511     147.459151         0.508280        1.479397e+08       2.958779e+08          0.500003            3977.407072             7603.145483               0.523127                 7716.775325          15428.915983             0.500150           4.189044  8.378088e+06      1479.623925      5662.308941\n",
       "1           40             [15]          4          20           0        10             3      278.067785     774.936330         0.358827        1.592167e+04       3.985473e+04          0.399493            5050.467338            12814.470885               0.394122                    2.382776              1.484835             1.604741           3.611062  1.235180e+03       425.632526         2.901988\n",
       "2           40             [15]          4          20           0        10             3        1.405022       3.247018         0.432712        9.126885e+05       3.025837e+06          0.301632             187.746538              420.619524               0.446357                  634.144526           2097.710029             0.302303          -0.807072 -5.674591e+01      -138.004767         0.411188\n",
       "3           40             [15]          4          20           0        10             3        1.582610       3.574802         0.442713        2.610400e+02       5.610042e+02          0.465308              97.344412              228.506320               0.426003                    1.461892              0.632036             2.312990           0.408491  1.094061e+02        62.561447         1.748779\n",
       "4           40             [15]          4          20           0        10             3       10.077365      31.995710         0.314960        6.577771e+02       2.007828e+03          0.327606             232.676873              902.573007               0.257793                    0.932434              0.709970             1.313343          -0.385821 -1.047276e+02      -210.263039         0.498079\n",
       "..         ...              ...        ...         ...         ...       ...           ...             ...            ...              ...                 ...                ...               ...                    ...                     ...                    ...                         ...                   ...                  ...                ...           ...              ...              ...\n",
       "800          6  [15, 30, 60,...          5          20           0        10             9       -0.933872       0.000000             -inf       -3.565790e+01       0.000000e+00              -inf            -108.627379                0.000000                   -inf                    0.328259              0.000000                  inf          -0.864667 -5.091508e+01       -95.027459         0.535793\n",
       "801          6  [15, 30, 60,...          5          20           0        10             8       -0.412179       0.404332        -1.019406       -2.139015e+01       6.369611e+01         -0.335816            -123.316093              179.229294              -0.688035                    0.978119              0.573216             1.706370          -0.864667 -5.091508e+01       -95.027459         0.535793\n",
       "802          6  [15, 30, 60,...          5          20           0        10             6       -0.573099       0.560366        -1.022724       -1.554596e+01       2.307710e+01         -0.673653             -19.211139               19.979990              -0.961519                    1.274893              0.451515             2.823591          -0.864667 -5.091508e+01       -95.027459         0.535793\n",
       "803          6  [15, 30, 60,...          5          20           0        10             5       -0.733702       0.302423        -2.426079       -3.324763e+01       1.064873e+01         -3.122215             -56.341709               24.956295              -2.257615                    0.756306              0.413644             1.828399          -0.864667 -5.091508e+01       -95.027459         0.535793\n",
       "804          6  [15, 30, 60,...          5          20           0        10             4       -0.857364       0.158130        -5.421890       -3.723342e+01       1.280018e+01         -2.908820             -54.547081               21.081003              -2.587499                    0.722736              0.270575             2.671113          -0.864667 -5.091508e+01       -95.027459         0.535793\n",
       "\n",
       "[805 rows x 23 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "df\n",
    "# df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_train)\n",
    "# df\n",
    "# df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_validate)\n",
    "# df\n",
    "# df = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_test)\n",
    "# df\n",
    "# df = pickle_load(path_data_dump, fp_df_picks)\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create column names to store current picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_picks_total:\n",
      "['date_end_df_train', 'max_days_lookbacks', 'days_lookbacks', 'sym_freq_15', 'sym_freq_14', 'sym_freq_13', 'sym_freq_12', 'sym_freq_11', 'sym_freq_10', 'sym_freq_9', 'sym_freq_8', 'sym_freq_7', 'sym_freq_6', 'sym_freq_5', 'sym_freq_4', 'sym_freq_3', 'sym_freq_2'], total columns: 17\n"
     ]
    }
   ],
   "source": [
    "# # columns for current picks\n",
    "# col_picks0 = ['date_end_df_train', 'max_days_lookbacks', 'days_lookbacks']\n",
    "# col_picks1 = ['sym_freq_15', 'sym_freq_14', 'sym_freq_13', 'sym_freq_12', 'sym_freq_11', 'sym_freq_10', 'sym_freq_9']\n",
    "# col_picks2 = ['sym_freq_8',  'sym_freq_7',  'sym_freq_6',  'sym_freq_5',  'sym_freq_4',  'sym_freq_3',  'sym_freq_2']\n",
    "# col_picks_total = col_picks0 + col_picks1 + col_picks2\n",
    "# print(f'col_picks_total:\\n{col_picks_total}, total columns: {len(col_picks_total)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DANGER: Create a new Dataframe to Picks. Previous Picks will be destroyed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_end_df_train</th>\n",
       "      <th>max_days_lookbacks</th>\n",
       "      <th>days_lookbacks</th>\n",
       "      <th>sym_freq_15</th>\n",
       "      <th>sym_freq_14</th>\n",
       "      <th>sym_freq_13</th>\n",
       "      <th>sym_freq_12</th>\n",
       "      <th>sym_freq_11</th>\n",
       "      <th>sym_freq_10</th>\n",
       "      <th>sym_freq_9</th>\n",
       "      <th>sym_freq_8</th>\n",
       "      <th>sym_freq_7</th>\n",
       "      <th>sym_freq_6</th>\n",
       "      <th>sym_freq_5</th>\n",
       "      <th>sym_freq_4</th>\n",
       "      <th>sym_freq_3</th>\n",
       "      <th>sym_freq_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date_end_df_train, max_days_lookbacks, days_lookbacks, sym_freq_15, sym_freq_14, sym_freq_13, sym_freq_12, sym_freq_11, sym_freq_10, sym_freq_9, sym_freq_8, sym_freq_7, sym_freq_6, sym_freq_5, sym_freq_4, sym_freq_3, sym_freq_2]\n",
       "Index: []"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_picks_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_picks)\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create column names to store run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_add_total:\n",
      "['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'syms_start', 'syms_end', 'sym_freq_cnt', 'grp(CAGR)_mean', 'grp(CAGR)_std', 'grp(CAGR)_mean/std', 'grp(CAGR/UI)_mean', 'grp(CAGR/UI)_std', 'grp(CAGR/UI)_mean/std', 'grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std', 'grp(retnStd/UI)_mean', 'grp(retnStd/UI)_std', 'grp(retnStd/UI)_mean/std', 'SPY_CAGR', 'SPY_CAGR/UI', 'SPY_CAGR/retnStd', 'SPY_retnStd/UI'], total columns: 23\n"
     ]
    }
   ],
   "source": [
    "# col_add0 = ['n_samples', 'days_lookbacks', 'days_eval', 'n_top_syms', 'syms_start', 'syms_end', 'sym_freq_cnt']\n",
    "# col_add1 = ['grp(CAGR)_mean',         'grp(CAGR)_std',         'grp(CAGR)_mean/std']\n",
    "# col_add2 = ['grp(CAGR/UI)_mean',      'grp(CAGR/UI)_std',      'grp(CAGR/UI)_mean/std']\n",
    "# col_add3 = ['grp(CAGR/retnStd)_mean', 'grp(CAGR/retnStd)_std', 'grp(CAGR/retnStd)_mean/std']\n",
    "# col_add4 = ['grp(retnStd/UI)_mean',   'grp(retnStd/UI)_std',   'grp(retnStd/UI)_mean/std']\n",
    "# col_add5 = ['SPY_CAGR', 'SPY_CAGR/UI', 'SPY_CAGR/retnStd', 'SPY_retnStd/UI']\n",
    "\n",
    "# col_add_total = col_add0 + col_add1 + col_add2 + col_add3 + col_add4 + col_add5\n",
    "# print(f'col_add_total:\\n{col_add_total}, total columns: {len(col_add_total)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DANGER: Create a new Dataframe to store run results. Previous data will be destroyed. To create a new dataframe, uncomment one choice from below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>days_lookbacks</th>\n",
       "      <th>days_eval</th>\n",
       "      <th>n_top_syms</th>\n",
       "      <th>syms_start</th>\n",
       "      <th>syms_end</th>\n",
       "      <th>sym_freq_cnt</th>\n",
       "      <th>grp(CAGR)_mean</th>\n",
       "      <th>grp(CAGR)_std</th>\n",
       "      <th>grp(CAGR)_mean/std</th>\n",
       "      <th>grp(CAGR/UI)_mean</th>\n",
       "      <th>grp(CAGR/UI)_std</th>\n",
       "      <th>grp(CAGR/UI)_mean/std</th>\n",
       "      <th>grp(CAGR/retnStd)_mean</th>\n",
       "      <th>grp(CAGR/retnStd)_std</th>\n",
       "      <th>grp(CAGR/retnStd)_mean/std</th>\n",
       "      <th>grp(retnStd/UI)_mean</th>\n",
       "      <th>grp(retnStd/UI)_std</th>\n",
       "      <th>grp(retnStd/UI)_mean/std</th>\n",
       "      <th>SPY_CAGR</th>\n",
       "      <th>SPY_CAGR/UI</th>\n",
       "      <th>SPY_CAGR/retnStd</th>\n",
       "      <th>SPY_retnStd/UI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [n_samples, days_lookbacks, days_eval, n_top_syms, syms_start, syms_end, sym_freq_cnt, grp(CAGR)_mean, grp(CAGR)_std, grp(CAGR)_mean/std, grp(CAGR/UI)_mean, grp(CAGR/UI)_std, grp(CAGR/UI)_mean/std, grp(CAGR/retnStd)_mean, grp(CAGR/retnStd)_std, grp(CAGR/retnStd)_mean/std, grp(retnStd/UI)_mean, grp(retnStd/UI)_std, grp(retnStd/UI)_mean/std, SPY_CAGR, SPY_CAGR/UI, SPY_CAGR/retnStd, SPY_retnStd/UI]\n",
       "Index: []"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_eval_results)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_eval_sym_freq_results_train)\n",
    "# df\n",
    "\n",
    "# # # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_eval_sym_freq_results_validate)\n",
    "# df\n",
    "\n",
    "# # # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_eval_sym_freq_results_test)\n",
    "# df\n",
    "\n",
    "# # # Creating Empty DataFrame and save it to file\n",
    "# df = pd.DataFrame(columns=col_add_total)\n",
    "# pickle_dump(df, path_data_dump, fp_df_picks)\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select run parameters. Parameters can also be passed using papermill by running yf_7_freq_cnt_pm_.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose : True\n",
      "store_results: True\n",
      "run_type: current\n",
      "n_samples: 1\n",
      "days_lookbacks: [15, 30, 60, 120]\n",
      "days_eval: 0\n",
      "n_top_syms: 20\n",
      "syms_start: 0\n",
      "syms_end: 10\n"
     ]
    }
   ],
   "source": [
    "fp_df_eval_results = f'df_eval_results'\n",
    "fp_df_picks = f'df_picks'\n",
    "\n",
    "\n",
    "# SELECT RUN PARAMETERS.async Parameters can also be passed using papermill by running yf_7_freq_cnt_pm_.ipynb\n",
    "verbose = True  # True prints more output\n",
    "# verbose = False  # True prints more output\n",
    "\n",
    "# write run results to df_eval_results\n",
    "# store_results = False\n",
    "store_results = True\n",
    "\n",
    "# select run type\n",
    "# run_type = 'train'\n",
    "# run_type = 'validate'\n",
    "# run_type = 'test'\n",
    "run_type = 'current'\n",
    "\n",
    "# number of max lookback tuples to create for iloc iloc_start_train:iloc_end_train:iloc_end_eval\n",
    "# i.e. number of grp_top_set_syms_n_freq and grp_top_set_syms \n",
    "# n_samples = 400  \n",
    "n_samples = 40\n",
    "\n",
    "# for training, the number of days to lookback from iloc max-lookback iloc_end_train\n",
    "# days_lookbacks = [30, 60, 120]\n",
    "days_lookbacks = [15, 30, 60, 120]\n",
    "days_lookbacks.sort()\n",
    "\n",
    "# number of days from iloc_end_train are used to evaluate effectiveness of the training\n",
    "days_eval = 4\n",
    "# days_eval = 5\n",
    "\n",
    "# number of the most-common symbols from days_lookbacks' performance rankings to keep\n",
    "n_top_syms = 20  \n",
    "\n",
    "syms_start = 0  #  start index of n_top_syms for evaluation\n",
    "syms_end = 10  #  end index of n_top_syms for evaluation\n",
    "\n",
    "# over-ride parameters for run_type 'current'\n",
    "if run_type == 'current':\n",
    "  days_eval = 0  # no need to eval, df_eval will be empty\n",
    "  n_samples = 1  # no need to repeat sample the current result, repeat sample will yield the same tuple\n",
    "\n",
    "print(f'verbose : {verbose }')\n",
    "print(f'store_results: {store_results}')\n",
    "print(f'run_type: {run_type}')\n",
    "print(f'n_samples: {n_samples}')\n",
    "print(f'days_lookbacks: {days_lookbacks}')\n",
    "print(f'days_eval: {days_eval}')\n",
    "print(f'n_top_syms: {n_top_syms}')\n",
    "print(f'syms_start: {syms_start}')\n",
    "print(f'syms_end: {syms_end}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load previous run results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_results = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "df_picks = pickle_load(path_data_dump, fp_df_picks)\n",
    "df_close_clean = pickle_load(path_data_dump, fp_df_close_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the last n row in df_close_clean to get previous picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop the last n row(s)\n",
    "# n = 1\n",
    "# df_close_clean = df_close_clean[:-n]\n",
    "# df_close_clean.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataframe into Train, Validate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df_close_clean into training (df_train), validation (df_val) and test (df_test) set.\n",
    "# The default split is 0.7, 0.2, 0.1 respectively.\n",
    "df_train, df_val, df_test = _2_split_train_val_test(df_close_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create df_current, a df with the latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_days_lookbacks: 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAWW</th>\n",
       "      <th>AB</th>\n",
       "      <th>ABB</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABM</th>\n",
       "      <th>ABR</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>ACHC</th>\n",
       "      <th>...</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YELP</th>\n",
       "      <th>YUMC</th>\n",
       "      <th>YY</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZD</th>\n",
       "      <th>ZG</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTO</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZUMZ</th>\n",
       "      <th>ZWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-14</th>\n",
       "      <td>138.399994</td>\n",
       "      <td>44.59</td>\n",
       "      <td>14.66</td>\n",
       "      <td>121.699997</td>\n",
       "      <td>152.589996</td>\n",
       "      <td>99.300003</td>\n",
       "      <td>35.709999</td>\n",
       "      <td>33.759998</td>\n",
       "      <td>153.850006</td>\n",
       "      <td>149.289993</td>\n",
       "      <td>44.570000</td>\n",
       "      <td>12.12</td>\n",
       "      <td>98.550003</td>\n",
       "      <td>67.339996</td>\n",
       "      <td>69.160004</td>\n",
       "      <td>...</td>\n",
       "      <td>38.130001</td>\n",
       "      <td>15.14</td>\n",
       "      <td>99.900002</td>\n",
       "      <td>29.260000</td>\n",
       "      <td>60.680000</td>\n",
       "      <td>27.469999</td>\n",
       "      <td>126.629997</td>\n",
       "      <td>292.459991</td>\n",
       "      <td>74.370003</td>\n",
       "      <td>39.610001</td>\n",
       "      <td>31.309999</td>\n",
       "      <td>26.270000</td>\n",
       "      <td>164.559998</td>\n",
       "      <td>20.43</td>\n",
       "      <td>21.379999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-15</th>\n",
       "      <td>134.029999</td>\n",
       "      <td>39.77</td>\n",
       "      <td>13.86</td>\n",
       "      <td>121.769997</td>\n",
       "      <td>152.990005</td>\n",
       "      <td>102.449997</td>\n",
       "      <td>35.080002</td>\n",
       "      <td>31.990000</td>\n",
       "      <td>154.059998</td>\n",
       "      <td>149.610001</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>11.53</td>\n",
       "      <td>97.800003</td>\n",
       "      <td>62.740002</td>\n",
       "      <td>68.459999</td>\n",
       "      <td>...</td>\n",
       "      <td>37.209999</td>\n",
       "      <td>15.00</td>\n",
       "      <td>96.550003</td>\n",
       "      <td>29.170000</td>\n",
       "      <td>60.439999</td>\n",
       "      <td>27.070000</td>\n",
       "      <td>125.260002</td>\n",
       "      <td>287.739990</td>\n",
       "      <td>73.779999</td>\n",
       "      <td>39.919998</td>\n",
       "      <td>30.709999</td>\n",
       "      <td>25.940001</td>\n",
       "      <td>163.570007</td>\n",
       "      <td>19.50</td>\n",
       "      <td>20.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16</th>\n",
       "      <td>136.820007</td>\n",
       "      <td>40.75</td>\n",
       "      <td>14.12</td>\n",
       "      <td>122.029999</td>\n",
       "      <td>155.850006</td>\n",
       "      <td>102.459999</td>\n",
       "      <td>35.310001</td>\n",
       "      <td>32.549999</td>\n",
       "      <td>155.300003</td>\n",
       "      <td>152.050003</td>\n",
       "      <td>44.790001</td>\n",
       "      <td>11.50</td>\n",
       "      <td>99.029999</td>\n",
       "      <td>66.070000</td>\n",
       "      <td>70.230003</td>\n",
       "      <td>...</td>\n",
       "      <td>37.439999</td>\n",
       "      <td>15.20</td>\n",
       "      <td>97.160004</td>\n",
       "      <td>29.780001</td>\n",
       "      <td>60.980000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>125.430000</td>\n",
       "      <td>294.929993</td>\n",
       "      <td>74.510002</td>\n",
       "      <td>40.849998</td>\n",
       "      <td>32.110001</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>166.309998</td>\n",
       "      <td>19.25</td>\n",
       "      <td>20.969999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A     AA    AAL         AAP        AAPL        AAWW         AB        ABB        ABBV         ABC        ABM    ABR        ABT       ACGL       ACHC  ...       XRAY    XRX        XYL       YELP       YUMC         YY         ZBH        ZBRA         ZD         ZG       ZION        ZTO         ZTS   ZUMZ        ZWS\n",
       "Date                                                                                                                                                                       ...                                                                                                                                                                \n",
       "2023-03-14  138.399994  44.59  14.66  121.699997  152.589996   99.300003  35.709999  33.759998  153.850006  149.289993  44.570000  12.12  98.550003  67.339996  69.160004  ...  38.130001  15.14  99.900002  29.260000  60.680000  27.469999  126.629997  292.459991  74.370003  39.610001  31.309999  26.270000  164.559998  20.43  21.379999\n",
       "2023-03-15  134.029999  39.77  13.86  121.769997  152.990005  102.449997  35.080002  31.990000  154.059998  149.610001  44.250000  11.53  97.800003  62.740002  68.459999  ...  37.209999  15.00  96.550003  29.170000  60.439999  27.070000  125.260002  287.739990  73.779999  39.919998  30.709999  25.940001  163.570007  19.50  20.980000\n",
       "2023-03-16  136.820007  40.75  14.12  122.029999  155.850006  102.459999  35.310001  32.549999  155.300003  152.050003  44.790001  11.50  99.029999  66.070000  70.230003  ...  37.439999  15.20  97.160004  29.780001  60.980000  28.000000  125.430000  294.929993  74.510002  40.849998  32.110001  28.000000  166.309998  19.25  20.969999\n",
       "\n",
       "[3 rows x 1290 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_days_lookbacks = max(days_lookbacks)\n",
    "print(f'max_days_lookbacks: {max_days_lookbacks}')\n",
    "df_current = df_test.tail(max_days_lookbacks)  \n",
    "df_current.tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load df according to run_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_type == 'train':\n",
    "  # df_eval_sym_freq_results_train = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_train)\n",
    "  df = df_train.copy()    \n",
    "elif run_type == 'validate':\n",
    "  # df_eval_sym_freq_results_validate = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_validate)\n",
    "  df = df_val.copy()\n",
    "elif run_type == 'test':\n",
    "  # df_eval_sym_freq_results_test = pickle_load(path_data_dump, fp_df_eval_sym_freq_results_test)\n",
    "  df = df_test.copy()\n",
    "elif run_type == 'current':  # get the current results\n",
    "  # df_picks = pickle_load(path_data_dump, fp_df_picks)  \n",
    "  df = df_current.copy()\n",
    "else:\n",
    "  msg_stop = f\"ERROR run_type must be 'train', 'validate', 'test' or 'current', run_type is: {run_type}\"\n",
    "  raise SystemExit(msg_stop )  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print dataframe for the run, and lengths of other dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_type: current, df.tail(3):\n",
      "                     A     AA    AAL         AAP        AAPL        AAWW         AB        ABB        ABBV         ABC        ABM    ABR        ABT       ACGL       ACHC  ...       XRAY    XRX        XYL       YELP       YUMC         YY         ZBH        ZBRA         ZD         ZG       ZION        ZTO         ZTS   ZUMZ        ZWS\n",
      "Date                                                                                                                                                                       ...                                                                                                                                                                \n",
      "2023-03-14  138.399994  44.59  14.66  121.699997  152.589996   99.300003  35.709999  33.759998  153.850006  149.289993  44.570000  12.12  98.550003  67.339996  69.160004  ...  38.130001  15.14  99.900002  29.260000  60.680000  27.469999  126.629997  292.459991  74.370003  39.610001  31.309999  26.270000  164.559998  20.43  21.379999\n",
      "2023-03-15  134.029999  39.77  13.86  121.769997  152.990005  102.449997  35.080002  31.990000  154.059998  149.610001  44.250000  11.53  97.800003  62.740002  68.459999  ...  37.209999  15.00  96.550003  29.170000  60.439999  27.070000  125.260002  287.739990  73.779999  39.919998  30.709999  25.940001  163.570007  19.50  20.980000\n",
      "2023-03-16  136.820007  40.75  14.12  122.029999  155.850006  102.459999  35.310001  32.549999  155.300003  152.050003  44.790001  11.50  99.029999  66.070000  70.230003  ...  37.439999  15.20  97.160004  29.780001  60.980000  28.000000  125.430000  294.929993  74.510002  40.849998  32.110001  28.000000  166.309998  19.25  20.969999\n",
      "\n",
      "[3 rows x 1290 columns]\n",
      "\n",
      "run_type: current, len(df): 120\n",
      "len_df_train: 1050, len_df_val: 300, len_df_test: 150, len_df_current: 120 \n"
     ]
    }
   ],
   "source": [
    "print(f'run_type: {run_type}, df.tail(3):\\n{df.tail(3)}\\n')\n",
    "len_df = len(df)\n",
    "len_df_train = len(df_train)\n",
    "len_df_val = len(df_val)\n",
    "len_df_test = len(df_test)\n",
    "len_df_current = len(df_current)\n",
    "print(f'run_type: {run_type}, len(df): {len(df)}')\n",
    "print(f'len_df_train: {len_df_train}, len_df_val: {len_df_val}, len_df_test: {len_df_test}, len_df_current: {len_df_current} ')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a sets of iloc lookback slices (iloc_start_train:iloc_end_train:iloc_end_eval), where:  \n",
    "* iloc_end_train - iloc_start_train = days_lookback\n",
    "* iloc_end_eval - iloc_end_train = days_eval  \n",
    "#### for example, if given:  \n",
    "* n_samples = 2  \n",
    "* days_lookbacks = [10, 20, 30]  \n",
    "* days_eval = 5  \n",
    "#### a possible result is:  \n",
    "  - max_lookback_slices: [(417, 447, 452), (265, 295, 300)], where:\n",
    "    - len(max_lookback_slices) = n_samples = 2\n",
    "    - middle number in the tuples, 447 and 295, is the iloc of the \"pivot day\" for the days in \"days_lookbacks\" to lookback\n",
    "    - 447 - 417 = middle number - first number = max(days_lookbacks) = 30\n",
    "    - 295 - 265 = middle number - first number = max(days_lookbacks) = 30      \n",
    "    - 452 - 447 = last number - middle number = days_eval = 5\n",
    "    - 300 - 295 = last number - middle number = days_eval = 5    \n",
    "  - sets_lookback_slices: [[(437, 447, 452), (427, 447, 452), (417, 447, 452)], [(285, 295, 300), (275, 295, 300), (265, 295, 300)]], where:\n",
    "    - len(sets_lookback_slices) = n_samples = 2\n",
    "    - last tuple in each list, i.e. (417, 447, 452) and (265, 295, 300), is a tuple from max_lookback_slices\n",
    "    - where a set, e.g. [(437, 447, 452), (427, 447, 452), (417, 447, 452)]:\n",
    "      - middle number, 447, iloc of the \"pivot day\" is constant for that set\n",
    "      - middle number - first number, is the training period specified in days_lookbacks\n",
    "        - 447 - 437 = middle number - first number = days_lookbacks[0] = 10\n",
    "        - 447 - 427 = middle number - first number = days_lookbacks[1] = 20\n",
    "        - 447 - 417 = middle number - first number = days_lookbacks[2] = 30\n",
    "      - last number, 452, iloc of the end of the evaluation period is constant\n",
    "        - 452 - 447 = last number - middle number = days_eval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of max_lookback_slices is equal to n_samples = 1\n",
      "max_lookback_slices:\n",
      "[(0, 120, 120)]\n",
      "\n",
      "number of sets in sets_lookback_slices is equal to n_samples = 1\n",
      "days_lookbacks: [15, 30, 60, 120]\n",
      "sets_lookback_slices:\n",
      "[[(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)]]\n",
      "\n",
      "number of tuples in each \"set of lookback slices\" is equal to len(days_lookbacks): len([15, 30, 60, 120])\n"
     ]
    }
   ],
   "source": [
    "# return n_samples slices\n",
    "max_lookback_slices = _3_random_slices(len_df, n_samples=n_samples, days_lookback=max(days_lookbacks), days_eval=days_eval, verbose=False)\n",
    "# return n_samples * len(days_lookbacks) slices\n",
    "sets_lookback_slices = _4_lookback_slices(max_slices=max_lookback_slices, days_lookbacks=days_lookbacks, verbose=False)\n",
    "\n",
    "if verbose:\n",
    "  print(f'number of max_lookback_slices is equal to n_samples = {n_samples}')\n",
    "  print(f'max_lookback_slices:\\n{max_lookback_slices}\\n')\n",
    "  print(f'number of sets in sets_lookback_slices is equal to n_samples = {n_samples}')\n",
    "  print(f'days_lookbacks: {days_lookbacks}')  \n",
    "  print(f'sets_lookback_slices:\\n{sets_lookback_slices}\\n')\n",
    "  print(f'number of tuples in each \"set of lookback slices\" is equal to len(days_lookbacks): len({days_lookbacks})')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate grp_top_set_syms_n_freq. It is a list of sub-lists, e.g.:\n",
    " - [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)], ..., [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "#### grp_top_set_syms_n_freq has n_samples sub-lists. Each sub-list corresponds to a tuple in the max_lookback_slices. Each sub-list has n_top_syms tuples of (symbol, frequency) pairs, and is sorted in descending order of frequency. The frequency is the number of times the symbol appears in the top n_top_syms performance rankings of CAGR/UI, CAGR/retnStd and retnStd/UI.\n",
    "#### Therefore, symbols in the sub-list are the best performing symbols for the periods in days_lookbacks. Each sub-list corresponds to a tuple in max_lookback_slices. There are as many sub-lists as there are tuples in max_lookback_slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## 1 of 1 lb_slices in sets_lookcak_slices ##########\n",
      "days lookback:       15,  1 of 4 days_lookbacks: [15, 30, 60, 120]\n",
      "lb_slices:           [(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "lb_slice:            (105, 120, 120)\n",
      "days eval:           0\n",
      "iloc_start_train:    105\n",
      "iloc_end_train:      120\n",
      "date_start_df_train: 2023-02-24\n",
      "date_end_df_train:   2023-03-16\n",
      "perf_ranks: {'period-15': {'r_CAGR/UI': array(['HY', 'ANET', 'MLR', 'AMD', 'FSLR', 'SGEN', 'INTC', 'META', 'CMG',\n",
      "       'MYGN', 'NTRA', 'ZTO', 'SRPT', 'TAK', 'AU', 'BEP', 'FIZZ', 'LEN',\n",
      "       'PCH', 'GE'], dtype=object), 'r_CAGR/retnStd': array(['HY', 'MYGN', 'FSLR', 'AMD', 'MLR', 'ANET', 'INTC', 'SGEN', 'META',\n",
      "       'NTRA', 'SRPT', 'CMG', 'AU', 'GOOG', 'BPMC', 'ZTO', 'FIZZ', 'CRM',\n",
      "       'SSYS', 'MSFT'], dtype=object), 'r_retnStd/UI': array(['CMG', 'ANET', 'TAK', 'ZTO', 'MLR', 'SGEN', 'META', 'LEN', 'BEP',\n",
      "       'AMD', 'INTC', 'FTSM', 'KR', 'GE', 'PCH', 'IRBT', 'FSLR', 'FCN',\n",
      "       'CDNS', 'AVGO'], dtype=object)}}\n",
      "most_freq_syms: [('ANET', 3), ('MLR', 3), ('AMD', 3), ('FSLR', 3), ('SGEN', 3), ('INTC', 3), ('META', 3), ('CMG', 3), ('ZTO', 3), ('HY', 2), ('MYGN', 2), ('NTRA', 2), ('SRPT', 2), ('TAK', 2), ('AU', 2), ('BEP', 2), ('FIZZ', 2), ('LEN', 2), ('PCH', 2), ('GE', 2), ('GOOG', 1), ('BPMC', 1), ('CRM', 1), ('SSYS', 1), ('MSFT', 1), ('FTSM', 1), ('KR', 1), ('IRBT', 1), ('FCN', 1), ('CDNS', 1), ('AVGO', 1)]\n",
      "+++ finish lookback slice 15 +++\n",
      "\n",
      "days lookback:       30,  2 of 4 days_lookbacks: [15, 30, 60, 120]\n",
      "lb_slices:           [(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "lb_slice:            (90, 120, 120)\n",
      "days eval:           0\n",
      "iloc_start_train:    90\n",
      "iloc_end_train:      120\n",
      "date_start_df_train: 2023-02-02\n",
      "date_end_df_train:   2023-03-16\n",
      "perf_ranks: {'period-30': {'r_CAGR/UI': array(['TA', 'SGEN', 'FCN', 'LNTH', 'FTSM', 'TNK', 'ANET', 'FIZZ', 'PDFS',\n",
      "       'AMPH', 'ATCO', 'SRPT', 'HY', 'FSLR', 'NTRA', 'CTLT', 'WST',\n",
      "       'TWNK', 'NVDA', 'MLR'], dtype=object), 'r_CAGR/retnStd': array(['TA', 'SGEN', 'TNK', 'FCN', 'HY', 'ANET', 'LNTH', 'FIZZ', 'PDFS',\n",
      "       'SRPT', 'CTLT', 'FSLR', 'AMPH', 'FTSM', 'NTRA', 'WST', 'MLR',\n",
      "       'OEC', 'FTNT', 'NVDA'], dtype=object), 'r_retnStd/UI': array(['TA', 'ATCO', 'SGEN', 'FTSM', 'FCN', 'LNTH', 'AMPH', 'FIZZ',\n",
      "       'PDFS', 'TWNK', 'SRPT', 'FSLR', 'LMT', 'WST', 'NVDA', 'ANET',\n",
      "       'CLX', 'NTRA', 'KR', 'CTLT'], dtype=object)}}\n",
      "most_freq_syms: [('TA', 3), ('SGEN', 3), ('FCN', 3), ('LNTH', 3), ('FTSM', 3), ('ANET', 3), ('FIZZ', 3), ('PDFS', 3), ('AMPH', 3), ('SRPT', 3), ('FSLR', 3), ('NTRA', 3), ('CTLT', 3), ('WST', 3), ('NVDA', 3), ('TNK', 2), ('ATCO', 2), ('HY', 2), ('TWNK', 2), ('MLR', 2), ('OEC', 1), ('FTNT', 1), ('LMT', 1), ('CLX', 1), ('KR', 1)]\n",
      "+++ finish lookback slice 30 +++\n",
      "\n",
      "days lookback:       60,  3 of 4 days_lookbacks: [15, 30, 60, 120]\n",
      "lb_slices:           [(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "lb_slice:            (60, 120, 120)\n",
      "days eval:           0\n",
      "iloc_start_train:    60\n",
      "iloc_end_train:      120\n",
      "date_start_df_train: 2022-12-19\n",
      "date_end_df_train:   2023-03-16\n",
      "perf_ranks: {'period-60': {'r_CAGR/UI': array(['TA', 'FTSM', 'GE', 'ACLS', 'SGEN', 'META', 'DCP', 'CTLT', 'WST',\n",
      "       'LNTH', 'OEC', 'CRM', 'AMPH', 'PERI', 'HY', 'FCN', 'NVDA', 'SMG',\n",
      "       'WBD', 'ALGN'], dtype=object), 'r_CAGR/retnStd': array(['META', 'ACLS', 'GE', 'CTLT', 'SGEN', 'MARA', 'ALGN', 'HY', 'OEC',\n",
      "       'WST', 'FTSM', 'SMG', 'CRM', 'PAR', 'NVDA', 'WBD', 'LNTH', 'CRUS',\n",
      "       'PERI', 'AMD'], dtype=object), 'r_retnStd/UI': array(['DCP', 'TA', 'FTSM', 'SGEN', 'FCN', 'AMPH', 'GE', 'LRN', 'WST',\n",
      "       'RVNC', 'LNTH', 'CTLT', 'RELX', 'CPRT', 'OTTR', 'ACLS', 'GEL',\n",
      "       'GDEN', 'RACE', 'OLED'], dtype=object)}}\n",
      "most_freq_syms: [('FTSM', 3), ('GE', 3), ('ACLS', 3), ('SGEN', 3), ('CTLT', 3), ('WST', 3), ('LNTH', 3), ('TA', 2), ('META', 2), ('DCP', 2), ('OEC', 2), ('CRM', 2), ('AMPH', 2), ('PERI', 2), ('HY', 2), ('FCN', 2), ('NVDA', 2), ('SMG', 2), ('WBD', 2), ('ALGN', 2), ('MARA', 1), ('PAR', 1), ('CRUS', 1), ('AMD', 1), ('LRN', 1), ('RVNC', 1), ('RELX', 1), ('CPRT', 1), ('OTTR', 1), ('GEL', 1), ('GDEN', 1), ('RACE', 1), ('OLED', 1)]\n",
      "+++ finish lookback slice 60 +++\n",
      "\n",
      "days lookback:       120,  4 of 4 days_lookbacks: [15, 30, 60, 120]\n",
      "lb_slices:           [(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "lb_slice:            (0, 120, 120)\n",
      "days eval:           0\n",
      "iloc_start_train:    0\n",
      "iloc_end_train:      120\n",
      "date_start_df_train: 2022-09-23\n",
      "date_end_df_train:   2023-03-16\n",
      "perf_ranks: {'period-120': {'r_CAGR/UI': array(['FTSM', 'ELF', 'GE', 'AJRD', 'MCFT', 'NVO', 'RMBS', 'HZNP', 'ACLS',\n",
      "       'OI', 'MLR', 'ACGL', 'ATKR', 'STRL', 'THR', 'PERI', 'BURL', 'AXON',\n",
      "       'CCU', 'OEC'], dtype=object), 'r_CAGR/retnStd': array(['ACLS', 'FTSM', 'GE', 'RMBS', 'AXON', 'ELF', 'NVDA', 'PERI',\n",
      "       'LSCC', 'STRL', 'THR', 'ATKR', 'MLR', 'OI', 'MCFT', 'OEC', 'TEX',\n",
      "       'WYNN', 'CCU', 'BURL'], dtype=object), 'r_retnStd/UI': array(['FTSM', 'AJRD', 'ATCO', 'HZNP', 'NVO', 'MCFT', 'ELF', 'ACGL',\n",
      "       'TMHC', 'GVA', 'LW', 'DCI', 'OI', 'MLR', 'BA', 'BURL', 'HWM',\n",
      "       'ATKR', 'PGR', 'AGYS'], dtype=object)}}\n",
      "most_freq_syms: [('FTSM', 3), ('ELF', 3), ('MCFT', 3), ('OI', 3), ('MLR', 3), ('ATKR', 3), ('BURL', 3), ('GE', 2), ('AJRD', 2), ('NVO', 2), ('RMBS', 2), ('HZNP', 2), ('ACLS', 2), ('ACGL', 2), ('STRL', 2), ('THR', 2), ('PERI', 2), ('AXON', 2), ('CCU', 2), ('OEC', 2), ('NVDA', 1), ('LSCC', 1), ('TEX', 1), ('WYNN', 1), ('ATCO', 1), ('TMHC', 1), ('GVA', 1), ('LW', 1), ('DCI', 1), ('BA', 1), ('HWM', 1), ('PGR', 1), ('AGYS', 1)]\n",
      "+++ finish lookback slice 120 +++\n",
      "\n",
      "grp_most_freq_syms: [[('ANET', 3), ('MLR', 3), ('AMD', 3), ('FSLR', 3), ('SGEN', 3), ('INTC', 3), ('META', 3), ('CMG', 3), ('ZTO', 3), ('HY', 2), ('MYGN', 2), ('NTRA', 2), ('SRPT', 2), ('TAK', 2), ('AU', 2), ('BEP', 2), ('FIZZ', 2), ('LEN', 2), ('PCH', 2), ('GE', 2), ('GOOG', 1), ('BPMC', 1), ('CRM', 1), ('SSYS', 1), ('MSFT', 1), ('FTSM', 1), ('KR', 1), ('IRBT', 1), ('FCN', 1), ('CDNS', 1), ('AVGO', 1)], [('TA', 3), ('SGEN', 3), ('FCN', 3), ('LNTH', 3), ('FTSM', 3), ('ANET', 3), ('FIZZ', 3), ('PDFS', 3), ('AMPH', 3), ('SRPT', 3), ('FSLR', 3), ('NTRA', 3), ('CTLT', 3), ('WST', 3), ('NVDA', 3), ('TNK', 2), ('ATCO', 2), ('HY', 2), ('TWNK', 2), ('MLR', 2), ('OEC', 1), ('FTNT', 1), ('LMT', 1), ('CLX', 1), ('KR', 1)], [('FTSM', 3), ('GE', 3), ('ACLS', 3), ('SGEN', 3), ('CTLT', 3), ('WST', 3), ('LNTH', 3), ('TA', 2), ('META', 2), ('DCP', 2), ('OEC', 2), ('CRM', 2), ('AMPH', 2), ('PERI', 2), ('HY', 2), ('FCN', 2), ('NVDA', 2), ('SMG', 2), ('WBD', 2), ('ALGN', 2), ('MARA', 1), ('PAR', 1), ('CRUS', 1), ('AMD', 1), ('LRN', 1), ('RVNC', 1), ('RELX', 1), ('CPRT', 1), ('OTTR', 1), ('GEL', 1), ('GDEN', 1), ('RACE', 1), ('OLED', 1)], [('FTSM', 3), ('ELF', 3), ('MCFT', 3), ('OI', 3), ('MLR', 3), ('ATKR', 3), ('BURL', 3), ('GE', 2), ('AJRD', 2), ('NVO', 2), ('RMBS', 2), ('HZNP', 2), ('ACLS', 2), ('ACGL', 2), ('STRL', 2), ('THR', 2), ('PERI', 2), ('AXON', 2), ('CCU', 2), ('OEC', 2), ('NVDA', 1), ('LSCC', 1), ('TEX', 1), ('WYNN', 1), ('ATCO', 1), ('TMHC', 1), ('GVA', 1), ('LW', 1), ('DCI', 1), ('BA', 1), ('HWM', 1), ('PGR', 1), ('AGYS', 1)]]\n",
      "**** finish lookback slices [(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)] ****\n",
      "\n",
      "top 20 ranked symbols and frequency from set [(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)]:\n",
      "[('FTSM', 10), ('SGEN', 9), ('MLR', 8), ('GE', 7), ('ANET', 6), ('CTLT', 6), ('FCN', 6), ('FSLR', 6), ('HY', 6), ('LNTH', 6), ('NVDA', 6), ('WST', 6), ('ACLS', 5), ('AMPH', 5), ('FIZZ', 5), ('META', 5), ('NTRA', 5), ('OEC', 5), ('SRPT', 5), ('TA', 5)]\n",
      "top 20 ranked symbols from set [(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)]:\n",
      "['FTSM', 'SGEN', 'MLR', 'GE', 'ANET', 'CTLT', 'FCN', 'FSLR', 'HY', 'LNTH']\n",
      "===== finish top 20 ranked symbols from days_lookback set [(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)] =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grp_top_set_syms_n_freq is a list of lists of top_set_syms_n_freq, e.g.\n",
    "#   [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)],\n",
    "#    [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "#   where each list is the best performing symbols from a lb_slices, e.g.\n",
    "#     [(483, 513, 523), (453, 513, 523), (393, 513, 523)]  \n",
    "grp_top_set_syms_n_freq = []  # list of lists of top_set_symbols_n_freq, there are n_samples lists in list\n",
    "grp_top_set_syms = []  # grp_top_set_syms_n_freq without the frequency count\n",
    "\n",
    "# lb_slices, e.g  [(483, 513, 523), (453, 513, 523), (393, 513, 523)],\n",
    "#  is one max_lookback_slice, e.g. (393, 513, 523), along with\n",
    "#  the remaining slices of the days_lookbacks, e.g. (483, 513, 523), (453, 513, 523)  \n",
    "for i, lb_slices in enumerate(sets_lookback_slices):\n",
    "  print(f'\\n########## {i + 1} of {len(sets_lookback_slices)} lb_slices in sets_lookcak_slices ##########')\n",
    "  # unsorted list of the most frequent symbols in performance metrics of the lb_slices  \n",
    "  grp_most_freq_syms = []\n",
    "  for j, lb_slice in enumerate(lb_slices):  # lb_slice, e.g. (246, 276, 286)\n",
    "    iloc_start_train = lb_slice[0]     # iloc of start of training period\n",
    "    iloc_end_train   = lb_slice[1]     # iloc of end of training period\n",
    "    iloc_start_eval  = iloc_end_train  # iloc of start of evaluation period\n",
    "    iloc_end_eval    = lb_slice[2]     # iloc of end of evaluation period\n",
    "    lookback         = iloc_end_train - iloc_start_train\n",
    "    d_eval           = iloc_end_eval - iloc_start_eval\n",
    "\n",
    "    _df = df.iloc[iloc_start_train:iloc_end_train]\n",
    "    date_start_df_train = _df.index[0].strftime('%Y-%m-%d')\n",
    "    date_end_df_train = _df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    if verbose:\n",
    "      print(f'days lookback:       {lookback},  {j + 1} of {len(days_lookbacks)} days_lookbacks: {days_lookbacks}')\n",
    "      print(f'lb_slices:           {lb_slices}')\n",
    "      print(f'lb_slice:            {lb_slice}')\n",
    "      print(f'days eval:           {d_eval}')    \n",
    "      print(f'iloc_start_train:    {iloc_start_train}')\n",
    "      print(f'iloc_end_train:      {iloc_end_train}')\n",
    "      print(f'date_start_df_train: {date_start_df_train}')\n",
    "      print(f'date_end_df_train:   {date_end_df_train}')\n",
    "\n",
    "\n",
    "    perf_ranks, most_freq_syms = _5_perf_ranks(_df, n_top_syms=n_top_syms)\n",
    "    # unsorted list of the most frequent symbols in performance metrics of the lb_slices  \n",
    "    grp_most_freq_syms.append(most_freq_syms)  \n",
    "    if verbose:    \n",
    "      # 1 lookback of r_CAGR/UI, r_CAGR/retnStd, r_retnStd/UI\n",
    "      print(f'perf_ranks: {perf_ranks}')  \n",
    "      # most common symbols of perf_ranks \n",
    "      print(f'most_freq_syms: {most_freq_syms}')     \n",
    "      # grp_perf_ranks[lookback] = perf_ranks\n",
    "      print(f'+++ finish lookback slice {lookback} +++\\n')\n",
    "\n",
    "  if verbose:\n",
    "    print(f'grp_most_freq_syms: {grp_most_freq_syms}')\n",
    "    # grp_most_freq_syms a is list of lists of tuples of \n",
    "    #  the most-common-symbols symbol:frequency cumulated from\n",
    "    #  each days_lookback  \n",
    "    print(f'**** finish lookback slices {lb_slices} ****\\n')\n",
    "\n",
    "  # flatten list of lists of (symbol:frequency)\n",
    "  flat_grp_most_freq_syms = [val for sublist in grp_most_freq_syms for val in sublist]\n",
    "  # return \"symbol, frequency\" pairs of the most frequent symbols, i.e. best performing symbols,\n",
    "  #  in flat_grp_most_freq_syms. The paris are sorted in descending frequency.   \n",
    "  set_most_freq_syms = _6_grp_tuples_sort_sum(flat_grp_most_freq_syms, reverse=True)\n",
    "  # get the top n_top_syms of the most frequent \"symbol, frequency\" pairs\n",
    "  top_set_syms_n_freq = set_most_freq_syms[0:n_top_syms]\n",
    "  # get symbols from top_set_syms_n_freq, i[0] = symbol, i[1]=symbol's frequency count\n",
    "  top_set_syms = [i[0] for i in top_set_syms_n_freq[syms_start:syms_end]]  \n",
    "\n",
    "  # grp_top_set_syms_n_freq is a list of lists of top_set_syms_n_freq, e.g.\n",
    "  #   [[('AGY', 7), ('PCG', 7), ('KDN', 6), ..., ('CYT', 3)],\n",
    "  #    [('FCN', 9), ('HIG', 9), ('SJR', 8), ..., ('BFH', 2)]]\n",
    "  #   where each list is the best performing symbols from a lb_slices, e.g.\n",
    "  #     [(483, 513, 523), (453, 513, 523), (393, 513, 523)]    \n",
    "  grp_top_set_syms_n_freq.append(top_set_syms_n_freq)\n",
    "  grp_top_set_syms.append(top_set_syms)\n",
    "\n",
    "  if verbose:  \n",
    "    print(f'top {n_top_syms} ranked symbols and frequency from set {lb_slices}:\\n{top_set_syms_n_freq}')\n",
    "    print(f'top {n_top_syms} ranked symbols from set {lb_slices}:\\n{top_set_syms}')  \n",
    "    print(f'===== finish top {n_top_syms} ranked symbols from days_lookback set {lb_slices} =====\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output the best performing symbols for each set in sets_lookback_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_lookback_slices: [(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "max_lookback_slices: [(0, 120, 120)]\n",
      "\n",
      "date_end_df_train:   2023-03-16\n",
      "max_days_lookbacks:  120\n",
      "days_lookbacks:      [15, 30, 60, 120]\n",
      "sym_freq_15:         []\n",
      "sym_freq_14:         []\n",
      "sym_freq_13:         []\n",
      "sym_freq_12:         []\n",
      "sym_freq_11:         []\n",
      "sym_freq_10:         ['FTSM']\n",
      "sym_freq_9:          ['SGEN']\n",
      "sym_freq_8:          ['MLR']\n",
      "sym_freq_7:          ['GE']\n",
      "sym_freq_6:          ['ANET', 'CTLT', 'FCN', 'FSLR', 'HY', 'LNTH', 'NVDA', 'WST']\n",
      "sym_freq_5:          ['ACLS', 'AMPH', 'FIZZ', 'META', 'NTRA', 'OEC', 'SRPT', 'TA']\n",
      "sym_freq_4:          []\n",
      "sym_freq_3:          []\n",
      "sym_freq_2:          []\n",
      "\n",
      "row_picks_total: ['2023-03-16', 120, '[15, 30, 60, 120]', '[]', '[]', '[]', '[]', '[]', \"['FTSM']\", \"['SGEN']\", \"['MLR']\", \"['GE']\", \"['ANET', 'CTLT', 'FCN', 'FSLR', 'HY', 'LNTH', 'NVDA', 'WST']\", \"['ACLS', 'AMPH', 'FIZZ', 'META', 'NTRA', 'OEC', 'SRPT', 'TA']\", '[]', '[]', '[]']\n",
      "appended row_picks_total to df_picks:\n",
      "['2023-03-16', 120, '[15, 30, 60, 120]', '[]', '[]', '[]', '[]', '[]', \"['FTSM']\", \"['SGEN']\", \"['MLR']\", \"['GE']\", \"['ANET', 'CTLT', 'FCN', 'FSLR', 'HY', 'LNTH', 'NVDA', 'WST']\", \"['ACLS', 'AMPH', 'FIZZ', 'META', 'NTRA', 'OEC', 'SRPT', 'TA']\", '[]', '[]', '[]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, top_set_syms_n_freq in enumerate(grp_top_set_syms_n_freq):\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(top_set_syms_n_freq)\n",
    "  if verbose:\n",
    "    print(f'set_lookback_slices: {sets_lookback_slices[i]}')\n",
    "    print(f'max_lookback_slices: {max_lookback_slices}\\n')\n",
    "\n",
    "\n",
    "    # print(f'data below will be added to {fp_df_picks}')\n",
    "\n",
    "\n",
    "    print(f'date_end_df_train:   {date_end_df_train}')    \n",
    "    print(f'max_days_lookbacks:  {max_days_lookbacks}')   \n",
    "    print(f'days_lookbacks:      {days_lookbacks}')\n",
    "    print(f'sym_freq_15:         {l_sym_freq_cnt[0]}')\n",
    "    print(f'sym_freq_14:         {l_sym_freq_cnt[1]}')\n",
    "    print(f'sym_freq_13:         {l_sym_freq_cnt[2]}')\n",
    "    print(f'sym_freq_12:         {l_sym_freq_cnt[3]}')\n",
    "    print(f'sym_freq_11:         {l_sym_freq_cnt[4]}')\n",
    "    print(f'sym_freq_10:         {l_sym_freq_cnt[5]}')\n",
    "    print(f'sym_freq_9:          {l_sym_freq_cnt[6]}')\n",
    "    print(f'sym_freq_8:          {l_sym_freq_cnt[7]}')\n",
    "    print(f'sym_freq_7:          {l_sym_freq_cnt[8]}')\n",
    "    print(f'sym_freq_6:          {l_sym_freq_cnt[9]}')\n",
    "    print(f'sym_freq_5:          {l_sym_freq_cnt[10]}')\n",
    "    print(f'sym_freq_4:          {l_sym_freq_cnt[11]}')\n",
    "    print(f'sym_freq_3:          {l_sym_freq_cnt[12]}')\n",
    "    print(f'sym_freq_2:          {l_sym_freq_cnt[13]}\\n')\n",
    "\n",
    "if run_type == 'current':  # record results to df\n",
    "  row_picks0      = [date_end_df_train, max_days_lookbacks, str(days_lookbacks)]\n",
    "  row_picks1      = [str(l_sym_freq_cnt[0]),  str(l_sym_freq_cnt[1]), str(l_sym_freq_cnt[2]),  str(l_sym_freq_cnt[3])]\n",
    "  row_picks2      = [str(l_sym_freq_cnt[4]),  str(l_sym_freq_cnt[5]), str(l_sym_freq_cnt[6]),  str(l_sym_freq_cnt[7])]\n",
    "  row_picks3      = [str(l_sym_freq_cnt[8]),  str(l_sym_freq_cnt[9]), str(l_sym_freq_cnt[10]), str(l_sym_freq_cnt[11])]\n",
    "  row_picks4      = [str(l_sym_freq_cnt[12]), str(l_sym_freq_cnt[13])]\n",
    "  row_picks_total = row_picks0 + row_picks1 + row_picks2 + row_picks3 + row_picks4\n",
    "  print(f'row_picks_total: {row_picks_total}')\n",
    "\n",
    "  df_picks.loc[len(df_picks)] = row_picks_total\n",
    "  pickle_dump(df_picks, path_data_dump, fp_df_picks)\n",
    "  print(f'appended row_picks_total to df_picks:\\n{row_picks_total}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO make this another notebook \n",
    "# if run_type == 'current':\n",
    "#   _df = pickle_load(path_data_dump, fp_df_picks)\n",
    "\n",
    "# # _df = _df.loc[(_df['days_lookbacks'] == '[30, 60, 120]'), 'sym_freq_8']\n",
    "# _df = _df.loc[(_df['days_lookbacks'] == '[15, 30, 60, 120]'), 'sym_freq_7']\n",
    "# # _df = _df.loc[(_df['days_lookbacks'] == '[30, 60, 120]'), 'sym_freq_9']\n",
    "# _df.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare performance of symbols in set_lookback_slices versus SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_grp_top_set_syms_n_freq:\n",
      "1 of 1 max_lookback_slice: (0, 120, 120)\n",
      "\n",
      "len(idx_train): 120\n",
      "idx_train: DatetimeIndex(['2022-09-23', '2022-09-26', '2022-09-27', '2022-09-28', '2022-09-29', '2022-09-30', '2022-10-03', '2022-10-04', '2022-10-05', '2022-10-06',\n",
      "               ...\n",
      "               '2023-03-03', '2023-03-06', '2023-03-07', '2023-03-08', '2023-03-09', '2023-03-10', '2023-03-13', '2023-03-14', '2023-03-15', '2023-03-16'], dtype='datetime64[ns]', name='Date', length=120, freq=None)\n",
      "df_train_dates (inclusive): 2022-09-23 - 2023-03-16\n",
      "\n",
      "run_type: current, idx_eval is empty: True\n",
      "top_set_syms_n_freq: [('FTSM', 10), ('SGEN', 9), ('MLR', 8), ('GE', 7), ('ANET', 6), ('CTLT', 6), ('FCN', 6), ('FSLR', 6), ('HY', 6), ('LNTH', 6), ('NVDA', 6), ('WST', 6), ('ACLS', 5), ('AMPH', 5), ('FIZZ', 5), ('META', 5), ('NTRA', 5), ('OEC', 5), ('SRPT', 5), ('TA', 5)]\n",
      "\n",
      "set_lookback_slices: [(105, 120, 120), (90, 120, 120), (60, 120, 120), (0, 120, 120)]\n",
      "max_lookback_slice:  (0, 120, 120)\n",
      "days_lookbacks:      [15, 30, 60, 120]\n",
      "date_end_df_train:   2023-03-16\n",
      "sym_freq_15:         []\n",
      "sym_freq_14:         []\n",
      "sym_freq_13:         []\n",
      "sym_freq_12:         []\n",
      "sym_freq_10:         ['FTSM']\n",
      "sym_freq_9:          ['SGEN']\n",
      "sym_freq_8:          ['MLR']\n",
      "sym_freq_7:          ['GE']\n",
      "sym_freq_6:          ['ANET', 'CTLT', 'FCN', 'FSLR', 'HY', 'LNTH', 'NVDA', 'WST']\n",
      "sym_freq_5:          ['ACLS', 'AMPH', 'FIZZ', 'META', 'NTRA', 'OEC', 'SRPT', 'TA']\n",
      "sym_freq_4:          []\n",
      "sym_freq_3:          []\n",
      "sym_freq_2:          []\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "\n\n**** Normal termination for run_type \"current\" ****",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m \n\n**** Normal termination for run_type \"current\" ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ping\\MyDrive\\py_files\\python\\py3810\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from myUtils import symb_perf_stats_vectorized_v8\n",
    "\n",
    "print('z_grp_top_set_syms_n_freq:')\n",
    "# zip max_lookback_slices with top performing symbols:freq pairs\n",
    "z_grp_top_set_syms_n_freq = zip(max_lookback_slices, grp_top_set_syms_n_freq)\n",
    "\n",
    "idx_train = pd.Index([])\n",
    "idx_eval = pd.Index([])\n",
    "for i, (_lookback_slice, _top_set_syms_n_freq) in enumerate(z_grp_top_set_syms_n_freq):\n",
    "  iloc_start_train = _lookback_slice[0]\n",
    "  iloc_end_train = _lookback_slice[1]\n",
    "  iloc_start_eval = iloc_end_train\n",
    "  iloc_end_eval = _lookback_slice[2]\n",
    "\n",
    "  print(f'{i + 1 } of {n_samples} max_lookback_slice: {_lookback_slice}\\n')\n",
    "  # print(f'max_lookback_slice: {_lookback_slice}\\n')\n",
    "  # dates correspond to max_lookback_slice\n",
    "  idx_train = df.index[iloc_start_train:iloc_end_train]\n",
    "  date_start_df_train = idx_train[0].strftime('%Y-%m-%d')\n",
    "  date_end_df_train = idx_train[-1].strftime('%Y-%m-%d')\n",
    "  print(f'len(idx_train): {len(idx_train)}')\n",
    "  print(f'idx_train: {idx_train}')\n",
    "  print(f'df_train_dates (inclusive): {date_start_df_train} - {date_end_df_train}\\n')     \n",
    "\n",
    "  if run_type != 'current':\n",
    "    idx_eval = df.index[iloc_start_eval:iloc_end_eval]\n",
    "    date_start_df_eval = idx_eval[0].strftime('%Y-%m-%d')\n",
    "    date_end_df_eval = idx_eval[-1].strftime('%Y-%m-%d')\n",
    "    print(f'len(idx_eval): {len(idx_eval)}')\n",
    "    print(f'idx_eval: {idx_eval}')\n",
    "    print(f'df_eval dates (inclusive): {date_start_df_eval} - {date_end_df_eval}\\n')\n",
    "  else: # run_type == \"current'\n",
    "    print(f'run_type: {run_type}, idx_eval is empty: {idx_eval.empty}')\n",
    "\n",
    "  print(f'top_set_syms_n_freq: {_top_set_syms_n_freq}\\n')   \n",
    "\n",
    "  l_sym_freq_cnt = top_set_sym_freq_cnt(_top_set_syms_n_freq)\n",
    "  if verbose:\n",
    "    print(f'set_lookback_slices: {sets_lookback_slices[i]}')    \n",
    "    print(f'max_lookback_slice:  {_lookback_slice}')\n",
    "    print(f'days_lookbacks:      {days_lookbacks}')\n",
    "    print(f'date_end_df_train:   {date_end_df_train}')\n",
    "    print(f'sym_freq_15:         {l_sym_freq_cnt[0]}')\n",
    "    print(f'sym_freq_14:         {l_sym_freq_cnt[1]}')\n",
    "    print(f'sym_freq_13:         {l_sym_freq_cnt[2]}')\n",
    "    print(f'sym_freq_12:         {l_sym_freq_cnt[4]}')\n",
    "    print(f'sym_freq_10:         {l_sym_freq_cnt[5]}')\n",
    "    print(f'sym_freq_9:          {l_sym_freq_cnt[6]}')\n",
    "    print(f'sym_freq_8:          {l_sym_freq_cnt[7]}')\n",
    "    print(f'sym_freq_7:          {l_sym_freq_cnt[8]}')\n",
    "    print(f'sym_freq_6:          {l_sym_freq_cnt[9]}')\n",
    "    print(f'sym_freq_5:          {l_sym_freq_cnt[10]}')\n",
    "    print(f'sym_freq_4:          {l_sym_freq_cnt[11]}')\n",
    "    print(f'sym_freq_3:          {l_sym_freq_cnt[12]}')\n",
    "    print(f'sym_freq_2:          {l_sym_freq_cnt[13]}\\n') \n",
    "\n",
    "  if idx_eval.empty:\n",
    "    if run_type == 'current':\n",
    "      msg_stop = f'\\n\\n**** Normal termination for run_type \"{run_type}\" ****'\n",
    "      raise SystemExit(msg_stop)\n",
    "    else:\n",
    "      msg_stop = f'\\n\\n**** STOPPED df_eval is empty but run_type != \"current\", the run_type is \"{run_type}\" ****'\n",
    "      raise SystemExit(msg_stop)    \n",
    "\n",
    "  _sym_idx = ['SPY']\n",
    "  df_SPY = df[iloc_start_eval:iloc_end_eval][_sym_idx]\n",
    "\n",
    "  (\n",
    "    _symbols,\n",
    "    _period_yr,\n",
    "    _retn,\n",
    "    _DD,\n",
    "    _UI,\n",
    "    _MDD,\n",
    "    _retnMean,\n",
    "    _retnStd,\n",
    "    _retnStd_div_UI,\n",
    "    _CAGR,\n",
    "    _CAGR_div_retnStd,\n",
    "    _CAGR_div_UI,\n",
    "    SPY_retnStd_d_UI,     \n",
    "    SPY_CAGR,\n",
    "    SPY_CAGR_d_retnStd,\n",
    "    SPY_CAGR_d_UI,\n",
    "  ) = symb_perf_stats_vectorized_v8(df_SPY)  \n",
    "\n",
    "  print(f'\\nSPY: retnStd/UI, CAGR/retnStd, CAGR/UI, CAGR: {SPY_retnStd_d_UI[0]:>17,.1f}, {SPY_CAGR_d_retnStd[0]:>17,.1f}, {SPY_CAGR_d_UI[0]:>17.1f}, {SPY_CAGR[0]:>17.1f}')\n",
    "\n",
    "  # drop list with frequency count 2 or less, in l_sym_freq_cnt from zip\n",
    "  zip_cnt_n_syms = zip([15,14,13,12,11,10,9,8,7,6,5,4,3], l_sym_freq_cnt[:-1])\n",
    "  for item in zip_cnt_n_syms:\n",
    "    sym_freq_cnt = item[0]\n",
    "    syms = item[1]\n",
    "    if syms:  # iterate ONLY if there are symbols in syms\n",
    "      df_eval = df[iloc_start_eval:iloc_end_eval][syms]      \n",
    "\n",
    "      if verbose:\n",
    "        print(f'iloc_start_eval: {iloc_start_eval:>6},  df_eval first date: {date_start_df_eval:>10}') \n",
    "        print(f'iloc_end_eval:   {iloc_end_eval:>6},  df_eval last date:  {date_end_df_eval:>10}')        \n",
    "        print(f'frequency count of symbol(s): {sym_freq_cnt}')      \n",
    "\n",
    "        syms_n_SPY = syms + ['SPY']\n",
    "        df_eval_n_SPY = df[iloc_start_eval:iloc_end_eval][syms_n_SPY]   \n",
    "        print(f'\\ndf_eval_n_SPY:\\n{df_eval_n_SPY}\\n')\n",
    "\n",
    "      (\n",
    "        _symbols,\n",
    "        _period_yr,\n",
    "        _retn,\n",
    "        _DD,\n",
    "        _UI,\n",
    "        _MDD,\n",
    "        _retnMean,\n",
    "        _retnStd,\n",
    "        _retnStd_div_UI,\n",
    "        _CAGR,\n",
    "        _CAGR_div_retnStd,\n",
    "        _CAGR_div_UI,\n",
    "        grp_retnStd_d_UI,     \n",
    "        grp_CAGR,\n",
    "        grp_CAGR_d_retnStd,\n",
    "        grp_CAGR_d_UI,\n",
    "      ) = symb_perf_stats_vectorized_v8(df_eval)  \n",
    "      print(f'grp(retnStd/UI):   mean, std, mean/std: {grp_retnStd_d_UI[0]  :>17,.1f}, {grp_retnStd_d_UI[1]  :>17,.1f}, {grp_retnStd_d_UI[2]  :>17,.1f}')\n",
    "      print(f'grp(CAGR/retnStd): mean, std, mean/std: {grp_CAGR_d_retnStd[0]:>17,.1f}, {grp_CAGR_d_retnStd[1]:>17,.1f}, {grp_CAGR_d_retnStd[2]:>17,.1f}')\n",
    "      print(f'grp(CAGR/UI):      mean, std, mean/std: {grp_CAGR_d_UI[0]     :>17,.1f}, {grp_CAGR_d_UI[1]     :>17,.1f}, {grp_CAGR_d_UI[2]     :>17,.1f}')\n",
    "      print(f'grp(CAGR):         mean, std, mean/std: {grp_CAGR[0]          :>17,.1f}, {grp_CAGR[1]          :>17,.1f}, {grp_CAGR[2]          :>17,.1f}\\n')\n",
    "\n",
    "      if store_results:  # record results to df\n",
    "        row_add0      = [n_samples, str(days_lookbacks), days_eval, n_top_syms, syms_start, syms_end, sym_freq_cnt]\n",
    "        row_add1      = [grp_CAGR[0],           grp_CAGR[1],           grp_CAGR[2]]\n",
    "        row_add2      = [grp_CAGR_d_UI[0],      grp_CAGR_d_UI[1],      grp_CAGR_d_UI[2]]\n",
    "        row_add3      = [grp_CAGR_d_retnStd[0], grp_CAGR_d_retnStd[1], grp_CAGR_d_retnStd[2]]\n",
    "        row_add4      = [grp_retnStd_d_UI[0],   grp_retnStd_d_UI[1],   grp_retnStd_d_UI[2]]\n",
    "        row_add5      = [SPY_CAGR[0], SPY_CAGR_d_UI[0], SPY_CAGR_d_retnStd[0], SPY_retnStd_d_UI[0]]\n",
    "        row_add_total = row_add0 + row_add1 + row_add2 + row_add3 + row_add4 + row_add5\n",
    "        print(f'row_add_total: {row_add_total}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df_eval_results.loc[len(df_eval_results)] = row_add_total\n",
    "        print(f'appended row_add to df_eval_results:\\n{row_add_total}\\n')\n",
    "\n",
    "\n",
    "\n",
    "        # if run_type == 'train':\n",
    "        #   df_eval_sym_freq_results_train.loc[len(df_eval_sym_freq_results_train)] = row_add_total\n",
    "        #   print(f'appended row_add to df_eval_sym_freq_results_train:\\n{row_add_total}\\n')\n",
    "        # elif run_type == 'validate':\n",
    "        #   df_eval_sym_freq_results_validate.loc[len(df_eval_sym_freq_results_validate)] = row_add_total       \n",
    "        #   print(f'appended row_add to df_eval_sym_freq_results_validate:\\n{row_add_total}\\n')\n",
    "        # elif run_type == 'test':\n",
    "        #   df_eval_sym_freq_results_test.loc[len(df_eval_sym_freq_results_test)] = row_add_total       \n",
    "        #   print(f'appended row_add to df_eval_sym_freq_results_test:\\n{row_add_total}\\n')\n",
    "        # else:\n",
    "        #   msg_stop = f\"ERROR run_type must be 'train', 'validate', or 'test', run_type is: {run_type}\"\n",
    "        #   raise SystemExit(msg_stop )                             \n",
    "  \n",
    "  print('='*50, '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump(df_eval_results, path_data_dump, fp_df_eval_results)\n",
    "df = pickle_load(path_data_dump, fp_df_eval_results)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle_load(path_data_dump, fp_df_picks)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if store_results:  # record results to df\n",
    "#   if run_type == 'train':\n",
    "#     pickle_dump(df_eval_sym_freq_results_train, path_data_dump, fp_df_eval_sym_freq_results_train)\n",
    "#     print(f'Save results to: {fp_df_eval_sym_freq_results_train}')\n",
    "#   elif run_type == 'validate':\n",
    "#     pickle_dump(df_eval_sym_freq_results_validate, path_data_dump, fp_df_eval_sym_freq_results_validate)   \n",
    "#     print(f'Save results to: {fp_df_eval_sym_freq_results_validate}')\n",
    "#   elif run_type == 'test':\n",
    "#     pickle_dump(df_eval_sym_freq_results_test, path_data_dump, fp_df_eval_sym_freq_results_test)   \n",
    "#     print(f'Save results to: {fp_df_eval_sym_freq_results_test}')\n",
    "#   else:\n",
    "#     msg_stop = f\"ERROR: Result was not saved. run_type must be 'train', 'validate', or 'test', run_type is: {run_type}\"\n",
    "#     raise SystemExit(msg_stop )  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16adeade2e4c2fe5a5c8fae29fa6e6b24d9301998b78edb3420e7dd402ae68a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
